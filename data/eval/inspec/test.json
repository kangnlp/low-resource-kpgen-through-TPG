{"id": 0, "title": {"text": "twenty years of the literature on acquiring out of print materials .", "tokenized": "twenty years of the literature on acquiring out of print materials ."}, "abstract": {"text": "out of print materials to assess recurring issues and identify changing practices . the out of print literature is uniform in its assertion that libraries need to acquire o . p . materials to replace worn or damaged copies , to replace missing copies , to duplicate copies of heavily used materials , to fill gaps in collections , to strengthen weak collections , to continue to develop strong collections , and to provide materials for new courses , new programs , and even entire new libraries", "tokenized": "out of print materials to assess recurring issues and identify changing practices . the out of print literature is uniform in its assertion that libraries need to acquire o . p . materials to replace worn or damaged copies , to replace missing copies , to duplicate copies of heavily used materials , to fill gaps in collections , to strengthen weak collections , to continue to develop strong collections , and to provide materials for new courses , new programs , and even entire new libraries"}, "present_kps": {"text": ["out of print materials", "recurring issues", "changing practices"], "tokenized": ["out of print materials", "recurring issues", "changing practices"]}, "absent_kps": {"text": ["library materials", "out of print books", "acquisition"], "tokenized": ["library materials", "out of print books", "acquisition"]}}
{"id": 1, "title": {"text": "a new method of systemological analysis coordinated with the procedure of .", "tokenized": "a new method of systemological analysis coordinated with the procedure of ."}, "abstract": {"text": "for pt . i . see vestn . khgpu , no . [digit] , p . [digit] [digit] ( [digit] ) . the paper presents the results of development of an object oriented systemological method used to design complex systems . a formal system representation , as well as an axiomatics of the calculus of systems as functional flow type objects based on a node function object class hierarchy are proposed . a formalized nfo ufo analysis algorithm and case tools used to support it are considered", "tokenized": "for pt . i . see vestn . khgpu , no . [digit] , p . [digit] [digit] ( [digit] ) . the paper presents the results of development of an object oriented systemological method used to design complex systems . a formal system representation , as well as an axiomatics of the calculus of systems as functional flow type objects based on a node function object class hierarchy are proposed . a formalized nfo ufo analysis algorithm and case tools used to support it are considered"}, "present_kps": {"text": ["systemological analysis", "formal system representation", "axiomatics", "functional flow type objects", "formalized nfo ufo analysis algorithm", "case tools"], "tokenized": ["systemological analysis", "formal system representation", "axiomatics", "functional flow type objects", "formalized nfo ufo analysis algorithm", "case tools"]}, "absent_kps": {"text": ["object oriented design", "complex systems design"], "tokenized": ["object oriented design", "complex systems design"]}}
{"id": 2, "title": {"text": "mathematical fundamentals of constructing fuzzy bayesian inference techniques .", "tokenized": "mathematical fundamentals of constructing fuzzy bayesian inference techniques ."}, "abstract": {"text": "decision making in the case of fuzzy data are presented . the concept of fuzzy and pseudofuzzy quantities is introduced and main operations with pseudofuzzy quantities are considered . the basic relationships and the principal concepts of the bayesian decision procedure based on the modus ponens rule are proposed . some problems concerned with the practical realization of the fuzzy bayesian method are considered", "tokenized": "decision making in the case of fuzzy data are presented . the concept of fuzzy and pseudofuzzy quantities is introduced and main operations with pseudofuzzy quantities are considered . the basic relationships and the principal concepts of the bayesian decision procedure based on the modus ponens rule are proposed . some problems concerned with the practical realization of the fuzzy bayesian method are considered"}, "present_kps": {"text": ["mathematical fundamentals", "fuzzy bayesian inference techniques", "decision making", "pseudofuzzy quantities", "modus ponens rule"], "tokenized": ["mathematical fundamentals", "fuzzy bayesian inference techniques", "decision making", "pseudofuzzy quantities", "modus ponens rule"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 3, "title": {"text": "solution of the safe problem on ( [digit] , [digit] ) matrices .", "tokenized": "solution of the safe problem on ( [digit] , [digit] ) matrices ."}, "abstract": {"text": "equations in the modulo [digit] residue class . there are three possible variants defined by the numbers m and n evenness , with only one of them having a solution . in two other cases , correction of the initial state of the safe insuring a solution is proposed", "tokenized": "equations in the modulo [digit] residue class . there are three possible variants defined by the numbers m and n evenness , with only one of them having a solution . in two other cases , correction of the initial state of the safe insuring a solution is proposed"}, "present_kps": {"text": ["safe problem", "( [digit]", "[digit] ) matrices", "modulo [digit] residue class"], "tokenized": ["safe problem", "( [digit]", "[digit] ) matrices", "modulo [digit] residue class"]}, "absent_kps": {"text": ["linear diophantine equations", "mn locks", "linear equations", "computer games"], "tokenized": ["linear diophantine equations", "mn locks", "linear equations", "computer games"]}}
{"id": 4, "title": {"text": "accelerated simulation of the steady state availability of non markovian .", "tokenized": "accelerated simulation of the steady state availability of non markovian ."}, "abstract": {"text": "a general accelerated simulation method for evaluation of the steady state availability of non markovian systems is proposed . it is applied to the investigation of a class of systems with repair . numerical examples are given", "tokenized": "a general accelerated simulation method for evaluation of the steady state availability of non markovian systems is proposed . it is applied to the investigation of a class of systems with repair . numerical examples are given"}, "present_kps": {"text": ["accelerated simulation", "steady state availability", "general accelerated simulation method", "non markovian systems", "numerical examples"], "tokenized": ["accelerated simulation", "steady state availability", "general accelerated simulation method", "non markovian systems", "numerical examples"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 5, "title": {"text": "computational finite element schemes for optimal control of an elliptic system .", "tokenized": "computational finite element schemes for optimal control of an elliptic system ."}, "abstract": {"text": "new optimal control problems are considered for distributed systems described by elliptic equations with conjugate conditions and a quadratic minimized function . highly accurate computational discretization schemes are constructed for the case where a feasible control set u sub delta coincides with the full hilbert space u of controls", "tokenized": "new optimal control problems are considered for distributed systems described by elliptic equations with conjugate conditions and a quadratic minimized function . highly accurate computational discretization schemes are constructed for the case where a feasible control set u sub delta coincides with the full hilbert space u of controls"}, "present_kps": {"text": ["optimal control problems", "distributed systems", "elliptic equations", "conjugate conditions", "quadratic minimized function", "computational discretization schemes"], "tokenized": ["optimal control problems", "distributed systems", "elliptic equations", "conjugate conditions", "quadratic minimized function", "computational discretization schemes"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 6, "title": {"text": "identification of states of complex systems with estimation of admissible .", "tokenized": "identification of states of complex systems with estimation of admissible ."}, "abstract": {"text": "the problem of identification of states of complex systems on the basis of fuzzy values of informative attributes is considered . some estimates of a maximally admissible degree of measurement error are obtained that make it possible , using the apparatus of fuzzy set theory , to correctly identify the current state of a system", "tokenized": "the problem of identification of states of complex systems on the basis of fuzzy values of informative attributes is considered . some estimates of a maximally admissible degree of measurement error are obtained that make it possible , using the apparatus of fuzzy set theory , to correctly identify the current state of a system"}, "present_kps": {"text": ["informative attributes", "measurement error", "fuzzy set theory"], "tokenized": ["informative attributes", "measurement error", "fuzzy set theory"]}, "absent_kps": {"text": ["complex systems states identification", "fuzzy information", "admissible measurement errors"], "tokenized": ["complex systems states identification", "fuzzy information", "admissible measurement errors"]}}
{"id": 7, "title": {"text": "a new approach to the decomposition of boolean functions by the method of .", "tokenized": "a new approach to the decomposition of boolean functions by the method of ."}, "abstract": {"text": "for pt . i . see upr . sist . mash . , no . [digit] , p . [digit] [digit] ( [digit] ) . a new approach to the decomposition of boolean , functions that depend on n variables and are represented in various forms is considered . the approach is based on the method of q partitioning of minterms and on the introduced concept of a decomposition clone . the theorem on simple disjunctive decomposition of full and partial functions is formulated . the approach proposed is illustrated by examples", "tokenized": "for pt . i . see upr . sist . mash . , no . [digit] , p . [digit] [digit] ( [digit] ) . a new approach to the decomposition of boolean , functions that depend on n variables and are represented in various forms is considered . the approach is based on the method of q partitioning of minterms and on the introduced concept of a decomposition clone . the theorem on simple disjunctive decomposition of full and partial functions is formulated . the approach proposed is illustrated by examples"}, "present_kps": {"text": ["q partitions", "minterms", "decomposition clone", "disjunctive decomposition", "partial functions"], "tokenized": ["q partitions", "minterms", "decomposition clone", "disjunctive decomposition", "partial functions"]}, "absent_kps": {"text": ["logic synthesis", "boolean functions decomposition"], "tokenized": ["logic synthesis", "boolean functions decomposition"]}}
{"id": 8, "title": {"text": "nonlinear extrapolation algorithm for realization of a scalar random process .", "tokenized": "nonlinear extrapolation algorithm for realization of a scalar random process ."}, "abstract": {"text": "this method makes it possible to take into account any nonlinear random dependences that exist in an investigated process and are described by mixed central moment functions . the method is based on the v . s . pugachev canonical decomposition apparatus . as an example , the problem of nonlinear extrapolation is solved for a moment function of third order", "tokenized": "this method makes it possible to take into account any nonlinear random dependences that exist in an investigated process and are described by mixed central moment functions . the method is based on the v . s . pugachev canonical decomposition apparatus . as an example , the problem of nonlinear extrapolation is solved for a moment function of third order"}, "present_kps": {"text": ["nonlinear extrapolation algorithm", "scalar random process", "nonlinear random dependences", "mixed central moment functions", "moment function", "canonical decomposition apparatus"], "tokenized": ["nonlinear extrapolation algorithm", "scalar random process", "nonlinear random dependences", "mixed central moment functions", "moment function", "canonical decomposition apparatus"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 9, "title": {"text": "a method for solution of systems of linear algebraic equations with .", "tokenized": "a method for solution of systems of linear algebraic equations with ."}, "abstract": {"text": "a system of linear algebraic equations with m dimensional lambda matrices is considered . the proposed method of searching for the solution of this system lies in reducing it to a numerical system of a special kind", "tokenized": "a system of linear algebraic equations with m dimensional lambda matrices is considered . the proposed method of searching for the solution of this system lies in reducing it to a numerical system of a special kind"}, "present_kps": {"text": ["linear algebraic equations", "m dimensional lambda matrices", "numerical system"], "tokenized": ["linear algebraic equations", "m dimensional lambda matrices", "numerical system"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 10, "title": {"text": "compatibility of systems of linear constraints over the set of natural numbers .", "tokenized": "compatibility of systems of linear constraints over the set of natural numbers ."}, "abstract": {"text": "inequations , and nonstrict inequations are considered . upper bounds for components of a minimal set of solutions and algorithms of construction of minimal generating sets of solutions for all types of systems are given . these criteria and the corresponding algorithms for constructing a minimal supporting set of solutions can be used in solving all the considered types of systems and systems of mixed types", "tokenized": "inequations , and nonstrict inequations are considered . upper bounds for components of a minimal set of solutions and algorithms of construction of minimal generating sets of solutions for all types of systems are given . these criteria and the corresponding algorithms for constructing a minimal supporting set of solutions can be used in solving all the considered types of systems and systems of mixed types"}, "present_kps": {"text": ["linear constraints", "set of natural numbers", "nonstrict inequations", "upper bounds", "minimal generating sets"], "tokenized": ["linear constraints", "set of natural numbers", "nonstrict inequations", "upper bounds", "minimal generating sets"]}, "absent_kps": {"text": ["linear diophantine equations", "strict inequations"], "tokenized": ["linear diophantine equations", "strict inequations"]}}
{"id": 11, "title": {"text": "books on demand just in time acquisitions .", "tokenized": "books on demand just in time acquisitions ."}, "abstract": {"text": "to purchase patrons ' loan requests from amazon . com , lend them to the patrons , and then add the titles to the collection . staff analyzed previous monograph loans , developed ordering criteria , implemented the proposal as a pilot project for six months , and evaluated the resulting patron comments , statistics , and staff perceptions . as a result of enthusiastic patron comments and a review of the project statistics , the program was extended", "tokenized": "to purchase patrons ' loan requests from amazon . com , lend them to the patrons , and then add the titles to the collection . staff analyzed previous monograph loans , developed ordering criteria , implemented the proposal as a pilot project for six months , and evaluated the resulting patron comments , statistics , and staff perceptions . as a result of enthusiastic patron comments and a review of the project statistics , the program was extended"}, "present_kps": {"text": ["monograph loans", "ordering criteria", "patron comments", "staff perceptions"], "tokenized": ["monograph loans", "ordering criteria", "patron comments", "staff perceptions"]}, "absent_kps": {"text": ["purdue university libraries interlibrary loan unit", "publication on demand"], "tokenized": ["purdue university libraries interlibrary loan unit", "publication on demand"]}}
{"id": 12, "title": {"text": "new lower bounds of the size of error correcting codes for the z channel .", "tokenized": "new lower bounds of the size of error correcting codes for the z channel ."}, "abstract": {"text": "the size of error correcting codes for the z channel", "tokenized": "the size of error correcting codes for the z channel"}, "present_kps": {"text": ["lower bounds", "error correcting codes", "z channel"], "tokenized": ["lower bounds", "error correcting codes", "z channel"]}, "absent_kps": {"text": ["optimization problems", "graphs"], "tokenized": ["optimization problems", "graphs"]}}
{"id": 13, "title": {"text": "descriptological foundations of programming .", "tokenized": "descriptological foundations of programming ."}, "abstract": {"text": "the concept of a descriptive process is given . the operations of introduction and elimination of abstraction at the level of processes are refined . an intensional concept of a bipolar function is introduced . an explication of the concept of introduction and extraction of abstraction at the bipole level is given . on this basis , a complete set of descriptological operations is constructed", "tokenized": "the concept of a descriptive process is given . the operations of introduction and elimination of abstraction at the level of processes are refined . an intensional concept of a bipolar function is introduced . an explication of the concept of introduction and extraction of abstraction at the bipole level is given . on this basis , a complete set of descriptological operations is constructed"}, "present_kps": {"text": ["descriptological foundations", "programming", "descriptive process", "intensional concept", "bipolar function", "bipole level"], "tokenized": ["descriptological foundations", "programming", "descriptive process", "intensional concept", "bipolar function", "bipole level"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 14, "title": {"text": "precoded ofdm with adaptive vector channel allocation for scalable video .", "tokenized": "precoded ofdm with adaptive vector channel allocation for scalable video ."}, "abstract": {"text": "orthogonal frequency division multiplexing ( ofdm ) has been applied in broadband wireline and wireless systems for high data rate transmission where severe intersymbol interference ( isi ) always occurs . the conventional ofdm system provides advantages through conversion of an isi channel into isi free subchannels at multiple frequency bands . however , it may suffer from channel spectral nulls and heavy data rate overhead due to cyclic prefix insertion . previously , a new ofdm framework , the precoded ofdm , has been proposed to mitigate the above two problems through precoding and conversion of an isi channel into isi free vector channels . in this paper , we consider the application of the precoded ofdm system to efficient scalable video transmission . we propose to enhance the precoded ofdm system with adaptive vector channel allocation to provide stronger protection against errors to more important layers in the layered bit stream structure of scalable video . the more critical layers , or equivalently , the lower layers , are allocated vector channels of higher transmission quality . the channel quality is characterized by frobenius norm metrics based on channel estimation at the receiver . the channel allocation information is fed back periodically to the transmitter through a control channel . simulation results have demonstrated the robustness of the proposed scheme to noise and fading inherent in wireless channels", "tokenized": "orthogonal frequency division multiplexing ( ofdm ) has been applied in broadband wireline and wireless systems for high data rate transmission where severe intersymbol interference ( isi ) always occurs . the conventional ofdm system provides advantages through conversion of an isi channel into isi free subchannels at multiple frequency bands . however , it may suffer from channel spectral nulls and heavy data rate overhead due to cyclic prefix insertion . previously , a new ofdm framework , the precoded ofdm , has been proposed to mitigate the above two problems through precoding and conversion of an isi channel into isi free vector channels . in this paper , we consider the application of the precoded ofdm system to efficient scalable video transmission . we propose to enhance the precoded ofdm system with adaptive vector channel allocation to provide stronger protection against errors to more important layers in the layered bit stream structure of scalable video . the more critical layers , or equivalently , the lower layers , are allocated vector channels of higher transmission quality . the channel quality is characterized by frobenius norm metrics based on channel estimation at the receiver . the channel allocation information is fed back periodically to the transmitter through a control channel . simulation results have demonstrated the robustness of the proposed scheme to noise and fading inherent in wireless channels"}, "present_kps": {"text": ["precoded ofdm", "adaptive vector channel allocation", "orthogonal frequency division multiplexing", "isi channel", "channel spectral nulls", "heavy data rate overhead", "isi free vector channels", "scalable video transmission", "layered bit stream structure", "critical layers", "lower layers", "channel quality", "frobenius norm metrics", "channel estimation", "channel allocation information", "control channel", "robustness"], "tokenized": ["precoded ofdm", "adaptive vector channel allocation", "orthogonal frequency division multiplexing", "isi channel", "channel spectral nulls", "heavy data rate overhead", "isi free vector channels", "scalable video transmission", "layered bit stream structure", "critical layers", "lower layers", "channel quality", "frobenius norm metrics", "channel estimation", "channel allocation information", "control channel", "robustness"]}, "absent_kps": {"text": ["frequency selective fading channels"], "tokenized": ["frequency selective fading channels"]}}
{"id": 15, "title": {"text": "i wap an intelligent wap site management system .", "tokenized": "i wap an intelligent wap site management system ."}, "abstract": {"text": "sites have been developed with wireless markup language ( wml ) . meanwhile , to translate hypertext markup language ( html ) pages into proper wml ones becomes imperative since it is difficult for wap users to read most contents designed for pc users via their mobile phone screens . however , for those sites that have been maintained with hypertext markup language ( html ) , considerable time and manpower costs will be incurred to rebuild them with wml . in this paper , we propose an intelligent wap site management system to cope with these problems . with the help of the intelligent management system , the original contents of html web sites can be automatically translated to proper wap content in an efficient way . as a consequence , the costs associated with maintaining wap sites could be significantly reduced . the management system also allows the system manager to define the relevance of numerals and keywords for removing unimportant or meaningless contents . the original contents will be reduced and reorganized to fit the size of mobile phone screens , thus reducing the communication cost and enhancing readability . numerical results gained through various experiments have evinced the effective performance of the wap management system", "tokenized": "sites have been developed with wireless markup language ( wml ) . meanwhile , to translate hypertext markup language ( html ) pages into proper wml ones becomes imperative since it is difficult for wap users to read most contents designed for pc users via their mobile phone screens . however , for those sites that have been maintained with hypertext markup language ( html ) , considerable time and manpower costs will be incurred to rebuild them with wml . in this paper , we propose an intelligent wap site management system to cope with these problems . with the help of the intelligent management system , the original contents of html web sites can be automatically translated to proper wap content in an efficient way . as a consequence , the costs associated with maintaining wap sites could be significantly reduced . the management system also allows the system manager to define the relevance of numerals and keywords for removing unimportant or meaningless contents . the original contents will be reduced and reorganized to fit the size of mobile phone screens , thus reducing the communication cost and enhancing readability . numerical results gained through various experiments have evinced the effective performance of the wap management system"}, "present_kps": {"text": ["i wap", "intelligent wap site management system", "wireless markup language", "hypertext markup language", "mobile phone", "communication cost", "readability"], "tokenized": ["i wap", "intelligent wap site management system", "wireless markup language", "hypertext markup language", "mobile phone", "communication cost", "readability"]}, "absent_kps": {"text": ["wireless mobile internet", "wireless communication", "html pages"], "tokenized": ["wireless mobile internet", "wireless communication", "html pages"]}}
{"id": 16, "title": {"text": "a framework of electronic tendering for government procurement a lesson .", "tokenized": "a framework of electronic tendering for government procurement a lesson ."}, "abstract": {"text": "to render government procurement efficient , transparent , nondiscriminating , and accountable , an electronic government procurement system is required . accordingly , taiwan government procurement law ( tgpl ) states that suppliers may employ electronic devices to forward a tender . this investigation demonstrates how the electronic government procurement system functions and reengineers internal procurement processes , which in turn benefits both government bodies and vendors . the system features explored herein include posting receiving bids via the internet , vendor registration , certificate authorization , contract development tools , bid request for proposal ( rfp ) development , online bidding , and online payment , all of which can be integrated easily within most existing information infrastructures", "tokenized": "to render government procurement efficient , transparent , nondiscriminating , and accountable , an electronic government procurement system is required . accordingly , taiwan government procurement law ( tgpl ) states that suppliers may employ electronic devices to forward a tender . this investigation demonstrates how the electronic government procurement system functions and reengineers internal procurement processes , which in turn benefits both government bodies and vendors . the system features explored herein include posting receiving bids via the internet , vendor registration , certificate authorization , contract development tools , bid request for proposal ( rfp ) development , online bidding , and online payment , all of which can be integrated easily within most existing information infrastructures"}, "present_kps": {"text": ["electronic tendering", "electronic government procurement system", "taiwan government procurement law", "reengineering", "internal procurement processes", "vendor registration", "certificate authorization", "certification authority", "contract development tools", "online bidding", "online payment"], "tokenized": ["electronic tendering", "electronic government procurement system", "taiwan government procurement law", "reengineering", "internal procurement processes", "vendor registration", "certificate authorization", "certification authority", "contract development tools", "online bidding", "online payment"]}, "absent_kps": {"text": ["rfp development", "internet bids", "request for proposal development", "public key infrastructure", "payment gateway"], "tokenized": ["rfp development", "internet bids", "request for proposal development", "public key infrastructure", "payment gateway"]}}
{"id": 17, "title": {"text": "the development of a mobile manipulator imaging system for bridge crack .", "tokenized": "the development of a mobile manipulator imaging system for bridge crack ."}, "abstract": {"text": "a mobile manipulator imaging system is developed for the automation of bridge crack inspection . during bridge safety inspections , an eyesight inspection is made for preliminary evaluation and screening before a more precise inspection . the inspection for cracks is an important part of the preliminary evaluation . currently , the inspectors must stand on the platform of a bridge inspection vehicle or a temporarily erected scaffolding to examine the underside of a bridge . however , such a procedure is risky . to help automate the bridge crack inspection process , we installed two ccd cameras and a four axis manipulator system on a mobile vehicle . the parallel cameras are used to detect cracks . the manipulator system is equipped with binocular charge coupled devices ( ccd ) for examining structures that may not be accessible to the eye . the system also reduces the danger of accidents to the human inspectors . the manipulator system consists of four arms . balance weights are placed at the ends of arms [digit] and [digit] , respectively , to maintain the center of gravity during operation . mechanically , arms [digit] and [digit] can revolve smoothly . experiments indicated that the system could be useful for bridge crack inspections", "tokenized": "a mobile manipulator imaging system is developed for the automation of bridge crack inspection . during bridge safety inspections , an eyesight inspection is made for preliminary evaluation and screening before a more precise inspection . the inspection for cracks is an important part of the preliminary evaluation . currently , the inspectors must stand on the platform of a bridge inspection vehicle or a temporarily erected scaffolding to examine the underside of a bridge . however , such a procedure is risky . to help automate the bridge crack inspection process , we installed two ccd cameras and a four axis manipulator system on a mobile vehicle . the parallel cameras are used to detect cracks . the manipulator system is equipped with binocular charge coupled devices ( ccd ) for examining structures that may not be accessible to the eye . the system also reduces the danger of accidents to the human inspectors . the manipulator system consists of four arms . balance weights are placed at the ends of arms [digit] and [digit] , respectively , to maintain the center of gravity during operation . mechanically , arms [digit] and [digit] can revolve smoothly . experiments indicated that the system could be useful for bridge crack inspections"}, "present_kps": {"text": ["mobile manipulator", "imaging system", "automation", "bridge crack inspection", "eyesight inspection", "ccd cameras", "four axis manipulator", "parallel cameras", "charge coupled devices"], "tokenized": ["mobile manipulator", "imaging system", "automation", "bridge crack inspection", "eyesight inspection", "ccd cameras", "four axis manipulator", "parallel cameras", "charge coupled devices"]}, "absent_kps": {"text": ["binocular ccd"], "tokenized": ["binocular ccd"]}}
{"id": 18, "title": {"text": "integrating building management system and facilities management on the .", "tokenized": "integrating building management system and facilities management on the ."}, "abstract": {"text": "recently , it is of great interest to adopt the internet intranet to develop building management systems ( bms ) and facilities management systems ( fms ) . this paper addresses two technical issues the web based access ( including database integration ) and the integration of bms and fms . these should be addressed for accessing bms remotely via the internet , integrating control networks using the internet protocols and infrastructures , and using internet intranet for building facilities management . an experimental internet enabled system that integrates building and facilities management systems has been developed and tested . this system integrated open control networks with the internet and is developed utilizing the embedded web server , the pc web server and the distributed component object model ( dcom ) software development technology on the platform of an open control network . three strategies for interconnecting bms local networks via internet intranet are presented and analyzed", "tokenized": "recently , it is of great interest to adopt the internet intranet to develop building management systems ( bms ) and facilities management systems ( fms ) . this paper addresses two technical issues the web based access ( including database integration ) and the integration of bms and fms . these should be addressed for accessing bms remotely via the internet , integrating control networks using the internet protocols and infrastructures , and using internet intranet for building facilities management . an experimental internet enabled system that integrates building and facilities management systems has been developed and tested . this system integrated open control networks with the internet and is developed utilizing the embedded web server , the pc web server and the distributed component object model ( dcom ) software development technology on the platform of an open control network . three strategies for interconnecting bms local networks via internet intranet are presented and analyzed"}, "present_kps": {"text": ["building management systems", "intranet", "bms", "facilities management systems", "fms", "web based access", "database integration", "internet protocols", "open control network", "embedded web server", "pc web server", "distributed component object model", "dcom", "software development technology"], "tokenized": ["building management systems", "intranet", "bms", "facilities management systems", "fms", "web based access", "database integration", "internet protocols", "open control network", "embedded web server", "pc web server", "distributed component object model", "dcom", "software development technology"]}, "absent_kps": {"text": ["local network interconnection"], "tokenized": ["local network interconnection"]}}
{"id": 19, "title": {"text": "modelling user acceptance of building management systems .", "tokenized": "modelling user acceptance of building management systems ."}, "abstract": {"text": "a questionnaire survey . these systems are crucial for optimising building performance and yet it has been widely reported that users are not making full use of their systems ' facilities . established models of technology acceptance have been employed in this research , and the positive influence of user perceptions of ease of use and compatibility has been demonstrated . previous research has indicated differing levels of importance of perceived ease of use relative to other factors . here , perceived ease of use is shown generally to be more important , though the balance between this and compatibility is moderated by the user perceptions of voluntariness", "tokenized": "a questionnaire survey . these systems are crucial for optimising building performance and yet it has been widely reported that users are not making full use of their systems ' facilities . established models of technology acceptance have been employed in this research , and the positive influence of user perceptions of ease of use and compatibility has been demonstrated . previous research has indicated differing levels of importance of perceived ease of use relative to other factors . here , perceived ease of use is shown generally to be more important , though the balance between this and compatibility is moderated by the user perceptions of voluntariness"}, "present_kps": {"text": ["building management systems", "questionnaire survey", "user perceptions", "ease of use", "compatibility", "voluntariness"], "tokenized": ["building management systems", "questionnaire survey", "user perceptions", "ease of use", "compatibility", "voluntariness"]}, "absent_kps": {"text": ["information systems", "user acceptance modelling", "innovation characteristics", "technology acceptance model"], "tokenized": ["information systems", "user acceptance modelling", "innovation characteristics", "technology acceptance model"]}}
{"id": 20, "title": {"text": "estimating populations for collective dose calculations .", "tokenized": "estimating populations for collective dose calculations ."}, "abstract": {"text": "on the public based on an estimate of the population in the area . geographic information system software , electronic population data resources , and a personal computer were used to develop estimates of population within [digit] km radii of two sites", "tokenized": "on the public based on an estimate of the population in the area . geographic information system software , electronic population data resources , and a personal computer were used to develop estimates of population within [digit] km radii of two sites"}, "present_kps": {"text": ["collective dose calculations", "public", "geographic information system software", "electronic population data resources", "personal computer"], "tokenized": ["collective dose calculations", "public", "geographic information system software", "electronic population data resources", "personal computer"]}, "absent_kps": {"text": ["facility operations"], "tokenized": ["facility operations"]}}
{"id": 21, "title": {"text": "a new graphical user interface for fast construction of computation phantoms .", "tokenized": "a new graphical user interface for fast construction of computation phantoms ."}, "abstract": {"text": "measurement systems reports on a new utility for development of computational phantoms for monte carlo calculations and data analysis for in vivo measurements of radionuclides deposited in tissues . the individual properties of each worker can be acquired for a rather precise geometric representation of his ( her ) anatomy , which is particularly important for low energy gamma ray emitting sources such as thorium , uranium , plutonium and other actinides . the software enables automatic creation of an mcnp input data file based on scanning data . the utility includes segmentation of images obtained with either computed tomography or magnetic resonance imaging by distinguishing tissues according to their signal ( brightness ) and specification of the source and detector . in addition , a coupling of individual voxels within the tissue is used to reduce the memory demand and to increase the calculational speed . the utility was tested for low energy emitters in plastic and biological tissues as well as for computed tomography and magnetic resonance imaging scanning information", "tokenized": "measurement systems reports on a new utility for development of computational phantoms for monte carlo calculations and data analysis for in vivo measurements of radionuclides deposited in tissues . the individual properties of each worker can be acquired for a rather precise geometric representation of his ( her ) anatomy , which is particularly important for low energy gamma ray emitting sources such as thorium , uranium , plutonium and other actinides . the software enables automatic creation of an mcnp input data file based on scanning data . the utility includes segmentation of images obtained with either computed tomography or magnetic resonance imaging by distinguishing tissues according to their signal ( brightness ) and specification of the source and detector . in addition , a coupling of individual voxels within the tissue is used to reduce the memory demand and to increase the calculational speed . the utility was tested for low energy emitters in plastic and biological tissues as well as for computed tomography and magnetic resonance imaging scanning information"}, "present_kps": {"text": ["graphical user interface", "computational phantoms", "computation phantoms", "monte carlo calculations", "in vivo measurements", "radionuclides", "tissues", "worker", "precise geometric representation", "anatomy", "low energy gamma ray emitting sources", "actinides", "software", "automatic creation", "mcnp input data file", "scanning data", "computed tomography", "signal", "brightness", "detector", "individual voxels", "memory demand", "calculational speed", "plastic", "biological tissues", "magnetic resonance imaging scanning information"], "tokenized": ["graphical user interface", "computational phantoms", "computation phantoms", "monte carlo calculations", "in vivo measurements", "radionuclides", "tissues", "worker", "precise geometric representation", "anatomy", "low energy gamma ray emitting sources", "actinides", "software", "automatic creation", "mcnp input data file", "scanning data", "computed tomography", "signal", "brightness", "detector", "individual voxels", "memory demand", "calculational speed", "plastic", "biological tissues", "magnetic resonance imaging scanning information"]}, "absent_kps": {"text": ["th", "calibration", "in vivo measurement systems", "u", "pu"], "tokenized": ["th", "calibration", "in vivo measurement systems", "u", "pu"]}}
{"id": 22, "title": {"text": "the acquisition of out of print music .", "tokenized": "the acquisition of out of print music ."}, "abstract": {"text": "acquisition of out of print music , both scholarly editions and performance editions . the appropriate technical music vocabulary , the music publishing industry , specialized publishers and vendors , and methods of acquisition of out of print printed music are introduced , and the need for familiarity with them is emphasized", "tokenized": "acquisition of out of print music , both scholarly editions and performance editions . the appropriate technical music vocabulary , the music publishing industry , specialized publishers and vendors , and methods of acquisition of out of print printed music are introduced , and the need for familiarity with them is emphasized"}, "present_kps": {"text": ["out of print music", "scholarly editions", "performance editions", "technical music vocabulary", "music publishing industry", "specialized publishers", "out of print printed music"], "tokenized": ["out of print music", "scholarly editions", "performance editions", "technical music vocabulary", "music publishing industry", "specialized publishers", "out of print printed music"]}, "absent_kps": {"text": ["specialized vendors"], "tokenized": ["specialized vendors"]}}
{"id": 23, "title": {"text": "general solution of a density functionally gradient piezoelectric cantilever .", "tokenized": "general solution of a density functionally gradient piezoelectric cantilever ."}, "abstract": {"text": "we have used the plane strain theory of transversely isotropic bodies to study a piezoelectric cantilever . in order to find the general solution of a density functionally gradient piezoelectric cantilever , we have used the inverse method ( i . e . the airy stress function method ) . we have obtained the stress and induction functions in the form of polynomials as well as the general solution of the beam . based on this general solution , we have deduced the solutions of the cantilever under different loading conditions . furthermore , as applications of this general solution in engineering , we have studied the tip deflection and blocking force of a piezoelectric cantilever actuator . finally , we have addressed a method to determine the density distribution profile for a given piezoelectric material", "tokenized": "we have used the plane strain theory of transversely isotropic bodies to study a piezoelectric cantilever . in order to find the general solution of a density functionally gradient piezoelectric cantilever , we have used the inverse method ( i . e . the airy stress function method ) . we have obtained the stress and induction functions in the form of polynomials as well as the general solution of the beam . based on this general solution , we have deduced the solutions of the cantilever under different loading conditions . furthermore , as applications of this general solution in engineering , we have studied the tip deflection and blocking force of a piezoelectric cantilever actuator . finally , we have addressed a method to determine the density distribution profile for a given piezoelectric material"}, "present_kps": {"text": ["plane strain theory", "transversely isotropic bodies", "inverse method", "airy stress function", "polynomials", "loading conditions", "piezoelectric cantilever actuator", "density distribution profile", "piezoelectric material"], "tokenized": ["plane strain theory", "transversely isotropic bodies", "inverse method", "airy stress function", "polynomials", "loading conditions", "piezoelectric cantilever actuator", "density distribution profile", "piezoelectric material"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 24, "title": {"text": "recording quantum properties of light in a long lived atomic spin state .", "tokenized": "recording quantum properties of light in a long lived atomic spin state ."}, "abstract": {"text": "we report an experiment on mapping a quantum state of light onto the ground state spin of an ensemble of cs atoms with the lifetime of [digit] ms . recording of one of the two quadrature phase operators of light is demonstrated with vacuum and squeezed states of light . the sensitivity of the mapping procedure at the level of approximately [digit] photon sec per hz is shown . the results pave the road towards complete ( storing both quadrature phase observables ) quantum memory for gaussian states of light . the experiment also sheds new light on fundamental limits of sensitivity of the magneto optical resonance method", "tokenized": "we report an experiment on mapping a quantum state of light onto the ground state spin of an ensemble of cs atoms with the lifetime of [digit] ms . recording of one of the two quadrature phase operators of light is demonstrated with vacuum and squeezed states of light . the sensitivity of the mapping procedure at the level of approximately [digit] photon sec per hz is shown . the results pave the road towards complete ( storing both quadrature phase observables ) quantum memory for gaussian states of light . the experiment also sheds new light on fundamental limits of sensitivity of the magneto optical resonance method"}, "present_kps": {"text": ["long lived atomic spin state", "ground state spin", "ensemble", "cs", "[digit] ms", "two quadrature phase operators", "squeezed states", "mapping procedure", "quantum memory"], "tokenized": ["long lived atomic spin state", "ground state spin", "ensemble", "cs", "[digit] ms", "two quadrature phase operators", "squeezed states", "mapping procedure", "quantum memory"]}, "absent_kps": {"text": ["vacuum states", "light quantum properties recording", "magnetooptical resonance method"], "tokenized": ["vacuum states", "light quantum properties recording", "magnetooptical resonance method"]}}
{"id": 25, "title": {"text": "comprehensive encoding and decoupling solution to problems of decoherence and .", "tokenized": "comprehensive encoding and decoupling solution to problems of decoherence and ."}, "abstract": {"text": "proposals for scalable quantum computing devices suffer not only from decoherence due to the interaction with their environment , but also from severe engineering constraints . here we introduce a practical solution to these major concerns , addressing solid state proposals in particular . decoherence is first reduced by encoding a logical qubit into two qubits , then completely eliminated by an efficient set of decoupling pulse sequences . the same encoding removes the need for single qubit operations , which pose a difficult design constraint . we further show how the dominant decoherence processes can be identified empirically , in order to optimize the decoupling pulses", "tokenized": "proposals for scalable quantum computing devices suffer not only from decoherence due to the interaction with their environment , but also from severe engineering constraints . here we introduce a practical solution to these major concerns , addressing solid state proposals in particular . decoherence is first reduced by encoding a logical qubit into two qubits , then completely eliminated by an efficient set of decoupling pulse sequences . the same encoding removes the need for single qubit operations , which pose a difficult design constraint . we further show how the dominant decoherence processes can be identified empirically , in order to optimize the decoupling pulses"}, "present_kps": {"text": ["decoherence", "scalable quantum computing devices", "engineering constraints"], "tokenized": ["decoherence", "scalable quantum computing devices", "engineering constraints"]}, "absent_kps": {"text": ["logical qubit encoding", "decoupling pulse optimization", "solid state quantum computing", "exchange hamiltonian", "pulse sequence decoupling"], "tokenized": ["logical qubit encoding", "decoupling pulse optimization", "solid state quantum computing", "exchange hamiltonian", "pulse sequence decoupling"]}}
{"id": 26, "title": {"text": "social percolation and the influence of mass media .", "tokenized": "social percolation and the influence of mass media ."}, "abstract": {"text": "their neighbours tell them of its quality , and if this quality is higher than their own quality expectations . now we introduce additional information from the mass media , which is analogous to the ghost field in percolation theory . the mass media shift the percolative phase transition observed in the model , and decrease the time after which the stationary state is reached", "tokenized": "their neighbours tell them of its quality , and if this quality is higher than their own quality expectations . now we introduce additional information from the mass media , which is analogous to the ghost field in percolation theory . the mass media shift the percolative phase transition observed in the model , and decrease the time after which the stationary state is reached"}, "present_kps": {"text": ["social percolation", "quality expectations", "ghost field", "percolative phase transition", "stationary state"], "tokenized": ["social percolation", "quality expectations", "ghost field", "percolative phase transition", "stationary state"]}, "absent_kps": {"text": ["customers", "cinema", "solomon weisbuch marketing model", "external field", "mass media influence"], "tokenized": ["customers", "cinema", "solomon weisbuch marketing model", "external field", "mass media influence"]}}
{"id": 27, "title": {"text": "estimating long range dependence finite sample properties and confidence .", "tokenized": "estimating long range dependence finite sample properties and confidence ."}, "abstract": {"text": "a major issue in financial economics is the behavior of asset returns over long horizons . various estimators of long range dependence have been proposed . even though some have known asymptotic properties , it is important to test their accuracy by using simulated series of different lengths . we test r s analysis , detrended fluctuation analysis and periodogram regression methods on samples drawn from gaussian white noise . the dfa statistics turns out to be the unanimous winner . unfortunately , no asymptotic distribution theory has been derived for this statistics so far . we were able , however , to construct empirical ( i . e . approximate ) confidence intervals for all three methods . the obtained values differ largely from heuristic values proposed by some authors for the r s statistics and are very close to asymptotic values for the periodogram regression method", "tokenized": "a major issue in financial economics is the behavior of asset returns over long horizons . various estimators of long range dependence have been proposed . even though some have known asymptotic properties , it is important to test their accuracy by using simulated series of different lengths . we test r s analysis , detrended fluctuation analysis and periodogram regression methods on samples drawn from gaussian white noise . the dfa statistics turns out to be the unanimous winner . unfortunately , no asymptotic distribution theory has been derived for this statistics so far . we were able , however , to construct empirical ( i . e . approximate ) confidence intervals for all three methods . the obtained values differ largely from heuristic values proposed by some authors for the r s statistics and are very close to asymptotic values for the periodogram regression method"}, "present_kps": {"text": ["long range dependence", "finite sample properties", "financial economics", "asset returns", "long horizons", "asymptotic properties", "detrended fluctuation analysis", "periodogram regression methods", "gaussian white noise", "confidence intervals", "heuristic values"], "tokenized": ["long range dependence", "finite sample properties", "financial economics", "asset returns", "long horizons", "asymptotic properties", "detrended fluctuation analysis", "periodogram regression methods", "gaussian white noise", "confidence intervals", "heuristic values"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 28, "title": {"text": "simulation of evacuation processes using a bionics inspired cellular automaton .", "tokenized": "simulation of evacuation processes using a bionics inspired cellular automaton ."}, "abstract": {"text": "we present simulations of evacuation processes using a recently introduced cellular automaton model for pedestrian dynamics . this model applies a bionics approach to describe the interaction between the pedestrians using ideas from chemotaxis . here we study a rather simple situation , namely the evacuation from a large room with one or two doors . it is shown that the variation of the model parameters allows to describe different types of behaviour , from regular to panic . we find a non monotonic dependence of the evacuation times on the coupling constants . these times depend on the strength of the herding behaviour , with minimal evacuation times for some intermediate values of the couplings , i . e . , a proper combination of herding and use of knowledge about the shortest way to the exit", "tokenized": "we present simulations of evacuation processes using a recently introduced cellular automaton model for pedestrian dynamics . this model applies a bionics approach to describe the interaction between the pedestrians using ideas from chemotaxis . here we study a rather simple situation , namely the evacuation from a large room with one or two doors . it is shown that the variation of the model parameters allows to describe different types of behaviour , from regular to panic . we find a non monotonic dependence of the evacuation times on the coupling constants . these times depend on the strength of the herding behaviour , with minimal evacuation times for some intermediate values of the couplings , i . e . , a proper combination of herding and use of knowledge about the shortest way to the exit"}, "present_kps": {"text": ["pedestrian dynamics", "chemotaxis", "coupling constants", "herding behaviour"], "tokenized": ["pedestrian dynamics", "chemotaxis", "coupling constants", "herding behaviour"]}, "absent_kps": {"text": ["bionics inspired cellular automaton model", "nonmonotonic dependence", "evacuation processes simulation"], "tokenized": ["bionics inspired cellular automaton model", "nonmonotonic dependence", "evacuation processes simulation"]}}
{"id": 29, "title": {"text": "dynamical transition to periodic motions of a recurrent bus induced by nonstops .", "tokenized": "dynamical transition to periodic motions of a recurrent bus induced by nonstops ."}, "abstract": {"text": "many bus stops when the recurrent bus passes some bus stops without stopping . the recurrent time ( one period ) is described in terms of a nonlinear map . it is shown that the recurrent bus exhibits the complex periodic behaviors . the dynamical transitions to periodic motions occur by increasing nonstops . the periodic motions depend on the property of an attractor of the nonlinear map . the period n of the attractor varies sensitively with the number of nonstops", "tokenized": "many bus stops when the recurrent bus passes some bus stops without stopping . the recurrent time ( one period ) is described in terms of a nonlinear map . it is shown that the recurrent bus exhibits the complex periodic behaviors . the dynamical transitions to periodic motions occur by increasing nonstops . the periodic motions depend on the property of an attractor of the nonlinear map . the period n of the attractor varies sensitively with the number of nonstops"}, "present_kps": {"text": ["dynamical transition", "periodic motions", "recurrent bus", "nonstops", "recurrent time", "nonlinear map", "complex periodic behaviors", "attractor"], "tokenized": ["dynamical transition", "periodic motions", "recurrent bus", "nonstops", "recurrent time", "nonlinear map", "complex periodic behaviors", "attractor"]}, "absent_kps": {"text": ["circular route"], "tokenized": ["circular route"]}}
{"id": 30, "title": {"text": "the two populations ' cellular automata model with predation based on the penna .", "tokenized": "the two populations ' cellular automata model with predation based on the penna ."}, "abstract": {"text": "in penna ' s ( [digit] ) single species asexual bit string model of biological ageing , the verhulst factor has too strong a restraining effect on the development of the population . danuta makowiec gave an improved model based on the lattice , where the restraining factor of the four neighbours take the place of the verhulst factor . here , we discuss the two populations ' penna model with predation on the planar lattice of two dimensions . a cellular automata model containing movable wolves and sheep has been built . the results show that both the quantity of the wolves and the sheep fluctuate in accordance with the law that one quantity increases while the other one decreases", "tokenized": "in penna ' s ( [digit] ) single species asexual bit string model of biological ageing , the verhulst factor has too strong a restraining effect on the development of the population . danuta makowiec gave an improved model based on the lattice , where the restraining factor of the four neighbours take the place of the verhulst factor . here , we discuss the two populations ' penna model with predation on the planar lattice of two dimensions . a cellular automata model containing movable wolves and sheep has been built . the results show that both the quantity of the wolves and the sheep fluctuate in accordance with the law that one quantity increases while the other one decreases"}, "present_kps": {"text": ["population", "cellular automata model", "predation", "single species asexual bit string model", "biological ageing", "verhulst factor", "restraining effect", "lattice", "penna model", "wolves", "sheep", "fluctuation"], "tokenized": ["population", "cellular automata model", "predation", "single species asexual bit string model", "biological ageing", "verhulst factor", "restraining effect", "lattice", "penna model", "wolves", "sheep", "fluctuation"]}, "absent_kps": {"text": ["lotka volterra model"], "tokenized": ["lotka volterra model"]}}
{"id": 31, "title": {"text": "option pricing from path integral for non gaussian fluctuations . natural .", "tokenized": "option pricing from path integral for non gaussian fluctuations . natural ."}, "abstract": {"text": "within a path integral formalism for non gaussian price fluctuations , we set up a simple stochastic calculus and derive a natural martingale for option pricing from the wealth balance of options , stocks , and bonds . the resulting formula is evaluated for truncated levy distributions", "tokenized": "within a path integral formalism for non gaussian price fluctuations , we set up a simple stochastic calculus and derive a natural martingale for option pricing from the wealth balance of options , stocks , and bonds . the resulting formula is evaluated for truncated levy distributions"}, "present_kps": {"text": ["option pricing", "path integrals", "stochastic calculus", "natural martingale", "stocks", "bonds", "truncated levy distributions"], "tokenized": ["option pricing", "path integrals", "stochastic calculus", "natural martingale", "stocks", "bonds", "truncated levy distributions"]}, "absent_kps": {"text": ["nongaussian fluctuations"], "tokenized": ["nongaussian fluctuations"]}}
{"id": 32, "title": {"text": "quantum market games .", "tokenized": "quantum market games ."}, "abstract": {"text": "has roots in the recently developed quantum game theory", "tokenized": "has roots in the recently developed quantum game theory"}, "present_kps": {"text": ["quantum market games", "quantum game theory"], "tokenized": ["quantum market games", "quantum game theory"]}, "absent_kps": {"text": ["financial markets", "quantum strategies", "economics"], "tokenized": ["financial markets", "quantum strategies", "economics"]}}
{"id": 33, "title": {"text": "on the emergence of rules in neural networks .", "tokenized": "on the emergence of rules in neural networks ."}, "abstract": {"text": "grammars ) from sequences of arbitrary input symbols by inventing abstract representations that accommodate unseen symbol sets as well as unseen but similar grammars . the neural network is shown to have the ability to transfer grammatical knowledge to both new symbol vocabularies and new grammars . analysis of the state space shows that the network learns generalized abstract structures of the input and is not simply memorizing the input strings . these representations are context sensitive , hierarchical , and based on the state variable of the finite state machines that the neural network has learned . generalization to new symbol sets or grammars arises from the spatial nature of the internal representations used by the network , allowing new symbol sets to be encoded close to symbol sets that have already been learned in the hidden unit space of the network . the results are counter to the arguments that learning algorithms based on weight adaptation after each exemplar presentation ( such as the long term potentiation found in the mammalian nervous system ) can not in principle extract symbolic knowledge from positive examples as prescribed by prevailing human linguistic theory and evolutionary psychology", "tokenized": "grammars ) from sequences of arbitrary input symbols by inventing abstract representations that accommodate unseen symbol sets as well as unseen but similar grammars . the neural network is shown to have the ability to transfer grammatical knowledge to both new symbol vocabularies and new grammars . analysis of the state space shows that the network learns generalized abstract structures of the input and is not simply memorizing the input strings . these representations are context sensitive , hierarchical , and based on the state variable of the finite state machines that the neural network has learned . generalization to new symbol sets or grammars arises from the spatial nature of the internal representations used by the network , allowing new symbol sets to be encoded close to symbol sets that have already been learned in the hidden unit space of the network . the results are counter to the arguments that learning algorithms based on weight adaptation after each exemplar presentation ( such as the long term potentiation found in the mammalian nervous system ) can not in principle extract symbolic knowledge from positive examples as prescribed by prevailing human linguistic theory and evolutionary psychology"}, "present_kps": {"text": ["neural network", "state space", "learns", "symbolic knowledge"], "tokenized": ["neural network", "state space", "learns", "symbolic knowledge"]}, "absent_kps": {"text": ["abstract rules", "cognitive neurosciences", "associationist learning", "associationist neural network"], "tokenized": ["abstract rules", "cognitive neurosciences", "associationist learning", "associationist neural network"]}}
{"id": 34, "title": {"text": "streaming , disruptive interference and power law behavior in the exit dynamics .", "tokenized": "streaming , disruptive interference and power law behavior in the exit dynamics ."}, "abstract": {"text": "we analyze the exit dynamics of pedestrians who are initially confined in a room . pedestrians are modeled as cellular automata and compete to escape via a known exit at the soonest possible time . a pedestrian could move forward , backward , left or right within each iteration time depending on adjacent cell vacancy and in accordance with simple rules that determine the compulsion to move and physical capability relative to his neighbors . the arching signatures of jamming were observed and the pedestrians exited in bursts of various sizes . power law behavior is found in the burst size frequency distribution for exit widths w greater than one cell dimension ( w > [digit] ) . the slope of the power law curve varies with w from [digit] . [digit] ( w [digit] ) to [digit] . [digit] ( w [digit] ) . streaming which is a diffusive behavior , arises in large burst sizes and is more likely in a single exit room with w [digit] and leads to a counterintuitive result wherein an average exit throughput q is obtained that is higher than with w [digit] , [digit] , or [digit] . for a two exit room ( w [digit] ) , q is not greater than twice the yield of a single exit room . if the doors are not separated far enough ( < 4w ) , q becomes even significantly less due to a collective slow down that emerges among pedestrians crossing in each other ' s path ( disruptive interference effect ) . for the same w and door number , q is also higher with relaxed pedestrians than with anxious ones", "tokenized": "we analyze the exit dynamics of pedestrians who are initially confined in a room . pedestrians are modeled as cellular automata and compete to escape via a known exit at the soonest possible time . a pedestrian could move forward , backward , left or right within each iteration time depending on adjacent cell vacancy and in accordance with simple rules that determine the compulsion to move and physical capability relative to his neighbors . the arching signatures of jamming were observed and the pedestrians exited in bursts of various sizes . power law behavior is found in the burst size frequency distribution for exit widths w greater than one cell dimension ( w > [digit] ) . the slope of the power law curve varies with w from [digit] . [digit] ( w [digit] ) to [digit] . [digit] ( w [digit] ) . streaming which is a diffusive behavior , arises in large burst sizes and is more likely in a single exit room with w [digit] and leads to a counterintuitive result wherein an average exit throughput q is obtained that is higher than with w [digit] , [digit] , or [digit] . for a two exit room ( w [digit] ) , q is not greater than twice the yield of a single exit room . if the doors are not separated far enough ( < 4w ) , q becomes even significantly less due to a collective slow down that emerges among pedestrians crossing in each other ' s path ( disruptive interference effect ) . for the same w and door number , q is also higher with relaxed pedestrians than with anxious ones"}, "present_kps": {"text": ["streaming", "disruptive interference", "power law behavior", "exit dynamics", "cellular automata", "iteration time", "adjacent cell vacancy", "arching signatures", "jamming", "burst size frequency distribution", "collective slow down"], "tokenized": ["streaming", "disruptive interference", "power law behavior", "exit dynamics", "cellular automata", "iteration time", "adjacent cell vacancy", "arching signatures", "jamming", "burst size frequency distribution", "collective slow down"]}, "absent_kps": {"text": ["confined pedestrians", "self organised criticality"], "tokenized": ["confined pedestrians", "self organised criticality"]}}
{"id": 35, "title": {"text": "the influence of tollbooths on highway traffic .", "tokenized": "the influence of tollbooths on highway traffic ."}, "abstract": {"text": "simulated by the nagel schreckenberg model . various types of toll collection are examined , which can be characterized either by a waiting time or a reduced speed . a first order phase transition is observed . the phase separation results a saturated flow , which is observed as a plateau region in the fundamental diagram . the effects of lane expansion near the tollbooth are examined . the full capacity of a highway can be restored . the emergence of vehicle queuing is studied . besides the numerical results , we also obtain analytical expressions for various quantities . the numerical simulations can be well described by the analytical formulas . we also discuss the influence on the travel time and its variance . the tollbooth increases the travel time but decreases its variance . the differences between long and short distance travelers are also discussed", "tokenized": "simulated by the nagel schreckenberg model . various types of toll collection are examined , which can be characterized either by a waiting time or a reduced speed . a first order phase transition is observed . the phase separation results a saturated flow , which is observed as a plateau region in the fundamental diagram . the effects of lane expansion near the tollbooth are examined . the full capacity of a highway can be restored . the emergence of vehicle queuing is studied . besides the numerical results , we also obtain analytical expressions for various quantities . the numerical simulations can be well described by the analytical formulas . we also discuss the influence on the travel time and its variance . the tollbooth increases the travel time but decreases its variance . the differences between long and short distance travelers are also discussed"}, "present_kps": {"text": ["tollbooths", "highway traffic", "nagel schreckenberg model", "toll collection", "waiting time", "reduced speed", "first order phase transition", "saturated flow", "lane expansion", "vehicle queuing", "numerical simulations"], "tokenized": ["tollbooths", "highway traffic", "nagel schreckenberg model", "toll collection", "waiting time", "reduced speed", "first order phase transition", "saturated flow", "lane expansion", "vehicle queuing", "numerical simulations"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 36, "title": {"text": "the bagsik oscillator without complex numbers .", "tokenized": "the bagsik oscillator without complex numbers ."}, "abstract": {"text": "published by piotrowski and sladkowski ( [digit] ) , is erroneous due to ( [digit] ) the incorrect banking data used and ( [digit] ) the application of statistical mechanism apparatus to processes that are totally deterministic", "tokenized": "published by piotrowski and sladkowski ( [digit] ) , is erroneous due to ( [digit] ) the incorrect banking data used and ( [digit] ) the application of statistical mechanism apparatus to processes that are totally deterministic"}, "present_kps": {"text": ["bagsik oscillator", "incorrect banking data", "statistical mechanism apparatus"], "tokenized": ["bagsik oscillator", "incorrect banking data", "statistical mechanism apparatus"]}, "absent_kps": {"text": ["noncomplex numbers", "game theory", "deterministic processes"], "tokenized": ["noncomplex numbers", "game theory", "deterministic processes"]}}
{"id": 37, "title": {"text": "the variance of firm growth rates the ' scaling ' puzzle .", "tokenized": "the variance of firm growth rates the ' scaling ' puzzle ."}, "abstract": {"text": "size and the variance of its growth rate . the flatness of the relation is regarded as puzzling , in that it suggests that large firms are not much more stable than small firms . it has been suggested that the powerlaw nature of the relationship reflects the presence of some form of correlation of growth rates across the firm ' s constituent businesses . here , it is shown that a model of independent businesses which allows for the fact that these businesses vary in size , as modelled by a simple ' partitions of integers ' model , provides a good representation of what is observed empirically", "tokenized": "size and the variance of its growth rate . the flatness of the relation is regarded as puzzling , in that it suggests that large firms are not much more stable than small firms . it has been suggested that the powerlaw nature of the relationship reflects the presence of some form of correlation of growth rates across the firm ' s constituent businesses . here , it is shown that a model of independent businesses which allows for the fact that these businesses vary in size , as modelled by a simple ' partitions of integers ' model , provides a good representation of what is observed empirically"}, "present_kps": {"text": ["firm growth rates", "flatness", "correlation", "constituent businesses"], "tokenized": ["firm growth rates", "flatness", "correlation", "constituent businesses"]}, "absent_kps": {"text": ["scaling puzzle", "corporate growth", "partitions of integers model", "power law", "size distribution"], "tokenized": ["scaling puzzle", "corporate growth", "partitions of integers model", "power law", "size distribution"]}}
{"id": 38, "title": {"text": "antipersistent markov behavior in foreign exchange markets .", "tokenized": "antipersistent markov behavior in foreign exchange markets ."}, "abstract": {"text": "developed using high frequency ( tick by tick ) data . the antipersistent markov behavior of log price fluctuations of given size implies , in principle , the possibility of a statistical forecast . we introduce and measure the available information of the quote sequence , and we show how it can be profitable following a particular trading rule", "tokenized": "developed using high frequency ( tick by tick ) data . the antipersistent markov behavior of log price fluctuations of given size implies , in principle , the possibility of a statistical forecast . we introduce and measure the available information of the quote sequence , and we show how it can be profitable following a particular trading rule"}, "present_kps": {"text": ["antipersistent markov behavior", "foreign exchange markets", "log price fluctuations", "statistical forecast", "forecasting", "quote sequence", "trading rule"], "tokenized": ["antipersistent markov behavior", "foreign exchange markets", "log price fluctuations", "statistical forecast", "forecasting", "quote sequence", "trading rule"]}, "absent_kps": {"text": ["exchange rates", "efficiency", "deutsche mark", "us dollar", "high frequency data", "shannon entropy"], "tokenized": ["exchange rates", "efficiency", "deutsche mark", "us dollar", "high frequency data", "shannon entropy"]}}
{"id": 39, "title": {"text": "stock market dynamics .", "tokenized": "stock market dynamics ."}, "abstract": {"text": "returns . moreover , we find that these properties are recurrent and are also present in invariant measures of low dimensional dynamical systems . thus , we propose that the returns are modeled by the first poincare return time of a low dimensional chaotic trajectory . this modeling , which captures the recurrent properties of the return fluctuations , is able to predict well the evolution of the observed statistical quantities . in addition , it explains the reason for which stocks present simultaneously dynamical properties and high uncertainties . in our analysis , we use data from the s p [digit] index and the brazilian stock telebras", "tokenized": "returns . moreover , we find that these properties are recurrent and are also present in invariant measures of low dimensional dynamical systems . thus , we propose that the returns are modeled by the first poincare return time of a low dimensional chaotic trajectory . this modeling , which captures the recurrent properties of the return fluctuations , is able to predict well the evolution of the observed statistical quantities . in addition , it explains the reason for which stocks present simultaneously dynamical properties and high uncertainties . in our analysis , we use data from the s p [digit] index and the brazilian stock telebras"}, "present_kps": {"text": ["invariant measures", "low dimensional dynamical systems", "first poincare return time", "low dimensional chaotic trajectory", "statistical quantities", "brazilian stock"], "tokenized": ["invariant measures", "low dimensional dynamical systems", "first poincare return time", "low dimensional chaotic trajectory", "statistical quantities", "brazilian stock"]}, "absent_kps": {"text": ["stock market returns", "empirical statistical observations", "econophysics"], "tokenized": ["stock market returns", "empirical statistical observations", "econophysics"]}}
{"id": 40, "title": {"text": "application of nonlinear time series analysis techniques to high frequency .", "tokenized": "application of nonlinear time series analysis techniques to high frequency ."}, "abstract": {"text": "in this work we have applied nonlinear time series analysis to high frequency currency exchange data . the time series studied are the exchange rates between the us dollar and [digit] other foreign currencies from within and without the euro zone . our goal was to determine if their dynamical behaviours were in some way correlated . the nonexistence of stationarity called for the application of recurrence quantification analysis as a tool for this analysis , and is based on the definition of several parameters that allow for the quantification of recurrence plots . the method was checked using the european monetary system currency exchanges . the results show , as expected , the high correlation between the currencies that are part of the euro , but also a strong correlation between the japanese yen , the canadian dollar and the british pound . singularities of the series are also demonstrated taking into account historical events , in [digit] , in the euro zone", "tokenized": "in this work we have applied nonlinear time series analysis to high frequency currency exchange data . the time series studied are the exchange rates between the us dollar and [digit] other foreign currencies from within and without the euro zone . our goal was to determine if their dynamical behaviours were in some way correlated . the nonexistence of stationarity called for the application of recurrence quantification analysis as a tool for this analysis , and is based on the definition of several parameters that allow for the quantification of recurrence plots . the method was checked using the european monetary system currency exchanges . the results show , as expected , the high correlation between the currencies that are part of the euro , but also a strong correlation between the japanese yen , the canadian dollar and the british pound . singularities of the series are also demonstrated taking into account historical events , in [digit] , in the euro zone"}, "present_kps": {"text": ["nonlinear time series", "high frequency currency exchange data", "exchange rates", "us dollar", "foreign currencies", "euro zone", "stationarity", "recurrence quantification analysis", "recurrence plots", "european monetary system", "japanese yen", "canadian dollar", "british pound", "historical events"], "tokenized": ["nonlinear time series", "high frequency currency exchange data", "exchange rates", "us dollar", "foreign currencies", "euro zone", "stationarity", "recurrence quantification analysis", "recurrence plots", "european monetary system", "japanese yen", "canadian dollar", "british pound", "historical events"]}, "absent_kps": {"text": ["nonlinear dynamics", "econophysics"], "tokenized": ["nonlinear dynamics", "econophysics"]}}
{"id": 41, "title": {"text": "modeling daily realized futures volatility with singular spectrum analysis .", "tokenized": "modeling daily realized futures volatility with singular spectrum analysis ."}, "abstract": {"text": "logarithmic standard deviations of two important futures return series . the realized volatility and logarithmic standard deviations are constructed following the methodology of andersen et al . j . am . stat . ass . [digit] ( [digit] ) [digit] [digit] using intra day transaction data . we find that ssa decomposes the volatility series quite well and effectively captures both the market trend ( accounting for about [digit] [digit] % of the total variance in the series ) and , more importantly , a number of underlying market periodicities . reliable identification of any periodicities is extremely important for options pricing and risk management and we believe that ssa can be a useful addition to the financial practitioners ' toolbox", "tokenized": "logarithmic standard deviations of two important futures return series . the realized volatility and logarithmic standard deviations are constructed following the methodology of andersen et al . j . am . stat . ass . [digit] ( [digit] ) [digit] [digit] using intra day transaction data . we find that ssa decomposes the volatility series quite well and effectively captures both the market trend ( accounting for about [digit] [digit] % of the total variance in the series ) and , more importantly , a number of underlying market periodicities . reliable identification of any periodicities is extremely important for options pricing and risk management and we believe that ssa can be a useful addition to the financial practitioners ' toolbox"}, "present_kps": {"text": ["daily realized futures volatility", "singular spectrum analysis", "logarithmic standard deviations", "return series", "ssa", "market trend", "market periodicities", "options pricing", "risk management", "financial practitioners"], "tokenized": ["daily realized futures volatility", "singular spectrum analysis", "logarithmic standard deviations", "return series", "ssa", "market trend", "market periodicities", "options pricing", "risk management", "financial practitioners"]}, "absent_kps": {"text": ["intraday transaction data", "econophysics", "asset return"], "tokenized": ["intraday transaction data", "econophysics", "asset return"]}}
{"id": 42, "title": {"text": "phase control of higher order squeezing of a quantum field .", "tokenized": "phase control of higher order squeezing of a quantum field ."}, "abstract": {"text": "photon statistics in a c . w . system has been observed in the mixing of a coherent field with a two photon source . their system has the advantage over other atomic transition based fluorescent systems . in this paper , we examine further the squeezing properties of higher order quantum fluctuations in one of the quadrature components of the combined field in this system . we demonstrate that efficient and lasting higher order squeezing effects could be observed with proper choice of the relative phase between the pump and coherent fields . this nonclassical feature is attributed to a constructive two photon interference . relationship between the second and higher order squeezing of the field is discussed", "tokenized": "photon statistics in a c . w . system has been observed in the mixing of a coherent field with a two photon source . their system has the advantage over other atomic transition based fluorescent systems . in this paper , we examine further the squeezing properties of higher order quantum fluctuations in one of the quadrature components of the combined field in this system . we demonstrate that efficient and lasting higher order squeezing effects could be observed with proper choice of the relative phase between the pump and coherent fields . this nonclassical feature is attributed to a constructive two photon interference . relationship between the second and higher order squeezing of the field is discussed"}, "present_kps": {"text": ["phase control", "higher order squeezing", "quantum field", "atomic transition based fluorescent systems", "quantum fluctuations", "two photon interference"], "tokenized": ["phase control", "higher order squeezing", "quantum field", "atomic transition based fluorescent systems", "quantum fluctuations", "two photon interference"]}, "absent_kps": {"text": ["coherent field mixing", "phase dependent photon statistics"], "tokenized": ["coherent field mixing", "phase dependent photon statistics"]}}
{"id": 43, "title": {"text": "modeling self consistent multi class dynamic traffic flow .", "tokenized": "modeling self consistent multi class dynamic traffic flow ."}, "abstract": {"text": "traffic model derived from the vehicular boltzmann equation and the traffic dispersion model . the multilane domain is considered as a two dimensional space and the interaction among vehicles in the domain is described by a dispersion model . the reason we consider a multilane domain as a two dimensional space is that the driving behavior of road users may not be restricted by lanes , especially motorcyclists . the dispersion model , which is a nonlinear poisson equation , is derived from the car following theory and the equilibrium assumption . under the concept that all kinds of users share the finite section , the density is distributed on a road by the dispersion model . in addition , the dynamic evolution of the traffic flow is determined by the systematic gas kinetic model derived from the boltzmann equation . multiplying boltzmann equation by the zeroth , first and second order moment functions , integrating both side of the equation and using chain rules , we can derive continuity , motion and variance equation , respectively . however , the second order moment function , which is the square of the individual velocity , is employed by previous researches does not have physical meaning in traffic flow", "tokenized": "traffic model derived from the vehicular boltzmann equation and the traffic dispersion model . the multilane domain is considered as a two dimensional space and the interaction among vehicles in the domain is described by a dispersion model . the reason we consider a multilane domain as a two dimensional space is that the driving behavior of road users may not be restricted by lanes , especially motorcyclists . the dispersion model , which is a nonlinear poisson equation , is derived from the car following theory and the equilibrium assumption . under the concept that all kinds of users share the finite section , the density is distributed on a road by the dispersion model . in addition , the dynamic evolution of the traffic flow is determined by the systematic gas kinetic model derived from the boltzmann equation . multiplying boltzmann equation by the zeroth , first and second order moment functions , integrating both side of the equation and using chain rules , we can derive continuity , motion and variance equation , respectively . however , the second order moment function , which is the square of the individual velocity , is employed by previous researches does not have physical meaning in traffic flow"}, "present_kps": {"text": ["vehicular boltzmann equation", "traffic dispersion model", "road users", "nonlinear poisson equation", "poisson equation", "car following theory", "dynamic evolution", "variance equation"], "tokenized": ["vehicular boltzmann equation", "traffic dispersion model", "road users", "nonlinear poisson equation", "poisson equation", "car following theory", "dynamic evolution", "variance equation"]}, "absent_kps": {"text": ["motion equation", "multilane traffic model", "self consistent multiclass dynamic traffic flow modeling"], "tokenized": ["motion equation", "multilane traffic model", "self consistent multiclass dynamic traffic flow modeling"]}}
{"id": 44, "title": {"text": "mixture of experts classification using a hierarchical mixture model .", "tokenized": "mixture of experts classification using a hierarchical mixture model ."}, "abstract": {"text": "models the following data generation process ( [digit] ) the data are generated by a finite number of sources ( clusters ) , and ( [digit] ) the generation mechanism of each source assumes the existence of individual internal class labeled sources ( subclusters of the external cluster ) . the model estimates the posterior probability of class membership similar to a mixture of experts classifier . in order to learn the parameters of the model , we have developed a general training approach based on maximum likelihood that results in two efficient training algorithms . compared to other classification mixture models , the proposed hierarchical model exhibits several advantages and provides improved classification performance as indicated by the experimental results", "tokenized": "models the following data generation process ( [digit] ) the data are generated by a finite number of sources ( clusters ) , and ( [digit] ) the generation mechanism of each source assumes the existence of individual internal class labeled sources ( subclusters of the external cluster ) . the model estimates the posterior probability of class membership similar to a mixture of experts classifier . in order to learn the parameters of the model , we have developed a general training approach based on maximum likelihood that results in two efficient training algorithms . compared to other classification mixture models , the proposed hierarchical model exhibits several advantages and provides improved classification performance as indicated by the experimental results"}, "present_kps": {"text": ["classification", "hierarchical mixture model", "data generation process", "posterior probability of class membership", "experts classifier"], "tokenized": ["classification", "hierarchical mixture model", "data generation process", "posterior probability of class membership", "experts classifier"]}, "absent_kps": {"text": ["bayes classifier"], "tokenized": ["bayes classifier"]}}
{"id": 45, "title": {"text": "emarketing restaurant web sites that click .", "tokenized": "emarketing restaurant web sites that click ."}, "abstract": {"text": "reducing transaction related expenditures , connecting with current and potential customers , and enhancing revenues and profitability . if a restaurant is to have an internet presence , what aspects of the business should be highlighted food service companies that have successfully ventured onto the web have employed assorted web based technologies to create a powerful marketing tool of unparalleled strength . historically , it has been difficult to create a set of criteria against which to evaluate website effectiveness . as practitioners consider additional resources for website development , the effectiveness of e marketing investment becomes increasingly important . care must be exercised to ensure that the quality of the site adheres to high standards and incorporates evolving technology , as appropriate . developing a coherent website strategy , including an effective website design , are proving critical to an effective web presence", "tokenized": "reducing transaction related expenditures , connecting with current and potential customers , and enhancing revenues and profitability . if a restaurant is to have an internet presence , what aspects of the business should be highlighted food service companies that have successfully ventured onto the web have employed assorted web based technologies to create a powerful marketing tool of unparalleled strength . historically , it has been difficult to create a set of criteria against which to evaluate website effectiveness . as practitioners consider additional resources for website development , the effectiveness of e marketing investment becomes increasingly important . care must be exercised to ensure that the quality of the site adheres to high standards and incorporates evolving technology , as appropriate . developing a coherent website strategy , including an effective website design , are proving critical to an effective web presence"}, "present_kps": {"text": ["restaurant web sites", "revenues", "profitability", "internet presence", "food service companies", "e marketing"], "tokenized": ["restaurant web sites", "revenues", "profitability", "internet presence", "food service companies", "e marketing"]}, "absent_kps": {"text": ["electronic commerce"], "tokenized": ["electronic commerce"]}}
{"id": 46, "title": {"text": "exploring developments in web based relationship marketing within the hotel .", "tokenized": "exploring developments in web based relationship marketing within the hotel ."}, "abstract": {"text": "this paper provides a content analysis study of the application of world wide web marketing by the hotel industry . there is a lack of historical perspective on industry related web marketing applications and this paper attempts to resolve this with a two year follow up case study of the changing use of the web to develop different types of relationships . specifically , the aims are ( [digit] ) to identify key changes in the way hotels are using the web ( [digit] ) to look for evidence of the adoption of a relationship marketing ( rm ) model as a strategy for the development of hotel web sites and the use of new technologies and , ( [digit] ) to investigate the use of multimedia in hotel web sites . the development and strategic exploitation of the internet has transformed the basis of marketing . using the evidence from a web content survey this study reveals the way relationships are being created and managed within the hotel industry by its use of the web as a marketing tool . the authors have collected evidence by means of a descriptive study on the way hotels build and create relationships with their web presence delivering multimedia information as well as channel and interactive means of communication . in addition a strategic framework is offered as the means to describe the mechanism and orientation of web based marketing by hotels . the study utilizes a model by gilbert ( [digit] ) as a means of developing a measurement instrument to allow a content analysis of the current approach by hotels to the development of web sites . the results indicate hotels are aware of the new uses of web technology and are promoting hotel products in the global electronic market in new and sophisticated ways", "tokenized": "this paper provides a content analysis study of the application of world wide web marketing by the hotel industry . there is a lack of historical perspective on industry related web marketing applications and this paper attempts to resolve this with a two year follow up case study of the changing use of the web to develop different types of relationships . specifically , the aims are ( [digit] ) to identify key changes in the way hotels are using the web ( [digit] ) to look for evidence of the adoption of a relationship marketing ( rm ) model as a strategy for the development of hotel web sites and the use of new technologies and , ( [digit] ) to investigate the use of multimedia in hotel web sites . the development and strategic exploitation of the internet has transformed the basis of marketing . using the evidence from a web content survey this study reveals the way relationships are being created and managed within the hotel industry by its use of the web as a marketing tool . the authors have collected evidence by means of a descriptive study on the way hotels build and create relationships with their web presence delivering multimedia information as well as channel and interactive means of communication . in addition a strategic framework is offered as the means to describe the mechanism and orientation of web based marketing by hotels . the study utilizes a model by gilbert ( [digit] ) as a means of developing a measurement instrument to allow a content analysis of the current approach by hotels to the development of web sites . the results indicate hotels are aware of the new uses of web technology and are promoting hotel products in the global electronic market in new and sophisticated ways"}, "present_kps": {"text": ["web based relationship marketing", "world wide web marketing", "hotel industry", "hotel web sites", "multimedia", "web content survey", "global electronic market"], "tokenized": ["web based relationship marketing", "world wide web marketing", "hotel industry", "hotel web sites", "multimedia", "web content survey", "global electronic market"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 47, "title": {"text": "online auctions dynamic pricing and the lodging industry .", "tokenized": "online auctions dynamic pricing and the lodging industry ."}, "abstract": {"text": "rapidly being displaced by web site scripting , online intermediaries , and specialty brokers . businesses that pioneered internet usage relied on it as a sales and marketing alternative to predecessor product distribution channels . as such , web sites replace the traditional trading model to the internet . web enabled companies are popular because the medium renders the process faster , less costly , highly reliable , and secure . auction based models impact business models by converting the price setting mechanism from supplier centric to market centric and transforming the trading model from one to many to many to many . historically , pricing was based on the cost of production plus a margin of profit . traditionally , as products and services move through the supply chain , from the producer to the consumer , various intermediaries added their share of profit to the price . as internet based mediums of distribution become more prevalent , traditional pricing models are being supplanted with dynamic pricing . a dynamic pricing model represents a flexible system that changes prices not only from product to product , but also from customer to customer and transaction to transaction . many industry leaders are skeptical of the long run impact of online auctions on lodging industry profit margins , despite the fact pricing theory suggests that an increase in the flow of information results in efficient market pricing . the future of such endeavors remains promising , but controversial", "tokenized": "rapidly being displaced by web site scripting , online intermediaries , and specialty brokers . businesses that pioneered internet usage relied on it as a sales and marketing alternative to predecessor product distribution channels . as such , web sites replace the traditional trading model to the internet . web enabled companies are popular because the medium renders the process faster , less costly , highly reliable , and secure . auction based models impact business models by converting the price setting mechanism from supplier centric to market centric and transforming the trading model from one to many to many to many . historically , pricing was based on the cost of production plus a margin of profit . traditionally , as products and services move through the supply chain , from the producer to the consumer , various intermediaries added their share of profit to the price . as internet based mediums of distribution become more prevalent , traditional pricing models are being supplanted with dynamic pricing . a dynamic pricing model represents a flexible system that changes prices not only from product to product , but also from customer to customer and transaction to transaction . many industry leaders are skeptical of the long run impact of online auctions on lodging industry profit margins , despite the fact pricing theory suggests that an increase in the flow of information results in efficient market pricing . the future of such endeavors remains promising , but controversial"}, "present_kps": {"text": ["online auctions", "dynamic pricing", "lodging industry", "web site scripting", "online intermediaries", "specialty brokers", "internet usage", "sales", "marketing", "trading model", "business models", "price setting mechanism", "supply chain"], "tokenized": ["online auctions", "dynamic pricing", "lodging industry", "web site scripting", "online intermediaries", "specialty brokers", "internet usage", "sales", "marketing", "trading model", "business models", "price setting mechanism", "supply chain"]}, "absent_kps": {"text": ["overnight accommodations"], "tokenized": ["overnight accommodations"]}}
{"id": 48, "title": {"text": "affine invariants of convex polygons .", "tokenized": "affine invariants of convex polygons ."}, "abstract": {"text": "registration and object recognition , proposed recently by yang and cohen ( see ibid . , vol . [digit] , no . [digit] , p . [digit] [digit] , july [digit] ) are algebraically dependent . we show how to select an independent and complete set of the invariants . the use of this new set leads to a significant reduction of the computing complexity without decreasing the discrimination power", "tokenized": "registration and object recognition , proposed recently by yang and cohen ( see ibid . , vol . [digit] , no . [digit] , p . [digit] [digit] , july [digit] ) are algebraically dependent . we show how to select an independent and complete set of the invariants . the use of this new set leads to a significant reduction of the computing complexity without decreasing the discrimination power"}, "present_kps": {"text": ["affine invariants", "convex polygons", "object recognition"], "tokenized": ["affine invariants", "convex polygons", "object recognition"]}, "absent_kps": {"text": ["image registration", "feature vector", "convex quadruplet", "complexity reduction", "algebraically dependent . invariants"], "tokenized": ["image registration", "feature vector", "convex quadruplet", "complexity reduction", "algebraically dependent . invariants"]}}
{"id": 49, "title": {"text": "real time implementation of a new low memory spiht image coding algorithm using .", "tokenized": "real time implementation of a new low memory spiht image coding algorithm using ."}, "abstract": {"text": "among all algorithms based on wavelet transform and zerotree quantization , said and pearlman ' s ( [digit] ) set partitioning in hierarchical trees ( spiht ) algorithm is well known for its simplicity and efficiency . this paper deals with the real time implementation of spiht algorithm using dsp chip . in order to facilitate the implementation and improve the codec ' s performance , some relative issues are thoroughly discussed , such as the optimization of program structure to speed up the wavelet decomposition . spiht ' s high memory requirement is a major drawback for hardware implementation . in this paper , we modify the original spiht algorithm by presenting two new concepts number of error bits and absolute zerotree . consequently , the memory cost is significantly reduced . we also introduce a new method to control the coding process by number of error bits . our experimental results show that the implementation meets common requirement of real time video coding and is proven to be a practical and efficient dsp solution", "tokenized": "among all algorithms based on wavelet transform and zerotree quantization , said and pearlman ' s ( [digit] ) set partitioning in hierarchical trees ( spiht ) algorithm is well known for its simplicity and efficiency . this paper deals with the real time implementation of spiht algorithm using dsp chip . in order to facilitate the implementation and improve the codec ' s performance , some relative issues are thoroughly discussed , such as the optimization of program structure to speed up the wavelet decomposition . spiht ' s high memory requirement is a major drawback for hardware implementation . in this paper , we modify the original spiht algorithm by presenting two new concepts number of error bits and absolute zerotree . consequently , the memory cost is significantly reduced . we also introduce a new method to control the coding process by number of error bits . our experimental results show that the implementation meets common requirement of real time video coding and is proven to be a practical and efficient dsp solution"}, "present_kps": {"text": ["real time implementation", "wavelet transform", "zerotree quantization", "set partitioning in hierarchical trees", "spiht algorithm", "dsp chip", "codec", "wavelet decomposition", "number of error bits", "absolute zerotree", "video coding"], "tokenized": ["real time implementation", "wavelet transform", "zerotree quantization", "set partitioning in hierarchical trees", "spiht algorithm", "dsp chip", "codec", "wavelet decomposition", "number of error bits", "absolute zerotree", "video coding"]}, "absent_kps": {"text": ["memory cost reduction"], "tokenized": ["memory cost reduction"]}}
{"id": 50, "title": {"text": "efficient computation of local geometric moments .", "tokenized": "efficient computation of local geometric moments ."}, "abstract": {"text": "as edge detection and texture segmentation . the main reason for this is that they are inherently integral based features , so that their use reduces the effect of uncorrelated noise . the computation of local moments , when viewed as a neighborhood operation , can be interpreted as a convolution of the image with a set of masks . nevertheless , moments computed inside overlapping windows are not independent and convolution does not take this fact into account . by introducing a matrix formulation and the concept of accumulation moments , this paper presents an algorithm which is computationally much more efficient than convolving and yet as simple", "tokenized": "as edge detection and texture segmentation . the main reason for this is that they are inherently integral based features , so that their use reduces the effect of uncorrelated noise . the computation of local moments , when viewed as a neighborhood operation , can be interpreted as a convolution of the image with a set of masks . nevertheless , moments computed inside overlapping windows are not independent and convolution does not take this fact into account . by introducing a matrix formulation and the concept of accumulation moments , this paper presents an algorithm which is computationally much more efficient than convolving and yet as simple"}, "present_kps": {"text": ["edge detection", "texture segmentation", "integral based features", "neighborhood operation", "overlapping windows", "matrix formulation", "accumulation moments"], "tokenized": ["edge detection", "texture segmentation", "integral based features", "neighborhood operation", "overlapping windows", "matrix formulation", "accumulation moments"]}, "absent_kps": {"text": ["image convolution", "computationally efficient algorithm", "image analysis", "local geometric moments computation", "local features"], "tokenized": ["image convolution", "computationally efficient algorithm", "image analysis", "local geometric moments computation", "local features"]}}
{"id": 51, "title": {"text": "adaptive image denoising using scale and space consistency .", "tokenized": "adaptive image denoising using scale and space consistency ."}, "abstract": {"text": "based on image multiresolution decomposition by a redundant wavelet transform . in our approach , edges are implicitly located and preserved in the wavelet domain , whilst image noise is filtered out . at each resolution level , the image edges are estimated by gradient magnitudes ( obtained from the wavelet coefficients ) , which are modeled probabilistically , and a shrinkage function is assembled based on the model obtained . joint use of space and scale consistency is applied for better preservation of edges . the shrinkage functions are combined to preserve edges that appear simultaneously at several resolutions , and geometric constraints are applied to preserve edges that are not isolated . the proposed technique produces a filtered version of the original image , where homogeneous regions appear separated by well defined edges . possible applications include image presegmentation , and image denoising", "tokenized": "based on image multiresolution decomposition by a redundant wavelet transform . in our approach , edges are implicitly located and preserved in the wavelet domain , whilst image noise is filtered out . at each resolution level , the image edges are estimated by gradient magnitudes ( obtained from the wavelet coefficients ) , which are modeled probabilistically , and a shrinkage function is assembled based on the model obtained . joint use of space and scale consistency is applied for better preservation of edges . the shrinkage functions are combined to preserve edges that appear simultaneously at several resolutions , and geometric constraints are applied to preserve edges that are not isolated . the proposed technique produces a filtered version of the original image , where homogeneous regions appear separated by well defined edges . possible applications include image presegmentation , and image denoising"}, "present_kps": {"text": ["adaptive image denoising", "space consistency", "image multiresolution decomposition", "redundant wavelet transform", "image edges", "gradient magnitudes", "shrinkage function", "scale consistency", "geometric constraints"], "tokenized": ["adaptive image denoising", "space consistency", "image multiresolution decomposition", "redundant wavelet transform", "image edges", "gradient magnitudes", "shrinkage function", "scale consistency", "geometric constraints"]}, "absent_kps": {"text": ["edge preservation", "edge enhancement"], "tokenized": ["edge preservation", "edge enhancement"]}}
{"id": 52, "title": {"text": "tracking nonparameterized object contours in video .", "tokenized": "tracking nonparameterized object contours in video ."}, "abstract": {"text": "transform of the edge map is used as an edge indicator function for contour detection . using the concept of topographical distance , the watershed segmentation can be formulated as a minimization . this new viewpoint gives a way to combine the results of the watershed algorithm on different surfaces . in particular , our algorithm determines the contour as a combination of the current edge map and the contour , predicted from the tracking result in the previous frame . we also show that the problem of background clutter can be relaxed by taking the object motion into account . the compensation with object motion allows to detect and remove spurious edges in background . the experimental results confirm the expected advantages of the proposed method over the existing approaches", "tokenized": "transform of the edge map is used as an edge indicator function for contour detection . using the concept of topographical distance , the watershed segmentation can be formulated as a minimization . this new viewpoint gives a way to combine the results of the watershed algorithm on different surfaces . in particular , our algorithm determines the contour as a combination of the current edge map and the contour , predicted from the tracking result in the previous frame . we also show that the problem of background clutter can be relaxed by taking the object motion into account . the compensation with object motion allows to detect and remove spurious edges in background . the experimental results confirm the expected advantages of the proposed method over the existing approaches"}, "present_kps": {"text": ["nonparameterized object contours", "video", "edge map", "edge indicator function", "topographical distance", "watershed segmentation", "minimization", "background clutter", "object motion"], "tokenized": ["nonparameterized object contours", "video", "edge map", "edge indicator function", "topographical distance", "watershed segmentation", "minimization", "background clutter", "object motion"]}, "absent_kps": {"text": ["edge detection", "inverted distance transform", "contour tracking", "motion analysis", "motion estimation"], "tokenized": ["edge detection", "inverted distance transform", "contour tracking", "motion analysis", "motion estimation"]}}
{"id": 53, "title": {"text": "multilayered image representation application to image compression .", "tokenized": "multilayered image representation application to image compression ."}, "abstract": {"text": "and image compression . we describe a new multilayered representation technique for images . an image is parsed into a superposition of coherent layers piecewise smooth regions layer , textures layer , etc . the multilayered decomposition algorithm consists in a cascade of compressions applied successively to the image itself and to the residuals that resulted from the previous compressions . during each iteration of the algorithm , we code the residual part in a lossy way we only retain the most significant structures of the residual part , which results in a sparse representation . each layer is encoded independently with a different transform , or basis , at a different bitrate , and the combination of the compressed layers can always be reconstructed in a meaningful way . the strength of the multilayer approach comes from the fact that different sets of basis functions complement each others some of the basis functions will give reasonable account of the large trend of the data , while others will catch the local transients , or the oscillatory patterns . this multilayered representation has a lot of beautiful applications in image understanding , and image and video coding . we have implemented the algorithm and we have studied its capabilities", "tokenized": "and image compression . we describe a new multilayered representation technique for images . an image is parsed into a superposition of coherent layers piecewise smooth regions layer , textures layer , etc . the multilayered decomposition algorithm consists in a cascade of compressions applied successively to the image itself and to the residuals that resulted from the previous compressions . during each iteration of the algorithm , we code the residual part in a lossy way we only retain the most significant structures of the residual part , which results in a sparse representation . each layer is encoded independently with a different transform , or basis , at a different bitrate , and the combination of the compressed layers can always be reconstructed in a meaningful way . the strength of the multilayer approach comes from the fact that different sets of basis functions complement each others some of the basis functions will give reasonable account of the large trend of the data , while others will catch the local transients , or the oscillatory patterns . this multilayered representation has a lot of beautiful applications in image understanding , and image and video coding . we have implemented the algorithm and we have studied its capabilities"}, "present_kps": {"text": ["image representation", "image compression", "multilayered representation", "piecewise smooth regions layer", "textures layer", "multilayered decomposition algorithm", "residual part", "sparse representation", "basis functions"], "tokenized": ["image representation", "image compression", "multilayered representation", "piecewise smooth regions layer", "textures layer", "multilayered decomposition algorithm", "residual part", "sparse representation", "basis functions"]}, "absent_kps": {"text": ["cosine transforms", "wavelet transforms", "transform coding"], "tokenized": ["cosine transforms", "wavelet transforms", "transform coding"]}}
{"id": 54, "title": {"text": "combining spatial and scale space techniques for edge detection to provide a .", "tokenized": "combining spatial and scale space techniques for edge detection to provide a ."}, "abstract": {"text": "new methods for detecting edges in an image using spatial and scale space domains are proposed . a priori knowledge about geometrical characteristics of edges is used to assign a probability factor to the chance of any pixel being on an edge . an improved double thresholding technique is introduced for spatial domain filtering . probabilities that pixels belong to a given edge are assigned based on pixel similarity across gradient amplitudes , gradient phases and edge connectivity . the scale space approach uses dynamic range compression to allow wavelet correlation over a wider range of scales . a probabilistic formulation is used to combine the results obtained from filtering in each domain to provide a final edge probability image which has the advantages of both spatial and scale space domain methods . decomposing this edge probability image with the same wavelet as the original image permits the generation of adaptive filters that can recognize the characteristics of the edges in all wavelet detail and approximation images regardless of scale . these matched filters permit significant reduction in image noise without contributing to edge distortion . the spatially adaptive wavelet noise filtering algorithm is qualitatively and quantitatively compared to a frequency domain and two wavelet based noise suppression algorithms using both natural and computer generated noisy images", "tokenized": "new methods for detecting edges in an image using spatial and scale space domains are proposed . a priori knowledge about geometrical characteristics of edges is used to assign a probability factor to the chance of any pixel being on an edge . an improved double thresholding technique is introduced for spatial domain filtering . probabilities that pixels belong to a given edge are assigned based on pixel similarity across gradient amplitudes , gradient phases and edge connectivity . the scale space approach uses dynamic range compression to allow wavelet correlation over a wider range of scales . a probabilistic formulation is used to combine the results obtained from filtering in each domain to provide a final edge probability image which has the advantages of both spatial and scale space domain methods . decomposing this edge probability image with the same wavelet as the original image permits the generation of adaptive filters that can recognize the characteristics of the edges in all wavelet detail and approximation images regardless of scale . these matched filters permit significant reduction in image noise without contributing to edge distortion . the spatially adaptive wavelet noise filtering algorithm is qualitatively and quantitatively compared to a frequency domain and two wavelet based noise suppression algorithms using both natural and computer generated noisy images"}, "present_kps": {"text": ["scale space techniques", "edge detection", "a priori knowledge", "geometrical characteristics", "probability factor", "double thresholding technique", "spatial domain filtering", "pixel similarity", "gradient amplitudes", "gradient phases", "edge connectivity", "dynamic range compression", "wavelet correlation", "probabilistic formulation", "final edge probability image", "adaptive filters", "approximation images", "matched filters", "image noise", "spatially adaptive wavelet noise filtering algorithm", "noise suppression"], "tokenized": ["scale space techniques", "edge detection", "a priori knowledge", "geometrical characteristics", "probability factor", "double thresholding technique", "spatial domain filtering", "pixel similarity", "gradient amplitudes", "gradient phases", "edge connectivity", "dynamic range compression", "wavelet correlation", "probabilistic formulation", "final edge probability image", "adaptive filters", "approximation images", "matched filters", "image noise", "spatially adaptive wavelet noise filtering algorithm", "noise suppression"]}, "absent_kps": {"text": ["spatial techniques", "spatially adaptive wavelet based noise filtering algorithm"], "tokenized": ["spatial techniques", "spatially adaptive wavelet based noise filtering algorithm"]}}
{"id": 55, "title": {"text": "computational capacity of an odorant discriminator the linear separability of .", "tokenized": "computational capacity of an odorant discriminator the linear separability of ."}, "abstract": {"text": "we introduce and study an artificial neural network inspired by the probabilistic receptor affinity distribution model of olfaction . our system consists of n sensory neurons whose outputs converge on a single processing linear threshold element . the system ' s aim is to model discrimination of a single target odorant from a large number p of background odorants within a range of odorant concentrations . we show that this is possible provided p does not exceed a critical value p sub c and calculate the critical capacity alpha c p sub c n . the critical capacity depends on the range of concentrations in which the discrimination is to be accomplished . if the olfactory bulb may be thought of as a collection of such processing elements , each responsible for the discrimination of a single odorant , our study provides a quantitative analysis of the potential computational properties of the olfactory bulb . the mathematical formulation of the problem we consider is one of determining the capacity for linear separability of continuous curves , embedded in a large dimensional space . this is accomplished here by a numerical study , using a method that signals whether the discrimination task is realizable , together with a finite size scaling analysis", "tokenized": "we introduce and study an artificial neural network inspired by the probabilistic receptor affinity distribution model of olfaction . our system consists of n sensory neurons whose outputs converge on a single processing linear threshold element . the system ' s aim is to model discrimination of a single target odorant from a large number p of background odorants within a range of odorant concentrations . we show that this is possible provided p does not exceed a critical value p sub c and calculate the critical capacity alpha c p sub c n . the critical capacity depends on the range of concentrations in which the discrimination is to be accomplished . if the olfactory bulb may be thought of as a collection of such processing elements , each responsible for the discrimination of a single odorant , our study provides a quantitative analysis of the potential computational properties of the olfactory bulb . the mathematical formulation of the problem we consider is one of determining the capacity for linear separability of continuous curves , embedded in a large dimensional space . this is accomplished here by a numerical study , using a method that signals whether the discrimination task is realizable , together with a finite size scaling analysis"}, "present_kps": {"text": ["odorant discriminator", "linear separability", "artificial neural network", "receptor affinity distribution", "olfaction", "sensory neurons", "linear threshold element"], "tokenized": ["odorant discriminator", "linear separability", "artificial neural network", "receptor affinity distribution", "olfaction", "sensory neurons", "linear threshold element"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 56, "title": {"text": "lossy to lossless object based coding of [digit] d mri data .", "tokenized": "lossy to lossless object based coding of [digit] d mri data ."}, "abstract": {"text": "exploiting the diagnostic relevance of the different regions of the volumetric data for rate allocation . the data are first decorrelated via a [digit] d discrete wavelet transform . the implementation via the lifting steps scheme allows to map integer to integer values , enabling lossless coding , and facilitates the definition of the object based inverse transform . the coding process assigns disjoint segments of the bitstream to the different objects , which can be independently accessed and reconstructed at any up to lossless quality . two fully [digit] d coding strategies are considered embedded zerotree coding ( ezw 3d ) and multidimensional layered zero coding ( mlzc ) , both generalized for region of interest ( roi ) based processing . in order to avoid artifacts along region boundaries , some extra coefficients must be encoded for each object . this gives rise to an overheading of the bitstream with respect to the case where the volume is encoded as a whole . the amount of such extra information depends on both the filter length and the decomposition depth . the system is characterized on a set of head magnetic resonance images . results show that mlzc and ezw 3d have competitive performances . in particular , the best mlzc mode outperforms the others state of the art techniques on one of the datasets for which results are available in the literature", "tokenized": "exploiting the diagnostic relevance of the different regions of the volumetric data for rate allocation . the data are first decorrelated via a [digit] d discrete wavelet transform . the implementation via the lifting steps scheme allows to map integer to integer values , enabling lossless coding , and facilitates the definition of the object based inverse transform . the coding process assigns disjoint segments of the bitstream to the different objects , which can be independently accessed and reconstructed at any up to lossless quality . two fully [digit] d coding strategies are considered embedded zerotree coding ( ezw 3d ) and multidimensional layered zero coding ( mlzc ) , both generalized for region of interest ( roi ) based processing . in order to avoid artifacts along region boundaries , some extra coefficients must be encoded for each object . this gives rise to an overheading of the bitstream with respect to the case where the volume is encoded as a whole . the amount of such extra information depends on both the filter length and the decomposition depth . the system is characterized on a set of head magnetic resonance images . results show that mlzc and ezw 3d have competitive performances . in particular , the best mlzc mode outperforms the others state of the art techniques on one of the datasets for which results are available in the literature"}, "present_kps": {"text": ["lossless object based coding", "[digit] d mri data", "diagnostic relevance", "volumetric data", "rate allocation", "[digit] d discrete wavelet transform", "lifting steps scheme", "integer to integer values", "object based inverse transform", "disjoint segments", "bitstream", "embedded zerotree coding", "ezw 3d", "multidimensional layered zero coding", "region boundaries", "filter length", "decomposition depth", "head magnetic resonance images"], "tokenized": ["lossless object based coding", "[digit] d mri data", "diagnostic relevance", "volumetric data", "rate allocation", "[digit] d discrete wavelet transform", "lifting steps scheme", "integer to integer values", "object based inverse transform", "disjoint segments", "bitstream", "embedded zerotree coding", "ezw 3d", "multidimensional layered zero coding", "region boundaries", "filter length", "decomposition depth", "head magnetic resonance images"]}, "absent_kps": {"text": ["roi based processing", "region of interest based processing", "nmzq", "lossy object based coding"], "tokenized": ["roi based processing", "region of interest based processing", "nmzq", "lossy object based coding"]}}
{"id": 57, "title": {"text": "optimal linear control in stabilizer design .", "tokenized": "optimal linear control in stabilizer design ."}, "abstract": {"text": "synthesis of the turbine and generator control systems , because of the high effectiveness and relatively low cost of these elements . the synthesis and construction of the effective synchronous generator and turbine controller is a very difficult task . this paper describes the seven step mu synthesis approach to pss design enabling the synchronous generator to remain stable over a wide range of system operating conditions", "tokenized": "synthesis of the turbine and generator control systems , because of the high effectiveness and relatively low cost of these elements . the synthesis and construction of the effective synchronous generator and turbine controller is a very difficult task . this paper describes the seven step mu synthesis approach to pss design enabling the synchronous generator to remain stable over a wide range of system operating conditions"}, "present_kps": {"text": ["optimal linear control", "mu synthesis approach", "pss design"], "tokenized": ["optimal linear control", "mu synthesis approach", "pss design"]}, "absent_kps": {"text": ["synchronous generator control system synthesis", "turbine control system synthesis"], "tokenized": ["synchronous generator control system synthesis", "turbine control system synthesis"]}}
{"id": 58, "title": {"text": "verifying resonant grounding in distribution systems .", "tokenized": "verifying resonant grounding in distribution systems ."}, "abstract": {"text": "distribution network resonant grounding systems with regard to compensation coil tuning and to fault detection", "tokenized": "distribution network resonant grounding systems with regard to compensation coil tuning and to fault detection"}, "present_kps": {"text": ["resonant grounding systems", "compensation coil tuning", "fault detection"], "tokenized": ["resonant grounding systems", "compensation coil tuning", "fault detection"]}, "absent_kps": {"text": ["power distribution systems", "resfal software tool", "computer simulation"], "tokenized": ["power distribution systems", "resfal software tool", "computer simulation"]}}
{"id": 59, "title": {"text": "power electronics spark new simulation challenges .", "tokenized": "power electronics spark new simulation challenges ."}, "abstract": {"text": "systems and explores some of the inherent requirements for simulation technologies in order to keep up with this rapidly changing environment . the authors describe how energy utilities are realizing that , with the appropriate tools , they can train and sustain engineers who can maintain a great insight into system dynamics", "tokenized": "systems and explores some of the inherent requirements for simulation technologies in order to keep up with this rapidly changing environment . the authors describe how energy utilities are realizing that , with the appropriate tools , they can train and sustain engineers who can maintain a great insight into system dynamics"}, "present_kps": {"text": ["power electronics", "simulation challenges", "simulation technologies"], "tokenized": ["power electronics", "simulation challenges", "simulation technologies"]}, "absent_kps": {"text": ["power system computer simulation", "electric utilities"], "tokenized": ["power system computer simulation", "electric utilities"]}}
{"id": 60, "title": {"text": "deriving model parameters from field test measurements generator control .", "tokenized": "deriving model parameters from field test measurements generator control ."}, "abstract": {"text": "a major component of any power system simulation is the generating plant . the purpose of deriveassist is to speed up the parameter derivation process and to allow engineers less versed in parameter matching and identification to get involved in the process of power plant electric generator modelling", "tokenized": "a major component of any power system simulation is the generating plant . the purpose of deriveassist is to speed up the parameter derivation process and to allow engineers less versed in parameter matching and identification to get involved in the process of power plant electric generator modelling"}, "present_kps": {"text": ["power system simulation", "deriveassist", "parameter derivation process", "parameter matching"], "tokenized": ["power system simulation", "deriveassist", "parameter derivation process", "parameter matching"]}, "absent_kps": {"text": ["control simulation", "parameter identification", "computer simulation", "power system stability analysis", "steady state parameters derivation", "generator parameter derivation process", "turbine governor"], "tokenized": ["control simulation", "parameter identification", "computer simulation", "power system stability analysis", "steady state parameters derivation", "generator parameter derivation process", "turbine governor"]}}
{"id": 61, "title": {"text": "prospective on computer applications in power .", "tokenized": "prospective on computer applications in power ."}, "abstract": {"text": "have made it very difficult to keep up with industry changes and have made it much more difficult to envision the future . in this article , current key issues and major developments of the past few years are reviewed to provide perspective , and prospects for future computer applications in power are suggested . technology changes are occurring at an exponential rate . the interconnected bulk electric systems are becoming integrated with vast networked information systems . this article discusses the skills that will be needed by future power engineers to keep pace with these developments and trends", "tokenized": "have made it very difficult to keep up with industry changes and have made it much more difficult to envision the future . in this article , current key issues and major developments of the past few years are reviewed to provide perspective , and prospects for future computer applications in power are suggested . technology changes are occurring at an exponential rate . the interconnected bulk electric systems are becoming integrated with vast networked information systems . this article discusses the skills that will be needed by future power engineers to keep pace with these developments and trends"}, "present_kps": {"text": ["computer applications", "technology changes", "interconnected bulk electric systems", "networked information systems"], "tokenized": ["computer applications", "technology changes", "interconnected bulk electric systems", "networked information systems"]}, "absent_kps": {"text": ["electric power industry deregulation", "electricity industry restructuring"], "tokenized": ["electric power industry deregulation", "electricity industry restructuring"]}}
{"id": 62, "title": {"text": "control centers are here to stay .", "tokenized": "control centers are here to stay ."}, "abstract": {"text": "control center must always be in place to maintain the security , reliability , and quality of electric service . this article focuses on the energy management system ( ems ) control center , identifying the major functions that have become standard components of every application software package . the two most important control center functions , security control and load following control , guarantee the continuity of electric service , which after all , is the end product of the utility business . new technology trends in the design of control center infrastructures are emerging in the liberalized environment of the energy market . an example of a control center infrastructure is described . the article ends with a concern for the security of the control center itself", "tokenized": "control center must always be in place to maintain the security , reliability , and quality of electric service . this article focuses on the energy management system ( ems ) control center , identifying the major functions that have become standard components of every application software package . the two most important control center functions , security control and load following control , guarantee the continuity of electric service , which after all , is the end product of the utility business . new technology trends in the design of control center infrastructures are emerging in the liberalized environment of the energy market . an example of a control center infrastructure is described . the article ends with a concern for the security of the control center itself"}, "present_kps": {"text": ["energy management system", "standard components", "application software package", "security control", "load following control", "control center infrastructures", "liberalized environment", "energy market"], "tokenized": ["energy management system", "standard components", "application software package", "security control", "load following control", "control center infrastructures", "liberalized environment", "energy market"]}, "absent_kps": {"text": ["electric service continuity", "ems control centers"], "tokenized": ["electric service continuity", "ems control centers"]}}
{"id": 63, "title": {"text": "virus hunting .", "tokenized": "virus hunting ."}, "abstract": {"text": "software . the good news is that av software has come a long way fast . four or so years ago it was true to write that av software could not detect trojan horses and similar intrusion attempts . now it can and does . mcafee ' s virusscan , for example , goes one further it detects viruses , worms and trojan horses and deploys itself as a firewall to filter data packets , control access to internet resources , activate rule sets for specific applications , in general to protect against hackers . but like so much software , we use it with little thought as to how it came to do its job . behind the scenes there is an army of top notch programmers trying to stay ahead of the baddies who , at the last count , had produced some [digit] , [digit] viruses", "tokenized": "software . the good news is that av software has come a long way fast . four or so years ago it was true to write that av software could not detect trojan horses and similar intrusion attempts . now it can and does . mcafee ' s virusscan , for example , goes one further it detects viruses , worms and trojan horses and deploys itself as a firewall to filter data packets , control access to internet resources , activate rule sets for specific applications , in general to protect against hackers . but like so much software , we use it with little thought as to how it came to do its job . behind the scenes there is an army of top notch programmers trying to stay ahead of the baddies who , at the last count , had produced some [digit] , [digit] viruses"}, "present_kps": {"text": ["trojan horses", "worms", "programmers"], "tokenized": ["trojan horses", "worms", "programmers"]}, "absent_kps": {"text": ["anti virus software"], "tokenized": ["anti virus software"]}}
{"id": 64, "title": {"text": "integration is key an introduction to enterprise application integration .", "tokenized": "integration is key an introduction to enterprise application integration ."}, "abstract": {"text": "over the past few years , numerous organisations have invested in the latest software applications to drive their business forward . but many are now finding that these systems are becoming redundant on their own . the key to staying ahead of the competition in today ' s current climate is now to integrate all of these systems , says justin opie , portfolio director at imark communications", "tokenized": "over the past few years , numerous organisations have invested in the latest software applications to drive their business forward . but many are now finding that these systems are becoming redundant on their own . the key to staying ahead of the competition in today ' s current climate is now to integrate all of these systems , says justin opie , portfolio director at imark communications"}, "present_kps": {"text": ["enterprise application integration", "imark communications"], "tokenized": ["enterprise application integration", "imark communications"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 65, "title": {"text": "managing system risk .", "tokenized": "managing system risk ."}, "abstract": {"text": "secure and conform to commercial security standards . senior business managers are ultimately responsible for the security of their corporate systems and for the implications in the event of a failure . businesses will be exposed to unquantified security risks unless they have a formal risk management framework in place to enable risks to be identified , evaluated and managed . failure to assess and manage risks can lead to a business suffering serious financial impacts , commercial embarrassment and fines or sanctions from regulators . this is both a key responsibility and opportunity for management services practitioners", "tokenized": "secure and conform to commercial security standards . senior business managers are ultimately responsible for the security of their corporate systems and for the implications in the event of a failure . businesses will be exposed to unquantified security risks unless they have a formal risk management framework in place to enable risks to be identified , evaluated and managed . failure to assess and manage risks can lead to a business suffering serious financial impacts , commercial embarrassment and fines or sanctions from regulators . this is both a key responsibility and opportunity for management services practitioners"}, "present_kps": {"text": ["commercial security standards", "risk management framework"], "tokenized": ["commercial security standards", "risk management framework"]}, "absent_kps": {"text": ["it projects"], "tokenized": ["it projects"]}}
{"id": 66, "title": {"text": "on optimality in auditory information processing .", "tokenized": "on optimality in auditory information processing ."}, "abstract": {"text": "the primary part of the mammalian auditory system using a stochastic fitzhugh nagumo model and an action recovery model for synaptic depression . our overall model covers the chain from a hair cell to a point just after the synaptic connection with a cell in the cochlear nucleus . the information processing performance of the system is evaluated using so called phi divergences from statistics that quantify dissimilarity between probability measures and are intimately related to a number of fundamental limits in statistics and information theory ( it ) . we show that there exists a set of parameters that can optimize several important phi divergences simultaneously and that this set corresponds to a constant quiescent firing rate ( qfr ) of the spiral ganglion neuron . the optimal value of the qfr is frequency dependent but is essentially independent of the amplitude of the signal ( for small amplitudes ) . consequently , optimal processing according to several standard it criteria can be accomplished for this model if and only if the parameters are tuned to values that correspond to one and the same qfr . this offers a new explanation for the qfr and can provide new insight into the role played by several other parameters of the peripheral auditory system", "tokenized": "the primary part of the mammalian auditory system using a stochastic fitzhugh nagumo model and an action recovery model for synaptic depression . our overall model covers the chain from a hair cell to a point just after the synaptic connection with a cell in the cochlear nucleus . the information processing performance of the system is evaluated using so called phi divergences from statistics that quantify dissimilarity between probability measures and are intimately related to a number of fundamental limits in statistics and information theory ( it ) . we show that there exists a set of parameters that can optimize several important phi divergences simultaneously and that this set corresponds to a constant quiescent firing rate ( qfr ) of the spiral ganglion neuron . the optimal value of the qfr is frequency dependent but is essentially independent of the amplitude of the signal ( for small amplitudes ) . consequently , optimal processing according to several standard it criteria can be accomplished for this model if and only if the parameters are tuned to values that correspond to one and the same qfr . this offers a new explanation for the qfr and can provide new insight into the role played by several other parameters of the peripheral auditory system"}, "present_kps": {"text": ["mammalian auditory system", "stochastic fitzhugh nagumo model", "action recovery model", "quiescent firing rate", "spiral ganglion neuron", "peripheral auditory system"], "tokenized": ["mammalian auditory system", "stochastic fitzhugh nagumo model", "action recovery model", "quiescent firing rate", "spiral ganglion neuron", "peripheral auditory system"]}, "absent_kps": {"text": ["weak sinusoidal signals", "brain"], "tokenized": ["weak sinusoidal signals", "brain"]}}
{"id": 67, "title": {"text": "electrical facility construction work for information network structuring by .", "tokenized": "electrical facility construction work for information network structuring by ."}, "abstract": {"text": "to confront the advent of the advanced information society , there has been a pressing demand for the adjustment of the communications infrastructure and the structuring of the information network by utilizing the sewage conduits . the city of tokyo is promoting a project by the name of the sewer optical fiber teleway ( soft ) network plan . according to this plan , the total distance of the optical fiber network laid in the sewer conduits is scheduled to reach about [digit] km by the end of march [digit] . at the final stage , this distance will reach [digit] km as a whole . we completed the construction work for the information control facilities scattered in [digit] places inclusive of the treatment site s , with the intention to adjust and extend the information transmission network laid through the above mentioned optical fiber network , to be used exclusively by the bureau of sewerage . this construction work is described in the paper", "tokenized": "to confront the advent of the advanced information society , there has been a pressing demand for the adjustment of the communications infrastructure and the structuring of the information network by utilizing the sewage conduits . the city of tokyo is promoting a project by the name of the sewer optical fiber teleway ( soft ) network plan . according to this plan , the total distance of the optical fiber network laid in the sewer conduits is scheduled to reach about [digit] km by the end of march [digit] . at the final stage , this distance will reach [digit] km as a whole . we completed the construction work for the information control facilities scattered in [digit] places inclusive of the treatment site s , with the intention to adjust and extend the information transmission network laid through the above mentioned optical fiber network , to be used exclusively by the bureau of sewerage . this construction work is described in the paper"}, "present_kps": {"text": ["electrical facility construction work", "information network structuring", "communications infrastructure", "sewage conduits", "tokyo", "information control facilities", "treatment site s", "information transmission network", "bureau of sewerage"], "tokenized": ["electrical facility construction work", "information network structuring", "communications infrastructure", "sewage conduits", "tokyo", "information control facilities", "treatment site s", "information transmission network", "bureau of sewerage"]}, "absent_kps": {"text": ["sewer optical fiber teleway network plan", "asynchronous transmission mode switches", "atm switches"], "tokenized": ["sewer optical fiber teleway network plan", "asynchronous transmission mode switches", "atm switches"]}}
{"id": 68, "title": {"text": "a framework for evaluating the data hiding capacity of image sources .", "tokenized": "a framework for evaluating the data hiding capacity of image sources ."}, "abstract": {"text": "presented in this paper . previous theoretical results are used to characterize the fundamental capacity limits of image watermarking and data hiding systems . capacity is determined by the statistical model used for the host image , by the distortion constraints on the data hider and the attacker , and by the information available to the data hider , to the attacker , and to the decoder . we consider autoregressive , block dct , and wavelet statistical models for images and compute data hiding capacity for compressed and uncompressed host image sources . closed form expressions are obtained under sparse model approximations . models for geometric attacks and distortion measures that are invariant to such attacks are considered", "tokenized": "presented in this paper . previous theoretical results are used to characterize the fundamental capacity limits of image watermarking and data hiding systems . capacity is determined by the statistical model used for the host image , by the distortion constraints on the data hider and the attacker , and by the information available to the data hider , to the attacker , and to the decoder . we consider autoregressive , block dct , and wavelet statistical models for images and compute data hiding capacity for compressed and uncompressed host image sources . closed form expressions are obtained under sparse model approximations . models for geometric attacks and distortion measures that are invariant to such attacks are considered"}, "present_kps": {"text": ["data hiding capacity", "image sources", "capacity limits", "watermarking", "statistical model", "distortion constraints", "wavelet statistical models", "uncompressed host image sources", "closed form expressions", "sparse model approximations", "geometric attacks", "distortion measures"], "tokenized": ["data hiding capacity", "image sources", "capacity limits", "watermarking", "statistical model", "distortion constraints", "wavelet statistical models", "uncompressed host image sources", "closed form expressions", "sparse model approximations", "geometric attacks", "distortion measures"]}, "absent_kps": {"text": ["autoregressive statistical models", "information theoretic model", "block dct statistical models", "compressed host image sources"], "tokenized": ["autoregressive statistical models", "information theoretic model", "block dct statistical models", "compressed host image sources"]}}
{"id": 69, "title": {"text": "geometrically invariant watermarking using feature points .", "tokenized": "geometrically invariant watermarking using feature points ."}, "abstract": {"text": "robustness to geometrical distortions . the weaknesses of classical watermarking methods to geometrical distortions are outlined first . geometrical distortions can be decomposed into two classes global transformations such as rotations and translations and local transformations such as the stirmark attack . an overview of existing self synchronizing schemes is then presented . theses schemes can use periodical properties of the mark , invariant properties of transforms , template insertion , or information provided by the original image to counter geometrical distortions . thereafter , a new class of watermarking schemes using the image content is presented . we propose an embedding and detection scheme where the mark is bound with a content descriptor defined by salient points . three different types of feature points are studied and their robustness to geometrical transformations is evaluated to develop an enhanced detector . the embedding of the signature is done by extracting feature points of the image and performing a delaunay tessellation on the set of points . the mark is embedded using a classical additive scheme inside each triangle of the tessellation . the detection is done using correlation properties on the different triangles . the performance of the presented scheme is evaluated after jpeg compression , geometrical attack and transformations . results show that the fact that the scheme is robust to these different manipulations . finally , in our concluding remarks , we analyze the different perspectives of such content based watermarking scheme", "tokenized": "robustness to geometrical distortions . the weaknesses of classical watermarking methods to geometrical distortions are outlined first . geometrical distortions can be decomposed into two classes global transformations such as rotations and translations and local transformations such as the stirmark attack . an overview of existing self synchronizing schemes is then presented . theses schemes can use periodical properties of the mark , invariant properties of transforms , template insertion , or information provided by the original image to counter geometrical distortions . thereafter , a new class of watermarking schemes using the image content is presented . we propose an embedding and detection scheme where the mark is bound with a content descriptor defined by salient points . three different types of feature points are studied and their robustness to geometrical transformations is evaluated to develop an enhanced detector . the embedding of the signature is done by extracting feature points of the image and performing a delaunay tessellation on the set of points . the mark is embedded using a classical additive scheme inside each triangle of the tessellation . the detection is done using correlation properties on the different triangles . the performance of the presented scheme is evaluated after jpeg compression , geometrical attack and transformations . results show that the fact that the scheme is robust to these different manipulations . finally , in our concluding remarks , we analyze the different perspectives of such content based watermarking scheme"}, "present_kps": {"text": ["geometrically invariant watermarking", "feature points", "geometrical distortions", "global transformations", "transforms", "rotations", "translations", "local transformations", "stirmark attack", "self synchronizing schemes", "periodical properties", "invariant properties", "template insertion", "image content", "embedding", "detection scheme", "content descriptor", "delaunay tessellation", "additive scheme", "correlation properties", "jpeg compression", "geometrical attack"], "tokenized": ["geometrically invariant watermarking", "feature points", "geometrical distortions", "global transformations", "transforms", "rotations", "translations", "local transformations", "stirmark attack", "self synchronizing schemes", "periodical properties", "invariant properties", "template insertion", "image content", "embedding", "detection scheme", "content descriptor", "delaunay tessellation", "additive scheme", "correlation properties", "jpeg compression", "geometrical attack"]}, "absent_kps": {"text": ["digital images", "feature extraction"], "tokenized": ["digital images", "feature extraction"]}}
{"id": 70, "title": {"text": "color plane interpolation using alternating projections .", "tokenized": "color plane interpolation using alternating projections ."}, "abstract": {"text": "and blue colors according to a specific pattern . at the location of each pixel only one color sample is taken , and the values of the other colors must be interpolated using neighboring samples . this color plane interpolation is known as demosaicing it is one of the important tasks in a digital camera pipeline . if demosaicing is not performed appropriately , images suffer from highly visible color artifacts . in this paper we present a new demosaicing technique that uses inter channel correlation effectively in an alternating projections scheme . we have compared this technique with six state of the art demosaicing techniques , and it outperforms all of them , both visually and in terms of mean square error", "tokenized": "and blue colors according to a specific pattern . at the location of each pixel only one color sample is taken , and the values of the other colors must be interpolated using neighboring samples . this color plane interpolation is known as demosaicing it is one of the important tasks in a digital camera pipeline . if demosaicing is not performed appropriately , images suffer from highly visible color artifacts . in this paper we present a new demosaicing technique that uses inter channel correlation effectively in an alternating projections scheme . we have compared this technique with six state of the art demosaicing techniques , and it outperforms all of them , both visually and in terms of mean square error"}, "present_kps": {"text": ["color plane interpolation", "alternating projections", "demosaicing", "digital cameras", "color artifacts", "inter channel correlation"], "tokenized": ["color plane interpolation", "alternating projections", "demosaicing", "digital cameras", "color artifacts", "inter channel correlation"]}, "absent_kps": {"text": ["color filter arrays"], "tokenized": ["color filter arrays"]}}
{"id": 71, "title": {"text": "a comparison of computational color constancy algorithms . ii . experiments with .", "tokenized": "a comparison of computational color constancy algorithms . ii . experiments with ."}, "abstract": {"text": "for pt . i see ibid . , vol . [digit] , no . [digit] , p . [digit] [digit] ( [digit] ) . we test a number of the leading computational color constancy algorithms using a comprehensive set of images . these were of [digit] different scenes under [digit] different sources representative of common illumination conditions . the algorithms studied include two gray world methods , a version of the retinex method , several variants of forsyth ' s ( [digit] ) gamut mapping method , cardei et al . ' s ( [digit] ) neural net method , and finlayson et al . ' s color by correlation method ( finlayson et al . [digit] , [digit] hubel and finlayson [digit] ) . we discuss a number of issues in applying color constancy ideas to image data , and study in depth the effect of different preprocessing strategies . we compare the performance of the algorithms on image data with their performance on synthesized data . all data used for this study are available online at http www . cs . sfu . ca color data , and implementations for most of the algorithms are also available ( http www . cs . sfu . ca color code ) . experiments with synthesized data ( part one of this paper ) suggested that the methods which emphasize the use of the input data statistics , specifically color by correlation and the neural net algorithm , are potentially the most effective at estimating the chromaticity of the scene illuminant . unfortunately , we were unable to realize comparable performance on real images . here exploiting pixel intensity proved to be more beneficial than exploiting the details of image chromaticity statistics , and the three dimensional ( [digit] d ) gamut mapping algorithms gave the best performance", "tokenized": "for pt . i see ibid . , vol . [digit] , no . [digit] , p . [digit] [digit] ( [digit] ) . we test a number of the leading computational color constancy algorithms using a comprehensive set of images . these were of [digit] different scenes under [digit] different sources representative of common illumination conditions . the algorithms studied include two gray world methods , a version of the retinex method , several variants of forsyth ' s ( [digit] ) gamut mapping method , cardei et al . ' s ( [digit] ) neural net method , and finlayson et al . ' s color by correlation method ( finlayson et al . [digit] , [digit] hubel and finlayson [digit] ) . we discuss a number of issues in applying color constancy ideas to image data , and study in depth the effect of different preprocessing strategies . we compare the performance of the algorithms on image data with their performance on synthesized data . all data used for this study are available online at http www . cs . sfu . ca color data , and implementations for most of the algorithms are also available ( http www . cs . sfu . ca color code ) . experiments with synthesized data ( part one of this paper ) suggested that the methods which emphasize the use of the input data statistics , specifically color by correlation and the neural net algorithm , are potentially the most effective at estimating the chromaticity of the scene illuminant . unfortunately , we were unable to realize comparable performance on real images . here exploiting pixel intensity proved to be more beneficial than exploiting the details of image chromaticity statistics , and the three dimensional ( [digit] d ) gamut mapping algorithms gave the best performance"}, "present_kps": {"text": ["computational color constancy algorithms", "images", "illumination conditions", "gray world methods", "retinex method", "gamut mapping method", "neural net method", "color by correlation method", "image data", "preprocessing strategies", "synthesized data", "input data statistics", "chromaticity", "scene illuminant", "pixel intensity"], "tokenized": ["computational color constancy algorithms", "images", "illumination conditions", "gray world methods", "retinex method", "gamut mapping method", "neural net method", "color by correlation method", "image data", "preprocessing strategies", "synthesized data", "input data statistics", "chromaticity", "scene illuminant", "pixel intensity"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 72, "title": {"text": "a comparison of computational color constancy algorithms . i methodology and .", "tokenized": "a comparison of computational color constancy algorithms . i methodology and ."}, "abstract": {"text": "we introduce a context for testing computational color constancy , specify our approach to the implementation of a number of the leading algorithms , and report the results of three experiments using synthesized data . experiments using synthesized data are important because the ground truth is known , possible confounds due to camera characterization and pre processing are absent , and various factors affecting color constancy can be efficiently investigated because they can be manipulated individually and precisely . the algorithms chosen for close study include two gray world methods , a limiting case of a version of the retinex method , a number of variants of forsyth ' s ( [digit] ) gamut mapping method , cardei et al . ' s ( [digit] ) neural net method , and finlayson et al . ' s color by correlation method ( finlayson et al . [digit] , [digit] hubel and finlayson [digit] ) . we investigate the ability of these algorithms to make estimates of three different color constancy quantities the chromaticity of the scene illuminant , the overall magnitude of that illuminant , and a corrected , illumination invariant , image . we consider algorithm performance as a function of the number of surfaces in scenes generated from reflectance spectra , the relative effect on the algorithms of added specularities , and the effect of subsequent clipping of the data . all data is available on line at http www . cs . sfu . ca color data , and implementations for most of the algorithms are also available ( http www . cs . sfu . ca color code )", "tokenized": "we introduce a context for testing computational color constancy , specify our approach to the implementation of a number of the leading algorithms , and report the results of three experiments using synthesized data . experiments using synthesized data are important because the ground truth is known , possible confounds due to camera characterization and pre processing are absent , and various factors affecting color constancy can be efficiently investigated because they can be manipulated individually and precisely . the algorithms chosen for close study include two gray world methods , a limiting case of a version of the retinex method , a number of variants of forsyth ' s ( [digit] ) gamut mapping method , cardei et al . ' s ( [digit] ) neural net method , and finlayson et al . ' s color by correlation method ( finlayson et al . [digit] , [digit] hubel and finlayson [digit] ) . we investigate the ability of these algorithms to make estimates of three different color constancy quantities the chromaticity of the scene illuminant , the overall magnitude of that illuminant , and a corrected , illumination invariant , image . we consider algorithm performance as a function of the number of surfaces in scenes generated from reflectance spectra , the relative effect on the algorithms of added specularities , and the effect of subsequent clipping of the data . all data is available on line at http www . cs . sfu . ca color data , and implementations for most of the algorithms are also available ( http www . cs . sfu . ca color code )"}, "present_kps": {"text": ["computational color constancy algorithms", "synthesized data", "gray world methods", "retinex method", "gamut mapping method", "neural net method", "color by correlation method", "chromaticity", "scene illuminant", "algorithm performance", "reflectance spectra", "specularities", "clipping"], "tokenized": ["computational color constancy algorithms", "synthesized data", "gray world methods", "retinex method", "gamut mapping method", "neural net method", "color by correlation method", "chromaticity", "scene illuminant", "algorithm performance", "reflectance spectra", "specularities", "clipping"]}, "absent_kps": {"text": ["illumination invariant image"], "tokenized": ["illumination invariant image"]}}
{"id": 73, "title": {"text": "quality image metrics for synthetic images based on perceptual color .", "tokenized": "quality image metrics for synthetic images based on perceptual color ."}, "abstract": {"text": "due to the improvement of image rendering processes , and the increasing importance of quantitative comparisons among synthetic color images , it is essential to define perceptually based metrics which enable to objectively assess the visual quality of digital simulations . in response to this need , this paper proposes a new methodology for the determination of an objective image quality metric , and gives an answer to this problem through three metrics . this methodology is based on the llab color space for perception of color in complex images , a modification of the cielab1976 color space . the first metric proposed is a pixel by pixel metric which introduces a local distance map between two images . the second metric associates , to a pair of images , a global value . finally , the third metric uses a recursive subdivision of the images to obtain an adaptative distance map , rougher but less expensive to compute than the first method", "tokenized": "due to the improvement of image rendering processes , and the increasing importance of quantitative comparisons among synthetic color images , it is essential to define perceptually based metrics which enable to objectively assess the visual quality of digital simulations . in response to this need , this paper proposes a new methodology for the determination of an objective image quality metric , and gives an answer to this problem through three metrics . this methodology is based on the llab color space for perception of color in complex images , a modification of the cielab1976 color space . the first metric proposed is a pixel by pixel metric which introduces a local distance map between two images . the second metric associates , to a pair of images , a global value . finally , the third metric uses a recursive subdivision of the images to obtain an adaptative distance map , rougher but less expensive to compute than the first method"}, "present_kps": {"text": ["quality image metrics", "synthetic images", "image rendering", "color images", "perceptually based metrics", "visual quality", "digital simulations", "llab color space", "cielab1976 color space", "pixel by pixel metric", "local distance map", "global value", "recursive subdivision", "adaptative distance map"], "tokenized": ["quality image metrics", "synthetic images", "image rendering", "color images", "perceptually based metrics", "visual quality", "digital simulations", "llab color space", "cielab1976 color space", "pixel by pixel metric", "local distance map", "global value", "recursive subdivision", "adaptative distance map"]}, "absent_kps": {"text": ["perceptual color differences"], "tokenized": ["perceptual color differences"]}}
{"id": 74, "title": {"text": "exact controllability of shells in minimal time .", "tokenized": "exact controllability of shells in minimal time ."}, "abstract": {"text": "and recent improvements of ingham ( [digit] ) type theorems", "tokenized": "and recent improvements of ingham ( [digit] ) type theorems"}, "present_kps": {"text": ["controllability", "shells", "minimal time"], "tokenized": ["controllability", "shells", "minimal time"]}, "absent_kps": {"text": ["ingham type theorems", "partial differential equations", "hilbert space", "thin cups", "fourier method", "young modulus"], "tokenized": ["ingham type theorems", "partial differential equations", "hilbert space", "thin cups", "fourier method", "young modulus"]}}
{"id": 75, "title": {"text": "a friction compensator for pneumatic control valves .", "tokenized": "a friction compensator for pneumatic control valves ."}, "abstract": {"text": "control valves is presented . the compensation is obtained by adding pulses to the control signal . the characteristics of the pulses are determined from the control action . the compensator is implemented in industrial controllers and control systems , and the industrial experiences show that the procedure reduces the control error during stick slip motion significantly compared to standard control without stiction compensation", "tokenized": "control valves is presented . the compensation is obtained by adding pulses to the control signal . the characteristics of the pulses are determined from the control action . the compensator is implemented in industrial controllers and control systems , and the industrial experiences show that the procedure reduces the control error during stick slip motion significantly compared to standard control without stiction compensation"}, "present_kps": {"text": ["friction compensator", "pneumatic control valves", "industrial controllers", "stick slip motion", "standard control", "stiction compensation"], "tokenized": ["friction compensator", "pneumatic control valves", "industrial controllers", "stick slip motion", "standard control", "stiction compensation"]}, "absent_kps": {"text": ["static friction compensation", "control error reduction"], "tokenized": ["static friction compensation", "control error reduction"]}}
{"id": 76, "title": {"text": "performance comparison between pid and dead time compensating controllers .", "tokenized": "performance comparison between pid and dead time compensating controllers ."}, "abstract": {"text": "compensator be expected to perform better than a pid . the performance criterion used is the integrated absolute error ( iae ) . it is compared for pi and pid controllers and a simple dead time compensator ( dtc ) when a step load disturbance is applied at the plant input . both stable and integrating processes are considered . for a fair comparison the controllers should provide equal robustness in some sense . here , as a measure of robustness , the h sub infinity norm of the sum of the absolute values of the sensitivity function and the complementary sensitivity function is used . performance of the dtc ' s is given also as a function of dead time margin ( d sub m )", "tokenized": "compensator be expected to perform better than a pid . the performance criterion used is the integrated absolute error ( iae ) . it is compared for pi and pid controllers and a simple dead time compensator ( dtc ) when a step load disturbance is applied at the plant input . both stable and integrating processes are considered . for a fair comparison the controllers should provide equal robustness in some sense . here , as a measure of robustness , the h sub infinity norm of the sum of the absolute values of the sensitivity function and the complementary sensitivity function is used . performance of the dtc ' s is given also as a function of dead time margin ( d sub m )"}, "present_kps": {"text": ["performance comparison", "dead time compensator", "dead time compensating controllers", "performance criterion", "integrated absolute error", "iae", "pid controllers", "dtc", "step load disturbance", "integrating processes", "equal robustness", "complementary sensitivity function", "dead time margin"], "tokenized": ["performance comparison", "dead time compensator", "dead time compensating controllers", "performance criterion", "integrated absolute error", "iae", "pid controllers", "dtc", "step load disturbance", "integrating processes", "equal robustness", "complementary sensitivity function", "dead time margin"]}, "absent_kps": {"text": ["stable processes", "pi controllers", "absolute value sum h sub infinity norm"], "tokenized": ["stable processes", "pi controllers", "absolute value sum h sub infinity norm"]}}
{"id": 77, "title": {"text": "waiting for the wave to crest wavelength services .", "tokenized": "waiting for the wave to crest wavelength services ."}, "abstract": {"text": "quick turn up time and impressive margins , such services have yet to live up to the industry ' s expectations . the reasons for this lukewarm reception are many , not the least of which is the confusion that still surrounds the technology , but most industry observers are still convinced that wavelength services with ultimately flourish", "tokenized": "quick turn up time and impressive margins , such services have yet to live up to the industry ' s expectations . the reasons for this lukewarm reception are many , not the least of which is the confusion that still surrounds the technology , but most industry observers are still convinced that wavelength services with ultimately flourish"}, "present_kps": {"text": ["wavelength services"], "tokenized": ["wavelength services"]}, "absent_kps": {"text": ["looking glass networks", "fiber optic networks", "pointeast research"], "tokenized": ["looking glass networks", "fiber optic networks", "pointeast research"]}}
{"id": 78, "title": {"text": "adaptive state feedback control for a class of linear systems with unknown bounds of uncertainties .", "tokenized": "adaptive state feedback control for a class of linear systems with unknown bounds of uncertainties ."}, "abstract": {"text": "systems with disturbance and nonlinear uncertainties is considered . the bounds of the disturbance and uncertainties are assumed to be unknown , being even arbitrary . for such uncertain dynamical systems , the adaptive robust state feedback controller is obtained . and the resulting closed loop systems are asymptotically stable in theory . moreover , an adaptive robust state feedback control scheme is given . the scheme ensures the closed loop systems exponentially practically stable and can be used in practical engineering . finally , simulations show that the control scheme is effective", "tokenized": "systems with disturbance and nonlinear uncertainties is considered . the bounds of the disturbance and uncertainties are assumed to be unknown , being even arbitrary . for such uncertain dynamical systems , the adaptive robust state feedback controller is obtained . and the resulting closed loop systems are asymptotically stable in theory . moreover , an adaptive robust state feedback control scheme is given . the scheme ensures the closed loop systems exponentially practically stable and can be used in practical engineering . finally , simulations show that the control scheme is effective"}, "present_kps": {"text": ["state feedback", "nonlinear uncertainties", "uncertain dynamical systems", "closed loop systems"], "tokenized": ["state feedback", "nonlinear uncertainties", "uncertain dynamical systems", "closed loop systems"]}, "absent_kps": {"text": ["linear time varying systems", "robust stabilization", "robust control", "uncertain systems", "adaptive controller", "adaptive stabilization"], "tokenized": ["linear time varying systems", "robust stabilization", "robust control", "uncertain systems", "adaptive controller", "adaptive stabilization"]}}
{"id": 79, "title": {"text": "preintegration lateral inhibition enhances unsupervised learning .", "tokenized": "preintegration lateral inhibition enhances unsupervised learning ."}, "abstract": {"text": "postintegration lateral inhibition as a mechanism for competition . we argue that these algorithms are computationally deficient in that they fail to generate , or learn , appropriate perceptual representations under certain circumstances . an alternative neural network architecture is presented here in which nodes compete for the right to receive inputs rather than for the right to generate outputs . this form of competition , implemented through preintegration lateral inhibition , does provide appropriate coding properties and can be used to learn such representations efficiently . furthermore , this architecture is consistent with both neuroanatomical and neuropsychological data . we thus argue that preintegration lateral inhibition has computational advantages over conventional neural network architectures while remaining equally biologically plausible", "tokenized": "postintegration lateral inhibition as a mechanism for competition . we argue that these algorithms are computationally deficient in that they fail to generate , or learn , appropriate perceptual representations under certain circumstances . an alternative neural network architecture is presented here in which nodes compete for the right to receive inputs rather than for the right to generate outputs . this form of competition , implemented through preintegration lateral inhibition , does provide appropriate coding properties and can be used to learn such representations efficiently . furthermore , this architecture is consistent with both neuroanatomical and neuropsychological data . we thus argue that preintegration lateral inhibition has computational advantages over conventional neural network architectures while remaining equally biologically plausible"}, "present_kps": {"text": ["preintegration lateral inhibition", "unsupervised learning", "postintegration lateral inhibition", "competition", "neural network architectures", "neural network"], "tokenized": ["preintegration lateral inhibition", "unsupervised learning", "postintegration lateral inhibition", "competition", "neural network architectures", "neural network"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 80, "title": {"text": "generalized predictive control for non uniformly sampled systems .", "tokenized": "generalized predictive control for non uniformly sampled systems ."}, "abstract": {"text": "sampling patterns , which include multirate sampled data systems as special cases . we derive lifted models in the state space domain . the main obstacle for generalized predictive control ( gpc ) design using the lifted models is the so called causality constraint . taking into account this design constraint , we propose a new gpc algorithm , which results in optimal causal control laws for the non uniformly sampled systems . the solution applies immediately to multirate sampled data systems where rates are integer multiples of some base period", "tokenized": "sampling patterns , which include multirate sampled data systems as special cases . we derive lifted models in the state space domain . the main obstacle for generalized predictive control ( gpc ) design using the lifted models is the so called causality constraint . taking into account this design constraint , we propose a new gpc algorithm , which results in optimal causal control laws for the non uniformly sampled systems . the solution applies immediately to multirate sampled data systems where rates are integer multiples of some base period"}, "present_kps": {"text": ["multirate sampled data systems", "gpc", "causality constraint", "optimal causal control laws", "integer multiples"], "tokenized": ["multirate sampled data systems", "gpc", "causality constraint", "optimal causal control laws", "integer multiples"]}, "absent_kps": {"text": ["digital control systems", "generalized predictive control design", "nonuniformly sampled systems", "nonuniform updating patterns", "state space models", "nonuniform sampling patterns"], "tokenized": ["digital control systems", "generalized predictive control design", "nonuniformly sampled systems", "nonuniform updating patterns", "state space models", "nonuniform sampling patterns"]}}
{"id": 81, "title": {"text": "a simple graphic approach for observer decomposition .", "tokenized": "a simple graphic approach for observer decomposition ."}, "abstract": {"text": "system and those in the corresponding output injection observer do not really have to be consistent , a systematic procedure is developed in this work to properly divide a set of sparse system models and measurement models into a number of independent subsets with the help of a visual aid . several smaller sub observers can then be constructed accordingly to replace the original one . the size of each sub observer may be further reduced by strategically selecting one or more appended states . these techniques are shown to be quite effective in relieving on line computation load of the output injection observers and also in identifying detectable sub systems", "tokenized": "system and those in the corresponding output injection observer do not really have to be consistent , a systematic procedure is developed in this work to properly divide a set of sparse system models and measurement models into a number of independent subsets with the help of a visual aid . several smaller sub observers can then be constructed accordingly to replace the original one . the size of each sub observer may be further reduced by strategically selecting one or more appended states . these techniques are shown to be quite effective in relieving on line computation load of the output injection observers and also in identifying detectable sub systems"}, "present_kps": {"text": ["graphic approach", "observer decomposition", "output injection observer", "sparse system models", "measurement models", "independent subsets", "sub observers"], "tokenized": ["graphic approach", "observer decomposition", "output injection observer", "sparse system models", "measurement models", "independent subsets", "sub observers"]}, "absent_kps": {"text": ["detectable subsystems", "online computation load"], "tokenized": ["detectable subsystems", "online computation load"]}}
{"id": 82, "title": {"text": "a new subspace identification approach based on principal component analysis .", "tokenized": "a new subspace identification approach based on principal component analysis ."}, "abstract": {"text": "industrial processes with multiple variables and diagnosing process and sensor faults . the objective of this paper is to develop a new subspace identification algorithm that gives consistent model estimates under the errors in variables ( eiv ) situation . in this paper , we propose a new subspace identification approach using principal component analysis . pca naturally falls into the category of eiv formulation , which resembles total least squares and allows for errors in both process input and output . we propose to use pca to determine the system observability subspace , the matrices and the system order for an eiv formulation . standard pca is modified with instrumental variables in order to achieve consistent estimates of the system matrices . the proposed subspace identification method is demonstrated using a simulated process and a real industrial process for model identification and order determination . for comparison the moesp algorithm and n4sid algorithm are used as benchmarks to demonstrate the advantages of the proposed pca based subspace model identification ( smi ) algorithm", "tokenized": "industrial processes with multiple variables and diagnosing process and sensor faults . the objective of this paper is to develop a new subspace identification algorithm that gives consistent model estimates under the errors in variables ( eiv ) situation . in this paper , we propose a new subspace identification approach using principal component analysis . pca naturally falls into the category of eiv formulation , which resembles total least squares and allows for errors in both process input and output . we propose to use pca to determine the system observability subspace , the matrices and the system order for an eiv formulation . standard pca is modified with instrumental variables in order to achieve consistent estimates of the system matrices . the proposed subspace identification method is demonstrated using a simulated process and a real industrial process for model identification and order determination . for comparison the moesp algorithm and n4sid algorithm are used as benchmarks to demonstrate the advantages of the proposed pca based subspace model identification ( smi ) algorithm"}, "present_kps": {"text": ["subspace identification approach", "principal component analysis", "pca", "system observability subspace", "moesp algorithm", "n4sid algorithm", "subspace model identification", "smi"], "tokenized": ["subspace identification approach", "principal component analysis", "pca", "system observability subspace", "moesp algorithm", "n4sid algorithm", "subspace model identification", "smi"]}, "absent_kps": {"text": ["eiv situation", "sensor fault diagnosis", "errors in variables situation", "process fault diagnosis", "consistent system matrix estimates", "total least squares approximation", "complex industrial process monitoring"], "tokenized": ["eiv situation", "sensor fault diagnosis", "errors in variables situation", "process fault diagnosis", "consistent system matrix estimates", "total least squares approximation", "complex industrial process monitoring"]}}
{"id": 83, "title": {"text": "nonlinear modeling and adaptive fuzzy control of mcfc stack .", "tokenized": "nonlinear modeling and adaptive fuzzy control of mcfc stack ."}, "abstract": {"text": "temperature of the molten carbonate fuel cells ( mcfc ) stack should be controlled within a specified range . however , most existing models of mcfc are not ready to be applied in synthesis . in the paper , a radial basis function neural networks identification model of a mcfc stack is developed based on the input output sampled data . an adaptive fuzzy control procedure for the temperature of the mcfc stack is also developed . the parameters of the fuzzy control system are regulated by back propagation algorithm , and the rule database of the fuzzy system is also adaptively adjusted by the nearest neighbor clustering algorithm . finally using the neural networks model of mcfc stack , the simulation results of the control algorithm are presented . the results show the effectiveness of the proposed modeling and design procedures for the mcfc stack based on neural networks identification and the novel adaptive fuzzy control", "tokenized": "temperature of the molten carbonate fuel cells ( mcfc ) stack should be controlled within a specified range . however , most existing models of mcfc are not ready to be applied in synthesis . in the paper , a radial basis function neural networks identification model of a mcfc stack is developed based on the input output sampled data . an adaptive fuzzy control procedure for the temperature of the mcfc stack is also developed . the parameters of the fuzzy control system are regulated by back propagation algorithm , and the rule database of the fuzzy system is also adaptively adjusted by the nearest neighbor clustering algorithm . finally using the neural networks model of mcfc stack , the simulation results of the control algorithm are presented . the results show the effectiveness of the proposed modeling and design procedures for the mcfc stack based on neural networks identification and the novel adaptive fuzzy control"}, "present_kps": {"text": ["nonlinear modeling", "adaptive fuzzy control", "mcfc stack", "fuel cells", "radial basis function neural networks identification model", "input output sampled data", "rule database", "nearest neighbor clustering algorithm"], "tokenized": ["nonlinear modeling", "adaptive fuzzy control", "mcfc stack", "fuel cells", "radial basis function neural networks identification model", "input output sampled data", "rule database", "nearest neighbor clustering algorithm"]}, "absent_kps": {"text": ["molten carbonate fuel cells stack", "backpropagation algorithm"], "tokenized": ["molten carbonate fuel cells stack", "backpropagation algorithm"]}}
{"id": 84, "title": {"text": "new paradigms for interactive 3d volume segmentation .", "tokenized": "new paradigms for interactive 3d volume segmentation ."}, "abstract": {"text": "segmentation of medical 3d volume data . the mouse based , manual initialization of deformable surfaces in 3d represents a major bottleneck in interactive segmentation . in our multi modal system we enhance this process with additional sensory feedback . a 3d haptic device is used to extract the centreline of a tubular structure . based on the obtained path a cylinder with varying diameter is generated , which in turn is used as the initial guess for a deformable surface", "tokenized": "segmentation of medical 3d volume data . the mouse based , manual initialization of deformable surfaces in 3d represents a major bottleneck in interactive segmentation . in our multi modal system we enhance this process with additional sensory feedback . a 3d haptic device is used to extract the centreline of a tubular structure . based on the obtained path a cylinder with varying diameter is generated , which in turn is used as the initial guess for a deformable surface"}, "present_kps": {"text": ["interactive 3d volume segmentation", "mouse", "deformable surfaces", "deformable surface", "interactive segmentation", "multi modal system", "sensory feedback", "3d haptic device", "tubular structure"], "tokenized": ["interactive 3d volume segmentation", "mouse", "deformable surfaces", "deformable surface", "interactive segmentation", "multi modal system", "sensory feedback", "3d haptic device", "tubular structure"]}, "absent_kps": {"text": ["interaction metaphor", "virtual reality", "varying diameter cylinder", "medical image segmentation", "haptic interaction"], "tokenized": ["interaction metaphor", "virtual reality", "varying diameter cylinder", "medical image segmentation", "haptic interaction"]}}
{"id": 85, "title": {"text": "state of the art in orthopaedic surgical navigation with a focus on medical .", "tokenized": "state of the art in orthopaedic surgical navigation with a focus on medical ."}, "abstract": {"text": "this paper presents a review of surgical navigation systems in orthopaedics and categorizes these systems according to the image modalities that are used for the visualization of surgical action . medical images used to be an essential part of surgical education and documentation as well as diagnosis and operation planning over many years . with the recent introduction of navigation techniques in orthopaedic surgery , a new field of application has been opened . today surgical navigation systems also known as image guided surgery systems are available for various applications in orthopaedic surgery . they visualize the position and orientation of surgical instruments as graphical overlays onto a medical image of the operated anatomy on a computer monitor . preoperative image data such as computed tomography scans or intra operatively generated images ( for example , ultrasonic , endoscopic or fluoroscopic images ) are suitable for this purpose . a new category of medical images termed ' surgeon defined anatomy ' has been developed that exclusively relies upon the usage of navigation technology . points on the anatomy are digitized interactively by the surgeon and are used to build up an abstract geometrical model of the bony structures to be operated on . this technique may be used when no other image data is available or appropriate for a given application", "tokenized": "this paper presents a review of surgical navigation systems in orthopaedics and categorizes these systems according to the image modalities that are used for the visualization of surgical action . medical images used to be an essential part of surgical education and documentation as well as diagnosis and operation planning over many years . with the recent introduction of navigation techniques in orthopaedic surgery , a new field of application has been opened . today surgical navigation systems also known as image guided surgery systems are available for various applications in orthopaedic surgery . they visualize the position and orientation of surgical instruments as graphical overlays onto a medical image of the operated anatomy on a computer monitor . preoperative image data such as computed tomography scans or intra operatively generated images ( for example , ultrasonic , endoscopic or fluoroscopic images ) are suitable for this purpose . a new category of medical images termed ' surgeon defined anatomy ' has been developed that exclusively relies upon the usage of navigation technology . points on the anatomy are digitized interactively by the surgeon and are used to build up an abstract geometrical model of the bony structures to be operated on . this technique may be used when no other image data is available or appropriate for a given application"}, "present_kps": {"text": ["orthopaedic surgical navigation", "surgical education", "image guided surgery systems", "surgical instruments", "graphical overlays", "computer monitor", "computed tomography scans", "intra operatively generated images", "surgeon defined anatomy", "abstract geometrical model", "bony structures"], "tokenized": ["orthopaedic surgical navigation", "surgical education", "image guided surgery systems", "surgical instruments", "graphical overlays", "computer monitor", "computed tomography scans", "intra operatively generated images", "surgeon defined anatomy", "abstract geometrical model", "bony structures"]}, "absent_kps": {"text": ["image registration", "medical image modalities", "surgical action visualization", "medical image processing"], "tokenized": ["image registration", "medical image modalities", "surgical action visualization", "medical image processing"]}}
{"id": 86, "title": {"text": "lung metastasis detection and visualization on ct images a knowledge based .", "tokenized": "lung metastasis detection and visualization on ct images a knowledge based ."}, "abstract": {"text": "a solution to the problem of lung metastasis detection on computed tomography ( ct ) scans of the thorax is presented . a knowledge based top down approach for image interpretation is used . the method is inspired by the manner in which a radiologist and radiotherapist interpret ct images before radiotherapy is planned . a two dimensional followed by a three dimensional analysis is performed . the algorithm first detects the thorax contour , the lungs and the ribs , which further help the detection of metastases . thus , two types of tumors are detected nodules and metastases located at the lung extremities . a method to visualize the anatomical structures segmented is also presented . the system was tested on [digit] patients ( [digit] total images ) from the oncology department of la chaux de fonds hospital and the results show that the method is reliable as a computer aided diagnostic tool for clinical purpose in an oncology department", "tokenized": "a solution to the problem of lung metastasis detection on computed tomography ( ct ) scans of the thorax is presented . a knowledge based top down approach for image interpretation is used . the method is inspired by the manner in which a radiologist and radiotherapist interpret ct images before radiotherapy is planned . a two dimensional followed by a three dimensional analysis is performed . the algorithm first detects the thorax contour , the lungs and the ribs , which further help the detection of metastases . thus , two types of tumors are detected nodules and metastases located at the lung extremities . a method to visualize the anatomical structures segmented is also presented . the system was tested on [digit] patients ( [digit] total images ) from the oncology department of la chaux de fonds hospital and the results show that the method is reliable as a computer aided diagnostic tool for clinical purpose in an oncology department"}, "present_kps": {"text": ["lung metastasis detection", "ct images", "computed tomography", "thorax", "knowledge based top down approach", "image interpretation", "three dimensional analysis", "oncology", "computer aided diagnostic tool"], "tokenized": ["lung metastasis detection", "ct images", "computed tomography", "thorax", "knowledge based top down approach", "image interpretation", "three dimensional analysis", "oncology", "computer aided diagnostic tool"]}, "absent_kps": {"text": ["two dimensional analysis", "data visualization", "medical imaging", "knowledge representation"], "tokenized": ["two dimensional analysis", "data visualization", "medical imaging", "knowledge representation"]}}
{"id": 87, "title": {"text": "the creation of a high fidelity finite element model of the kidney for use in .", "tokenized": "the creation of a high fidelity finite element model of the kidney for use in ."}, "abstract": {"text": "a detailed finite element model of the human kidney for trauma research has been created directly from the national library of medicine visible human female ( vhf ) project data set . an image segmentation and organ reconstruction software package has been developed and employed to transform the 2d vhf images into a 3d polygonal representation . nonuniform rational b spline ( nurbs ) surfaces were then mapped to the polygonal surfaces , and were finally utilized to create a robust 3d hexahedral finite element mesh within a commercially available meshing software . the model employs a combined viscoelastic and hyperelastic material model to successfully simulate the behaviour of biological soft tissues . the finite element model was then validated for use in biomechanical research", "tokenized": "a detailed finite element model of the human kidney for trauma research has been created directly from the national library of medicine visible human female ( vhf ) project data set . an image segmentation and organ reconstruction software package has been developed and employed to transform the 2d vhf images into a 3d polygonal representation . nonuniform rational b spline ( nurbs ) surfaces were then mapped to the polygonal surfaces , and were finally utilized to create a robust 3d hexahedral finite element mesh within a commercially available meshing software . the model employs a combined viscoelastic and hyperelastic material model to successfully simulate the behaviour of biological soft tissues . the finite element model was then validated for use in biomechanical research"}, "present_kps": {"text": ["high fidelity finite element model", "kidney", "trauma research", "national library of medicine", "image segmentation", "organ reconstruction", "software package", "2d vhf images", "3d polygonal representation", "nurbs", "polygonal surfaces", "3d hexahedral finite element mesh", "hyperelastic material model", "biological soft tissues", "biomechanical research"], "tokenized": ["high fidelity finite element model", "kidney", "trauma research", "national library of medicine", "image segmentation", "organ reconstruction", "software package", "2d vhf images", "3d polygonal representation", "nurbs", "polygonal surfaces", "3d hexahedral finite element mesh", "hyperelastic material model", "biological soft tissues", "biomechanical research"]}, "absent_kps": {"text": ["nonuniform rational b spline surfaces", "viscoelastic model", "medical data set", "physically based animation", "visible human female project"], "tokenized": ["nonuniform rational b spline surfaces", "viscoelastic model", "medical data set", "physically based animation", "visible human female project"]}}
{"id": 88, "title": {"text": "building 3d anatomical scenes on the web .", "tokenized": "building 3d anatomical scenes on the web ."}, "abstract": {"text": "the web . the web server is connected to a database storing more than [digit] 3d anatomical models reconstructed from the visible human . users may combine existing models as well as planar oblique slices in order to create their own structured anatomical scenes . furthermore , they may record sequences of scene construction and visualization actions . these actions enable the server to construct high quality video animations , downloadable by the user . professionals and students in anatomy , medicine and related disciplines are invited to use the server and create their own anatomical scenes", "tokenized": "the web . the web server is connected to a database storing more than [digit] 3d anatomical models reconstructed from the visible human . users may combine existing models as well as planar oblique slices in order to create their own structured anatomical scenes . furthermore , they may record sequences of scene construction and visualization actions . these actions enable the server to construct high quality video animations , downloadable by the user . professionals and students in anatomy , medicine and related disciplines are invited to use the server and create their own anatomical scenes"}, "present_kps": {"text": ["3d anatomical scenes", "web server", "database", "3d anatomical models", "visible human", "planar oblique slices", "structured anatomical scenes", "scene construction", "visualization", "high quality video animation"], "tokenized": ["3d anatomical scenes", "web server", "database", "3d anatomical models", "visible human", "planar oblique slices", "structured anatomical scenes", "scene construction", "visualization", "high quality video animation"]}, "absent_kps": {"text": ["world wide web", "user defined 3d anatomical structures", "volume visualization", "java", "applet based rendering engine", "surface reconstruction"], "tokenized": ["world wide web", "user defined 3d anatomical structures", "volume visualization", "java", "applet based rendering engine", "surface reconstruction"]}}
{"id": 89, "title": {"text": "a survey of interactive mesh cutting techniques and a new method for .", "tokenized": "a survey of interactive mesh cutting techniques and a new method for ."}, "abstract": {"text": "in our experience , mesh cutting methods can be distinguished by how their solutions address the following major issues definition of the cut path , primitive removal and re meshing , number of new primitives created , when re meshing is performed , and representation of the cutting tool . many researchers have developed schemes for interactive mesh cutting with the goals of reducing the number of new primitives created , creating new primitives with good aspect ratios , avoiding a disconnected mesh structure between primitives in the cut path , and representing the path traversed by the tool as accurately as possible . the goal of this paper is to explain how , by using a very simple framework , one can build a generalized cutting scheme . this method allows for any arbitrary cut to be made within a virtual object , and can simulate cutting surface , layered surface or tetrahedral objects using a virtual scalpel , scissors , or loop cautery tool . this method has been implemented in a real time , haptic rate surgical simulation system allowing arbitrary cuts to be made on high resolution patient specific models", "tokenized": "in our experience , mesh cutting methods can be distinguished by how their solutions address the following major issues definition of the cut path , primitive removal and re meshing , number of new primitives created , when re meshing is performed , and representation of the cutting tool . many researchers have developed schemes for interactive mesh cutting with the goals of reducing the number of new primitives created , creating new primitives with good aspect ratios , avoiding a disconnected mesh structure between primitives in the cut path , and representing the path traversed by the tool as accurately as possible . the goal of this paper is to explain how , by using a very simple framework , one can build a generalized cutting scheme . this method allows for any arbitrary cut to be made within a virtual object , and can simulate cutting surface , layered surface or tetrahedral objects using a virtual scalpel , scissors , or loop cautery tool . this method has been implemented in a real time , haptic rate surgical simulation system allowing arbitrary cuts to be made on high resolution patient specific models"}, "present_kps": {"text": ["re meshing", "cutting tool", "disconnected mesh structure", "virtual object", "layered surface", "tetrahedral objects", "haptic rate surgical simulation system", "high resolution patient specific models"], "tokenized": ["re meshing", "cutting tool", "disconnected mesh structure", "virtual object", "layered surface", "tetrahedral objects", "haptic rate surgical simulation system", "high resolution patient specific models"]}, "absent_kps": {"text": ["generalized interactive mesh cutting", "rendering", "cut path definition", "real time system", "haptic interfaces", "virtual tools"], "tokenized": ["generalized interactive mesh cutting", "rendering", "cut path definition", "real time system", "haptic interfaces", "virtual tools"]}}
{"id": 90, "title": {"text": "correction to construction of panoramic image mosaics with global and local .", "tokenized": "correction to construction of panoramic image mosaics with global and local ."}, "abstract": {"text": "for original paper see ibid . , vol . [digit] , no . [digit] , p . [digit] [digit] ( [digit] ) . the authors had given a method for the construction of panoramic image mosaics with global and local alignment . unfortunately a mistake had led to an incorrect equation which whilst making little difference in many cases , for faster ( and assured ) convergence , the correct formulae given here should be used", "tokenized": "for original paper see ibid . , vol . [digit] , no . [digit] , p . [digit] [digit] ( [digit] ) . the authors had given a method for the construction of panoramic image mosaics with global and local alignment . unfortunately a mistake had led to an incorrect equation which whilst making little difference in many cases , for faster ( and assured ) convergence , the correct formulae given here should be used"}, "present_kps": {"text": ["panoramic image mosaics", "local alignment"], "tokenized": ["panoramic image mosaics", "local alignment"]}, "absent_kps": {"text": ["global alignment", "resampled image"], "tokenized": ["global alignment", "resampled image"]}}
{"id": 91, "title": {"text": "scale invariant segmentation of dynamic contrast enhanced perfusion mr images .", "tokenized": "scale invariant segmentation of dynamic contrast enhanced perfusion mr images ."}, "abstract": {"text": "selection of the best set of scales is problematic when developing signal driven approaches for pixel based image segmentation . often , different possibly conflicting criteria need to be fulfilled in order to obtain the best trade off between uncertainty ( variance ) and location accuracy . the optimal set of scales depends on several factors the noise level present in the image material , the prior distribution of the different types of segments , the class conditional distributions associated with each type of segment as well as the actual size of the ( connected ) segments . we analyse , theoretically and through experiments , the possibility of using the overall and class conditional error rates as criteria for selecting the optimal sampling of the linear and morphological scale spaces . it is shown that the overall error rate is optimized by taking the prior class distribution in the image material into account . however , a uniform ( ignorant ) prior distribution ensures constant class conditional error rates . consequently , we advocate for a uniform prior class distribution when an uncommitted , scale invariant segmentation approach is desired . experiments with a neural net classifier developed for segmentation of dynamic magnetic resonance ( mr ) images , acquired with a paramagnetic tracer , support the theoretical results . furthermore , the experiments show that the addition of spatial features to the classifier , extracted from the linear or morphological scale spaces , improves the segmentation result compared to a signal driven approach based solely on the dynamic mr signal . the segmentation results obtained from the two types of features are compared using two novel quality measures that characterize spatial properties of labelled images", "tokenized": "selection of the best set of scales is problematic when developing signal driven approaches for pixel based image segmentation . often , different possibly conflicting criteria need to be fulfilled in order to obtain the best trade off between uncertainty ( variance ) and location accuracy . the optimal set of scales depends on several factors the noise level present in the image material , the prior distribution of the different types of segments , the class conditional distributions associated with each type of segment as well as the actual size of the ( connected ) segments . we analyse , theoretically and through experiments , the possibility of using the overall and class conditional error rates as criteria for selecting the optimal sampling of the linear and morphological scale spaces . it is shown that the overall error rate is optimized by taking the prior class distribution in the image material into account . however , a uniform ( ignorant ) prior distribution ensures constant class conditional error rates . consequently , we advocate for a uniform prior class distribution when an uncommitted , scale invariant segmentation approach is desired . experiments with a neural net classifier developed for segmentation of dynamic magnetic resonance ( mr ) images , acquired with a paramagnetic tracer , support the theoretical results . furthermore , the experiments show that the addition of spatial features to the classifier , extracted from the linear or morphological scale spaces , improves the segmentation result compared to a signal driven approach based solely on the dynamic mr signal . the segmentation results obtained from the two types of features are compared using two novel quality measures that characterize spatial properties of labelled images"}, "present_kps": {"text": ["scale invariant segmentation", "dynamic contrast enhanced perfusion mr images", "pixel based image segmentation", "noise level", "class conditional distributions", "experiments", "class conditional error rates", "optimal sampling", "neural net classifier", "paramagnetic tracer", "quality measures", "labelled images"], "tokenized": ["scale invariant segmentation", "dynamic contrast enhanced perfusion mr images", "pixel based image segmentation", "noise level", "class conditional distributions", "experiments", "class conditional error rates", "optimal sampling", "neural net classifier", "paramagnetic tracer", "quality measures", "labelled images"]}, "absent_kps": {"text": ["dynamic magnetic resonance images", "inherent scale selection"], "tokenized": ["dynamic magnetic resonance images", "inherent scale selection"]}}
{"id": 92, "title": {"text": "innovative phase unwrapping algorithm hybrid approach .", "tokenized": "innovative phase unwrapping algorithm hybrid approach ."}, "abstract": {"text": "treatment of a wrapped map . the proposed algorithm is especially effective for the unwrapping of speckle coded interferogram contour maps . in contrast to earlier unwrapping algorithms by region , we propose a local discontinuity restoring criterion to serve as the preprocessor or postprocessor of our hybrid algorithm , which makes the unwrapping by region much easier and more efficient . with this hybrid algorithm , a robust , stable , and especially time effective phase unwrapping can be achieved . additionally , the criterion and limitation of this hybrid algorithm are fully described . the robustness , stability , and speed of this hybrid algorithm are also studied . the proposed algorithm can be easily upgraded with minor modifications to solve the unwrapping problem of maps with phase inconsistency . both numerical simulation and experimental applications demonstrate the effectiveness of the proposed algorithm", "tokenized": "treatment of a wrapped map . the proposed algorithm is especially effective for the unwrapping of speckle coded interferogram contour maps . in contrast to earlier unwrapping algorithms by region , we propose a local discontinuity restoring criterion to serve as the preprocessor or postprocessor of our hybrid algorithm , which makes the unwrapping by region much easier and more efficient . with this hybrid algorithm , a robust , stable , and especially time effective phase unwrapping can be achieved . additionally , the criterion and limitation of this hybrid algorithm are fully described . the robustness , stability , and speed of this hybrid algorithm are also studied . the proposed algorithm can be easily upgraded with minor modifications to solve the unwrapping problem of maps with phase inconsistency . both numerical simulation and experimental applications demonstrate the effectiveness of the proposed algorithm"}, "present_kps": {"text": ["phase unwrapping algorithm", "unwrapping algorithms", "wrapped map", "speckle coded interferogram contour maps", "local discontinuity restoring criterion", "postprocessor", "hybrid algorithm", "unwrapping problem", "phase inconsistency", "numerical simulation"], "tokenized": ["phase unwrapping algorithm", "unwrapping algorithms", "wrapped map", "speckle coded interferogram contour maps", "local discontinuity restoring criterion", "postprocessor", "hybrid algorithm", "unwrapping problem", "phase inconsistency", "numerical simulation"]}, "absent_kps": {"text": ["global treatment", "local treatment", "interferogram analysis", "light interferometry", "robust stable time effective phase unwrapping"], "tokenized": ["global treatment", "local treatment", "interferogram analysis", "light interferometry", "robust stable time effective phase unwrapping"]}}
{"id": 93, "title": {"text": "strain contouring using gabor filters principle and algorithm .", "tokenized": "strain contouring using gabor filters principle and algorithm ."}, "abstract": {"text": "deformation contouring . however , from an engineering viewpoint , the derivatives of displacement , i . e . , strain , are the desired parameter . thus there is a need to differentiate the displacement field . optical and digital methods have been proposed for this differentiation . optical methods provide contours that still need to be quantified , while digital methods suffer from drawbacks inherent in the digital differentiation process . we describe a novel approach of strain segmentation for the moire pattern using a multichannel gabor filter . appropriate filter design allows for user specific segmentation , which is essentially in engineering design and analysis", "tokenized": "deformation contouring . however , from an engineering viewpoint , the derivatives of displacement , i . e . , strain , are the desired parameter . thus there is a need to differentiate the displacement field . optical and digital methods have been proposed for this differentiation . optical methods provide contours that still need to be quantified , while digital methods suffer from drawbacks inherent in the digital differentiation process . we describe a novel approach of strain segmentation for the moire pattern using a multichannel gabor filter . appropriate filter design allows for user specific segmentation , which is essentially in engineering design and analysis"}, "present_kps": {"text": ["strain contouring", "gabor filters", "algorithm", "displacement", "differentiation", "displacement field", "digital methods", "optical methods", "digital differentiation process", "strain segmentation", "multichannel gabor filter", "filter design", "user specific segmentation", "engineering design"], "tokenized": ["strain contouring", "gabor filters", "algorithm", "displacement", "differentiation", "displacement field", "digital methods", "optical methods", "digital differentiation process", "strain segmentation", "multichannel gabor filter", "filter design", "user specific segmentation", "engineering design"]}, "absent_kps": {"text": ["high sensitivity in plane deformation contouring", "engineering analysis", "image segmentation", "moire interferometry", "spatial filters"], "tokenized": ["high sensitivity in plane deformation contouring", "engineering analysis", "image segmentation", "moire interferometry", "spatial filters"]}}
{"id": 94, "title": {"text": "novel denoising algorithm for obtaining a superresolved position estimation .", "tokenized": "novel denoising algorithm for obtaining a superresolved position estimation ."}, "abstract": {"text": "achieve high positioning accuracy by applying a modified averaging operation . using the suggested approach , noise sensitivity of the positioning accuracy can be significantly reduced . this new improved algorithm can improve the performances of tracking systems used for military as well as civil applications . the concept is demonstrated theoretically as well as by optical experiment", "tokenized": "achieve high positioning accuracy by applying a modified averaging operation . using the suggested approach , noise sensitivity of the positioning accuracy can be significantly reduced . this new improved algorithm can improve the performances of tracking systems used for military as well as civil applications . the concept is demonstrated theoretically as well as by optical experiment"}, "present_kps": {"text": ["denoising algorithm", "superresolved position estimation", "high positioning accuracy", "modified averaging operation", "noise sensitivity", "tracking systems", "civil applications", "optical experiment"], "tokenized": ["denoising algorithm", "superresolved position estimation", "high positioning accuracy", "modified averaging operation", "noise sensitivity", "tracking systems", "civil applications", "optical experiment"]}, "absent_kps": {"text": ["noise pattern randomness", "military applications"], "tokenized": ["noise pattern randomness", "military applications"]}}
{"id": 95, "title": {"text": "adaptive filtering for noise reduction in hue saturation intensity color space .", "tokenized": "adaptive filtering for noise reduction in hue saturation intensity color space ."}, "abstract": {"text": "in color image processing and analysis , the conversion formulas from the rgb color model to hsi are nonlinear and complicated in comparison with the conversion formulas of other color models . when an rgb image is degraded by random gaussian noise , this nonlinearity leads to a nonuniform noise distribution in hsi , making accurate image analysis more difficult . we have analyzed the noise characteristics of the hsi color model and developed an adaptive spatial filtering method to reduce the magnitude of noise and the nonuniformity of noise variance in the hsi color space . with this adaptive filtering method , the filter kernel for each pixel is dynamically adjusted , depending on the values of intensity and saturation . in our experiments we have filtered the saturation and hue components and generated edge maps from color gradients . we have found that by using the adaptive filtering method , the minimum error rate in edge detection improves by approximately [digit] %", "tokenized": "in color image processing and analysis , the conversion formulas from the rgb color model to hsi are nonlinear and complicated in comparison with the conversion formulas of other color models . when an rgb image is degraded by random gaussian noise , this nonlinearity leads to a nonuniform noise distribution in hsi , making accurate image analysis more difficult . we have analyzed the noise characteristics of the hsi color model and developed an adaptive spatial filtering method to reduce the magnitude of noise and the nonuniformity of noise variance in the hsi color space . with this adaptive filtering method , the filter kernel for each pixel is dynamically adjusted , depending on the values of intensity and saturation . in our experiments we have filtered the saturation and hue components and generated edge maps from color gradients . we have found that by using the adaptive filtering method , the minimum error rate in edge detection improves by approximately [digit] %"}, "present_kps": {"text": ["adaptive filtering", "noise reduction", "hue saturation intensity color space", "saturation", "intensity", "color image processing", "rgb color model", "random gaussian noise", "nonuniformity", "nonuniform noise distribution", "accurate image analysis", "adaptive spatial filtering method", "noise variance", "hsi color space", "filter kernel", "pixel", "generated edge maps", "color gradients", "minimum error rate", "edge detection"], "tokenized": ["adaptive filtering", "noise reduction", "hue saturation intensity color space", "saturation", "intensity", "color image processing", "rgb color model", "random gaussian noise", "nonuniformity", "nonuniform noise distribution", "accurate image analysis", "adaptive spatial filtering method", "noise variance", "hsi color space", "filter kernel", "pixel", "generated edge maps", "color gradients", "minimum error rate", "edge detection"]}, "absent_kps": {"text": ["color image analysis"], "tokenized": ["color image analysis"]}}
{"id": 96, "title": {"text": "optical recognition of three dimensional objects with scale invariance using a .", "tokenized": "optical recognition of three dimensional objects with scale invariance using a ."}, "abstract": {"text": "we present a real time method for recognizing three dimensional ( [digit] d ) objects with scale invariance . the [digit] d information of the objects is codified in deformed fringe patterns using the fourier transform profilometry technique and is correlated using a classical convergent correlator . the scale invariance property is achieved using two different approaches the mellin radial harmonic decomposition and the logarithmic radial harmonic filter . thus , the method is invariant for changes in the scale of the [digit] d target within a defined interval of scale factors . experimental results show the utility of the proposed method", "tokenized": "we present a real time method for recognizing three dimensional ( [digit] d ) objects with scale invariance . the [digit] d information of the objects is codified in deformed fringe patterns using the fourier transform profilometry technique and is correlated using a classical convergent correlator . the scale invariance property is achieved using two different approaches the mellin radial harmonic decomposition and the logarithmic radial harmonic filter . thus , the method is invariant for changes in the scale of the [digit] d target within a defined interval of scale factors . experimental results show the utility of the proposed method"}, "present_kps": {"text": ["optical recognition", "scale invariance", "invariant", "real time method", "[digit] d information", "deformed fringe patterns", "fourier transform profilometry technique", "classical convergent correlator", "scale invariance property", "mellin radial harmonic decomposition", "logarithmic radial harmonic filter", "scale factors"], "tokenized": ["optical recognition", "scale invariance", "invariant", "real time method", "[digit] d information", "deformed fringe patterns", "fourier transform profilometry technique", "classical convergent correlator", "scale invariance property", "mellin radial harmonic decomposition", "logarithmic radial harmonic filter", "scale factors"]}, "absent_kps": {"text": ["3d object recognition"], "tokenized": ["3d object recognition"]}}
{"id": 97, "title": {"text": "fully automatic algorithm for region of interest location in camera calibration .", "tokenized": "fully automatic algorithm for region of interest location in camera calibration ."}, "abstract": {"text": "calibration used in computer vision inspection . an intelligent roi location algorithm based on the radon transform is developed to automate the calibration process . the algorithm remains robust even if the anchor target has a notable rotation angle in the target plane . this method functions well although the anchor target is not carefully positioned . several improvement methods are studied to avoid the algorithm ' s huge time space consumption problem . the algorithm runs about [digit] times faster if these improvement methods are applied . using this method fully automatic camera calibration is achieved without human interactive roi specification . experiments show that this algorithm can help to calibrate the intrinsic parameters of the zoom lens and the camera parameters quickly and automatically", "tokenized": "calibration used in computer vision inspection . an intelligent roi location algorithm based on the radon transform is developed to automate the calibration process . the algorithm remains robust even if the anchor target has a notable rotation angle in the target plane . this method functions well although the anchor target is not carefully positioned . several improvement methods are studied to avoid the algorithm ' s huge time space consumption problem . the algorithm runs about [digit] times faster if these improvement methods are applied . using this method fully automatic camera calibration is achieved without human interactive roi specification . experiments show that this algorithm can help to calibrate the intrinsic parameters of the zoom lens and the camera parameters quickly and automatically"}, "present_kps": {"text": ["fully automatic algorithm", "region of interest location", "interest location", "camera calibration", "computer vision inspection", "roi location algorithm", "radon transform", "calibration process", "rotation angle", "time space consumption problem", "fully automatic camera calibration", "intrinsic parameters", "zoom lens", "camera parameters"], "tokenized": ["fully automatic algorithm", "region of interest location", "interest location", "camera calibration", "computer vision inspection", "roi location algorithm", "radon transform", "calibration process", "rotation angle", "time space consumption problem", "fully automatic camera calibration", "intrinsic parameters", "zoom lens", "camera parameters"]}, "absent_kps": {"text": ["human interactive specification"], "tokenized": ["human interactive specification"]}}
{"id": 98, "title": {"text": "autofocus system for microscope .", "tokenized": "autofocus system for microscope ."}, "abstract": {"text": "eccentric light beam approach with high resolution , wide focusing range , and compact construction . the principle is described . the theoretical formula of the eccentric light beam approach deduced can be applied not only to an object lens whose objective plane is just at the focal plane , but also to an object lens whose objective plane is not at the focal plane . the experimental setup uses a semiconductor laser device as the light source . the laser beam that enters into the microscope is eccentric with the main light axis . a defocused signal is acquired by a symmetrical silicon photocell for the change of the reflected light position caused by differential amplification and processed by a microprocessor . then the electric signal is power amplified and drives a dc motor , which moves a fine working platform to an automatic focus of the microscope . the result of the experiments shows a or [digit] . [digit] mu m precision of autofocusing for a range of or [digit] mu m defocusing . the system has high reliability and can meet the requirements of various accurate micro measurement systems", "tokenized": "eccentric light beam approach with high resolution , wide focusing range , and compact construction . the principle is described . the theoretical formula of the eccentric light beam approach deduced can be applied not only to an object lens whose objective plane is just at the focal plane , but also to an object lens whose objective plane is not at the focal plane . the experimental setup uses a semiconductor laser device as the light source . the laser beam that enters into the microscope is eccentric with the main light axis . a defocused signal is acquired by a symmetrical silicon photocell for the change of the reflected light position caused by differential amplification and processed by a microprocessor . then the electric signal is power amplified and drives a dc motor , which moves a fine working platform to an automatic focus of the microscope . the result of the experiments shows a or [digit] . [digit] mu m precision of autofocusing for a range of or [digit] mu m defocusing . the system has high reliability and can meet the requirements of various accurate micro measurement systems"}, "present_kps": {"text": ["autofocus system", "eccentric light beam approach", "object lens", "objective plane", "semiconductor laser", "main light axis", "defocused signal", "symmetrical silicon photocell", "reflected light position", "differential amplification", "microprocessor", "dc motor", "fine working platform", "high reliability", "micro measurement systems"], "tokenized": ["autofocus system", "eccentric light beam approach", "object lens", "objective plane", "semiconductor laser", "main light axis", "defocused signal", "symmetrical silicon photocell", "reflected light position", "differential amplification", "microprocessor", "dc motor", "fine working platform", "high reliability", "micro measurement systems"]}, "absent_kps": {"text": ["microscope autofocusing", "power amplified electric signal"], "tokenized": ["microscope autofocusing", "power amplified electric signal"]}}
{"id": 99, "title": {"text": "design and implementation of a [digit] d mapping system for highly irregular shaped .", "tokenized": "design and implementation of a [digit] d mapping system for highly irregular shaped ."}, "abstract": {"text": "the basic technology for a robotic system is developed to automate the packing of polycrystalline silicon nuggets into fragile fused silica crucible in czochralski ( melt pulling ) semiconductor wafer production . the highly irregular shapes of the nuggets and the packing constraints make this a difficult and challenging task . it requires the delicate manipulation and packing of highly irregular polycrystalline silicon nuggets into a fragile fused silica crucible . for this application , a dual optical [digit] d surface mapping system that uses active laser triangulation has been developed and successfully tested . one part of the system measures the geometry profile of a nugget being packed and the other the profile of the nuggets already in the crucible . a resolution of [digit] mm with [digit] khz sampling frequency is achieved . data from the system are used by the packing algorithm , which determines optimal nugget placement . the key contribution is to describe the design and implementation of an efficient and robust [digit] d imaging system to map highly irregular shaped objects using conventional components in context of real commercial manufacturing processes", "tokenized": "the basic technology for a robotic system is developed to automate the packing of polycrystalline silicon nuggets into fragile fused silica crucible in czochralski ( melt pulling ) semiconductor wafer production . the highly irregular shapes of the nuggets and the packing constraints make this a difficult and challenging task . it requires the delicate manipulation and packing of highly irregular polycrystalline silicon nuggets into a fragile fused silica crucible . for this application , a dual optical [digit] d surface mapping system that uses active laser triangulation has been developed and successfully tested . one part of the system measures the geometry profile of a nugget being packed and the other the profile of the nuggets already in the crucible . a resolution of [digit] mm with [digit] khz sampling frequency is achieved . data from the system are used by the packing algorithm , which determines optimal nugget placement . the key contribution is to describe the design and implementation of an efficient and robust [digit] d imaging system to map highly irregular shaped objects using conventional components in context of real commercial manufacturing processes"}, "present_kps": {"text": ["robotic system", "polycrystalline silicon nuggets", "fragile fused silica crucible", "highly irregular polycrystalline silicon nuggets", "active laser triangulation", "sampling frequency", "packing algorithm", "robust [digit] d imaging system", "highly irregular shaped objects", "irregular shaped objects", "commercial manufacturing processes"], "tokenized": ["robotic system", "polycrystalline silicon nuggets", "fragile fused silica crucible", "highly irregular polycrystalline silicon nuggets", "active laser triangulation", "sampling frequency", "packing algorithm", "robust [digit] d imaging system", "highly irregular shaped objects", "irregular shaped objects", "commercial manufacturing processes"]}, "absent_kps": {"text": ["3d mapping system", "semiconductor manufacturing", "dual optical 3d surface mapping system", "optical nugget placement", "czochralski semiconductor wafer production"], "tokenized": ["3d mapping system", "semiconductor manufacturing", "dual optical 3d surface mapping system", "optical nugget placement", "czochralski semiconductor wafer production"]}}
{"id": 100, "title": {"text": "effective moving cast shadow detection for monocular color traffic image .", "tokenized": "effective moving cast shadow detection for monocular color traffic image ."}, "abstract": {"text": "for an accurate scene analysis using monocular color traffic image sequences , a robust segmentation of moving vehicles from the stationary background is generally required . however , the presence of moving cast shadow may lead to an inaccurate vehicle segmentation , and as a result , may lead to further erroneous scene analysis . we propose an effective method for the detection of moving cast shadow . by observing the characteristics of cast shadow in the luminance , chrominance , gradient density , and geometry domains , a combined probability map , called a shadow confidence score ( scs ) , is obtained . from the edge map of the input image , each edge pixel is examined to determine whether it belongs to the vehicle region based on its neighboring scss . the cast shadow is identified as those regions with high scss , which are outside the convex hull of the selected vehicle edge pixels . the proposed method is tested on [digit] vehicle images taken under different lighting conditions ( sunny and cloudy ) , viewing angles ( roadside and overhead ) , vehicle sizes ( small , medium , and large ) , and colors ( similar to the road and not ) . the results indicate that an average error rate of around [digit] % is obtained while the lowest error rate is around [digit] % for large vehicles", "tokenized": "for an accurate scene analysis using monocular color traffic image sequences , a robust segmentation of moving vehicles from the stationary background is generally required . however , the presence of moving cast shadow may lead to an inaccurate vehicle segmentation , and as a result , may lead to further erroneous scene analysis . we propose an effective method for the detection of moving cast shadow . by observing the characteristics of cast shadow in the luminance , chrominance , gradient density , and geometry domains , a combined probability map , called a shadow confidence score ( scs ) , is obtained . from the edge map of the input image , each edge pixel is examined to determine whether it belongs to the vehicle region based on its neighboring scss . the cast shadow is identified as those regions with high scss , which are outside the convex hull of the selected vehicle edge pixels . the proposed method is tested on [digit] vehicle images taken under different lighting conditions ( sunny and cloudy ) , viewing angles ( roadside and overhead ) , vehicle sizes ( small , medium , and large ) , and colors ( similar to the road and not ) . the results indicate that an average error rate of around [digit] % is obtained while the lowest error rate is around [digit] % for large vehicles"}, "present_kps": {"text": ["effective moving cast shadow detection", "moving cast shadow", "cast shadow", "accurate scene analysis", "monocular color traffic image sequences", "robust segmentation", "moving vehicles", "stationary background", "inaccurate vehicle segmentation", "erroneous scene analysis", "luminance", "chrominance", "gradient density", "geometry domains", "combined probability map", "shadow confidence score", "input image", "convex hull", "selected vehicle edge pixels", "vehicle images", "lighting conditions", "sunny", "cloudy", "viewing angles", "vehicle sizes", "average error rate"], "tokenized": ["effective moving cast shadow detection", "moving cast shadow", "cast shadow", "accurate scene analysis", "monocular color traffic image sequences", "robust segmentation", "moving vehicles", "stationary background", "inaccurate vehicle segmentation", "erroneous scene analysis", "luminance", "chrominance", "gradient density", "geometry domains", "combined probability map", "shadow confidence score", "input image", "convex hull", "selected vehicle edge pixels", "vehicle images", "lighting conditions", "sunny", "cloudy", "viewing angles", "vehicle sizes", "average error rate"]}, "absent_kps": {"text": ["image segmentation"], "tokenized": ["image segmentation"]}}
{"id": 101, "title": {"text": "estimation of error in curvature computation on multi scale free form surfaces .", "tokenized": "estimation of error in curvature computation on multi scale free form surfaces ."}, "abstract": {"text": "surface is presented . this is achieved by convolving local parametrisations of the surface with [digit] d gaussian filters iteratively . in our technique , semigeodesic coordinates are constructed at each vertex of the mesh . smoothing results are shown for [digit] d surfaces with different shapes indicating that surface noise is eliminated and surface details are removed gradually . a number of evolution properties of [digit] d surfaces are described . next , the surface gaussian and mean curvature values are estimated accurately at multiple scales which are then mapped to colours and displayed directly on the surface . the performance of the technique when selecting different directions as an arbitrary direction for the geodesic at each vertex are also presented . the results indicate that the error observed for the estimation of gaussian and mean curvatures is quite low after only one iteration . furthermore , as the surface is smoothed iteratively , the error is further reduced . the results also show that the estimation error of gaussian curvature is less than that of mean curvature . our experiments demonstrate that estimation of smoothed surface curvatures are very accurate and not affected by the arbitrary direction of the first geodesic line when constructing semigeodesic coordinates . our technique is independent of the underlying triangulation and is also more efficient than volumetric diffusion techniques since [digit] d rather than [digit] d convolutions are employed . finally , the method presented here is a generalisation of the curvature scale space method for [digit] d contours . the css method has outperformed comparable techniques within the mpeg [digit] evaluation framework . as a result , it has been selected for inclusion in the mpeg [digit] package of standards", "tokenized": "surface is presented . this is achieved by convolving local parametrisations of the surface with [digit] d gaussian filters iteratively . in our technique , semigeodesic coordinates are constructed at each vertex of the mesh . smoothing results are shown for [digit] d surfaces with different shapes indicating that surface noise is eliminated and surface details are removed gradually . a number of evolution properties of [digit] d surfaces are described . next , the surface gaussian and mean curvature values are estimated accurately at multiple scales which are then mapped to colours and displayed directly on the surface . the performance of the technique when selecting different directions as an arbitrary direction for the geodesic at each vertex are also presented . the results indicate that the error observed for the estimation of gaussian and mean curvatures is quite low after only one iteration . furthermore , as the surface is smoothed iteratively , the error is further reduced . the results also show that the estimation error of gaussian curvature is less than that of mean curvature . our experiments demonstrate that estimation of smoothed surface curvatures are very accurate and not affected by the arbitrary direction of the first geodesic line when constructing semigeodesic coordinates . our technique is independent of the underlying triangulation and is also more efficient than volumetric diffusion techniques since [digit] d rather than [digit] d convolutions are employed . finally , the method presented here is a generalisation of the curvature scale space method for [digit] d contours . the css method has outperformed comparable techniques within the mpeg [digit] evaluation framework . as a result , it has been selected for inclusion in the mpeg [digit] package of standards"}, "present_kps": {"text": ["local parametrisations", "semigeodesic coordinates", "surface noise", "evolution properties", "mean curvature values", "underlying triangulation", "volumetric diffusion techniques", "convolutions", "curvature scale space method", "mpeg [digit] evaluation framework"], "tokenized": ["local parametrisations", "semigeodesic coordinates", "surface noise", "evolution properties", "mean curvature values", "underlying triangulation", "volumetric diffusion techniques", "convolutions", "curvature scale space method", "mpeg [digit] evaluation framework"]}, "absent_kps": {"text": ["surface gaussian values", "multi scale curvature computation", "2d gaussian filters", "free form 3d surface"], "tokenized": ["surface gaussian values", "multi scale curvature computation", "2d gaussian filters", "free form 3d surface"]}}
{"id": 102, "title": {"text": "restoration of broadband imagery steered with a liquid crystal optical phased .", "tokenized": "restoration of broadband imagery steered with a liquid crystal optical phased ."}, "abstract": {"text": "in many imaging applications , it is highly desirable to replace mechanical beam steering components ( i . e . , mirrors and gimbals ) with a nonmechanical device . one such device is a nematic liquid crystal optical phased array ( lcopa ) . an lcopa can implement a blazed phase grating to steer the incident light . however , when a phase grating is used in a broadband imaging system , two adverse effects can occur . first , dispersion will cause different incident wavelengths arriving at the same angle to be steered to different output angles , causing chromatic aberrations in the image plane . second , the device will steer energy not only to the first diffraction order , but to others as well . this multiple order effect results in multiple copies of the scene appearing in the image plane . we describe a digital image restoration technique designed to overcome these degradations . the proposed postprocessing technique is based on a wiener deconvolution filter . the technique , however , is applicable only to scenes containing objects with approximately constant reflectivities over the spectral region of interest . experimental results are presented to demonstrate the effectiveness of this technique", "tokenized": "in many imaging applications , it is highly desirable to replace mechanical beam steering components ( i . e . , mirrors and gimbals ) with a nonmechanical device . one such device is a nematic liquid crystal optical phased array ( lcopa ) . an lcopa can implement a blazed phase grating to steer the incident light . however , when a phase grating is used in a broadband imaging system , two adverse effects can occur . first , dispersion will cause different incident wavelengths arriving at the same angle to be steered to different output angles , causing chromatic aberrations in the image plane . second , the device will steer energy not only to the first diffraction order , but to others as well . this multiple order effect results in multiple copies of the scene appearing in the image plane . we describe a digital image restoration technique designed to overcome these degradations . the proposed postprocessing technique is based on a wiener deconvolution filter . the technique , however , is applicable only to scenes containing objects with approximately constant reflectivities over the spectral region of interest . experimental results are presented to demonstrate the effectiveness of this technique"}, "present_kps": {"text": ["broadband imagery", "imaging applications", "mechanical beam steering components", "mirrors", "gimbals", "nonmechanical device", "nematic liquid crystal optical phased array", "optical phased array", "blazed phase grating", "broadband imaging system", "dispersion", "incident wavelengths", "output angles", "chromatic aberrations", "image plane", "first diffraction order", "multiple order effect", "multiple copies", "digital image restoration technique", "postprocessing technique", "wiener deconvolution filter", "approximately constant reflectivities", "spectral region of interest"], "tokenized": ["broadband imagery", "imaging applications", "mechanical beam steering components", "mirrors", "gimbals", "nonmechanical device", "nematic liquid crystal optical phased array", "optical phased array", "blazed phase grating", "broadband imaging system", "dispersion", "incident wavelengths", "output angles", "chromatic aberrations", "image plane", "first diffraction order", "multiple order effect", "multiple copies", "digital image restoration technique", "postprocessing technique", "wiener deconvolution filter", "approximately constant reflectivities", "spectral region of interest"]}, "absent_kps": {"text": ["incident light steering", "halogen lamp", "liquid crystal optical phased array steering"], "tokenized": ["incident light steering", "halogen lamp", "liquid crystal optical phased array steering"]}}
{"id": 103, "title": {"text": "one step digit set restricted modified signed digit adder using an incoherent .", "tokenized": "one step digit set restricted modified signed digit adder using an incoherent ."}, "abstract": {"text": "an efficient one step digit set restricted modified signed digit ( msd ) adder based on symbolic substitution is presented . in this technique , carry propagation is avoided by introducing reference digits to restrict the intermediate carry and sum digits to [digit] , [digit] and [digit] , [digit] , respectively . the proposed technique requires significantly fewer minterms and simplifies system complexity compared to the reported one step msd addition techniques . an incoherent correlator based on an optoelectronic shared content addressable memory processor is suggested to perform the addition operation . in this technique , only one set of minterms needs to be stored , independent of the operand length", "tokenized": "an efficient one step digit set restricted modified signed digit ( msd ) adder based on symbolic substitution is presented . in this technique , carry propagation is avoided by introducing reference digits to restrict the intermediate carry and sum digits to [digit] , [digit] and [digit] , [digit] , respectively . the proposed technique requires significantly fewer minterms and simplifies system complexity compared to the reported one step msd addition techniques . an incoherent correlator based on an optoelectronic shared content addressable memory processor is suggested to perform the addition operation . in this technique , only one set of minterms needs to be stored , independent of the operand length"}, "present_kps": {"text": ["one step digit set restricted modified signed digit adder", "symbolic substitution", "reference digits", "intermediate carry", "sum digits", "minterms", "system complexity", "incoherent correlator", "optoelectronic shared content addressable memory processor", "shared content addressable memory", "addition operation", "operand length"], "tokenized": ["one step digit set restricted modified signed digit adder", "symbolic substitution", "reference digits", "intermediate carry", "sum digits", "minterms", "system complexity", "incoherent correlator", "optoelectronic shared content addressable memory processor", "shared content addressable memory", "addition operation", "operand length"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 104, "title": {"text": "two step integral imaging for orthoscopic three dimensional imaging with .", "tokenized": "two step integral imaging for orthoscopic three dimensional imaging with ."}, "abstract": {"text": "we present a two step integral imaging system to obtain [digit] d orthoscopic real images . by adopting a nonstationary micro optics technique , we demonstrate experimentally the potential usefulness of two step integral imaging", "tokenized": "we present a two step integral imaging system to obtain [digit] d orthoscopic real images . by adopting a nonstationary micro optics technique , we demonstrate experimentally the potential usefulness of two step integral imaging"}, "present_kps": {"text": ["two step integral imaging", "two step integral imaging system", "[digit] d orthoscopic real images", "nonstationary micro optics technique"], "tokenized": ["two step integral imaging", "two step integral imaging system", "[digit] d orthoscopic real images", "nonstationary micro optics technique"]}, "absent_kps": {"text": ["liquid crystal light valve", "display device", "[digit] d image reconstruction", "resolution improved viewing", "pickup lenslet array", "lclv"], "tokenized": ["liquid crystal light valve", "display device", "[digit] d image reconstruction", "resolution improved viewing", "pickup lenslet array", "lclv"]}}
{"id": 105, "title": {"text": "diffraction limit for a circular mask with a periodic rectangular apertures .", "tokenized": "diffraction limit for a circular mask with a periodic rectangular apertures ."}, "abstract": {"text": "a mask with periodic apertures imaging system is adopted very widely and plays a leading role in modern technology for uses such as pinhole cameras , coded imaging systems , optical information processing , etc . because of its high resolution , its infinite depth of focus , and its usefulness over a broad frequency spectra ranging from visible light to x rays and gamma rays . while the masks with periodic apertures investigated in the literature are limited only to far field diffraction , they do not take the shift of apertures within the mask into consideration . therefore the derivation of the far field diffraction for a single aperture can not be applied to a mask with periodic apertures . the far field diffraction formula modified for a multiaperture mask has been proposed in the past , the analysis remains too complicated to offer some practical guidance for mask design . we study a circular mask with periodic rectangular apertures and develop an easier way to interpret it . first , the near field diffraction intensity of a circular aperture is calculated by means of lommel ' s function . then the convolution of the circular mask diffraction with periodic rectangular apertures is put together , and we can present a simple mathematical tool to analyze the mask properties including the intensity distribution , blurring aberration , and the criterion of defining the far or near field diffraction . this concept can also be expanded to analyze different types of masks with the arbitrarily shaped apertures", "tokenized": "a mask with periodic apertures imaging system is adopted very widely and plays a leading role in modern technology for uses such as pinhole cameras , coded imaging systems , optical information processing , etc . because of its high resolution , its infinite depth of focus , and its usefulness over a broad frequency spectra ranging from visible light to x rays and gamma rays . while the masks with periodic apertures investigated in the literature are limited only to far field diffraction , they do not take the shift of apertures within the mask into consideration . therefore the derivation of the far field diffraction for a single aperture can not be applied to a mask with periodic apertures . the far field diffraction formula modified for a multiaperture mask has been proposed in the past , the analysis remains too complicated to offer some practical guidance for mask design . we study a circular mask with periodic rectangular apertures and develop an easier way to interpret it . first , the near field diffraction intensity of a circular aperture is calculated by means of lommel ' s function . then the convolution of the circular mask diffraction with periodic rectangular apertures is put together , and we can present a simple mathematical tool to analyze the mask properties including the intensity distribution , blurring aberration , and the criterion of defining the far or near field diffraction . this concept can also be expanded to analyze different types of masks with the arbitrarily shaped apertures"}, "present_kps": {"text": ["diffraction limit", "circular mask", "mask", "periodic rectangular apertures", "periodic apertures", "pinhole cameras", "coded imaging systems", "optical information processing", "high resolution", "infinite depth of focus", "broad frequency spectra", "visible light", "x rays", "gamma rays", "far field diffraction", "single aperture", "far field diffraction formula", "multiaperture mask", "near field diffraction", "convolution", "circular mask diffraction", "arbitrarily shaped apertures"], "tokenized": ["diffraction limit", "circular mask", "mask", "periodic rectangular apertures", "periodic apertures", "pinhole cameras", "coded imaging systems", "optical information processing", "high resolution", "infinite depth of focus", "broad frequency spectra", "visible light", "x rays", "gamma rays", "far field diffraction", "single aperture", "far field diffraction formula", "multiaperture mask", "near field diffraction", "convolution", "circular mask diffraction", "arbitrarily shaped apertures"]}, "absent_kps": {"text": ["periodic rectangular apertures array"], "tokenized": ["periodic rectangular apertures array"]}}
{"id": 106, "title": {"text": "binocular model for figure ground segmentation in translucent and occluding .", "tokenized": "binocular model for figure ground segmentation in translucent and occluding ."}, "abstract": {"text": "a fourier based solution to the problem of figure ground segmentation in short baseline binocular image pairs is presented . each image is modeled as an additive composite of two component images that exhibit a spatial shift due to the binocular parallax . the segmentation is accomplished by decoupling each fourier component in one of the resultant additive images into its two constituent phasors , allocating each to its appropriate object specific spectrum , and then reconstructing the foreground and background using the inverse fourier transform . it is shown that the foreground and background shifts can be computed from the differences of the magnitudes and phases of the fourier transform of the binocular image pair . while the model is based on translucent objects , it also works with occluding objects", "tokenized": "a fourier based solution to the problem of figure ground segmentation in short baseline binocular image pairs is presented . each image is modeled as an additive composite of two component images that exhibit a spatial shift due to the binocular parallax . the segmentation is accomplished by decoupling each fourier component in one of the resultant additive images into its two constituent phasors , allocating each to its appropriate object specific spectrum , and then reconstructing the foreground and background using the inverse fourier transform . it is shown that the foreground and background shifts can be computed from the differences of the magnitudes and phases of the fourier transform of the binocular image pair . while the model is based on translucent objects , it also works with occluding objects"}, "present_kps": {"text": ["binocular model", "figure ground segmentation", "fourier based solution", "short baseline binocular image pairs", "binocular image pair", "images", "component images", "spatial shift", "binocular parallax", "phasors", "object specific spectrum", "foreground", "background", "inverse fourier transform", "translucent objects", "occluding objects"], "tokenized": ["binocular model", "figure ground segmentation", "fourier based solution", "short baseline binocular image pairs", "binocular image pair", "images", "component images", "spatial shift", "binocular parallax", "phasors", "object specific spectrum", "foreground", "background", "inverse fourier transform", "translucent objects", "occluding objects"]}, "absent_kps": {"text": ["occluding images", "fourier component decoupling", "translucent images", "image segmentation"], "tokenized": ["occluding images", "fourier component decoupling", "translucent images", "image segmentation"]}}
{"id": 107, "title": {"text": "multispectral color image capture using a liquid crystal tunable filter .", "tokenized": "multispectral color image capture using a liquid crystal tunable filter ."}, "abstract": {"text": "system consisting of a professional monochrome ccd camera and a tunable filter in which the spectral transmittance can be controlled electronically . we perform a spectral characterization of the acquisition system taking into account the acquisition noise . to convert the camera output signals to device independent color data , two main approaches are proposed and evaluated . one consists in applying regression methods to convert from the k camera outputs to a device independent color space such as ciexyz or cielab . another method is based on a spectral model of the acquisition system . by inverting the model using a principal eigenvector approach , we estimate the spectral reflectance of each pixel of the imaged surface", "tokenized": "system consisting of a professional monochrome ccd camera and a tunable filter in which the spectral transmittance can be controlled electronically . we perform a spectral characterization of the acquisition system taking into account the acquisition noise . to convert the camera output signals to device independent color data , two main approaches are proposed and evaluated . one consists in applying regression methods to convert from the k camera outputs to a device independent color space such as ciexyz or cielab . another method is based on a spectral model of the acquisition system . by inverting the model using a principal eigenvector approach , we estimate the spectral reflectance of each pixel of the imaged surface"}, "present_kps": {"text": ["multispectral color image capture", "liquid crystal tunable filter", "tunable filter", "monochrome ccd camera", "spectral transmittance", "spectral characterization", "acquisition system", "acquisition noise", "camera output signals", "camera outputs", "device independent color data", "regression methods", "independent color space", "ciexyz", "cielab", "spectral model", "principal eigenvector approach", "spectral reflectance", "pixel", "imaged surface"], "tokenized": ["multispectral color image capture", "liquid crystal tunable filter", "tunable filter", "monochrome ccd camera", "spectral transmittance", "spectral characterization", "acquisition system", "acquisition noise", "camera output signals", "camera outputs", "device independent color data", "regression methods", "independent color space", "ciexyz", "cielab", "spectral model", "principal eigenvector approach", "spectral reflectance", "pixel", "imaged surface"]}, "absent_kps": {"text": ["multispectral color image acquisition system"], "tokenized": ["multispectral color image acquisition system"]}}
{"id": 108, "title": {"text": "iterative regularized least mean mixed norm image restoration .", "tokenized": "iterative regularized least mean mixed norm image restoration ."}, "abstract": {"text": "various types of noise . a mixed norm functional is introduced , which combines the least mean square ( lms ) and the least mean fourth ( lmf ) functionals , as well as a smoothing functional . two regularization parameters are introduced one to determine the relative importance of the lms and lmf functionals , which is a function of the kurtosis , and another to determine the relative importance of the smoothing functional . the two parameters are chosen in such a way that the proposed functional is convex , so that a unique minimizer exists . an iterative algorithm is utilized for obtaining the solution , and its convergence is analyzed . the novelty of the proposed algorithm is that no knowledge of the noise distribution is required , and the relative contributions of the lms , the lmf , and the smoothing functionals are adjusted based on the partially restored image . experimental results demonstrate the effectiveness of the proposed algorithm", "tokenized": "various types of noise . a mixed norm functional is introduced , which combines the least mean square ( lms ) and the least mean fourth ( lmf ) functionals , as well as a smoothing functional . two regularization parameters are introduced one to determine the relative importance of the lms and lmf functionals , which is a function of the kurtosis , and another to determine the relative importance of the smoothing functional . the two parameters are chosen in such a way that the proposed functional is convex , so that a unique minimizer exists . an iterative algorithm is utilized for obtaining the solution , and its convergence is analyzed . the novelty of the proposed algorithm is that no knowledge of the noise distribution is required , and the relative contributions of the lms , the lmf , and the smoothing functionals are adjusted based on the partially restored image . experimental results demonstrate the effectiveness of the proposed algorithm"}, "present_kps": {"text": ["iterative regularized least mean mixed norm image restoration", "noise", "mixed norm functional", "smoothing functional", "regularization parameters", "kurtosis", "unique minimizer", "iterative algorithm", "convergence", "noise distribution", "partially restored image"], "tokenized": ["iterative regularized least mean mixed norm image restoration", "noise", "mixed norm functional", "smoothing functional", "regularization parameters", "kurtosis", "unique minimizer", "iterative algorithm", "convergence", "noise distribution", "partially restored image"]}, "absent_kps": {"text": ["least mean square functionals", "mean fourth functionals", "convex functional"], "tokenized": ["least mean square functionals", "mean fourth functionals", "convex functional"]}}
{"id": 109, "title": {"text": "motion estimation using modified dynamic programming .", "tokenized": "motion estimation using modified dynamic programming ."}, "abstract": {"text": "moving objects in a sequence of images is proposed . correspondence vector field computation is formulated as a matching optimization problem for multiple dynamic images . the proposed method is a heuristic modification of dynamic programming applied to the [digit] d optimization problem . motion vector field estimates using real movie images demonstrate good performance of the algorithm in terms of dynamic motion analysis", "tokenized": "moving objects in a sequence of images is proposed . correspondence vector field computation is formulated as a matching optimization problem for multiple dynamic images . the proposed method is a heuristic modification of dynamic programming applied to the [digit] d optimization problem . motion vector field estimates using real movie images demonstrate good performance of the algorithm in terms of dynamic motion analysis"}, "present_kps": {"text": ["motion estimation", "modified dynamic programming", "dynamic programming", "moving objects", "vector field computation", "matching optimization problem", "multiple dynamic images", "heuristic modification", "[digit] d optimization problem", "motion vector field", "motion vector field estimates", "real movie images", "algorithm", "dynamic motion analysis"], "tokenized": ["motion estimation", "modified dynamic programming", "dynamic programming", "moving objects", "vector field computation", "matching optimization problem", "multiple dynamic images", "heuristic modification", "[digit] d optimization problem", "motion vector field", "motion vector field estimates", "real movie images", "algorithm", "dynamic motion analysis"]}, "absent_kps": {"text": ["precise estimates", "image sequence"], "tokenized": ["precise estimates", "image sequence"]}}
{"id": 110, "title": {"text": "centroid detection based on optical correlation .", "tokenized": "centroid detection based on optical correlation ."}, "abstract": {"text": "centroids of multiple objects in an input scene . the first method is based on the modulus of the moment function , the second method is based on squaring the moment function , and the third method works with a single intensity filter . these methods are invariant to changes in the position , orientation , and scale of the object and result in good noise smoothing performance . we use spatial light modulators ( slms ) to directly implement the input of the image and filter information for the purpose of these approaches . we present results showing simulations from different approaches and provide comparisons between optical correlation and digital moment based methods . experimental results corresponding to an optical correlator using slms for the centroid detection are also presented", "tokenized": "centroids of multiple objects in an input scene . the first method is based on the modulus of the moment function , the second method is based on squaring the moment function , and the third method works with a single intensity filter . these methods are invariant to changes in the position , orientation , and scale of the object and result in good noise smoothing performance . we use spatial light modulators ( slms ) to directly implement the input of the image and filter information for the purpose of these approaches . we present results showing simulations from different approaches and provide comparisons between optical correlation and digital moment based methods . experimental results corresponding to an optical correlator using slms for the centroid detection are also presented"}, "present_kps": {"text": ["centroids", "centroid detection", "optical correlation", "optical correlator", "multiple objects", "input scene", "single intensity filter", "position", "orientation", "scale", "noise smoothing performance", "spatial light modulators", "digital moment based methods"], "tokenized": ["centroids", "centroid detection", "optical correlation", "optical correlator", "multiple objects", "input scene", "single intensity filter", "position", "orientation", "scale", "noise smoothing performance", "spatial light modulators", "digital moment based methods"]}, "absent_kps": {"text": ["correlation based methods", "moment function modulus", "moment function squaring"], "tokenized": ["correlation based methods", "moment function modulus", "moment function squaring"]}}
{"id": 111, "title": {"text": "block truncation image bit plane coding .", "tokenized": "block truncation image bit plane coding ."}, "abstract": {"text": "to its simple and fast computational burden . the bit rate is fixed to [digit] . [digit] bits pixel , whose performance is moderate in terms of compression ratio compared to other compression schemes such as discrete cosine transform ( dct ) , vector quantization ( vq ) , wavelet transform coding ( wtc ) , etc . two kinds of overheads are required for btc coding bit plane and quantization values , respectively . a new technique is presented to reduce the bit plane overhead . conventional bit plane overhead is [digit] . [digit] bits pixel we decrease it to [digit] . [digit] bits pixel while maintaining the same decoded quality as absolute moment btc ( ambtc ) does for the lena image . compared to other published bit plane coding strategies , the proposed method outperforms all of the existing methods", "tokenized": "to its simple and fast computational burden . the bit rate is fixed to [digit] . [digit] bits pixel , whose performance is moderate in terms of compression ratio compared to other compression schemes such as discrete cosine transform ( dct ) , vector quantization ( vq ) , wavelet transform coding ( wtc ) , etc . two kinds of overheads are required for btc coding bit plane and quantization values , respectively . a new technique is presented to reduce the bit plane overhead . conventional bit plane overhead is [digit] . [digit] bits pixel we decrease it to [digit] . [digit] bits pixel while maintaining the same decoded quality as absolute moment btc ( ambtc ) does for the lena image . compared to other published bit plane coding strategies , the proposed method outperforms all of the existing methods"}, "present_kps": {"text": ["image bit plane coding", "bit rate", "performance", "compression ratio", "quantization values", "bit plane overhead", "decoded quality", "absolute moment btc", "ambtc", "lena image"], "tokenized": ["image bit plane coding", "bit rate", "performance", "compression ratio", "quantization values", "bit plane overhead", "decoded quality", "absolute moment btc", "ambtc", "lena image"]}, "absent_kps": {"text": ["image compression technique", "block truncation coding"], "tokenized": ["image compression technique", "block truncation coding"]}}
{"id": 112, "title": {"text": "plenoptic image editing .", "tokenized": "plenoptic image editing ."}, "abstract": {"text": "designed to maintain consistency between multiple images of a physical 3d scene . the distinguishing feature of these operations is that edits to any one image propagate automatically to all other images as if the ( unknown ) 3d scene had itself been modified . the modified scene can then be viewed interactively from any other camera viewpoint and under different scene illuminations . the approach is useful first as a power assist that enables a user to quickly modify many images by editing just a few , and second as a means for constructing and editing image based scene representations by manipulating a set of photographs . the approach works by extending operations like image painting , scissoring , and morphing so that they alter a scene ' s plenoptic function in a physically consistent way , thereby affecting scene appearance from all viewpoints simultaneously . a key element in realizing these operations is a new volumetric decomposition technique for reconstructing an scene ' s plenoptic function from an incomplete set of camera viewpoints", "tokenized": "designed to maintain consistency between multiple images of a physical 3d scene . the distinguishing feature of these operations is that edits to any one image propagate automatically to all other images as if the ( unknown ) 3d scene had itself been modified . the modified scene can then be viewed interactively from any other camera viewpoint and under different scene illuminations . the approach is useful first as a power assist that enables a user to quickly modify many images by editing just a few , and second as a means for constructing and editing image based scene representations by manipulating a set of photographs . the approach works by extending operations like image painting , scissoring , and morphing so that they alter a scene ' s plenoptic function in a physically consistent way , thereby affecting scene appearance from all viewpoints simultaneously . a key element in realizing these operations is a new volumetric decomposition technique for reconstructing an scene ' s plenoptic function from an incomplete set of camera viewpoints"}, "present_kps": {"text": ["plenoptic image editing", "multiple images", "physical 3d scene", "modified scene", "camera viewpoint", "image based scene representations", "image painting", "scissoring", "morphing", "plenoptic function", "volumetric decomposition technique"], "tokenized": ["plenoptic image editing", "multiple images", "physical 3d scene", "modified scene", "camera viewpoint", "image based scene representations", "image painting", "scissoring", "morphing", "plenoptic function", "volumetric decomposition technique"]}, "absent_kps": {"text": ["interactive image editing operations"], "tokenized": ["interactive image editing operations"]}}
{"id": 113, "title": {"text": "elimination of zero order diffraction in digital holography .", "tokenized": "elimination of zero order diffraction in digital holography ."}, "abstract": {"text": "image of digital holography is presented . in this method , the laplacian of a detected hologram is used instead of the hologram itself for numerical reconstruction by computing the discrete fresnel integral . this method can significantly improve the image quality and give better resolution and higher accuracy of the reconstructed image . the main advantages of this method are its simplicity in experimental requirements and convenience in data processing", "tokenized": "image of digital holography is presented . in this method , the laplacian of a detected hologram is used instead of the hologram itself for numerical reconstruction by computing the discrete fresnel integral . this method can significantly improve the image quality and give better resolution and higher accuracy of the reconstructed image . the main advantages of this method are its simplicity in experimental requirements and convenience in data processing"}, "present_kps": {"text": ["digital holography", "laplacian", "detected hologram", "discrete fresnel integral", "image quality", "accuracy", "reconstructed image", "data processing"], "tokenized": ["digital holography", "laplacian", "detected hologram", "discrete fresnel integral", "image quality", "accuracy", "reconstructed image", "data processing"]}, "absent_kps": {"text": ["image resolution", "zero order diffraction suppression", "numerical image reconstruction", "image . processing"], "tokenized": ["image resolution", "zero order diffraction suppression", "numerical image reconstruction", "image . processing"]}}
{"id": 114, "title": {"text": "efficient two level image thresholding method based on bayesian formulation and .", "tokenized": "efficient two level image thresholding method based on bayesian formulation and ."}, "abstract": {"text": "an efficient method for two level thresholding is proposed based on the bayes formula and the maximum entropy principle , in which no assumptions of the image histogram are made . an alternative criterion is derived based on maximizing entropy and used for speeding up the searching algorithm . five forms of conditional probability distributions simple , linear , parabola concave , parabola convex , and s function are employed and compared to each other for optimal threshold determination . the effect of precision on optimal threshold determination is discussed and a trade off precision epsilon [digit] . [digit] is selected experimentally . our experiments demonstrate that the proposed method achieves a significant improvement in speed from [digit] to [digit] times faster than the exhaustive search method", "tokenized": "an efficient method for two level thresholding is proposed based on the bayes formula and the maximum entropy principle , in which no assumptions of the image histogram are made . an alternative criterion is derived based on maximizing entropy and used for speeding up the searching algorithm . five forms of conditional probability distributions simple , linear , parabola concave , parabola convex , and s function are employed and compared to each other for optimal threshold determination . the effect of precision on optimal threshold determination is discussed and a trade off precision epsilon [digit] . [digit] is selected experimentally . our experiments demonstrate that the proposed method achieves a significant improvement in speed from [digit] to [digit] times faster than the exhaustive search method"}, "present_kps": {"text": ["two level image thresholding method", "image thresholding", "bayesian formulation", "maximum entropy principle", "entropy", "image histogram", "searching algorithm", "conditional probability distributions", "parabola concave", "parabola convex", "s function", "optimal threshold determination", "trade off precision"], "tokenized": ["two level image thresholding method", "image thresholding", "bayesian formulation", "maximum entropy principle", "entropy", "image histogram", "searching algorithm", "conditional probability distributions", "parabola concave", "parabola convex", "s function", "optimal threshold determination", "trade off precision"]}, "absent_kps": {"text": ["image segmentation"], "tokenized": ["image segmentation"]}}
{"id": 115, "title": {"text": "adaptive digital watermarking using fuzzy logic techniques .", "tokenized": "adaptive digital watermarking using fuzzy logic techniques ."}, "abstract": {"text": "society . we propose an adaptive digital watermarking scheme based on the human visual system model and a fuzzy logic technique . the fuzzy logic approach is employed to obtain the different strengths and lengths of a watermark by the local characteristics of the image in our proposed scheme . in our experiments , this scheme provides a more robust and imperceptible watermark", "tokenized": "society . we propose an adaptive digital watermarking scheme based on the human visual system model and a fuzzy logic technique . the fuzzy logic approach is employed to obtain the different strengths and lengths of a watermark by the local characteristics of the image in our proposed scheme . in our experiments , this scheme provides a more robust and imperceptible watermark"}, "present_kps": {"text": ["adaptive digital watermarking", "fuzzy logic techniques", "human visual system model", "local characteristics", "imperceptible watermark"], "tokenized": ["adaptive digital watermarking", "fuzzy logic techniques", "human visual system model", "local characteristics", "imperceptible watermark"]}, "absent_kps": {"text": ["copyright protection", "digital society", "image processing", "robust watermark"], "tokenized": ["copyright protection", "digital society", "image processing", "robust watermark"]}}
{"id": 116, "title": {"text": "optical encoding of color three dimensional correlation .", "tokenized": "optical encoding of color three dimensional correlation ."}, "abstract": {"text": "distribution as the third dimension , has been shown to be useful for color pattern recognition tasks . nevertheless , 3d correlation can not be directly performed on an optical correlator , that can only process two dimensional ( 2d ) signals . we propose a method to encode 3d functions onto 2d ones in such a way that the fourier transform and correlation of these signals , that can be optically performed , encode the 3d fourier transform and correlation of the 3d signals . the theory for the encoding is given and experimental results obtained in an optical correlator are shown", "tokenized": "distribution as the third dimension , has been shown to be useful for color pattern recognition tasks . nevertheless , 3d correlation can not be directly performed on an optical correlator , that can only process two dimensional ( 2d ) signals . we propose a method to encode 3d functions onto 2d ones in such a way that the fourier transform and correlation of these signals , that can be optically performed , encode the 3d fourier transform and correlation of the 3d signals . the theory for the encoding is given and experimental results obtained in an optical correlator are shown"}, "present_kps": {"text": ["optical encoding", "color three dimensional correlation", "color pattern recognition tasks", "3d correlation", "optical correlator", "fourier transform", "3d fourier transform"], "tokenized": ["optical encoding", "color three dimensional correlation", "color pattern recognition tasks", "3d correlation", "optical correlator", "fourier transform", "3d fourier transform"]}, "absent_kps": {"text": ["color distribution", "color images", "3d function encoding"], "tokenized": ["color distribution", "color images", "3d function encoding"]}}
{"id": 117, "title": {"text": "search for efficient solutions of multi criterion problems by target level .", "tokenized": "search for efficient solutions of multi criterion problems by target level ."}, "abstract": {"text": "the target level method is considered for solving continuous multi criterion maximization problems . in the first step , the decision maker specifies a target level point ( the desired criterion values ) then in the set of vector evaluations we seek points that are closest to the target point in the chebyshev metric . the vector evaluations obtained in this way are in general weakly efficient . to identify the efficient evaluations , the second step maximizes the sum of the criteria on the set generated in step [digit] . we prove the relationship between the evaluations and decisions obtained by the proposed procedure , on the one hand , and the efficient ( weakly efficient ) evaluations and decisions , on the other hand . if the edgeworth pareto hull of the set of vector evaluations is convex , the set of efficient vector evaluations can be approximated by the proposed method", "tokenized": "the target level method is considered for solving continuous multi criterion maximization problems . in the first step , the decision maker specifies a target level point ( the desired criterion values ) then in the set of vector evaluations we seek points that are closest to the target point in the chebyshev metric . the vector evaluations obtained in this way are in general weakly efficient . to identify the efficient evaluations , the second step maximizes the sum of the criteria on the set generated in step [digit] . we prove the relationship between the evaluations and decisions obtained by the proposed procedure , on the one hand , and the efficient ( weakly efficient ) evaluations and decisions , on the other hand . if the edgeworth pareto hull of the set of vector evaluations is convex , the set of efficient vector evaluations can be approximated by the proposed method"}, "present_kps": {"text": ["multi criterion problems", "target level method", "continuous multi criterion maximization problems", "target level point", "chebyshev metric", "edgeworth pareto hull"], "tokenized": ["multi criterion problems", "target level method", "continuous multi criterion maximization problems", "target level point", "chebyshev metric", "edgeworth pareto hull"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 118, "title": {"text": "computer processing of data on mental impairments during the acute period of .", "tokenized": "computer processing of data on mental impairments during the acute period of ."}, "abstract": {"text": "the article presents results of computer processing of experimental information obtained from patients during the acute period of concussion . a number of computational procedures are described", "tokenized": "the article presents results of computer processing of experimental information obtained from patients during the acute period of concussion . a number of computational procedures are described"}, "present_kps": {"text": ["computer processing", "mental impairments", "acute period of concussion", "computational procedures"], "tokenized": ["computer processing", "mental impairments", "acute period of concussion", "computational procedures"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 119, "title": {"text": "regularization of linear regression problems .", "tokenized": "regularization of linear regression problems ."}, "abstract": {"text": "regularization method , the pseudoinverse method , and the bayesian method allowing for correlations and errors in the data . regularizing algorithms are constructed and their relationship with pseudoinversion , the bayesian approach , and blue is investigated", "tokenized": "regularization method , the pseudoinverse method , and the bayesian method allowing for correlations and errors in the data . regularizing algorithms are constructed and their relationship with pseudoinversion , the bayesian approach , and blue is investigated"}, "present_kps": {"text": ["pseudoinversion", "pseudoinverse method", "bayesian method", "bayesian approach", "blue"], "tokenized": ["pseudoinversion", "pseudoinverse method", "bayesian method", "bayesian approach", "blue"]}, "absent_kps": {"text": ["linear regression problems regularization", "linear regression parameters", "robust estimation"], "tokenized": ["linear regression problems regularization", "linear regression parameters", "robust estimation"]}}
{"id": 120, "title": {"text": "choice from a three element set some lessons of the [digit] presidential campaign .", "tokenized": "choice from a three element set some lessons of the [digit] presidential campaign ."}, "abstract": {"text": "we consider the behavior of four choice rules plurality voting , approval voting , borda count , and self consistent choice when applied to choose the best option from a three element set . it is assumed that the two main options are preferred by a large majority of the voters , while the third option gets a very small number of votes and influences the election outcome only when the two main options receive a close number of votes . when used to rate the main options , borda count and self consistent choice contain terms that allow both for the strength of preferences of the voters and the rating of the main candidates by voters who vote for the third option . in this way , it becomes possible to determine more reliably the winner when plurality voting or approval voting produce close results", "tokenized": "we consider the behavior of four choice rules plurality voting , approval voting , borda count , and self consistent choice when applied to choose the best option from a three element set . it is assumed that the two main options are preferred by a large majority of the voters , while the third option gets a very small number of votes and influences the election outcome only when the two main options receive a close number of votes . when used to rate the main options , borda count and self consistent choice contain terms that allow both for the strength of preferences of the voters and the rating of the main candidates by voters who vote for the third option . in this way , it becomes possible to determine more reliably the winner when plurality voting or approval voting produce close results"}, "present_kps": {"text": ["three element set", "[digit] presidential campaign", "plurality voting", "approval voting", "borda count", "self consistent choice"], "tokenized": ["three element set", "[digit] presidential campaign", "plurality voting", "approval voting", "borda count", "self consistent choice"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 121, "title": {"text": "an inverse problem for a model of a hierarchical structure .", "tokenized": "an inverse problem for a model of a hierarchical structure ."}, "abstract": {"text": "parabolic equation . the model is applied to describe the functioning of a hierarchical structure it is also relevant for heat conduction theory . unique solvability of the inverse problem is proved", "tokenized": "parabolic equation . the model is applied to describe the functioning of a hierarchical structure it is also relevant for heat conduction theory . unique solvability of the inverse problem is proved"}, "present_kps": {"text": ["inverse problem", "hierarchical structure", "parabolic equation", "heat conduction theory", "unique solvability"], "tokenized": ["inverse problem", "hierarchical structure", "parabolic equation", "heat conduction theory", "unique solvability"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 122, "title": {"text": "self calibration from image derivatives .", "tokenized": "self calibration from image derivatives ."}, "abstract": {"text": "from image motion fields induced by a rigidly moving camera with unknown parameters , where the image formation is modeled with a linear pinhole camera model . the equations obtained show the flow to be separated into a component due to the translation and the calibration parameters and a component due to the rotation and the calibration parameters . a set of parameters encoding the latter component is linearly related to the flow , and from these parameters the calibration can be determined . however , as for discrete motion , in general it is not possible to decouple image measurements obtained from only two frames into translational and rotational components . geometrically , the ambiguity takes the form of a part of the rotational component being parallel to the translational component , and thus the scene can be reconstructed only up to a projective transformation . in general , for full calibration at least four successive image frames are necessary , with the 3d rotation changing between the measurements . the geometric analysis gives rise to a direct self calibration method that avoids computation of optical flow or point correspondences and uses only normal flow measurements . new constraints on the smoothness of the surfaces in view are formulated to relate structure and motion directly to image derivatives , and on the basis of these constraints the transformation of the viewing geometry between consecutive images is estimated . the calibration parameters are then estimated from the rotational components of several flow fields . as the proposed technique neither requires a special set up nor needs exact correspondence it is potentially useful for the calibration of active vision systems which have to acquire knowledge about their intrinsic parameters while they perform other tasks , or as a tool for analyzing image sequences in large video databases", "tokenized": "from image motion fields induced by a rigidly moving camera with unknown parameters , where the image formation is modeled with a linear pinhole camera model . the equations obtained show the flow to be separated into a component due to the translation and the calibration parameters and a component due to the rotation and the calibration parameters . a set of parameters encoding the latter component is linearly related to the flow , and from these parameters the calibration can be determined . however , as for discrete motion , in general it is not possible to decouple image measurements obtained from only two frames into translational and rotational components . geometrically , the ambiguity takes the form of a part of the rotational component being parallel to the translational component , and thus the scene can be reconstructed only up to a projective transformation . in general , for full calibration at least four successive image frames are necessary , with the 3d rotation changing between the measurements . the geometric analysis gives rise to a direct self calibration method that avoids computation of optical flow or point correspondences and uses only normal flow measurements . new constraints on the smoothness of the surfaces in view are formulated to relate structure and motion directly to image derivatives , and on the basis of these constraints the transformation of the viewing geometry between consecutive images is estimated . the calibration parameters are then estimated from the rotational components of several flow fields . as the proposed technique neither requires a special set up nor needs exact correspondence it is potentially useful for the calibration of active vision systems which have to acquire knowledge about their intrinsic parameters while they perform other tasks , or as a tool for analyzing image sequences in large video databases"}, "present_kps": {"text": ["image motion fields", "rigidly moving camera", "image formation", "linear pinhole camera model", "calibration parameters", "image measurements", "rotational components", "translational components", "direct self calibration method", "optical flow", "point correspondences", "normal flow measurements", "active vision systems", "image sequences", "large video databases"], "tokenized": ["image motion fields", "rigidly moving camera", "image formation", "linear pinhole camera model", "calibration parameters", "image measurements", "rotational components", "translational components", "direct self calibration method", "optical flow", "point correspondences", "normal flow measurements", "active vision systems", "image sequences", "large video databases"]}, "absent_kps": {"text": ["depth distortion", "camera calibration parameters"], "tokenized": ["depth distortion", "camera calibration parameters"]}}
{"id": 123, "title": {"text": "inverse problems for a mathematical model of ion exchange in a compressible ion .", "tokenized": "inverse problems for a mathematical model of ion exchange in a compressible ion ."}, "abstract": {"text": "a mathematical model of ion exchange is considered , allowing for ion exchanger compression in the process of ion exchange . two inverse problems are investigated for this model , unique solvability is proved , and numerical solution methods are proposed . the efficiency of the proposed methods is demonstrated by a numerical experiment", "tokenized": "a mathematical model of ion exchange is considered , allowing for ion exchanger compression in the process of ion exchange . two inverse problems are investigated for this model , unique solvability is proved , and numerical solution methods are proposed . the efficiency of the proposed methods is demonstrated by a numerical experiment"}, "present_kps": {"text": ["inverse problems", "mathematical model", "ion exchange", "ion exchanger compression", "unique solvability", "numerical solution methods"], "tokenized": ["inverse problems", "mathematical model", "ion exchange", "ion exchanger compression", "unique solvability", "numerical solution methods"]}, "absent_kps": {"text": ["compressible ion exchanger"], "tokenized": ["compressible ion exchanger"]}}
{"id": 124, "title": {"text": "application of multiprocessor systems for computation of jets .", "tokenized": "application of multiprocessor systems for computation of jets ."}, "abstract": {"text": "gas dynamic problems on a wide class of multiprocessor systems , conventionally characterized as cluster systems . a standard data transfer interface the so called message passing interface is used for parallelization of application algorithms among processors . simulation of jets escaping into a low pressure region is chosen as a computational example", "tokenized": "gas dynamic problems on a wide class of multiprocessor systems , conventionally characterized as cluster systems . a standard data transfer interface the so called message passing interface is used for parallelization of application algorithms among processors . simulation of jets escaping into a low pressure region is chosen as a computational example"}, "present_kps": {"text": ["multiprocessor systems", "computation of jets", "gas dynamic problems", "cluster systems", "data transfer interface", "message passing interface", "low pressure region"], "tokenized": ["multiprocessor systems", "computation of jets", "gas dynamic problems", "cluster systems", "data transfer interface", "message passing interface", "low pressure region"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 125, "title": {"text": "hybrid simulation of space plasmas models with massless fluid representation .", "tokenized": "hybrid simulation of space plasmas models with massless fluid representation ."}, "abstract": {"text": "for pt . iii . see prikl . mat . informatika , maks press , no . [digit] , p . [digit] [digit] ( [digit] ) . this is a survey of the literature on hybrid simulation of the kelvin helmholtz instability . we start with a brief review of the theory the simplest model of the instability a transition layer in the form of a tangential discontinuity compressibility of the medium finite size of the velocity shear region pressure anisotropy . we then describe the electromagnetic hybrid model ( ions as particles and electrons as a massless fluid ) and the main numerical schemes . we review the studies on two dimensional and three dimensional hybrid simulation of the process of particle mixing across the magnetopause shear layer driven by the onset of a kelvin helmholtz instability . the article concludes with a survey of literature on hybrid simulation of the kelvin helmholtz instability in finite size objects jets moving across the magnetic field in the middle of the field reversal layer interaction between a magnetized plasma flow and a cylindrical plasma source with zero own magnetic field", "tokenized": "for pt . iii . see prikl . mat . informatika , maks press , no . [digit] , p . [digit] [digit] ( [digit] ) . this is a survey of the literature on hybrid simulation of the kelvin helmholtz instability . we start with a brief review of the theory the simplest model of the instability a transition layer in the form of a tangential discontinuity compressibility of the medium finite size of the velocity shear region pressure anisotropy . we then describe the electromagnetic hybrid model ( ions as particles and electrons as a massless fluid ) and the main numerical schemes . we review the studies on two dimensional and three dimensional hybrid simulation of the process of particle mixing across the magnetopause shear layer driven by the onset of a kelvin helmholtz instability . the article concludes with a survey of literature on hybrid simulation of the kelvin helmholtz instability in finite size objects jets moving across the magnetic field in the middle of the field reversal layer interaction between a magnetized plasma flow and a cylindrical plasma source with zero own magnetic field"}, "present_kps": {"text": ["hybrid simulation", "space plasmas", "massless fluid representation", "kelvin helmholtz instability", "transition layer", "tangential discontinuity", "pressure anisotropy", "electromagnetic hybrid model", "three dimensional hybrid simulation", "magnetopause shear layer", "field reversal layer", "magnetized plasma flow", "cylindrical plasma source"], "tokenized": ["hybrid simulation", "space plasmas", "massless fluid representation", "kelvin helmholtz instability", "transition layer", "tangential discontinuity", "pressure anisotropy", "electromagnetic hybrid model", "three dimensional hybrid simulation", "magnetopause shear layer", "field reversal layer", "magnetized plasma flow", "cylindrical plasma source"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 126, "title": {"text": "limits for computational electromagnetics codes imposed by computer .", "tokenized": "limits for computational electromagnetics codes imposed by computer ."}, "abstract": {"text": "the algorithmic complexity of the innermost loops that determine the complexity of algorithms in computational electromagnetics ( cem ) codes are analyzed according to their operation count and the impact of the underlying computer hardware . as memory chips are much slower than arithmetic processors , codes that involve a high data movement compared to the number of arithmetic operations are executed comparatively slower . hence , matrix matrix multiplications are much faster than matrix vector multiplications . it is seen that it is not sufficient to compare only the complexity , but also the actual performance of algorithms to judge on faster execution . implications involve fdtd loops , lu factorizations , and iterative solvers for dense matrices . run times on two reference platforms , namely an athlon [digit] mhz and an hp pa [digit] processor , verify the findings", "tokenized": "the algorithmic complexity of the innermost loops that determine the complexity of algorithms in computational electromagnetics ( cem ) codes are analyzed according to their operation count and the impact of the underlying computer hardware . as memory chips are much slower than arithmetic processors , codes that involve a high data movement compared to the number of arithmetic operations are executed comparatively slower . hence , matrix matrix multiplications are much faster than matrix vector multiplications . it is seen that it is not sufficient to compare only the complexity , but also the actual performance of algorithms to judge on faster execution . implications involve fdtd loops , lu factorizations , and iterative solvers for dense matrices . run times on two reference platforms , namely an athlon [digit] mhz and an hp pa [digit] processor , verify the findings"}, "present_kps": {"text": ["computational electromagnetics codes", "algorithmic complexity", "innermost loops", "operation count", "computer hardware", "memory chips", "data movement", "matrix matrix multiplications", "matrix vector multiplications", "fdtd loops", "lu factorizations", "iterative solvers", "dense matrices"], "tokenized": ["computational electromagnetics codes", "algorithmic complexity", "innermost loops", "operation count", "computer hardware", "memory chips", "data movement", "matrix matrix multiplications", "matrix vector multiplications", "fdtd loops", "lu factorizations", "iterative solvers", "dense matrices"]}, "absent_kps": {"text": ["cem codes", "computer architecture"], "tokenized": ["cem codes", "computer architecture"]}}
{"id": 127, "title": {"text": "three dimensional geometrical optics code for indoor propagation .", "tokenized": "three dimensional geometrical optics code for indoor propagation ."}, "abstract": {"text": "in an indoor environment using geometrical optics . the program uses an image tree data structure to construct the images needed to compute all the rays carrying fields above a preset threshold value , no matter how many reflections are needed . the paper briefly describes the input file required to define wall construction , the floor plan , the transmitter , and the receiver locations . a case study consisting of a long corridor with a small room on one side is used to demonstrate the features of the go 3d program", "tokenized": "in an indoor environment using geometrical optics . the program uses an image tree data structure to construct the images needed to compute all the rays carrying fields above a preset threshold value , no matter how many reflections are needed . the paper briefly describes the input file required to define wall construction , the floor plan , the transmitter , and the receiver locations . a case study consisting of a long corridor with a small room on one side is used to demonstrate the features of the go 3d program"}, "present_kps": {"text": ["three dimensional geometrical optics", "indoor propagation", "image tree data structure", "wall construction", "floor plan", "transmitter", "receiver locations"], "tokenized": ["three dimensional geometrical optics", "indoor propagation", "image tree data structure", "wall construction", "floor plan", "transmitter", "receiver locations"]}, "absent_kps": {"text": ["image construction", "data visualisation", "ray tracing", "3d geometrical optics code"], "tokenized": ["image construction", "data visualisation", "ray tracing", "3d geometrical optics code"]}}
{"id": 128, "title": {"text": "building a better game through dynamic programming a flip analysis .", "tokenized": "building a better game through dynamic programming a flip analysis ."}, "abstract": {"text": "and suggest modifications to the rules to make the game more marketable . in addition to being an interesting application of dynamic programming , this case shows the use of operations research in managerial decision making", "tokenized": "and suggest modifications to the rules to make the game more marketable . in addition to being an interesting application of dynamic programming , this case shows the use of operations research in managerial decision making"}, "present_kps": {"text": ["dynamic programming", "flip analysis", "operations research", "managerial decision making"], "tokenized": ["dynamic programming", "flip analysis", "operations research", "managerial decision making"]}, "absent_kps": {"text": ["solitaire board game", "craft woodworkers"], "tokenized": ["solitaire board game", "craft woodworkers"]}}
{"id": 129, "title": {"text": "designing and delivering a university course a process ( or operations ) .", "tokenized": "designing and delivering a university course a process ( or operations ) ."}, "abstract": {"text": "with over [digit] years of academic experience in both engineering and management faculties , involving trial and error experimentation in teaching as well as reading relevant literature and observing other instructors in action , the author has accumulated a number of ideas , regarding the preparation and delivery of a university course , that should be of interest to other instructors . this should be particularly the case for those individuals who have had little or no teaching experience ( e . g . those whose graduate education was recently completed at research oriented institutions providing little guidance with respect to teaching ) . a particular perspective is used to convey the ideas , namely one of viewing the preparation and delivery of a course as two major processes that should provide outputs or outcomes that are of value to a number of customers , in particular , students", "tokenized": "with over [digit] years of academic experience in both engineering and management faculties , involving trial and error experimentation in teaching as well as reading relevant literature and observing other instructors in action , the author has accumulated a number of ideas , regarding the preparation and delivery of a university course , that should be of interest to other instructors . this should be particularly the case for those individuals who have had little or no teaching experience ( e . g . those whose graduate education was recently completed at research oriented institutions providing little guidance with respect to teaching ) . a particular perspective is used to convey the ideas , namely one of viewing the preparation and delivery of a course as two major processes that should provide outputs or outcomes that are of value to a number of customers , in particular , students"}, "present_kps": {"text": ["academic experience", "management faculties"], "tokenized": ["academic experience", "management faculties"]}, "absent_kps": {"text": ["engineering faculties", "search oriented institutions", "management perspective", "university course delivery"], "tokenized": ["engineering faculties", "search oriented institutions", "management perspective", "university course delivery"]}}
{"id": 130, "title": {"text": "a generalized pert cpm implementation in a spreadsheet .", "tokenized": "a generalized pert cpm implementation in a spreadsheet ."}, "abstract": {"text": "for finding the critical path in a project network in a spreadsheet . the problem is of importance due to the recent shift of attention to using the spreadsheet environment as a vehicle for delivering management science operations research ( ms or ) techniques to end users", "tokenized": "for finding the critical path in a project network in a spreadsheet . the problem is of importance due to the recent shift of attention to using the spreadsheet environment as a vehicle for delivering management science operations research ( ms or ) techniques to end users"}, "present_kps": {"text": ["generalized pert cpm implementation", "spreadsheet", "critical path"], "tokenized": ["generalized pert cpm implementation", "spreadsheet", "critical path"]}, "absent_kps": {"text": ["ms or techniques"], "tokenized": ["ms or techniques"]}}
{"id": 131, "title": {"text": "an object oriented version of simlib ( a simple simulation package ) .", "tokenized": "an object oriented version of simlib ( a simple simulation package ) ."}, "abstract": {"text": "easy to understand discrete event simulation package ) . the object oriented version is preferable to the original procedural language versions of simlib in that it is easier to understand and teach simulation from an object point of view . a single server queue simulation is demonstrated using the object oriented simlib", "tokenized": "easy to understand discrete event simulation package ) . the object oriented version is preferable to the original procedural language versions of simlib in that it is easier to understand and teach simulation from an object point of view . a single server queue simulation is demonstrated using the object oriented simlib"}, "present_kps": {"text": ["object oriented version", "simlib", "discrete event simulation", "teach simulation"], "tokenized": ["object oriented version", "simlib", "discrete event simulation", "teach simulation"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 132, "title": {"text": "the maximum possible evpi .", "tokenized": "the maximum possible evpi ."}, "abstract": {"text": "( evpi ) for any probability distribution for the states of the world . this maximum evpi is an upper bound for the evpi with given probabilities and thus an upper bound for any partial information about the states of the world", "tokenized": "( evpi ) for any probability distribution for the states of the world . this maximum evpi is an upper bound for the evpi with given probabilities and thus an upper bound for any partial information about the states of the world"}, "present_kps": {"text": ["probability distribution"], "tokenized": ["probability distribution"]}, "absent_kps": {"text": ["decision analysis", "management science", "expected value of perfect information", "optimisation", "operations research"], "tokenized": ["decision analysis", "management science", "expected value of perfect information", "optimisation", "operations research"]}}
{"id": 133, "title": {"text": "geotensity combining motion and lighting for 3d surface reconstruction .", "tokenized": "geotensity combining motion and lighting for 3d surface reconstruction ."}, "abstract": {"text": "object observed in motion by a single static camera . based on the two paradigms , structure from motion and linear intensity subspaces , we introduce the geotensity constraint that governs the relationship between four or more images of a moving object . we show that it is possible in theory to solve for 3d lambertian surface structure for the case of a single point light source and propose that a solution exists for an arbitrary number point light sources . the surface may or may not be textured . we then give an example of automatic surface reconstruction of a face under a point light source using arbitrary unknown object motion and a single fixed camera", "tokenized": "object observed in motion by a single static camera . based on the two paradigms , structure from motion and linear intensity subspaces , we introduce the geotensity constraint that governs the relationship between four or more images of a moving object . we show that it is possible in theory to solve for 3d lambertian surface structure for the case of a single point light source and propose that a solution exists for an arbitrary number point light sources . the surface may or may not be textured . we then give an example of automatic surface reconstruction of a face under a point light source using arbitrary unknown object motion and a single fixed camera"}, "present_kps": {"text": ["single static camera", "structure from motion", "linear intensity subspaces", "geotensity constraint", "3d lambertian surface structure", "single point light source", "point light source", "arbitrary number point light sources", "automatic surface reconstruction"], "tokenized": ["single static camera", "structure from motion", "linear intensity subspaces", "geotensity constraint", "3d lambertian surface structure", "single point light source", "point light source", "arbitrary number point light sources", "automatic surface reconstruction"]}, "absent_kps": {"text": ["full 3d surface", "linear image subspaces"], "tokenized": ["full 3d surface", "linear image subspaces"]}}
{"id": 134, "title": {"text": "who wants to be a millionaire ( r ) the classroom edition .", "tokenized": "who wants to be a millionaire ( r ) the classroom edition ."}, "abstract": {"text": "show who wants to be a millionaire ( r ) that has been created for use in the classroom using microsoft powerpoint ( r ) . a suggested framework for its classroom use is presented , instructions on operating and editing the classroom version of who wants to be a millionaire ( r ) are provided , and sample feedback from students who have played the classroom version of who wants to be a millionaire ( r ) is offered", "tokenized": "show who wants to be a millionaire ( r ) that has been created for use in the classroom using microsoft powerpoint ( r ) . a suggested framework for its classroom use is presented , instructions on operating and editing the classroom version of who wants to be a millionaire ( r ) are provided , and sample feedback from students who have played the classroom version of who wants to be a millionaire ( r ) is offered"}, "present_kps": {"text": ["who wants to be a millionaire", "classroom", "classroom version"], "tokenized": ["who wants to be a millionaire", "classroom", "classroom version"]}, "absent_kps": {"text": ["undergraduate business students", "student contestants"], "tokenized": ["undergraduate business students", "student contestants"]}}
{"id": 135, "title": {"text": "who wants to see a million error .", "tokenized": "who wants to see a million error ."}, "abstract": {"text": "case discusses the monetary decisions contestants face on a game consisting of [digit] increasingly difficult multiple choice questions . since the game continues as long as a contestant answers correctly , this case , at its core , is one of sequential decision analysis , amenable to analysis via stochastic dynamic programming . the case is also suitable for a course dealing with single decision analysis , allowing for discussion of utility theory and bayesian probability revision . in developing a story line for the case , the author has sprinkled in much background material on probability and statistics . this material is placed in a historical context , illuminating some of the influential scholars involved in the development of these subjects as well as the birth of operations research and the management sciences", "tokenized": "case discusses the monetary decisions contestants face on a game consisting of [digit] increasingly difficult multiple choice questions . since the game continues as long as a contestant answers correctly , this case , at its core , is one of sequential decision analysis , amenable to analysis via stochastic dynamic programming . the case is also suitable for a course dealing with single decision analysis , allowing for discussion of utility theory and bayesian probability revision . in developing a story line for the case , the author has sprinkled in much background material on probability and statistics . this material is placed in a historical context , illuminating some of the influential scholars involved in the development of these subjects as well as the birth of operations research and the management sciences"}, "present_kps": {"text": ["decision analysis", "stochastic dynamic programming", "statistics", "operations research"], "tokenized": ["decision analysis", "stochastic dynamic programming", "statistics", "operations research"]}, "absent_kps": {"text": ["probabilistic models", "game theory", "educational course"], "tokenized": ["probabilistic models", "game theory", "educational course"]}}
{"id": 136, "title": {"text": "blitzograms interactive histograms .", "tokenized": "blitzograms interactive histograms ."}, "abstract": {"text": "as iterative will continue to become instantaneous . the blitzogram is the application of this trend to histograms , which the author hopes will lead to a better tacit understanding of probability distributions among both students and managers . and this is not just an academic exercise . commercial monte carlo simulation packages like risk and crystal ball , and my insight . xla are widely available", "tokenized": "as iterative will continue to become instantaneous . the blitzogram is the application of this trend to histograms , which the author hopes will lead to a better tacit understanding of probability distributions among both students and managers . and this is not just an academic exercise . commercial monte carlo simulation packages like risk and crystal ball , and my insight . xla are widely available"}, "present_kps": {"text": ["blitzogram", "histograms", "probability distributions"], "tokenized": ["blitzogram", "histograms", "probability distributions"]}, "absent_kps": {"text": ["statistics", "management science", "mba", "operations research"], "tokenized": ["statistics", "management science", "mba", "operations research"]}}
{"id": 137, "title": {"text": "teaching management science with spreadsheets from decision models to decision .", "tokenized": "teaching management science with spreadsheets from decision models to decision ."}, "abstract": {"text": "the 1990s were a decade of enormous change for management science ( ms ) educators . while the outlook at the beginning of the decade was somewhat bleak , the renaissance in ms education brought about by the use of spreadsheets as the primary delivery vehicle for quantitative modeling techniques has resulted in a much brighter future . this paper takes inventory of the current state of ms education and suggests some promising new directions in the area of decision support systems for ms educators to consider for the future", "tokenized": "the 1990s were a decade of enormous change for management science ( ms ) educators . while the outlook at the beginning of the decade was somewhat bleak , the renaissance in ms education brought about by the use of spreadsheets as the primary delivery vehicle for quantitative modeling techniques has resulted in a much brighter future . this paper takes inventory of the current state of ms education and suggests some promising new directions in the area of decision support systems for ms educators to consider for the future"}, "present_kps": {"text": ["management science", "spreadsheets", "ms education", "quantitative modeling", "decision support systems"], "tokenized": ["management science", "spreadsheets", "ms education", "quantitative modeling", "decision support systems"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 138, "title": {"text": "teaching modeling in management science .", "tokenized": "teaching modeling in management science ."}, "abstract": {"text": "students in mba or similar programs who will be , at best , part time practitioners of these arts . i take as a working hypothesis the radical proposition that the heart of management science itself is not the impressive array of tools that have been built up over the years ( optimization , simulation , decision analysis , queuing , and so on ) but rather the art of reasoning logically with formal models . i believe it is necessary with this group of students to teach basic modeling skills , and in fact it is only when such students have these basic skills as a foundation that they are prepared to acquire the more sophisticated skills needed to employ management science . in this paper i present a hierarchy of modeling skills , from numeracy skills through sophisticated management science skills , as a framework within which to plan courses for the occasional practitioner", "tokenized": "students in mba or similar programs who will be , at best , part time practitioners of these arts . i take as a working hypothesis the radical proposition that the heart of management science itself is not the impressive array of tools that have been built up over the years ( optimization , simulation , decision analysis , queuing , and so on ) but rather the art of reasoning logically with formal models . i believe it is necessary with this group of students to teach basic modeling skills , and in fact it is only when such students have these basic skills as a foundation that they are prepared to acquire the more sophisticated skills needed to employ management science . in this paper i present a hierarchy of modeling skills , from numeracy skills through sophisticated management science skills , as a framework within which to plan courses for the occasional practitioner"}, "present_kps": {"text": ["modeling", "management science", "decision analysis", "formal models", "numeracy skills"], "tokenized": ["modeling", "management science", "decision analysis", "formal models", "numeracy skills"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 139, "title": {"text": "causes of the decline of the business school management science course .", "tokenized": "causes of the decline of the business school management science course ."}, "abstract": {"text": "traditional model and algorithm based course fails to meet the needs of mba programs and students . poor student mathematical preparation is a reality , and is not an acceptable justification for poor teaching outcomes . management science ph . d . s are often poorly prepared to teach in a general management program , having more experience and interest in algorithms than management . the management science profession as a whole has focused its attention on algorithms and a narrow subset of management problems for which they are most applicable . in contrast , mba ' s rarely encounter problems that are suitable for straightforward application of management science tools , living instead in a world where problems are ill defined , data is scarce , time is short , politics is dominant , and rational decision makers are non existent . the root cause of the profession ' s failure to address these issues seems to be ( in russell ackoff ' s words ) a habit of professional introversion that caused the profession to be uninterested in what mba ' s really do on the job and how management science can help them", "tokenized": "traditional model and algorithm based course fails to meet the needs of mba programs and students . poor student mathematical preparation is a reality , and is not an acceptable justification for poor teaching outcomes . management science ph . d . s are often poorly prepared to teach in a general management program , having more experience and interest in algorithms than management . the management science profession as a whole has focused its attention on algorithms and a narrow subset of management problems for which they are most applicable . in contrast , mba ' s rarely encounter problems that are suitable for straightforward application of management science tools , living instead in a world where problems are ill defined , data is scarce , time is short , politics is dominant , and rational decision makers are non existent . the root cause of the profession ' s failure to address these issues seems to be ( in russell ackoff ' s words ) a habit of professional introversion that caused the profession to be uninterested in what mba ' s really do on the job and how management science can help them"}, "present_kps": {"text": ["business school management science course", "management science", "mba programs", "profession"], "tokenized": ["business school management science course", "management science", "mba programs", "profession"]}, "absent_kps": {"text": ["mba students"], "tokenized": ["mba students"]}}
{"id": 140, "title": {"text": "gifts to a science academic librarian .", "tokenized": "gifts to a science academic librarian ."}, "abstract": {"text": "universities and academic libraries . as a university ' s community and general public continue to donate materials , libraries accept donations willingly , both in kind and monetary . eight steps of gift processing are listed in the paper . positive and negative aspects of gift acceptance are discussed . gifts bring value for academic libraries . gifts can be considered additional routes to contribute to library collections without direct purchases , options to add money to the library budget , and the cement of social relationships . but , unfortunately , large donations are time consuming , labor intensive and costly to process . great amounts of staff time and processing space are two main negative aspects that cause concern and put the value of gift acceptance under consideration by librarians . some strategies in handling gifts are recommended . to be effective , academic science librarians need to approach gifts as an investment . librarians are not to be forced by moral and public notions and should be able to make professional decisions in evaluating proposed collections", "tokenized": "universities and academic libraries . as a university ' s community and general public continue to donate materials , libraries accept donations willingly , both in kind and monetary . eight steps of gift processing are listed in the paper . positive and negative aspects of gift acceptance are discussed . gifts bring value for academic libraries . gifts can be considered additional routes to contribute to library collections without direct purchases , options to add money to the library budget , and the cement of social relationships . but , unfortunately , large donations are time consuming , labor intensive and costly to process . great amounts of staff time and processing space are two main negative aspects that cause concern and put the value of gift acceptance under consideration by librarians . some strategies in handling gifts are recommended . to be effective , academic science librarians need to approach gifts as an investment . librarians are not to be forced by moral and public notions and should be able to make professional decisions in evaluating proposed collections"}, "present_kps": {"text": ["science academic librarian", "academic libraries", "donations", "gift processing", "library collections", "budget", "staff time", "professional decisions"], "tokenized": ["science academic librarian", "academic libraries", "donations", "gift processing", "library collections", "budget", "staff time", "professional decisions"]}, "absent_kps": {"text": ["acquisitions", "research libraries", "gift books"], "tokenized": ["acquisitions", "research libraries", "gift books"]}}
{"id": 141, "title": {"text": "four factors influencing the fair market value of out of print books . [digit] .", "tokenized": "four factors influencing the fair market value of out of print books . [digit] ."}, "abstract": {"text": "qualitatively in the patterson study are examined quantitatively . in addition to the four factors of edition , condition , dust jacket , and autograph that were hypothesized to influence the value of a book , four other factors for which information was available in the data were examined", "tokenized": "qualitatively in the patterson study are examined quantitatively . in addition to the four factors of edition , condition , dust jacket , and autograph that were hypothesized to influence the value of a book , four other factors for which information was available in the data were examined"}, "present_kps": {"text": ["fair market value", "out of print books"], "tokenized": ["fair market value", "out of print books"]}, "absent_kps": {"text": ["publisher", "economics", "pricing", "quantitative analysis"], "tokenized": ["publisher", "economics", "pricing", "quantitative analysis"]}}
{"id": 142, "title": {"text": "four factors influencing the fair market value of out of print books . [digit] .", "tokenized": "four factors influencing the fair market value of out of print books . [digit] ."}, "abstract": {"text": "hypothesized to influence the value of books are identified and linked to basic economic principles , which are explained . a sample of fifty six titles is qualitatively examined to test the hypothesis", "tokenized": "hypothesized to influence the value of books are identified and linked to basic economic principles , which are explained . a sample of fifty six titles is qualitatively examined to test the hypothesis"}, "present_kps": {"text": ["fair market value", "out of print books", "economic principles"], "tokenized": ["fair market value", "out of print books", "economic principles"]}, "absent_kps": {"text": ["pricing"], "tokenized": ["pricing"]}}
{"id": 143, "title": {"text": "acquiring materials in the history of science , technology , and medicine .", "tokenized": "acquiring materials in the history of science , technology , and medicine ."}, "abstract": {"text": "materials in the history of science , technology , and medicine for the beginner in these fields . the focus is on the policy formation , basic reference tools , and methods of collection development and acquisitions that are the necessary basis for success in this endeavor", "tokenized": "materials in the history of science , technology , and medicine for the beginner in these fields . the focus is on the policy formation , basic reference tools , and methods of collection development and acquisitions that are the necessary basis for success in this endeavor"}, "present_kps": {"text": ["science", "technology", "medicine", "policy formation", "basic reference tools", "collection development"], "tokenized": ["science", "technology", "medicine", "policy formation", "basic reference tools", "collection development"]}, "absent_kps": {"text": ["special collections", "library acquisitions", "out of print books", "rare materials"], "tokenized": ["special collections", "library acquisitions", "out of print books", "rare materials"]}}
{"id": 144, "title": {"text": "information architecture looking ahead .", "tokenized": "information architecture looking ahead ."}, "abstract": {"text": "( ia ) is headed . after all , many would argue that it ' s too new to be considered as a field at all , or that it is mislabeled , and by no means is there a widely accepted definition of what information architecture actually is . practicing information architects probably number in the thousands , and this vibrant group is already building various forms of communal infrastructure , ranging from an ia journal and a self organizing library of resources to a passel of local professional groups and degree granting academic programs . so the profession has achieved a beachhead that will enable it to stabilize and perhaps even grow during these difficult times", "tokenized": "( ia ) is headed . after all , many would argue that it ' s too new to be considered as a field at all , or that it is mislabeled , and by no means is there a widely accepted definition of what information architecture actually is . practicing information architects probably number in the thousands , and this vibrant group is already building various forms of communal infrastructure , ranging from an ia journal and a self organizing library of resources to a passel of local professional groups and degree granting academic programs . so the profession has achieved a beachhead that will enable it to stabilize and perhaps even grow during these difficult times"}, "present_kps": {"text": ["information architecture", "information architects", "communal infrastructure", "local professional groups", "degree granting academic programs"], "tokenized": ["information architecture", "information architects", "communal infrastructure", "local professional groups", "degree granting academic programs"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 145, "title": {"text": "decisions , decisions , decisions a tale of special collections in the small .", "tokenized": "decisions , decisions , decisions a tale of special collections in the small ."}, "abstract": {"text": "a case study of a special collections department in a small academic library and how its collections have been acquired and developed over the years is described . it looks at the changes that have occurred in the academic environment and what effect , if any , these changes may have had on the department and how it has adapted to them . it raises questions about development and acquisitions policies and procedures", "tokenized": "a case study of a special collections department in a small academic library and how its collections have been acquired and developed over the years is described . it looks at the changes that have occurred in the academic environment and what effect , if any , these changes may have had on the department and how it has adapted to them . it raises questions about development and acquisitions policies and procedures"}, "present_kps": {"text": ["special collections", "case study", "small academic library", "acquisitions policies"], "tokenized": ["special collections", "case study", "small academic library", "acquisitions policies"]}, "absent_kps": {"text": ["out of print books", "university library"], "tokenized": ["out of print books", "university library"]}}
{"id": 146, "title": {"text": "acquisitions in the james ford bell library .", "tokenized": "acquisitions in the james ford bell library ."}, "abstract": {"text": "special collection , with commentary on just saying no and on how the electronic revolution has changed the acquisition of special collections materials", "tokenized": "special collection , with commentary on just saying no and on how the electronic revolution has changed the acquisition of special collections materials"}, "present_kps": {"text": ["james ford bell library", "special collections", "electronic revolution"], "tokenized": ["james ford bell library", "special collections", "electronic revolution"]}, "absent_kps": {"text": ["out of print books", "library acquisitions philosophy", "university library"], "tokenized": ["out of print books", "library acquisitions philosophy", "university library"]}}
{"id": 147, "title": {"text": "underground poetry , collecting poetry , and the librarian .", "tokenized": "underground poetry , collecting poetry , and the librarian ."}, "abstract": {"text": "literature , and culture is discussed . the acquisitions difficulties encountered in the unique publishing world of underground poetry are introduced . strategies for acquiring underground poetry for library collections are proposed , including total immersion and local focus , with accompanying action", "tokenized": "literature , and culture is discussed . the acquisitions difficulties encountered in the unique publishing world of underground poetry are introduced . strategies for acquiring underground poetry for library collections are proposed , including total immersion and local focus , with accompanying action"}, "present_kps": {"text": ["underground poetry", "librarian", "literature", "culture", "publishing", "library collections"], "tokenized": ["underground poetry", "librarian", "literature", "culture", "publishing", "library collections"]}, "absent_kps": {"text": ["special collections", "out of print books"], "tokenized": ["special collections", "out of print books"]}}
{"id": 148, "title": {"text": "on emotion and bounded rationality reply to hanoch .", "tokenized": "on emotion and bounded rationality reply to hanoch ."}, "abstract": {"text": "his model of bounded rationality and the role of the yerkes dodson law and emotional arousal in it . the author points out that hanoch ' s comment , however , conspicuously fails to challenge much less contradict the central hypothesis of his paper . in addition , several of hanoch ' s criticisms are based on a wrong characterization of the positions", "tokenized": "his model of bounded rationality and the role of the yerkes dodson law and emotional arousal in it . the author points out that hanoch ' s comment , however , conspicuously fails to challenge much less contradict the central hypothesis of his paper . in addition , several of hanoch ' s criticisms are based on a wrong characterization of the positions"}, "present_kps": {"text": ["emotion", "bounded rationality", "yerkes dodson law"], "tokenized": ["emotion", "bounded rationality", "yerkes dodson law"]}, "absent_kps": {"text": ["decision making", "psychology"], "tokenized": ["decision making", "psychology"]}}
{"id": 149, "title": {"text": "the effects of emotions on bounded rationality a comment on kaufman .", "tokenized": "the effects of emotions on bounded rationality a comment on kaufman ."}, "abstract": {"text": "rationality , objective is to present an additional source of bounded rationality , one that is not due to cognitive constraints , but to high emotional arousal . in doing so , kaufman is following a long tradition of thinkers who have contrasted emotion with reason , claiming , for the most part , that emotions are a violent force hindering rational thinking . this paper aims to challenge kaufman ' s unidimensional idea regarding the connection between high emotional arousal and decision making", "tokenized": "rationality , objective is to present an additional source of bounded rationality , one that is not due to cognitive constraints , but to high emotional arousal . in doing so , kaufman is following a long tradition of thinkers who have contrasted emotion with reason , claiming , for the most part , that emotions are a violent force hindering rational thinking . this paper aims to challenge kaufman ' s unidimensional idea regarding the connection between high emotional arousal and decision making"}, "present_kps": {"text": ["emotion", "bounded rationality", "rational thinking", "decision making"], "tokenized": ["emotion", "bounded rationality", "rational thinking", "decision making"]}, "absent_kps": {"text": ["psychology", "yerkes dodson law"], "tokenized": ["psychology", "yerkes dodson law"]}}
{"id": 150, "title": {"text": "emotion and self control .", "tokenized": "emotion and self control ."}, "abstract": {"text": "preferences and the problem of self control . emotion is shown to be the biological substrate of choice , in that emotional systems assign value to ' goods ' in the environment and also facilitate the learning of expectations regarding alternative options for acquiring those goods . a third major function of the emotional choice systems is motivation . self control is shown to be the result of a problem with the inhibition of the motive force of emotion , where this inhibition is necessary for higher level deliberation", "tokenized": "preferences and the problem of self control . emotion is shown to be the biological substrate of choice , in that emotional systems assign value to ' goods ' in the environment and also facilitate the learning of expectations regarding alternative options for acquiring those goods . a third major function of the emotional choice systems is motivation . self control is shown to be the result of a problem with the inhibition of the motive force of emotion , where this inhibition is necessary for higher level deliberation"}, "present_kps": {"text": ["emotion", "self control", "learning", "emotional choice systems", "inhibition"], "tokenized": ["emotion", "self control", "learning", "emotional choice systems", "inhibition"]}, "absent_kps": {"text": ["time inconsistent preferences", "choice model"], "tokenized": ["time inconsistent preferences", "choice model"]}}
{"id": 151, "title": {"text": "product and process innovations in the life cycle of an industry .", "tokenized": "product and process innovations in the life cycle of an industry ."}, "abstract": {"text": "quality along with an equilibrium model of industry evolution to estimate the nature and effects of quality and cost improvements in the personal computer industry and four other new industries . this paper studies the personal computer industry in more detail and shows that the model explains some peculiar patterns that can not be explained by previous life cycle models . the model estimates are evaluated using historical studies of the evolution of the personal computer industry and patterns that require further model development are described", "tokenized": "quality along with an equilibrium model of industry evolution to estimate the nature and effects of quality and cost improvements in the personal computer industry and four other new industries . this paper studies the personal computer industry in more detail and shows that the model explains some peculiar patterns that can not be explained by previous life cycle models . the model estimates are evaluated using historical studies of the evolution of the personal computer industry and patterns that require further model development are described"}, "present_kps": {"text": ["equilibrium model", "industry evolution", "life cycle models"], "tokenized": ["equilibrium model", "industry evolution", "life cycle models"]}, "absent_kps": {"text": ["production cost", "personal computer market", "pc industry", "microelectronics", "technological change", "industry dynamics"], "tokenized": ["production cost", "personal computer market", "pc industry", "microelectronics", "technological change", "industry dynamics"]}}
{"id": 152, "title": {"text": "a comparison of the discounted utility model and hyperbolic discounting models .", "tokenized": "a comparison of the discounted utility model and hyperbolic discounting models ."}, "abstract": {"text": "whilst there is substantial evidence that hyperbolic discounting models describe intertemporal preferences for monetary outcomes better than the discounted utility ( du ) model , there is only very limited evidence in the context of health outcomes . this study elicits private and social intertemporal preferences for non fatal changes in health . specific functional forms of the du model and three hyperbolic models are fitted . the results show that the stationarity axiom is violated , and that the hyperbolic models fit the data better than the du model . intertemporal preferences for private and social decisions are found to be very similar", "tokenized": "whilst there is substantial evidence that hyperbolic discounting models describe intertemporal preferences for monetary outcomes better than the discounted utility ( du ) model , there is only very limited evidence in the context of health outcomes . this study elicits private and social intertemporal preferences for non fatal changes in health . specific functional forms of the du model and three hyperbolic models are fitted . the results show that the stationarity axiom is violated , and that the hyperbolic models fit the data better than the du model . intertemporal preferences for private and social decisions are found to be very similar"}, "present_kps": {"text": ["discounted utility model", "hyperbolic discounting models", "intertemporal preferences", "health outcomes", "social decisions"], "tokenized": ["discounted utility model", "hyperbolic discounting models", "intertemporal preferences", "health outcomes", "social decisions"]}, "absent_kps": {"text": ["private decisions"], "tokenized": ["private decisions"]}}
{"id": 153, "title": {"text": "modeling the labor market as an evolving institution model artemis .", "tokenized": "modeling the labor market as an evolving institution model artemis ."}, "abstract": {"text": "institution . boundedly rational firms and individuals strive to decrease the cost or increase utility . the labor market is coordinated by a search process and decentralized setting of hiring standards , but intermediaries can speed up matching . the model reproduces the dynamics of the gross flows and spectacular changes in mobility patterns of some demographic groups when the oil crisis in the [digit] ' s occurred , notably the sudden decline of the integration in good jobs . the internal labor markets of large firms are shown to increase unemployment if the secondary ( temporary or bad ) jobs do not exist", "tokenized": "institution . boundedly rational firms and individuals strive to decrease the cost or increase utility . the labor market is coordinated by a search process and decentralized setting of hiring standards , but intermediaries can speed up matching . the model reproduces the dynamics of the gross flows and spectacular changes in mobility patterns of some demographic groups when the oil crisis in the [digit] ' s occurred , notably the sudden decline of the integration in good jobs . the internal labor markets of large firms are shown to increase unemployment if the secondary ( temporary or bad ) jobs do not exist"}, "present_kps": {"text": ["spectacular changes", "mobility patterns", "demographic groups", "jobs"], "tokenized": ["spectacular changes", "mobility patterns", "demographic groups", "jobs"]}, "absent_kps": {"text": ["simulation model", "endogenously evolving institution", "endogenous intermediary", "french labor market", "artemis model"], "tokenized": ["simulation model", "endogenously evolving institution", "endogenous intermediary", "french labor market", "artemis model"]}}
{"id": 154, "title": {"text": "the ultimate control group .", "tokenized": "the ultimate control group ."}, "abstract": {"text": "classified on the basis of their control structures . this should be done in a way that can potentially be made operational . it is easy to identify the ultimate controller of a hierarchical organization , and the literature has largely focused on this case . however , many organizational structures mix hierarchy with collective choice procedures such as voting , or use circular structures under which superiors are accountable to their subordinates . the author develops some analytic machinery that can be used to map the authority structures of such organizations , and show that under mild restrictions there is a well defined ultimate control group . the results are consistent with intuitions about the nature of control in familiar economic settings", "tokenized": "classified on the basis of their control structures . this should be done in a way that can potentially be made operational . it is easy to identify the ultimate controller of a hierarchical organization , and the literature has largely focused on this case . however , many organizational structures mix hierarchy with collective choice procedures such as voting , or use circular structures under which superiors are accountable to their subordinates . the author develops some analytic machinery that can be used to map the authority structures of such organizations , and show that under mild restrictions there is a well defined ultimate control group . the results are consistent with intuitions about the nature of control in familiar economic settings"}, "present_kps": {"text": ["ultimate control group", "hierarchical organization", "organizational structures", "authority structures"], "tokenized": ["ultimate control group", "hierarchical organization", "organizational structures", "authority structures"]}, "absent_kps": {"text": ["committees", "firm organization", "control rights"], "tokenized": ["committees", "firm organization", "control rights"]}}
{"id": 155, "title": {"text": "information architecture for bilingual web sites .", "tokenized": "information architecture for bilingual web sites ."}, "abstract": {"text": "particular challenges beyond those that exist for single and multilanguage sites . this article reports work in progress on the development of a content based bilingual web site to facilitate the sharing of resources and information between speech and language therapists . the development of the information architecture is based on a combination of two aspects an abstract structural analysis of existing bilingual web designs focusing on the presentation of bilingual material , and a bilingual card sorting activity conducted with potential users . issues for bilingual developments are discussed , and some observations are made regarding the use of card sorting activities", "tokenized": "particular challenges beyond those that exist for single and multilanguage sites . this article reports work in progress on the development of a content based bilingual web site to facilitate the sharing of resources and information between speech and language therapists . the development of the information architecture is based on a combination of two aspects an abstract structural analysis of existing bilingual web designs focusing on the presentation of bilingual material , and a bilingual card sorting activity conducted with potential users . issues for bilingual developments are discussed , and some observations are made regarding the use of card sorting activities"}, "present_kps": {"text": ["information architecture", "content based bilingual web site", "language therapists", "bilingual card sorting activity", "bilingual developments"], "tokenized": ["information architecture", "content based bilingual web site", "language therapists", "bilingual card sorting activity", "bilingual developments"]}, "absent_kps": {"text": ["world wide web", "speech therapists"], "tokenized": ["world wide web", "speech therapists"]}}
{"id": 156, "title": {"text": "modularity in technology and organization .", "tokenized": "modularity in technology and organization ."}, "abstract": {"text": "literature on property rights to create the outlines of a modularity theory of the firm . such a theory will look at firms , and other organizations , in terms of the partitioning of rights understood as protected spheres of authority among cooperating parties . it will assert that organizations reflect nonmodular structures , that is , structures in which decision rights , rights of alienation , and residual claims to income do not all reside in the same hands", "tokenized": "literature on property rights to create the outlines of a modularity theory of the firm . such a theory will look at firms , and other organizations , in terms of the partitioning of rights understood as protected spheres of authority among cooperating parties . it will assert that organizations reflect nonmodular structures , that is , structures in which decision rights , rights of alienation , and residual claims to income do not all reside in the same hands"}, "present_kps": {"text": ["modularity", "technology", "organization", "property rights", "partitioning of rights", "authority", "cooperating parties", "nonmodular structures", "decision rights", "rights of alienation"], "tokenized": ["modularity", "technology", "organization", "property rights", "partitioning of rights", "authority", "cooperating parties", "nonmodular structures", "decision rights", "rights of alienation"]}, "absent_kps": {"text": ["transaction costs"], "tokenized": ["transaction costs"]}}
{"id": 157, "title": {"text": "designing a new urban internet .", "tokenized": "designing a new urban internet ."}, "abstract": {"text": "a familiar one , but how often do we think of the internet as having parks and streets it would be absurd to say that the internet could ever take the place of real , livable communities however , it is safe to say that the context for using the internet is on a path of change . as the internet evolves beyond a simple linkage of disparate web sites and applications , the challenge for information architects is establishing a process by which to structure , organize , and design networked environments . the principles that guide new urbanism can offer much insight into networked electronic environment design . at the core of every new urbanism principle is the idea of wholeness of making sure that neighborhoods and communities are knit together in a way that supports civic activities , economic development , efficient ecosystems , aesthetic beauty , and human interaction", "tokenized": "a familiar one , but how often do we think of the internet as having parks and streets it would be absurd to say that the internet could ever take the place of real , livable communities however , it is safe to say that the context for using the internet is on a path of change . as the internet evolves beyond a simple linkage of disparate web sites and applications , the challenge for information architects is establishing a process by which to structure , organize , and design networked environments . the principles that guide new urbanism can offer much insight into networked electronic environment design . at the core of every new urbanism principle is the idea of wholeness of making sure that neighborhoods and communities are knit together in a way that supports civic activities , economic development , efficient ecosystems , aesthetic beauty , and human interaction"}, "present_kps": {"text": ["internet", "communities", "web site", "information architects", "networked environments", "networked electronic environment design"], "tokenized": ["internet", "communities", "web site", "information architects", "networked environments", "networked electronic environment design"]}, "absent_kps": {"text": ["private public sector cooperation", "global information networks"], "tokenized": ["private public sector cooperation", "global information networks"]}}
{"id": 158, "title": {"text": "three dimensional optimum design of the cooling lines of injection moulds based .", "tokenized": "three dimensional optimum design of the cooling lines of injection moulds based ."}, "abstract": {"text": "a three dimensional numerical simulation using the boundary element method is proposed , which can predict the cavity temperature distributions in the cooling stage of injection moulding . then , choosing the radii and positions of cooling lines as design variables , the boundary integral sensitivity formulations are deduced . for the optimum design of cooling lines , the squared difference between the objective temperature and temperature of the cavity is taken as the objective function . based on the optimization techniques with design sensitivity analysis , an iterative algorithm to reach the minimum value of the objective function is introduced , which leads to the optimum design of cooling lines at the same time", "tokenized": "a three dimensional numerical simulation using the boundary element method is proposed , which can predict the cavity temperature distributions in the cooling stage of injection moulding . then , choosing the radii and positions of cooling lines as design variables , the boundary integral sensitivity formulations are deduced . for the optimum design of cooling lines , the squared difference between the objective temperature and temperature of the cavity is taken as the objective function . based on the optimization techniques with design sensitivity analysis , an iterative algorithm to reach the minimum value of the objective function is introduced , which leads to the optimum design of cooling lines at the same time"}, "present_kps": {"text": ["injection moulding", "boundary element method", "cavity temperature distributions", "cooling stage", "objective function", "optimization", "iterative algorithm"], "tokenized": ["injection moulding", "boundary element method", "cavity temperature distributions", "cooling stage", "objective function", "optimization", "iterative algorithm"]}, "absent_kps": {"text": ["3d numerical simulation", "boundary integral sensitivity analysis", "heat conduction"], "tokenized": ["3d numerical simulation", "boundary integral sensitivity analysis", "heat conduction"]}}
{"id": 159, "title": {"text": "managing safety and strategic stocks to improve materials requirements planning .", "tokenized": "managing safety and strategic stocks to improve materials requirements planning ."}, "abstract": {"text": "this paper provides a methodology for managing safety and strategic stocks in materials requirements planning ( mrp ) environments to face uncertainty in market demand . a set of recommended guidelines suggest where to position , how to dimension and when to replenish both safety and strategic stocks . trade offs between stock positioning and dimensioning and between stock positioning and replenishment order triggering are outlined . the study reveals also that most of the decisions are system specific , so that they should be evaluated in a quantitative manner through simulation . a case study is reported , where the benefits from adopting the new proposed methodology lie in achieving the target service level even under peak demand conditions , with the value of safety stocks as a whole growing only by about [digit] per cent", "tokenized": "this paper provides a methodology for managing safety and strategic stocks in materials requirements planning ( mrp ) environments to face uncertainty in market demand . a set of recommended guidelines suggest where to position , how to dimension and when to replenish both safety and strategic stocks . trade offs between stock positioning and dimensioning and between stock positioning and replenishment order triggering are outlined . the study reveals also that most of the decisions are system specific , so that they should be evaluated in a quantitative manner through simulation . a case study is reported , where the benefits from adopting the new proposed methodology lie in achieving the target service level even under peak demand conditions , with the value of safety stocks as a whole growing only by about [digit] per cent"}, "present_kps": {"text": ["strategic stocks", "materials requirements planning", "mrp", "market demand", "service level", "peak demand", "safety stocks"], "tokenized": ["strategic stocks", "materials requirements planning", "mrp", "market demand", "service level", "peak demand", "safety stocks"]}, "absent_kps": {"text": ["variance control", "inventory management", "stock replenishment"], "tokenized": ["variance control", "inventory management", "stock replenishment"]}}
{"id": 160, "title": {"text": "innovative manufacture of impulse turbine blades for wave energy power .", "tokenized": "innovative manufacture of impulse turbine blades for wave energy power ."}, "abstract": {"text": "an innovative approach to the manufacture of impulse turbine blades using rapid prototyping , fused decomposition modelling ( fdm ) , is presented . these blades were designed and manufactured by the wave energy research team ( wert ) at the university of limerick for the experimental analysis of a [digit] . [digit] m impulse turbine with fixed guide vanes for wave energy power conversion . the computer aided design manufacture ( cad cam ) package pro engineer 2000i was used for three dimensional solid modelling of the individual blades . a detailed finite element analysis of the blades under centrifugal loads was performed using pro mechanica . based on this analysis and fdm machine capabilities , blades were redesigned . finally , pro e data were transferred to an fdm machine for the manufacture of turbine blades . the objective of this paper is to present the innovative method used to design , modify and manufacture blades in a time and cost effective manner using a concurrent engineering approach", "tokenized": "an innovative approach to the manufacture of impulse turbine blades using rapid prototyping , fused decomposition modelling ( fdm ) , is presented . these blades were designed and manufactured by the wave energy research team ( wert ) at the university of limerick for the experimental analysis of a [digit] . [digit] m impulse turbine with fixed guide vanes for wave energy power conversion . the computer aided design manufacture ( cad cam ) package pro engineer 2000i was used for three dimensional solid modelling of the individual blades . a detailed finite element analysis of the blades under centrifugal loads was performed using pro mechanica . based on this analysis and fdm machine capabilities , blades were redesigned . finally , pro e data were transferred to an fdm machine for the manufacture of turbine blades . the objective of this paper is to present the innovative method used to design , modify and manufacture blades in a time and cost effective manner using a concurrent engineering approach"}, "present_kps": {"text": ["manufacturing", "impulse turbine blades", "rapid prototyping", "fused decomposition modelling", "university of limerick", "wave energy power conversion", "cad cam", "solid modelling", "finite element analysis", "concurrent engineering"], "tokenized": ["manufacturing", "impulse turbine blades", "rapid prototyping", "fused decomposition modelling", "university of limerick", "wave energy power conversion", "cad cam", "solid modelling", "finite element analysis", "concurrent engineering"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 161, "title": {"text": "evaluation of combined dispatching and routeing strategies for a flexible .", "tokenized": "evaluation of combined dispatching and routeing strategies for a flexible ."}, "abstract": {"text": "this paper deals with the evaluation of combined dispatching and routeing strategies on the performance of a flexible manufacturing system . three routeing policies no alternative routings , alternative routeing dynamics and alternative routeing plans are considered with four dispatching rules with finite buffer capacity . in addition , the effect of changing part mix ratios is also discussed . the performance measures considered are makespan , average machine utilization , average flow time and average delay at local input buffers . simulation results indicate that the alternative routings dynamic policy gives the best results in three performance measures except for average delay at local input buffers . further , the effect of changing part mix ratios is not significant", "tokenized": "this paper deals with the evaluation of combined dispatching and routeing strategies on the performance of a flexible manufacturing system . three routeing policies no alternative routings , alternative routeing dynamics and alternative routeing plans are considered with four dispatching rules with finite buffer capacity . in addition , the effect of changing part mix ratios is also discussed . the performance measures considered are makespan , average machine utilization , average flow time and average delay at local input buffers . simulation results indicate that the alternative routings dynamic policy gives the best results in three performance measures except for average delay at local input buffers . further , the effect of changing part mix ratios is not significant"}, "present_kps": {"text": ["flexible manufacturing system", "alternative routings", "dispatching rules", "finite buffer capacity", "part mix ratios", "average flow time"], "tokenized": ["flexible manufacturing system", "alternative routings", "dispatching rules", "finite buffer capacity", "part mix ratios", "average flow time"]}, "absent_kps": {"text": ["fms"], "tokenized": ["fms"]}}
{"id": 162, "title": {"text": "an intelligent fuzzy decision system for a flexible manufacturing system with .", "tokenized": "an intelligent fuzzy decision system for a flexible manufacturing system with ."}, "abstract": {"text": "this paper describes an intelligent fuzzy decision support system for real time scheduling and dispatching of parts in a flexible manufacturing system ( fms ) , with alternative routing possibilities for all parts . a fuzzy logic approach is developed to improve the system performance by considering multiple performance measures and at multiple decision points . the characteristics of the system status , instead of parts , are fed back to assign priority to the parts waiting to be processed . a simulation model is developed and it is shown that the proposed intelligent fuzzy decision support system keeps all performance measures at a good level . the proposed intelligent system is a promising tool for dealing with scheduling fmss , in contrast to traditional rules", "tokenized": "this paper describes an intelligent fuzzy decision support system for real time scheduling and dispatching of parts in a flexible manufacturing system ( fms ) , with alternative routing possibilities for all parts . a fuzzy logic approach is developed to improve the system performance by considering multiple performance measures and at multiple decision points . the characteristics of the system status , instead of parts , are fed back to assign priority to the parts waiting to be processed . a simulation model is developed and it is shown that the proposed intelligent fuzzy decision support system keeps all performance measures at a good level . the proposed intelligent system is a promising tool for dealing with scheduling fmss , in contrast to traditional rules"}, "present_kps": {"text": ["flexible manufacturing system", "scheduling", "fms", "fuzzy logic", "multiple decision points", "simulation"], "tokenized": ["flexible manufacturing system", "scheduling", "fms", "fuzzy logic", "multiple decision points", "simulation"]}, "absent_kps": {"text": ["intelligent decision support system", "real time system"], "tokenized": ["intelligent decision support system", "real time system"]}}
{"id": 163, "title": {"text": "a design to cost system for innovative product development .", "tokenized": "a design to cost system for innovative product development ."}, "abstract": {"text": "modelling and design for automation at an early design stage . the developed system comprises a computer aided design ( cad ) solid modelling system , a material selection module , a knowledge based system ( kbs ) , a process optimization module , a design for assembly module , a cost estimation module and a user interface . two manufacturing processes , namely machining and injection moulding processes , were considered in the developed system . the main function of the system , besides estimating the product cost , is to generate initial process planning , including the generation and selection of machining processes , their sequence and their machining parameters , and to recommend the most economical assembly technique for a product and provide design improvement suggestions based on a design feasibility technique . in addition , a feature by feature cost estimation report is generated using the proposed system to highlight the features of high manufacturing cost . two case studies were used to validate the developed system", "tokenized": "modelling and design for automation at an early design stage . the developed system comprises a computer aided design ( cad ) solid modelling system , a material selection module , a knowledge based system ( kbs ) , a process optimization module , a design for assembly module , a cost estimation module and a user interface . two manufacturing processes , namely machining and injection moulding processes , were considered in the developed system . the main function of the system , besides estimating the product cost , is to generate initial process planning , including the generation and selection of machining processes , their sequence and their machining parameters , and to recommend the most economical assembly technique for a product and provide design improvement suggestions based on a design feasibility technique . in addition , a feature by feature cost estimation report is generated using the proposed system to highlight the features of high manufacturing cost . two case studies were used to validate the developed system"}, "present_kps": {"text": ["design to cost system", "innovative product development", "design for automation", "material selection module", "knowledge based system", "process optimization module", "design for assembly module", "cost estimation module", "user interface", "machining", "injection moulding", "process planning", "feature by feature cost estimation report"], "tokenized": ["design to cost system", "innovative product development", "design for automation", "material selection module", "knowledge based system", "process optimization module", "design for assembly module", "cost estimation module", "user interface", "machining", "injection moulding", "process planning", "feature by feature cost estimation report"]}, "absent_kps": {"text": ["object oriented rule based system", "concurrent engineering", "product cost modelling", "fuzzy logic", "object oriented programming", "computer aided design solid modelling system"], "tokenized": ["object oriented rule based system", "concurrent engineering", "product cost modelling", "fuzzy logic", "object oriented programming", "computer aided design solid modelling system"]}}
{"id": 164, "title": {"text": "re examining the machining frictional boundary conditions using fractals .", "tokenized": "re examining the machining frictional boundary conditions using fractals ."}, "abstract": {"text": "geometry at the tool chip interface in the machining of aluminium alloy , which challenges conventional assumptions . the geometry of contact at the tool rake face is modelled using fractals and a dimension is computed for its description . the variation in the fractal dimension with the cutting speed is explored", "tokenized": "geometry at the tool chip interface in the machining of aluminium alloy , which challenges conventional assumptions . the geometry of contact at the tool rake face is modelled using fractals and a dimension is computed for its description . the variation in the fractal dimension with the cutting speed is explored"}, "present_kps": {"text": ["machining frictional boundary conditions", "fractals", "tool chip interface", "aluminium alloy", "tool rake face", "cutting speed"], "tokenized": ["machining frictional boundary conditions", "fractals", "tool chip interface", "aluminium alloy", "tool rake face", "cutting speed"]}, "absent_kps": {"text": ["al", "noneuclidean contact geometry", "contact geometry"], "tokenized": ["al", "noneuclidean contact geometry", "contact geometry"]}}
{"id": 165, "title": {"text": "layer based machining recent development and support structure design .", "tokenized": "layer based machining recent development and support structure design ."}, "abstract": {"text": "synthesized to integrate the layered manufacturing process and material removal process . layer based machining has emerged as a promising method for integrated additive and subtractive shaping theory . in the paper , major layer based machining systems are reviewed and compared according to characteristics of stock layers , numerical control machining configurations , stacking operations , input format and raw materials . support structure , a major issue in machining based systems which has seldom been addressed in previous research , is investigated in the paper with considerations of four situations floating overhang , cantilever , vaulted overhang and ceiling . except for the floating overhang where a support structure should not be overlooked , the necessity for support structures for the other three situations is determined by stress and deflection analysis . this is demonstrated by the machining of a large castle model", "tokenized": "synthesized to integrate the layered manufacturing process and material removal process . layer based machining has emerged as a promising method for integrated additive and subtractive shaping theory . in the paper , major layer based machining systems are reviewed and compared according to characteristics of stock layers , numerical control machining configurations , stacking operations , input format and raw materials . support structure , a major issue in machining based systems which has seldom been addressed in previous research , is investigated in the paper with considerations of four situations floating overhang , cantilever , vaulted overhang and ceiling . except for the floating overhang where a support structure should not be overlooked , the necessity for support structures for the other three situations is determined by stress and deflection analysis . this is demonstrated by the machining of a large castle model"}, "present_kps": {"text": ["layer based machining", "support structure design", "layered manufacturing process", "material removal process", "subtractive shaping theories", "stock layers", "numerical control machining configurations", "stacking operations", "input format", "raw materials", "floating overhang", "cantilever", "vaulted overhang", "ceiling", "stress", "deflection analysis"], "tokenized": ["layer based machining", "support structure design", "layered manufacturing process", "material removal process", "subtractive shaping theories", "stock layers", "numerical control machining configurations", "stacking operations", "input format", "raw materials", "floating overhang", "cantilever", "vaulted overhang", "ceiling", "stress", "deflection analysis"]}, "absent_kps": {"text": ["additive shaping theories"], "tokenized": ["additive shaping theories"]}}
{"id": 166, "title": {"text": "world ' s biggest battery helps to stabilise alaska .", "tokenized": "world ' s biggest battery helps to stabilise alaska ."}, "abstract": {"text": "under construction to provide voltage compensation in support of alaska ' s [digit] kv northern intertie", "tokenized": "under construction to provide voltage compensation in support of alaska ' s [digit] kv northern intertie"}, "present_kps": {"text": ["voltage compensation", "[digit] kv"], "tokenized": ["voltage compensation", "[digit] kv"]}, "absent_kps": {"text": ["interconnected power systems", "usa", "power system stabilisation", "battery energy storage system", "[digit] mw"], "tokenized": ["interconnected power systems", "usa", "power system stabilisation", "battery energy storage system", "[digit] mw"]}}
{"id": 167, "title": {"text": "information interaction providing a framework for information architecture .", "tokenized": "information interaction providing a framework for information architecture ."}, "abstract": {"text": "content of an information system . information architecture is a blueprint and navigational aid to the content of information rich systems . as such information architecture performs an important supporting role in information interactivity . this article elaborates on a model of information interactivity that crosses the no man ' s land between user and computer articulating a model that includes user , content and system , illustrating the context for information architecture", "tokenized": "content of an information system . information architecture is a blueprint and navigational aid to the content of information rich systems . as such information architecture performs an important supporting role in information interactivity . this article elaborates on a model of information interactivity that crosses the no man ' s land between user and computer articulating a model that includes user , content and system , illustrating the context for information architecture"}, "present_kps": {"text": ["information interaction", "information interactivity", "navigational aid", "information rich systems"], "tokenized": ["information interaction", "information interactivity", "navigational aid", "information rich systems"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 168, "title": {"text": "all optical logic nor gate using two cascaded semiconductor optical amplifiers .", "tokenized": "all optical logic nor gate using two cascaded semiconductor optical amplifiers ."}, "abstract": {"text": "semiconductor optical . amplifiers ( soas ) in a counterpropagating feedback configuration . this configuration accentuates the gain nonlinearity due to the mutual gain modulation of the two soas . the all optical nor gate feasibility has been demonstrated delivering an extinction ratio higher than [digit] db over a wide range of wavelength", "tokenized": "semiconductor optical . amplifiers ( soas ) in a counterpropagating feedback configuration . this configuration accentuates the gain nonlinearity due to the mutual gain modulation of the two soas . the all optical nor gate feasibility has been demonstrated delivering an extinction ratio higher than [digit] db over a wide range of wavelength"}, "present_kps": {"text": ["all optical logic nor gate", "two cascaded semiconductor optical amplifiers", "soa", "counterpropagating feedback configuration", "gain nonlinearity", "mutual gain modulation", "extinction ratio"], "tokenized": ["all optical logic nor gate", "two cascaded semiconductor optical amplifiers", "soa", "counterpropagating feedback configuration", "gain nonlinearity", "mutual gain modulation", "extinction ratio"]}, "absent_kps": {"text": ["wide wavelength range"], "tokenized": ["wide wavelength range"]}}
{"id": 169, "title": {"text": "prospects for quantitative computed tomography imaging in the presence of .", "tokenized": "prospects for quantitative computed tomography imaging in the presence of ."}, "abstract": {"text": "x ray computed tomography ( ct ) images of patients bearing metal intracavitary applicators or other metal foreign objects exhibit severe artifacts including streaks and aliasing . we have systematically evaluated via computer simulations the impact of scattered radiation , the polyenergetic spectrum , and measurement noise on the performance of three reconstruction algorithms conventional filtered backprojection ( fbp ) , deterministic iterative deblurring , and a new iterative algorithm , alternating minimization ( am ) , based on a ct detector model that includes noise , scatter , and polyenergetic spectra . contrary to the dominant view of the literature , fbp streaking artifacts are due mostly to mismatches between fbp ' s simplified model of ct detector response and the physical process of signal acquisition . artifacts on am images are significantly mitigated as this algorithm substantially reduces detector model mismatches . however , metal artifacts are reduced to acceptable levels only when prior knowledge of the metal object in the patient , including its pose , shape , and attenuation map , are used to constrain am ' s iterations . am image reconstruction , in combination with object constrained ct to estimate the pose of metal objects in the patient , is a promising approach for effectively mitigating metal artifacts and making quantitative estimation of tissue attenuation coefficients a clinical possibility", "tokenized": "x ray computed tomography ( ct ) images of patients bearing metal intracavitary applicators or other metal foreign objects exhibit severe artifacts including streaks and aliasing . we have systematically evaluated via computer simulations the impact of scattered radiation , the polyenergetic spectrum , and measurement noise on the performance of three reconstruction algorithms conventional filtered backprojection ( fbp ) , deterministic iterative deblurring , and a new iterative algorithm , alternating minimization ( am ) , based on a ct detector model that includes noise , scatter , and polyenergetic spectra . contrary to the dominant view of the literature , fbp streaking artifacts are due mostly to mismatches between fbp ' s simplified model of ct detector response and the physical process of signal acquisition . artifacts on am images are significantly mitigated as this algorithm substantially reduces detector model mismatches . however , metal artifacts are reduced to acceptable levels only when prior knowledge of the metal object in the patient , including its pose , shape , and attenuation map , are used to constrain am ' s iterations . am image reconstruction , in combination with object constrained ct to estimate the pose of metal objects in the patient , is a promising approach for effectively mitigating metal artifacts and making quantitative estimation of tissue attenuation coefficients a clinical possibility"}, "present_kps": {"text": ["quantitative computed tomography imaging", "scatter", "noise", "filtered backprojection", "deterministic iterative deblurring", "iterative algorithm", "alternating minimization", "ct detector model", "polyenergetic spectra", "object constrained ct", "clinical possibility"], "tokenized": ["quantitative computed tomography imaging", "scatter", "noise", "filtered backprojection", "deterministic iterative deblurring", "iterative algorithm", "alternating minimization", "ct detector model", "polyenergetic spectra", "object constrained ct", "clinical possibility"]}, "absent_kps": {"text": ["medical diagnostic imaging", "foreign metal bodies", "metal artifact reduction", "brachytherapy", "statistical image reconstruction", "signal acquisition physical process"], "tokenized": ["medical diagnostic imaging", "foreign metal bodies", "metal artifact reduction", "brachytherapy", "statistical image reconstruction", "signal acquisition physical process"]}}
{"id": 170, "title": {"text": "matching pet and ct scans of the head and neck area development of method and .", "tokenized": "matching pet and ct scans of the head and neck area development of method and ."}, "abstract": {"text": "positron emission tomography ( pet ) provides important information on tumor biology , but lacks detailed anatomical information . our aim in the present study was to develop and validate an automatic registration method for matching pet and ct scans of the head and neck . three difficulties in achieving this goal are ( [digit] ) nonrigid motions of the neck can hamper the use of automatic ridged body transformations ( [digit] ) emission scans contain too little anatomical information to apply standard image fusion methods and ( [digit] ) no objective way exists to quantify the quality of the match results . these problems are solved as follows accurate and reproducible positioning of the patient was achieved by using a radiotherapy treatment mask . the proposed method makes use of the transmission rather than the emission scan . to obtain sufficient ( anatomical ) information for matching , two bed positions for the transmission scan were included in the protocol . a mutual information based algorithm was used as a registration technique . pet and ct data were obtained in seven patients . each patient had two ct scans and one pet scan . the datasets were used to estimate the consistency by matching pet to ct sub [digit] , ct sub [digit] to ct sub [digit] , and ct sub [digit] to pet using the full circle consistency test . it was found that using our method , consistency could be obtained of [digit] mm and [digit] . [digit] degrees on average . the pet voxels used for registration were [digit] . [digit] mm , so the errors compared quite favorably with the voxel size . cropping the images ( removing the scanner bed from images ) did not improve the consistency of the algorithm . the transmission scan , however , could potentially be reduced to a single position using this approach . in conclusion , the represented algorithm and validation technique has several features that are attractive from both theoretical and practical point of view , it is a user independent , automatic validation technique for matching ct and pet scans of the head and neck , which gives the opportunity to compare different image enhancements", "tokenized": "positron emission tomography ( pet ) provides important information on tumor biology , but lacks detailed anatomical information . our aim in the present study was to develop and validate an automatic registration method for matching pet and ct scans of the head and neck . three difficulties in achieving this goal are ( [digit] ) nonrigid motions of the neck can hamper the use of automatic ridged body transformations ( [digit] ) emission scans contain too little anatomical information to apply standard image fusion methods and ( [digit] ) no objective way exists to quantify the quality of the match results . these problems are solved as follows accurate and reproducible positioning of the patient was achieved by using a radiotherapy treatment mask . the proposed method makes use of the transmission rather than the emission scan . to obtain sufficient ( anatomical ) information for matching , two bed positions for the transmission scan were included in the protocol . a mutual information based algorithm was used as a registration technique . pet and ct data were obtained in seven patients . each patient had two ct scans and one pet scan . the datasets were used to estimate the consistency by matching pet to ct sub [digit] , ct sub [digit] to ct sub [digit] , and ct sub [digit] to pet using the full circle consistency test . it was found that using our method , consistency could be obtained of [digit] mm and [digit] . [digit] degrees on average . the pet voxels used for registration were [digit] . [digit] mm , so the errors compared quite favorably with the voxel size . cropping the images ( removing the scanner bed from images ) did not improve the consistency of the algorithm . the transmission scan , however , could potentially be reduced to a single position using this approach . in conclusion , the represented algorithm and validation technique has several features that are attractive from both theoretical and practical point of view , it is a user independent , automatic validation technique for matching ct and pet scans of the head and neck , which gives the opportunity to compare different image enhancements"}, "present_kps": {"text": ["head", "neck", "tumor biology", "anatomical information", "automatic registration method", "nonrigid motions", "automatic ridged body transformations", "standard image fusion methods", "patients", "radiotherapy treatment mask", "bed positions", "transmission scan", "mutual information based algorithm", "registration technique", "full circle consistency test", "errors", "scanner bed", "image enhancements"], "tokenized": ["head", "neck", "tumor biology", "anatomical information", "automatic registration method", "nonrigid motions", "automatic ridged body transformations", "standard image fusion methods", "patients", "radiotherapy treatment mask", "bed positions", "transmission scan", "mutual information based algorithm", "registration technique", "full circle consistency test", "errors", "scanner bed", "image enhancements"]}, "absent_kps": {"text": ["positron emission tomography scans", "user independent automatic validation technique", "computerised tomography scans"], "tokenized": ["positron emission tomography scans", "user independent automatic validation technique", "computerised tomography scans"]}}
{"id": 171, "title": {"text": "fresh tracks food processing .", "tokenized": "fresh tracks food processing ."}, "abstract": {"text": "accurately track meat products from receiving to customers for farmland foods", "tokenized": "accurately track meat products from receiving to customers for farmland foods"}, "present_kps": {"text": ["food processing", "farmland foods"], "tokenized": ["food processing", "farmland foods"]}, "absent_kps": {"text": ["wireless terminals", "automatic data capture", "bar code labels", "intermec technologies"], "tokenized": ["wireless terminals", "automatic data capture", "bar code labels", "intermec technologies"]}}
{"id": 172, "title": {"text": "statistical inference with partial prior information based on a gauss type .", "tokenized": "statistical inference with partial prior information based on a gauss type ."}, "abstract": {"text": "potter and anderson ( [digit] ) have developed a bayesian decision procedure requiring the specification of a class of prior distributions restricted to have a minimal probability content for a given subset of the parameter space . they do not , however , provide a method for the selection of that subset . we show how a generalization of gauss ' inequality can be used to determine the relevant parameter subset", "tokenized": "potter and anderson ( [digit] ) have developed a bayesian decision procedure requiring the specification of a class of prior distributions restricted to have a minimal probability content for a given subset of the parameter space . they do not , however , provide a method for the selection of that subset . we show how a generalization of gauss ' inequality can be used to determine the relevant parameter subset"}, "present_kps": {"text": ["partial prior information", "bayesian decision procedure", "prior distributions", "minimal probability content", "parameter space"], "tokenized": ["partial prior information", "bayesian decision procedure", "prior distributions", "minimal probability content", "parameter space"]}, "absent_kps": {"text": ["prior to posterior sensitivity", "gauss inequality"], "tokenized": ["prior to posterior sensitivity", "gauss inequality"]}}
{"id": 173, "title": {"text": "global stability of the attracting set of an enzyme catalysed reaction system .", "tokenized": "global stability of the attracting set of an enzyme catalysed reaction system ."}, "abstract": {"text": "reaction rate on metabolite concentration taking the form of saturation kinetics . recently , it has been shown that this feature is associated with the phenomenon of loss of system coordination ( liu , [digit] ) . in this paper , we study a system of ordinary differential equations representing a branched biochemical system of enzyme mediated reactions . we show that this system can become very sensitive to changes in certain maximum enzyme activities . in particular , we show that the system exhibits three distinct responses a unique , globally stable steady state , large amplitude oscillations , and asymptotically unbounded solutions , with the transition between these states being almost instantaneous . it is shown that the appearance of large amplitude , stable limit cycles occurs due to a false bifurcation or canard explosion . the subsequent disappearance of limit cycles corresponds to the collapse of the domain of attraction of the attracting set for the system and occurs due to a global bifurcation in the flow , namely , a saddle connection . subsequently , almost all nonnegative data become unbounded under the action of the dynamical system and correspond exactly to loss of system coordination . we discuss the relevance of these results to the possible consequences of modulating such systems", "tokenized": "reaction rate on metabolite concentration taking the form of saturation kinetics . recently , it has been shown that this feature is associated with the phenomenon of loss of system coordination ( liu , [digit] ) . in this paper , we study a system of ordinary differential equations representing a branched biochemical system of enzyme mediated reactions . we show that this system can become very sensitive to changes in certain maximum enzyme activities . in particular , we show that the system exhibits three distinct responses a unique , globally stable steady state , large amplitude oscillations , and asymptotically unbounded solutions , with the transition between these states being almost instantaneous . it is shown that the appearance of large amplitude , stable limit cycles occurs due to a false bifurcation or canard explosion . the subsequent disappearance of limit cycles corresponds to the collapse of the domain of attraction of the attracting set for the system and occurs due to a global bifurcation in the flow , namely , a saddle connection . subsequently , almost all nonnegative data become unbounded under the action of the dynamical system and correspond exactly to loss of system coordination . we discuss the relevance of these results to the possible consequences of modulating such systems"}, "present_kps": {"text": ["metabolite concentration", "saturation kinetics", "ordinary differential equations", "biochemical system", "enzyme mediated reactions", "stable limit cycles", "bifurcation", "saddle connection"], "tokenized": ["metabolite concentration", "saturation kinetics", "ordinary differential equations", "biochemical system", "enzyme mediated reactions", "stable limit cycles", "bifurcation", "saddle connection"]}, "absent_kps": {"text": ["nonlinear dependency", "enzymatic reactions"], "tokenized": ["nonlinear dependency", "enzymatic reactions"]}}
{"id": 174, "title": {"text": "a spatial rainfall simulator for crop production modeling in southern africa .", "tokenized": "a spatial rainfall simulator for crop production modeling in southern africa ."}, "abstract": {"text": "set of spatial units in areas where long term meteorological records are available for a small number of sites only . the work forms part of a larger simulation model of the food system in a district of zimbabwe , which includes a crop production component for yields of maize , small grains and groundnuts . only a limited number of meteorological stations are available within or surrounding the district that have long time series of rainfall records . preliminary analysis of rainfall data for these stations suggested that intra seasonal temporal correlation was negligible , but that rainfall at any given station was correlated with rainfall at neighbouring stations . this spatial correlation structure can be modeled using a multivariate normal distribution consisting of [digit] related variables , representing dekadly rainfall in each of the [digit] wards . for each ward , log transformed rainfall for each of the [digit] dekads in the year was characterized by a mean and standard deviation , which were interpolated from surrounding meteorological stations . a covariance matrix derived from a distance measure was then used to represent the spatial correlation between wards . sets of random numbers were then drawn from this distribution to simulate rainfall across the wards in any given dekad . cross validation of estimated rainfall parameters against observed parameters for the one meteorological station within the district suggests that the interpolation process works well . the methodology developed is useful in situations where long term climatic records are scarce and where rainfall shows pronounced spatial correlation , but negligible temporal correlation", "tokenized": "set of spatial units in areas where long term meteorological records are available for a small number of sites only . the work forms part of a larger simulation model of the food system in a district of zimbabwe , which includes a crop production component for yields of maize , small grains and groundnuts . only a limited number of meteorological stations are available within or surrounding the district that have long time series of rainfall records . preliminary analysis of rainfall data for these stations suggested that intra seasonal temporal correlation was negligible , but that rainfall at any given station was correlated with rainfall at neighbouring stations . this spatial correlation structure can be modeled using a multivariate normal distribution consisting of [digit] related variables , representing dekadly rainfall in each of the [digit] wards . for each ward , log transformed rainfall for each of the [digit] dekads in the year was characterized by a mean and standard deviation , which were interpolated from surrounding meteorological stations . a covariance matrix derived from a distance measure was then used to represent the spatial correlation between wards . sets of random numbers were then drawn from this distribution to simulate rainfall across the wards in any given dekad . cross validation of estimated rainfall parameters against observed parameters for the one meteorological station within the district suggests that the interpolation process works well . the methodology developed is useful in situations where long term climatic records are scarce and where rainfall shows pronounced spatial correlation , but negligible temporal correlation"}, "present_kps": {"text": ["crop production modeling", "southern africa", "zimbabwe", "rainfall records", "rainfall data", "spatial correlation", "multivariate normal distribution", "covariance matrix", "simulating rainfall"], "tokenized": ["crop production modeling", "southern africa", "zimbabwe", "rainfall records", "rainfall data", "spatial correlation", "multivariate normal distribution", "covariance matrix", "simulating rainfall"]}, "absent_kps": {"text": ["parameter estimation"], "tokenized": ["parameter estimation"]}}
{"id": 175, "title": {"text": "an algorithm to generate all spanning trees with flow .", "tokenized": "an algorithm to generate all spanning trees with flow ."}, "abstract": {"text": "in many problems encountered in computer network and circuit analysis . this paper discusses the spanning tree with flow for the case that there are flow requirements between each node pair . an algorithm based on minimal paths ( mps ) is proposed to generate all spanning trees without flow . the proposed algorithm is a structured approach , which splits the system into structural mps first , and also all steps in it are easy to follow", "tokenized": "in many problems encountered in computer network and circuit analysis . this paper discusses the spanning tree with flow for the case that there are flow requirements between each node pair . an algorithm based on minimal paths ( mps ) is proposed to generate all spanning trees without flow . the proposed algorithm is a structured approach , which splits the system into structural mps first , and also all steps in it are easy to follow"}, "present_kps": {"text": ["spanning trees", "circuit analysis", "minimal paths"], "tokenized": ["spanning trees", "circuit analysis", "minimal paths"]}, "absent_kps": {"text": ["undirected graphs", "computer network analysis"], "tokenized": ["undirected graphs", "computer network analysis"]}}
{"id": 176, "title": {"text": "nonlinear systems arising from nonisothermal , non newtonian hele shaw flows in .", "tokenized": "nonlinear systems arising from nonisothermal , non newtonian hele shaw flows in ."}, "abstract": {"text": "in this paper , we first give a formal derivation of several systems of equations for injection moulding . this is done starting from the basic equations for nonisothermal , non newtonian flows in a three dimensional domain . we derive systems for both ( t sup [digit] , p sup [digit] ) and ( t sup [digit] , p sup [digit] ) in the presence of body forces and sources . we find that body forces and sources have a nonlinear effect on the systems . we also derive a nonlinear darcy law . our formulation includes not only the pressure gradient , but also body forces and sources , which play the role of a nonlinearity . later , we prove the existence of weak solutions to certain boundary value problems and initial boundary value problems associated with the resulting equations for ( t sup [digit] , p sup [digit] ) but in a more general mathematical setting", "tokenized": "in this paper , we first give a formal derivation of several systems of equations for injection moulding . this is done starting from the basic equations for nonisothermal , non newtonian flows in a three dimensional domain . we derive systems for both ( t sup [digit] , p sup [digit] ) and ( t sup [digit] , p sup [digit] ) in the presence of body forces and sources . we find that body forces and sources have a nonlinear effect on the systems . we also derive a nonlinear darcy law . our formulation includes not only the pressure gradient , but also body forces and sources , which play the role of a nonlinearity . later , we prove the existence of weak solutions to certain boundary value problems and initial boundary value problems associated with the resulting equations for ( t sup [digit] , p sup [digit] ) but in a more general mathematical setting"}, "present_kps": {"text": ["nonlinear systems", "hele shaw flows", "injection moulding", "body forces", "sources", "darcy law", "boundary value problems"], "tokenized": ["nonlinear systems", "hele shaw flows", "injection moulding", "body forces", "sources", "darcy law", "boundary value problems"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 177, "title": {"text": "analyzing the potential of a firm an operations research approach .", "tokenized": "analyzing the potential of a firm an operations research approach ."}, "abstract": {"text": "firm ' s ability to provide goods or ( and ) services to be supplied to a marketplace under restrictions imposed by a business environment in which the firm functions , is proposed . the approach is based on using linear inequalities and , generally , mixed variables in modelling this ability for a broad spectrum of industrial , transportation , agricultural , and other types of firms and allows one to formulate problems of analyzing the potential of a firm as linear programming problems or mixed programming problems with linear constraints . this approach generalizes a previous one which was proposed for a more narrow class of models , and allows one to effectively employ a widely available software for solving practical problems of the considered kind , especially for firms described by large scale models of mathematical programming", "tokenized": "firm ' s ability to provide goods or ( and ) services to be supplied to a marketplace under restrictions imposed by a business environment in which the firm functions , is proposed . the approach is based on using linear inequalities and , generally , mixed variables in modelling this ability for a broad spectrum of industrial , transportation , agricultural , and other types of firms and allows one to formulate problems of analyzing the potential of a firm as linear programming problems or mixed programming problems with linear constraints . this approach generalizes a previous one which was proposed for a more narrow class of models , and allows one to effectively employ a widely available software for solving practical problems of the considered kind , especially for firms described by large scale models of mathematical programming"}, "present_kps": {"text": ["operations research", "or", "linear inequalities", "linear programming", "mixed programming", "large scale models", "mathematical programming"], "tokenized": ["operations research", "or", "linear inequalities", "linear programming", "mixed programming", "large scale models", "mathematical programming"]}, "absent_kps": {"text": ["transportation firms", "agricultural firms", "industrial firms", "firm potential analysis"], "tokenized": ["transportation firms", "agricultural firms", "industrial firms", "firm potential analysis"]}}
{"id": 178, "title": {"text": "discrete output feedback sliding mode control of second order systems a moving switching line approach .", "tokenized": "discrete output feedback sliding mode control of second order systems a moving switching line approach ."}, "abstract": {"text": "designed independent of the initial conditions are known to be sensitive to parameter variations and extraneous disturbances during the reaching phase . for second order systems this drawback is eliminated by using the moving switching line technique where the switching line is initially designed to pass the initial conditions and is subsequently moved towards a predetermined switching line . in this paper , we make use of the above idea of moving switching line together with the reaching law approach to design a discrete output feedback sliding mode control . the main contributions of this work are such that we do not require to use system states as it makes use of only the output samples for designing the controller . and by using the moving switching line a low sensitivity system is obtained through shortening the reaching phase . simulation results show that the fast output sampling feedback guarantees sliding motion similar to that obtained using state feedback", "tokenized": "designed independent of the initial conditions are known to be sensitive to parameter variations and extraneous disturbances during the reaching phase . for second order systems this drawback is eliminated by using the moving switching line technique where the switching line is initially designed to pass the initial conditions and is subsequently moved towards a predetermined switching line . in this paper , we make use of the above idea of moving switching line together with the reaching law approach to design a discrete output feedback sliding mode control . the main contributions of this work are such that we do not require to use system states as it makes use of only the output samples for designing the controller . and by using the moving switching line a low sensitivity system is obtained through shortening the reaching phase . simulation results show that the fast output sampling feedback guarantees sliding motion similar to that obtained using state feedback"}, "present_kps": {"text": ["discrete output feedback", "sliding mode control", "moving switching line", "parameter variations", "fast output sampling feedback", "state feedback"], "tokenized": ["discrete output feedback", "sliding mode control", "moving switching line", "parameter variations", "fast output sampling feedback", "state feedback"]}, "absent_kps": {"text": ["switching variable"], "tokenized": ["switching variable"]}}
{"id": 179, "title": {"text": "when a better interface and easy navigation aren ' t enough examining the .", "tokenized": "when a better interface and easy navigation aren ' t enough examining the ."}, "abstract": {"text": "an information architecture that allows users to easily navigate through a system and quickly recover from mistakes is often defined as a highly usable system . but usability in systems design goes beyond a good interface and efficient navigation . in this article we describe two database systems in a law enforcement agency . one system is a legacy , text based system with cumbersome navigation ( rms ) the newer system is a graphical user interface with simplified navigation ( copnet ) . it is hypothesized that law enforcement users will evaluate copnet higher than rms , but experts of the older system will evaluate it higher than others will . we conducted two user studies . one study examined what users thought of rms and copnet , and compared rms experts ' evaluations with nonexperts . we found that all users evaluated copnet as more effective , easier to use , and easier to navigate than rms , and this was especially noticeable for users who were not experts with the older system . the second , follow up study examined use behavior after copnet was deployed some time later . the findings revealed that evaluations of copnet were not associated with its use . if the newer system had a better interface and was easier to navigate than the older , legacy system , why were law enforcement personnel reluctant to switch we discuss reasons why switching to a new system is difficult , especially for those who are most adept at using the older system . implications for system design and usability are also discussed", "tokenized": "an information architecture that allows users to easily navigate through a system and quickly recover from mistakes is often defined as a highly usable system . but usability in systems design goes beyond a good interface and efficient navigation . in this article we describe two database systems in a law enforcement agency . one system is a legacy , text based system with cumbersome navigation ( rms ) the newer system is a graphical user interface with simplified navigation ( copnet ) . it is hypothesized that law enforcement users will evaluate copnet higher than rms , but experts of the older system will evaluate it higher than others will . we conducted two user studies . one study examined what users thought of rms and copnet , and compared rms experts ' evaluations with nonexperts . we found that all users evaluated copnet as more effective , easier to use , and easier to navigate than rms , and this was especially noticeable for users who were not experts with the older system . the second , follow up study examined use behavior after copnet was deployed some time later . the findings revealed that evaluations of copnet were not associated with its use . if the newer system had a better interface and was easier to navigate than the older , legacy system , why were law enforcement personnel reluctant to switch we discuss reasons why switching to a new system is difficult , especially for those who are most adept at using the older system . implications for system design and usability are also discussed"}, "present_kps": {"text": ["information architecture", "law enforcement agency", "rms", "graphical user interface", "simplified navigation", "copnet", "law enforcement users"], "tokenized": ["information architecture", "law enforcement agency", "rms", "graphical user interface", "simplified navigation", "copnet", "law enforcement users"]}, "absent_kps": {"text": ["legacy text based system"], "tokenized": ["legacy text based system"]}}
{"id": 180, "title": {"text": "optimization of planning an advertising campaign of goods and services .", "tokenized": "optimization of planning an advertising campaign of goods and services ."}, "abstract": {"text": "formulated on its basis , which were presented by belenky ( [digit] ) in the framework of an approach to planning an advertising campaign of goods and services , is considered , and corresponding nonlinear programming problems with linear constraints are formulated", "tokenized": "formulated on its basis , which were presented by belenky ( [digit] ) in the framework of an approach to planning an advertising campaign of goods and services , is considered , and corresponding nonlinear programming problems with linear constraints are formulated"}, "present_kps": {"text": ["optimization", "nonlinear programming"], "tokenized": ["optimization", "nonlinear programming"]}, "absent_kps": {"text": ["advertising campaign planning", "or", "operations research"], "tokenized": ["advertising campaign planning", "or", "operations research"]}}
{"id": 181, "title": {"text": "all optical xor gate using semiconductor optical amplifiers without additional .", "tokenized": "all optical xor gate using semiconductor optical amplifiers without additional ."}, "abstract": {"text": "the novel design of an all optical xor gate by using cross gain modulation of semiconductor optical amplifiers has been suggested and demonstrated successfully at [digit] gb s . boolean ab and ab of the two input signals a and b have been obtained and combined to achieve the all optical xor gate . no additional input beam such as a clock signal or continuous wave light is used in this new design , which is required in other all optical xor gates", "tokenized": "the novel design of an all optical xor gate by using cross gain modulation of semiconductor optical amplifiers has been suggested and demonstrated successfully at [digit] gb s . boolean ab and ab of the two input signals a and b have been obtained and combined to achieve the all optical xor gate . no additional input beam such as a clock signal or continuous wave light is used in this new design , which is required in other all optical xor gates"}, "present_kps": {"text": ["all optical xor gate", "semiconductor optical amplifiers", "design", "cross gain modulation"], "tokenized": ["all optical xor gate", "semiconductor optical amplifiers", "design", "cross gain modulation"]}, "absent_kps": {"text": ["[digit] gbit s", "boolean logic"], "tokenized": ["[digit] gbit s", "boolean logic"]}}
{"id": 182, "title": {"text": "trust in online advice .", "tokenized": "trust in online advice ."}, "abstract": {"text": "internet , much of it of dubious quality . this article describes two studies concerned with those factors capable of influencing people ' s response to online advice . the first study is a qualitative account of a group of house hunters attempting to find worthwhile information online . the second study describes a survey of more than [digit] , [digit] people who had actively sought advice over the internet . a framework for understanding trust in online advice is proposed in which first impressions are distinguished from more detailed evaluations . good web design can influence the first process , but three key factors source credibility , personalization , and predictability are shown to predict whether people actually follow the advice given", "tokenized": "internet , much of it of dubious quality . this article describes two studies concerned with those factors capable of influencing people ' s response to online advice . the first study is a qualitative account of a group of house hunters attempting to find worthwhile information online . the second study describes a survey of more than [digit] , [digit] people who had actively sought advice over the internet . a framework for understanding trust in online advice is proposed in which first impressions are distinguished from more detailed evaluations . good web design can influence the first process , but three key factors source credibility , personalization , and predictability are shown to predict whether people actually follow the advice given"}, "present_kps": {"text": ["internet", "survey", "web design", "source credibility", "personalization", "predictability"], "tokenized": ["internet", "survey", "web design", "source credibility", "personalization", "predictability"]}, "absent_kps": {"text": ["house buying advice", "online mortgage advice", "e commerce", "online advice trust"], "tokenized": ["house buying advice", "online mortgage advice", "e commerce", "online advice trust"]}}
{"id": 183, "title": {"text": "the social impact of internet gambling .", "tokenized": "the social impact of internet gambling ."}, "abstract": {"text": "and continues to provide new market opportunities . one of the fastest growing areas is that of internet gambling . the effect of such technologies should not be accepted uncritically , particularly as there may be areas of potential concern based on what is known about problem gambling offline . this article has three aims . first , it overviews some of the main social concerns about the rise of internet gambling . second , it looks at the limited research that has been carried out in this area . third , it examines whether internet gambling is doubly addictive , given research that suggests that the internet can be addictive itself . it is concluded that technological developments in internet gambling will increase the potential for problem gambling globally , but that many of the ideas and speculations outlined in this article need to be addressed further by large scale empirical studies", "tokenized": "and continues to provide new market opportunities . one of the fastest growing areas is that of internet gambling . the effect of such technologies should not be accepted uncritically , particularly as there may be areas of potential concern based on what is known about problem gambling offline . this article has three aims . first , it overviews some of the main social concerns about the rise of internet gambling . second , it looks at the limited research that has been carried out in this area . third , it examines whether internet gambling is doubly addictive , given research that suggests that the internet can be addictive itself . it is concluded that technological developments in internet gambling will increase the potential for problem gambling globally , but that many of the ideas and speculations outlined in this article need to be addressed further by large scale empirical studies"}, "present_kps": {"text": ["social impact", "internet gambling", "market opportunities", "addiction", "technological developments"], "tokenized": ["social impact", "internet gambling", "market opportunities", "addiction", "technological developments"]}, "absent_kps": {"text": ["psychology", "electronic cash"], "tokenized": ["psychology", "electronic cash"]}}
{"id": 184, "title": {"text": "computer mediated communication and remote management integration or .", "tokenized": "computer mediated communication and remote management integration or ."}, "abstract": {"text": "the use of intranets and e mails to communicate with remote staff is increasing rapidly within organizations . for many companies this is viewed as a speedy and cost effective way of keeping in contact with staff and ensuring their continuing commitment to company goals . this article highlights the problems experienced by staff when managers use intranets and e mails in an inappropriate fashion for these purposes . issues of remoteness and isolation are discussed , along with the reports of frustration and disidentification experienced . however , it will be shown that when used appropriately , communication using these technologies can facilitate shared understanding and help remote staff to view their company as alive and exciting . theoretical aspects are highlighted and the implications of these findings are discussed", "tokenized": "the use of intranets and e mails to communicate with remote staff is increasing rapidly within organizations . for many companies this is viewed as a speedy and cost effective way of keeping in contact with staff and ensuring their continuing commitment to company goals . this article highlights the problems experienced by staff when managers use intranets and e mails in an inappropriate fashion for these purposes . issues of remoteness and isolation are discussed , along with the reports of frustration and disidentification experienced . however , it will be shown that when used appropriately , communication using these technologies can facilitate shared understanding and help remote staff to view their company as alive and exciting . theoretical aspects are highlighted and the implications of these findings are discussed"}, "present_kps": {"text": ["computer mediated communication", "remote management", "remoteness", "managers", "intranets", "e mails", "remote staff", "organizations", "companies", "cost effective"], "tokenized": ["computer mediated communication", "remote management", "remoteness", "managers", "intranets", "e mails", "remote staff", "organizations", "companies", "cost effective"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 185, "title": {"text": "collective action in the age of the internet mass communication and online .", "tokenized": "collective action in the age of the internet mass communication and online ."}, "abstract": {"text": "this article examines how the internet transforms collective action . current practices on the web bear witness to thriving collective action ranging from persuasive to confrontational , individual to collective , undertakings . even more influential than direct calls for action is the indirect mobilizing influence of the internet ' s powers of mass communication , which is boosted by an antiauthoritarian ideology on the web . theoretically , collective action through the otherwise socially isolating computer is possible because people rely on internalized group memberships and social identities to achieve social involvement . empirical evidence from an online survey among environmental activists and nonactivists confirms that online action is considered an equivalent alternative to offline action by activists and nonactivists alike . however , the internet may slightly alter the motives underlying collective action and thereby alter the nature of collective action and social movements . perhaps more fundamental is the reverse influence that successful collective action will have on the nature and function of the internet", "tokenized": "this article examines how the internet transforms collective action . current practices on the web bear witness to thriving collective action ranging from persuasive to confrontational , individual to collective , undertakings . even more influential than direct calls for action is the indirect mobilizing influence of the internet ' s powers of mass communication , which is boosted by an antiauthoritarian ideology on the web . theoretically , collective action through the otherwise socially isolating computer is possible because people rely on internalized group memberships and social identities to achieve social involvement . empirical evidence from an online survey among environmental activists and nonactivists confirms that online action is considered an equivalent alternative to offline action by activists and nonactivists alike . however , the internet may slightly alter the motives underlying collective action and thereby alter the nature of collective action and social movements . perhaps more fundamental is the reverse influence that successful collective action will have on the nature and function of the internet"}, "present_kps": {"text": ["collective action", "internet", "mass communication", "antiauthoritarian ideology", "group memberships", "social identities", "online survey"], "tokenized": ["collective action", "internet", "mass communication", "antiauthoritarian ideology", "group memberships", "social identities", "online survey"]}, "absent_kps": {"text": ["world wide web", "politics", "online mobilization", "anonymity"], "tokenized": ["world wide web", "politics", "online mobilization", "anonymity"]}}
{"id": 186, "title": {"text": "explanations for the perpetration of and reactions to deception in a virtual .", "tokenized": "explanations for the perpetration of and reactions to deception in a virtual ."}, "abstract": {"text": "cases of identity deception on the internet are not uncommon . several cases of a revealed identity deception have been reported in the media . the authors examine a case of deception in an online community composed primarily of information technology professionals . in this case , an established community member ( df ) invented a character ( nowheremom ) whom he fell in love with and who was eventually killed in a tragic accident . when other members of the community eventually began to question nowheremom ' s actual identity , df admitted that he invented her . the discussion board was flooded with reactions to df ' s revelation . the authors propose several explanations for the perpetration of identity deception , including psychiatric illness , identity play , and expressions of true self . they also analyze the reactions of community members and propose three related explanations ( social identity , deviance , and norm violation ) to account for their reactions . it is argued that virtual communities ' reactions to such threatening events provide invaluable clues for the study of group processes on the internet", "tokenized": "cases of identity deception on the internet are not uncommon . several cases of a revealed identity deception have been reported in the media . the authors examine a case of deception in an online community composed primarily of information technology professionals . in this case , an established community member ( df ) invented a character ( nowheremom ) whom he fell in love with and who was eventually killed in a tragic accident . when other members of the community eventually began to question nowheremom ' s actual identity , df admitted that he invented her . the discussion board was flooded with reactions to df ' s revelation . the authors propose several explanations for the perpetration of identity deception , including psychiatric illness , identity play , and expressions of true self . they also analyze the reactions of community members and propose three related explanations ( social identity , deviance , and norm violation ) to account for their reactions . it is argued that virtual communities ' reactions to such threatening events provide invaluable clues for the study of group processes on the internet"}, "present_kps": {"text": ["identity deception", "internet", "online community", "information technology professionals", "psychiatric illness", "virtual community", "group processes"], "tokenized": ["identity deception", "internet", "online community", "information technology professionals", "psychiatric illness", "virtual community", "group processes"]}, "absent_kps": {"text": ["social processes", "web sites", "psychology", "bulletin boards"], "tokenized": ["social processes", "web sites", "psychology", "bulletin boards"]}}
{"id": 187, "title": {"text": "the effects of asynchronous computer mediated group interaction on group .", "tokenized": "the effects of asynchronous computer mediated group interaction on group ."}, "abstract": {"text": "this article reports a study undertaken to investigate some of the social psychological processes underlying computer supported group discussion in natural computer mediated contexts . based on the concept of deindividuation , it was hypothesized that personal identifiability and group identity would be important factors that affect the perceptions and behavior of members of computer mediated groups . the degree of personal identifiability and the strength of group identity were manipulated across groups of geographically dispersed computer users who took part in e mail discussions during a [digit] week period . the results do not support the association between deindividuation and uninhibited behavior cited in much previous research . instead , the data provide some support for a social identity perspective of computer mediated communication , which explains the higher levels uninhibited in identifiable computer mediated groups . however , predictions based on social identity theory regarding group polarization and group cohesion were not supported . possible explanations for this are discussed and further research is suggested to resolve these discrepancies", "tokenized": "this article reports a study undertaken to investigate some of the social psychological processes underlying computer supported group discussion in natural computer mediated contexts . based on the concept of deindividuation , it was hypothesized that personal identifiability and group identity would be important factors that affect the perceptions and behavior of members of computer mediated groups . the degree of personal identifiability and the strength of group identity were manipulated across groups of geographically dispersed computer users who took part in e mail discussions during a [digit] week period . the results do not support the association between deindividuation and uninhibited behavior cited in much previous research . instead , the data provide some support for a social identity perspective of computer mediated communication , which explains the higher levels uninhibited in identifiable computer mediated groups . however , predictions based on social identity theory regarding group polarization and group cohesion were not supported . possible explanations for this are discussed and further research is suggested to resolve these discrepancies"}, "present_kps": {"text": ["asynchronous computer mediated group interaction", "psychology", "deindividuation", "personal identifiability", "group identity", "geographically dispersed computer users", "e mail discussions", "social identity theory", "group polarization", "group cohesion"], "tokenized": ["asynchronous computer mediated group interaction", "psychology", "deindividuation", "personal identifiability", "group identity", "geographically dispersed computer users", "e mail discussions", "social identity theory", "group polarization", "group cohesion"]}, "absent_kps": {"text": ["social issues", "group processes", "internet"], "tokenized": ["social issues", "group processes", "internet"]}}
{"id": 188, "title": {"text": "online longitudinal survey research viability and participation .", "tokenized": "online longitudinal survey research viability and participation ."}, "abstract": {"text": "using the internet in samples exposed to trauma . a questionnaire battery assessing psychological adjustment following adverse life experiences was posted online . participants who signed up to take part in the longitudinal aspect of the study were contacted [digit] and [digit] months after initial participation to complete the second and third waves of the research . issues of data screening and sample attrition rates are considered and the demographic profiles and questionnaire scores of those who did and did not take part in the study during successive time points are compared . the results demonstrate that it is possible to conduct repeated measures survey research online and that the similarity in characteristics between those who do and do not take part during successive time points mirrors that found in traditional pencil and paper trauma surveys", "tokenized": "using the internet in samples exposed to trauma . a questionnaire battery assessing psychological adjustment following adverse life experiences was posted online . participants who signed up to take part in the longitudinal aspect of the study were contacted [digit] and [digit] months after initial participation to complete the second and third waves of the research . issues of data screening and sample attrition rates are considered and the demographic profiles and questionnaire scores of those who did and did not take part in the study during successive time points are compared . the results demonstrate that it is possible to conduct repeated measures survey research online and that the similarity in characteristics between those who do and do not take part during successive time points mirrors that found in traditional pencil and paper trauma surveys"}, "present_kps": {"text": ["online longitudinal survey research", "internet", "trauma", "questionnaire", "psychological adjustment", "data screening", "sample attrition rates", "demographic profiles"], "tokenized": ["online longitudinal survey research", "internet", "trauma", "questionnaire", "psychological adjustment", "data screening", "sample attrition rates", "demographic profiles"]}, "absent_kps": {"text": ["world wide web", "psychology research"], "tokenized": ["world wide web", "psychology research"]}}
{"id": 189, "title": {"text": "internet based psychological experimenting five dos and five don ' ts .", "tokenized": "internet based psychological experimenting five dos and five don ' ts ."}, "abstract": {"text": "careful consideration of a number of issues from potential data corruption to revealing confidential information about participants . ten issues are grouped into five areas of actions to be taken when developing an internet experiment ( dos ) and five errors to be avoided ( don ' ts ) . dos include ( a ) utilizing dropout as a dependent variable , ( b ) the use of dropout to detect motivational confounding , ( c ) placement of questions for personal information , ( d ) using a collection of techniques , and ( e ) using internet based tools . don ' ts are about ( a ) unprotected directories , ( b ) public access to confidential data , ( c ) revealing the experiment ' s structure , ( d ) ignoring the internet ' s technical variance , and ( e ) improper use of form elements", "tokenized": "careful consideration of a number of issues from potential data corruption to revealing confidential information about participants . ten issues are grouped into five areas of actions to be taken when developing an internet experiment ( dos ) and five errors to be avoided ( don ' ts ) . dos include ( a ) utilizing dropout as a dependent variable , ( b ) the use of dropout to detect motivational confounding , ( c ) placement of questions for personal information , ( d ) using a collection of techniques , and ( e ) using internet based tools . don ' ts are about ( a ) unprotected directories , ( b ) public access to confidential data , ( c ) revealing the experiment ' s structure , ( d ) ignoring the internet ' s technical variance , and ( e ) improper use of form elements"}, "present_kps": {"text": ["internet based psychological experimenting", "psychology", "data corruption", "dropout", "motivational confounding", "personal information", "unprotected directories"], "tokenized": ["internet based psychological experimenting", "psychology", "data corruption", "dropout", "motivational confounding", "personal information", "unprotected directories"]}, "absent_kps": {"text": ["online research techniques", "data confidentiality", "web experiment"], "tokenized": ["online research techniques", "data confidentiality", "web experiment"]}}
{"id": 190, "title": {"text": "pervasive computing goes to work interfacing to the enterprise .", "tokenized": "pervasive computing goes to work interfacing to the enterprise ."}, "abstract": {"text": "to see how pervasive computing applications might bring some substance to this dream , the author spoke recently with key managers and technologists at mckesson corporation ( san francisco ) , a healthcare supplier , service , and technology company with us [digit] billion in sales last year , and also at avantgo ( hayward , calif . ) , a provider of mobile infrastructure software and services . for the past several years , mckesson has used mobility middleware developed by avantgo to deploy major supply chain applications with thousands of pervasive clients and multiple servers that replace existing paper based tracking systems . according to mckesson ' s managers , their system greatly reduced errors and associated costs caused by redelivery or loss of valuable products , giving mckesson a solid return on its investment", "tokenized": "to see how pervasive computing applications might bring some substance to this dream , the author spoke recently with key managers and technologists at mckesson corporation ( san francisco ) , a healthcare supplier , service , and technology company with us [digit] billion in sales last year , and also at avantgo ( hayward , calif . ) , a provider of mobile infrastructure software and services . for the past several years , mckesson has used mobility middleware developed by avantgo to deploy major supply chain applications with thousands of pervasive clients and multiple servers that replace existing paper based tracking systems . according to mckesson ' s managers , their system greatly reduced errors and associated costs caused by redelivery or loss of valuable products , giving mckesson a solid return on its investment"}, "present_kps": {"text": ["pervasive clients", "multiple servers"], "tokenized": ["pervasive clients", "multiple servers"]}, "absent_kps": {"text": ["enterprise resource planning", "paperless office", "data warehousing", "mobile workers"], "tokenized": ["enterprise resource planning", "paperless office", "data warehousing", "mobile workers"]}}
{"id": 191, "title": {"text": "psychology and the internet .", "tokenized": "psychology and the internet ."}, "abstract": {"text": "assist psychological research and mediate psychological practice . it shows how psychologists are using the internet to examine the interactions between people and computers , and highlights some of the ways that this research is important to the design and development of useable and acceptable computer systems . in particular , this introduction reviews the research presented at the international conference on psychology and the internet held in the united kingdom . the final part introduces the eight articles in this special edition . the articles are representative of the breadth of research being conducted on psychology and the internet there are two on methodological issues , three on group processes , one on organizational implications , and two on social implications of internet use", "tokenized": "assist psychological research and mediate psychological practice . it shows how psychologists are using the internet to examine the interactions between people and computers , and highlights some of the ways that this research is important to the design and development of useable and acceptable computer systems . in particular , this introduction reviews the research presented at the international conference on psychology and the internet held in the united kingdom . the final part introduces the eight articles in this special edition . the articles are representative of the breadth of research being conducted on psychology and the internet there are two on methodological issues , three on group processes , one on organizational implications , and two on social implications of internet use"}, "present_kps": {"text": ["psychology", "internet", "psychological research", "methodological issues", "group processes", "organizational implications", "social implications"], "tokenized": ["psychology", "internet", "psychological research", "methodological issues", "group processes", "organizational implications", "social implications"]}, "absent_kps": {"text": ["online research", "human computer interactions", "usability"], "tokenized": ["online research", "human computer interactions", "usability"]}}
{"id": 192, "title": {"text": "extended depth of focus imaging of chlorophyll fluorescence from intact leaves .", "tokenized": "extended depth of focus imaging of chlorophyll fluorescence from intact leaves ."}, "abstract": {"text": "with which to examine localised changes in photosynthetic function . microscope based systems provide excellent spatial resolution which allows the response of individual cells to be measured . however , such systems have a restricted depth of focus and , as leaves are inherently uneven , only a small proportion of each image at any given focal plane is in focus . in this report we describe the development of algorithms , specifically adapted for imaging chlorophyll fluorescence and photosynthetic function in living plant cells , which allow extended focus images to be reconstructed from images taken in different focal planes . we describe how these procedures can be used to reconstruct images of chlorophyll fluorescence and calculated photosynthetic parameters , as well as producing a map of leaf topology . the robustness of this procedure is demonstrated using leaves from a number of different plant species", "tokenized": "with which to examine localised changes in photosynthetic function . microscope based systems provide excellent spatial resolution which allows the response of individual cells to be measured . however , such systems have a restricted depth of focus and , as leaves are inherently uneven , only a small proportion of each image at any given focal plane is in focus . in this report we describe the development of algorithms , specifically adapted for imaging chlorophyll fluorescence and photosynthetic function in living plant cells , which allow extended focus images to be reconstructed from images taken in different focal planes . we describe how these procedures can be used to reconstruct images of chlorophyll fluorescence and calculated photosynthetic parameters , as well as producing a map of leaf topology . the robustness of this procedure is demonstrated using leaves from a number of different plant species"}, "present_kps": {"text": ["extended depth of focus imaging", "chlorophyll fluorescence", "intact leaves", "microscope based systems", "spatial resolution", "calculated photosynthetic parameters", "plant species"], "tokenized": ["extended depth of focus imaging", "chlorophyll fluorescence", "intact leaves", "microscope based systems", "spatial resolution", "calculated photosynthetic parameters", "plant species"]}, "absent_kps": {"text": ["numerical aperture", "minimum fluorescence yield", "leaf topology map", "primary quinone acceptor", "charge coupled device", "variable fluorescence", "extended focus images reconstruction", "algorithms development", "individual cells response", "biophysical research technique", "maximum fluorescence yield"], "tokenized": ["numerical aperture", "minimum fluorescence yield", "leaf topology map", "primary quinone acceptor", "charge coupled device", "variable fluorescence", "extended focus images reconstruction", "algorithms development", "individual cells response", "biophysical research technique", "maximum fluorescence yield"]}}
{"id": 193, "title": {"text": "allan variance and fractal brownian motion .", "tokenized": "allan variance and fractal brownian motion ."}, "abstract": {"text": "the methods of filtering require knowledge of the frequency response , which is usually unknown . d . w . allan ( see proc . ieee , vol . [digit] , no . [digit] , p . [digit] [digit] , [digit] ieee trans . instr . measur . , vol . im [digit] , p . [digit] [digit] , [digit] ) proposed a simple method of determining the interval between equally accurate observations which does without this information . in this method , the variances of the increments of noise and signal are equal , so that , in observations with a greater step , the variations caused by noise are smaller than those caused by the signal . this method is the standard accepted by the usa metrology community . the present paper is devoted to a statistical analysis of the allan method and acquisition of additional information", "tokenized": "the methods of filtering require knowledge of the frequency response , which is usually unknown . d . w . allan ( see proc . ieee , vol . [digit] , no . [digit] , p . [digit] [digit] , [digit] ieee trans . instr . measur . , vol . im [digit] , p . [digit] [digit] , [digit] ) proposed a simple method of determining the interval between equally accurate observations which does without this information . in this method , the variances of the increments of noise and signal are equal , so that , in observations with a greater step , the variations caused by noise are smaller than those caused by the signal . this method is the standard accepted by the usa metrology community . the present paper is devoted to a statistical analysis of the allan method and acquisition of additional information"}, "present_kps": {"text": ["allan variance", "fractal brownian motion", "frequency response", "usa metrology community", "statistical analysis"], "tokenized": ["allan variance", "fractal brownian motion", "frequency response", "usa metrology community", "statistical analysis"]}, "absent_kps": {"text": ["radio engineering", "noise filtering", "white noise"], "tokenized": ["radio engineering", "noise filtering", "white noise"]}}
{"id": 194, "title": {"text": "ideal sliding mode in the problems of convex optimization .", "tokenized": "ideal sliding mode in the problems of convex optimization ."}, "abstract": {"text": "convex programming algorithms based on the exact penalty functions were discussed . for the case under study , the ideal sliding mode was shown to occur in the absence of infinite number of switchings", "tokenized": "convex programming algorithms based on the exact penalty functions were discussed . for the case under study , the ideal sliding mode was shown to occur in the absence of infinite number of switchings"}, "present_kps": {"text": ["ideal sliding mode", "convex optimization", "exact penalty functions"], "tokenized": ["ideal sliding mode", "convex optimization", "exact penalty functions"]}, "absent_kps": {"text": ["continuous convex programming algorithms"], "tokenized": ["continuous convex programming algorithms"]}}
{"id": 195, "title": {"text": "automation of the recovery of efficiency of complex structure systems .", "tokenized": "automation of the recovery of efficiency of complex structure systems ."}, "abstract": {"text": "recovery of systems of complex structures in real time without the interruption of operation . specific features of the method are revealed in an important example of the system of control of hardware components of ships", "tokenized": "recovery of systems of complex structures in real time without the interruption of operation . specific features of the method are revealed in an important example of the system of control of hardware components of ships"}, "present_kps": {"text": ["complex structure systems", "hardware components", "ships"], "tokenized": ["complex structure systems", "hardware components", "ships"]}, "absent_kps": {"text": ["efficiency recovery", "serviceability recovery"], "tokenized": ["efficiency recovery", "serviceability recovery"]}}
{"id": 196, "title": {"text": "control of combustion processes in an internal combustion engine by .", "tokenized": "control of combustion processes in an internal combustion engine by ."}, "abstract": {"text": "a new method of operation of internal combustion engines enhances power and reduces fuel consumption and exhaust toxicity . low temperature plasma control combines working processes of thermal engines and steam machines into a single process", "tokenized": "a new method of operation of internal combustion engines enhances power and reduces fuel consumption and exhaust toxicity . low temperature plasma control combines working processes of thermal engines and steam machines into a single process"}, "present_kps": {"text": ["combustion processes", "internal combustion engine", "fuel consumption", "exhaust toxicity", "low temperature plasma", "working processes", "thermal engines", "steam machines"], "tokenized": ["combustion processes", "internal combustion engine", "fuel consumption", "exhaust toxicity", "low temperature plasma", "working processes", "thermal engines", "steam machines"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 197, "title": {"text": "optimization of the characteristics of computational processes in scalable .", "tokenized": "optimization of the characteristics of computational processes in scalable ."}, "abstract": {"text": "the scalableness of resources is taken to mean the possibility of the prior change in the obtained dynamic characteristics of computational processes for a certain basic set of processors and the communication medium in an effort to optimize the dynamics of software applications . a method is put forward for the generation of optimal strategies a set of the versions of the fulfillment of programs on the basis of a vector criterion . the method is urgent for the effective use of resources of computational clusters and metacomputational media and also for dynamic control of processes in real time on the basis of the static scaling", "tokenized": "the scalableness of resources is taken to mean the possibility of the prior change in the obtained dynamic characteristics of computational processes for a certain basic set of processors and the communication medium in an effort to optimize the dynamics of software applications . a method is put forward for the generation of optimal strategies a set of the versions of the fulfillment of programs on the basis of a vector criterion . the method is urgent for the effective use of resources of computational clusters and metacomputational media and also for dynamic control of processes in real time on the basis of the static scaling"}, "present_kps": {"text": ["computational processes", "dynamic characteristics", "communication medium", "software applications", "optimal strategies", "vector criterion", "computational clusters", "metacomputational media", "dynamic control", "static scaling"], "tokenized": ["computational processes", "dynamic characteristics", "communication medium", "software applications", "optimal strategies", "vector criterion", "computational clusters", "metacomputational media", "dynamic control", "static scaling"]}, "absent_kps": {"text": ["scalable resources"], "tokenized": ["scalable resources"]}}
{"id": 198, "title": {"text": "the p p rearrangement and failure tolerance of double p ary multirings and .", "tokenized": "the p p rearrangement and failure tolerance of double p ary multirings and ."}, "abstract": {"text": "it is shown that an arbitrary grouped p element permutation can be implemented in a conflict free way through the commutation of channels on the double p ary multiring or the double p ary hypercube . it is revealed that in arbitrary single element permutations , these commutators display the property of the ( p [digit] ) nodal failure tolerance and the generalized hypercube displays in addition the property of the ( p [digit] ) channel failure tolerance", "tokenized": "it is shown that an arbitrary grouped p element permutation can be implemented in a conflict free way through the commutation of channels on the double p ary multiring or the double p ary hypercube . it is revealed that in arbitrary single element permutations , these commutators display the property of the ( p [digit] ) nodal failure tolerance and the generalized hypercube displays in addition the property of the ( p [digit] ) channel failure tolerance"}, "present_kps": {"text": ["p p rearrangement", "failure tolerance", "double p ary multirings", "p element permutation", "commutators", "single element permutations", "generalized hypercubes"], "tokenized": ["p p rearrangement", "failure tolerance", "double p ary multirings", "p element permutation", "commutators", "single element permutations", "generalized hypercubes"]}, "absent_kps": {"text": ["conflict free implementation"], "tokenized": ["conflict free implementation"]}}
{"id": 199, "title": {"text": "solutions for cooperative games .", "tokenized": "solutions for cooperative games ."}, "abstract": {"text": "games far better than the classical characteristic function and is useful in reducing the number of decisions that can be used as the unique solution of a game", "tokenized": "games far better than the classical characteristic function and is useful in reducing the number of decisions that can be used as the unique solution of a game"}, "present_kps": {"text": ["cooperative games", "characteristic function", "decisions", "unique solution"], "tokenized": ["cooperative games", "characteristic function", "decisions", "unique solution"]}, "absent_kps": {"text": ["transferrable utility"], "tokenized": ["transferrable utility"]}}
{"id": 200, "title": {"text": "location of transport nets on a heterogeneous territory .", "tokenized": "location of transport nets on a heterogeneous territory ."}, "abstract": {"text": "network joins a given set of terminal points and a certain number of additional ( branch ) points . the problem is formulated , properties of the optimal solution for a . tree like network , and the number of branch points are studied . a stepwise optimization algorithm for a . network with given adjacency matrix based on an algorithm for constructing minimal cost routes is designed", "tokenized": "network joins a given set of terminal points and a certain number of additional ( branch ) points . the problem is formulated , properties of the optimal solution for a . tree like network , and the number of branch points are studied . a stepwise optimization algorithm for a . network with given adjacency matrix based on an algorithm for constructing minimal cost routes is designed"}, "present_kps": {"text": ["transport nets", "heterogeneous territory", "terminal points", "tree like network", "branch points", "stepwise optimization algorithm", "adjacency matrix"], "tokenized": ["transport nets", "heterogeneous territory", "terminal points", "tree like network", "branch points", "stepwise optimization algorithm", "adjacency matrix"]}, "absent_kps": {"text": ["transport routes"], "tokenized": ["transport routes"]}}
{"id": 201, "title": {"text": "knowledge management capturing the skills of key performers in the power .", "tokenized": "knowledge management capturing the skills of key performers in the power ."}, "abstract": {"text": "the growing pressure to reduce the cost of electrical power in recent years has resulted in an enormous brain drain within the power industry . a novel approach has been developed by eskom to capture these skills before they are lost and to incorporate these into a computer based programme called knowledge management", "tokenized": "the growing pressure to reduce the cost of electrical power in recent years has resulted in an enormous brain drain within the power industry . a novel approach has been developed by eskom to capture these skills before they are lost and to incorporate these into a computer based programme called knowledge management"}, "present_kps": {"text": ["knowledge management", "key performers", "brain drain", "power industry", "eskom", "computer based programme"], "tokenized": ["knowledge management", "key performers", "brain drain", "power industry", "eskom", "computer based programme"]}, "absent_kps": {"text": ["south africa", "skills capture", "personnel management"], "tokenized": ["south africa", "skills capture", "personnel management"]}}
{"id": 202, "title": {"text": "control in active systems based on criteria and motivation .", "tokenized": "control in active systems based on criteria and motivation ."}, "abstract": {"text": "adding to them appropriately weighted goal functions of other agents or a balanced system of inter agent transfers , the paper formulated and solved the problems of control based on criteria and motivation . linear active systems were considered by way of example", "tokenized": "adding to them appropriately weighted goal functions of other agents or a balanced system of inter agent transfers , the paper formulated and solved the problems of control based on criteria and motivation . linear active systems were considered by way of example"}, "present_kps": {"text": ["goal functions", "inter agent transfers", "linear active systems"], "tokenized": ["goal functions", "inter agent transfers", "linear active systems"]}, "absent_kps": {"text": ["criteria based control", "motivation based control"], "tokenized": ["criteria based control", "motivation based control"]}}
{"id": 203, "title": {"text": "flexibility analysis of complex technical systems under uncertainty .", "tokenized": "flexibility analysis of complex technical systems under uncertainty ."}, "abstract": {"text": "of the initial physical , chemical , and technological data is the determination of a design in which the technical system is flexible , i . e . , its control system is capable of guaranteeing that the constraints hold even under changes in external and internal factors and application of fuzzy mathematical models in its design . three flexibility problems , viz . , the flexibility of a technical system of given structure , structural flexibility of a technical system , and the optimal design guaranteeing the flexibility of a technical system , are studied . two approaches to these problems are elaborated . results of a computation experiment are given", "tokenized": "of the initial physical , chemical , and technological data is the determination of a design in which the technical system is flexible , i . e . , its control system is capable of guaranteeing that the constraints hold even under changes in external and internal factors and application of fuzzy mathematical models in its design . three flexibility problems , viz . , the flexibility of a technical system of given structure , structural flexibility of a technical system , and the optimal design guaranteeing the flexibility of a technical system , are studied . two approaches to these problems are elaborated . results of a computation experiment are given"}, "present_kps": {"text": ["flexibility analysis", "complex technical systems", "control system", "fuzzy mathematical models", "structural flexibility", "optimal design"], "tokenized": ["flexibility analysis", "complex technical systems", "control system", "fuzzy mathematical models", "structural flexibility", "optimal design"]}, "absent_kps": {"text": ["partial uncertainty"], "tokenized": ["partial uncertainty"]}}
{"id": 204, "title": {"text": "a fuzzy logic adaptation circuit for control systems of deformable space .", "tokenized": "a fuzzy logic adaptation circuit for control systems of deformable space ."}, "abstract": {"text": "a fuzzy logic adaptation algorithm is designed for adjusting the discreteness period of a control system for ensuring the stability and quality of control process with regard to the elastic structural vibrations of a deformable space vehicle . its performance is verified by digital modeling of a discrete control system with two objects", "tokenized": "a fuzzy logic adaptation algorithm is designed for adjusting the discreteness period of a control system for ensuring the stability and quality of control process with regard to the elastic structural vibrations of a deformable space vehicle . its performance is verified by digital modeling of a discrete control system with two objects"}, "present_kps": {"text": ["fuzzy logic adaptation circuit", "control systems", "discreteness period", "stability", "elastic structural vibrations", "deformable space vehicles", "digital modeling"], "tokenized": ["fuzzy logic adaptation circuit", "control systems", "discreteness period", "stability", "elastic structural vibrations", "deformable space vehicles", "digital modeling"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 205, "title": {"text": "hidden convexity of finite dimensional stationary linear discrete time .", "tokenized": "hidden convexity of finite dimensional stationary linear discrete time ."}, "abstract": {"text": "new properties of finite dimensional linear discrete time systems under conical control constraints that are similar to the hidden convexity of continuous time systems are studied", "tokenized": "new properties of finite dimensional linear discrete time systems under conical control constraints that are similar to the hidden convexity of continuous time systems are studied"}, "present_kps": {"text": ["hidden convexity", "control constraint"], "tokenized": ["hidden convexity", "control constraint"]}, "absent_kps": {"text": ["conical constraints", "finite dimensional stationary linear discrete time systems"], "tokenized": ["conical constraints", "finite dimensional stationary linear discrete time systems"]}}
{"id": 206, "title": {"text": "the set of stable polynomials of linear discrete systems its geometry .", "tokenized": "the set of stable polynomials of linear discrete systems its geometry ."}, "abstract": {"text": "its configuration is determined from the parameters of its intersection with coordinate axes , coordinate planes , and certain auxiliary planes . counterexamples for the discrete variant of the kharitonov theorem are given", "tokenized": "its configuration is determined from the parameters of its intersection with coordinate axes , coordinate planes , and certain auxiliary planes . counterexamples for the discrete variant of the kharitonov theorem are given"}, "present_kps": {"text": ["stable polynomials", "linear discrete systems", "geometry", "kharitonov theorem"], "tokenized": ["stable polynomials", "linear discrete systems", "geometry", "kharitonov theorem"]}, "absent_kps": {"text": ["multidimensional stability domain", "characteristic polynomial"], "tokenized": ["multidimensional stability domain", "characteristic polynomial"]}}
{"id": 207, "title": {"text": "stochastic systems with a random jump in phase trajectory stability of their .", "tokenized": "stochastic systems with a random jump in phase trajectory stability of their ."}, "abstract": {"text": "the probabilistic stability of the perturbed motion of a system with parameters under the action of a general markov process is studied . the phase vector is assumed to experience random jumps when the structure the system suffers random jumps . such a situation is encountered , for example , in the motion of a solid with random jumps in its mass . the mean square stability of random structure linear systems and stability . of nonlinear systems in the first approximation are studied . the applied approach is helpful in studying the asymptotic probabilistic stability and mean square exponential stability of stochastic systems through the stability of the respective deterministic systems", "tokenized": "the probabilistic stability of the perturbed motion of a system with parameters under the action of a general markov process is studied . the phase vector is assumed to experience random jumps when the structure the system suffers random jumps . such a situation is encountered , for example , in the motion of a solid with random jumps in its mass . the mean square stability of random structure linear systems and stability . of nonlinear systems in the first approximation are studied . the applied approach is helpful in studying the asymptotic probabilistic stability and mean square exponential stability of stochastic systems through the stability of the respective deterministic systems"}, "present_kps": {"text": ["stochastic systems", "random jump", "phase trajectory", "general markov process", "asymptotic probabilistic stability", "mean square exponential stability"], "tokenized": ["stochastic systems", "random jump", "phase trajectory", "general markov process", "asymptotic probabilistic stability", "mean square exponential stability"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 208, "title": {"text": "a nonlinear time optimal control problem .", "tokenized": "a nonlinear time optimal control problem ."}, "abstract": {"text": "control problem with fixed ends for a smooth nonlinear control system are formulated . the properties of this system for characterizing the optimal control switching points are studied", "tokenized": "control problem with fixed ends for a smooth nonlinear control system are formulated . the properties of this system for characterizing the optimal control switching points are studied"}, "present_kps": {"text": ["nonlinear time optimal control problem", "smooth nonlinear control system", "optimal control switching points"], "tokenized": ["nonlinear time optimal control problem", "smooth nonlinear control system", "optimal control switching points"]}, "absent_kps": {"text": ["sufficient existence conditions"], "tokenized": ["sufficient existence conditions"]}}
{"id": 209, "title": {"text": "system embedding . polynomial equations .", "tokenized": "system embedding . polynomial equations ."}, "abstract": {"text": "generalizations in the form of the bezout matrix identities was constructed analytically using the technology of constructive system embedding . the structure of a solution depends on the number of steps of the euclidean algorithm and is obtained explicitly by appropriate substitutions . illustrative and descriptive examples are presented", "tokenized": "generalizations in the form of the bezout matrix identities was constructed analytically using the technology of constructive system embedding . the structure of a solution depends on the number of steps of the euclidean algorithm and is obtained explicitly by appropriate substitutions . illustrative and descriptive examples are presented"}, "present_kps": {"text": ["polynomial equations", "bezout matrix identities", "constructive system embedding", "euclidean algorithm"], "tokenized": ["polynomial equations", "bezout matrix identities", "constructive system embedding", "euclidean algorithm"]}, "absent_kps": {"text": ["determinate systems"], "tokenized": ["determinate systems"]}}
{"id": 210, "title": {"text": "an optimal control algorithm based on reachability set approximation and .", "tokenized": "an optimal control algorithm based on reachability set approximation and ."}, "abstract": {"text": "the terminal functional of a general control system is refined by studying an analogous problem for a variational system and regularization . a sequential refinement method is designed by combining the local approximation of the reachability set and reduction . the corresponding algorithm has relaxation properties . an illustrative example is given", "tokenized": "the terminal functional of a general control system is refined by studying an analogous problem for a variational system and regularization . a sequential refinement method is designed by combining the local approximation of the reachability set and reduction . the corresponding algorithm has relaxation properties . an illustrative example is given"}, "present_kps": {"text": ["optimal control algorithm", "reachability set approximation", "terminal functional", "variational system", "regularization", "sequential refinement method", "local approximation", "relaxation properties"], "tokenized": ["optimal control algorithm", "reachability set approximation", "terminal functional", "variational system", "regularization", "sequential refinement method", "local approximation", "relaxation properties"]}, "absent_kps": {"text": ["determinate systems", "linearization"], "tokenized": ["determinate systems", "linearization"]}}
{"id": 211, "title": {"text": "a universal decomposition of the integration range for exponential functions .", "tokenized": "a universal decomposition of the integration range for exponential functions ."}, "abstract": {"text": "integration range of exponential functions was solved on the basis of a similar approach to polynomials . the constants obtained enable one to decompose the integration range in two so that the integrals over them are equal independently of the function parameters . for the nontrigonometrical polynomials of even functions , an alternative approach was presented", "tokenized": "integration range of exponential functions was solved on the basis of a similar approach to polynomials . the constants obtained enable one to decompose the integration range in two so that the integrals over them are equal independently of the function parameters . for the nontrigonometrical polynomials of even functions , an alternative approach was presented"}, "present_kps": {"text": ["exponential functions", "polynomials", "nontrigonometrical polynomials", "even functions"], "tokenized": ["exponential functions", "polynomials", "nontrigonometrical polynomials", "even functions"]}, "absent_kps": {"text": ["integration range decomposition", "integration range universal decomposition"], "tokenized": ["integration range decomposition", "integration range universal decomposition"]}}
{"id": 212, "title": {"text": "an application of fuzzy linear regression to the information technology in .", "tokenized": "an application of fuzzy linear regression to the information technology in ."}, "abstract": {"text": "fuzzy set theory deals with the vagueness of human thought . a major contribution of fuzzy set theory is its capability of representing vague knowledge . fuzzy set theory is very practical when sufficient and reliable data isn ' t available . information technology ( it ) is the acquisition , processing , storage and dissemination of information in all its forms ( auditory , pictorial , textual and numerical ) through a combination of computers , telecommunication , networks and electronic devices . it includes matters concerned with the furtherance of computer science and technology , design , development , installation and implementation of information systems and applications . in the paper , assuming that there are n independent variables and the regression function is linear , the possible levels of information technology ( the sale levels of computer equipment ) in turkey are forecasted by using fuzzy linear regression . the independent variables assumed are the import level and the export level of computer equipment", "tokenized": "fuzzy set theory deals with the vagueness of human thought . a major contribution of fuzzy set theory is its capability of representing vague knowledge . fuzzy set theory is very practical when sufficient and reliable data isn ' t available . information technology ( it ) is the acquisition , processing , storage and dissemination of information in all its forms ( auditory , pictorial , textual and numerical ) through a combination of computers , telecommunication , networks and electronic devices . it includes matters concerned with the furtherance of computer science and technology , design , development , installation and implementation of information systems and applications . in the paper , assuming that there are n independent variables and the regression function is linear , the possible levels of information technology ( the sale levels of computer equipment ) in turkey are forecasted by using fuzzy linear regression . the independent variables assumed are the import level and the export level of computer equipment"}, "present_kps": {"text": ["fuzzy linear regression", "information technology", "it", "computers", "telecommunication", "electronic devices", "computer science", "information systems", "regression function", "turkey"], "tokenized": ["fuzzy linear regression", "information technology", "it", "computers", "telecommunication", "electronic devices", "computer science", "information systems", "regression function", "turkey"]}, "absent_kps": {"text": ["computer technology", "vague knowledge representation", "computer equipment export level"], "tokenized": ["computer technology", "vague knowledge representation", "computer equipment export level"]}}
{"id": 213, "title": {"text": "synchronizing experiments with linear interval systems .", "tokenized": "synchronizing experiments with linear interval systems ."}, "abstract": {"text": "method of constructing a minimal synchronizing sequence for a linear interval system over the field of real numbers is developed . this problem is reduced to a system of linear inequalities", "tokenized": "method of constructing a minimal synchronizing sequence for a linear interval system over the field of real numbers is developed . this problem is reduced to a system of linear inequalities"}, "present_kps": {"text": ["synchronizing experiments", "linear interval systems", "real numbers", "linear inequalities"], "tokenized": ["synchronizing experiments", "linear interval systems", "real numbers", "linear inequalities"]}, "absent_kps": {"text": ["generalized control problems", "controllability", "minimal synchronizing sequence construction"], "tokenized": ["generalized control problems", "controllability", "minimal synchronizing sequence construction"]}}
{"id": 214, "title": {"text": "diagnosis of the technical state of heat systems .", "tokenized": "diagnosis of the technical state of heat systems ."}, "abstract": {"text": "is stated . the class of physical defects is supplemented by the behavioral defects of objects , which are related to the disturbance of the modes of their operation . the implementation of the approach is illustrated by an example of the solution of a specific problem of the diagnosis of a closed heat consumption system", "tokenized": "is stated . the class of physical defects is supplemented by the behavioral defects of objects , which are related to the disturbance of the modes of their operation . the implementation of the approach is illustrated by an example of the solution of a specific problem of the diagnosis of a closed heat consumption system"}, "present_kps": {"text": [], "tokenized": []}, "absent_kps": {"text": ["closed heat consumption system diagnosis", "step by step diagnosis", "heat system technical state diagnosis", "operational mode disturbance"], "tokenized": ["closed heat consumption system diagnosis", "step by step diagnosis", "heat system technical state diagnosis", "operational mode disturbance"]}}
{"id": 215, "title": {"text": "fault tolerant computer aided control systems with multiversion threshold .", "tokenized": "fault tolerant computer aided control systems with multiversion threshold ."}, "abstract": {"text": "an architecture for multiversion majority redundant computer aided control systems , systematization of adaptation methods that are stable to hardware and software failures , a method for estimating their reliability from an event graph model , and a method for selecting a standard architecture with regard for reliability requirements are studied", "tokenized": "an architecture for multiversion majority redundant computer aided control systems , systematization of adaptation methods that are stable to hardware and software failures , a method for estimating their reliability from an event graph model , and a method for selecting a standard architecture with regard for reliability requirements are studied"}, "present_kps": {"text": ["fault tolerant computer aided control systems", "architecture", "multiversion majority redundant computer aided control systems", "event graph model"], "tokenized": ["fault tolerant computer aided control systems", "architecture", "multiversion majority redundant computer aided control systems", "event graph model"]}, "absent_kps": {"text": ["software failure stability", "hardware failure stability", "multiversion threshold adaptation", "reliability estimation"], "tokenized": ["software failure stability", "hardware failure stability", "multiversion threshold adaptation", "reliability estimation"]}}
{"id": 216, "title": {"text": "nonlockability in multirings and hypercubes at serial transmission of data .", "tokenized": "nonlockability in multirings and hypercubes at serial transmission of data ."}, "abstract": {"text": "for the multiring and hypercube , a method of conflictless realization of an arbitrary permutation of large data items that can be divided into many smaller data blocks was considered , and its high efficiency was demonstrated", "tokenized": "for the multiring and hypercube , a method of conflictless realization of an arbitrary permutation of large data items that can be divided into many smaller data blocks was considered , and its high efficiency was demonstrated"}, "present_kps": {"text": ["nonlockability", "multirings", "hypercubes"], "tokenized": ["nonlockability", "multirings", "hypercubes"]}, "absent_kps": {"text": ["data block serial transmission", "multiprocessor computer systems"], "tokenized": ["data block serial transmission", "multiprocessor computer systems"]}}
{"id": 217, "title": {"text": "linear models of circuits based on the multivalued components .", "tokenized": "linear models of circuits based on the multivalued components ."}, "abstract": {"text": "submicron technologies . on the other hand , the characteristics of the vlsi circuits can be sometimes improved by using the multivalued components . it was shown that any l level circuit based on the multivalued components is representable as an algebraic model based on l linear arithmetic polynomials mapped correspondingly into l decision diagrams that are linear and planar by nature . complexity of representing a circuit as the linear decision diagram was estimated as o ( g ) with g for the number of multivalued components in the circuit . the results of testing the lineardesignmv algorithm on circuits of more than [digit] lgsynth [digit] multivalued components were presented", "tokenized": "submicron technologies . on the other hand , the characteristics of the vlsi circuits can be sometimes improved by using the multivalued components . it was shown that any l level circuit based on the multivalued components is representable as an algebraic model based on l linear arithmetic polynomials mapped correspondingly into l decision diagrams that are linear and planar by nature . complexity of representing a circuit as the linear decision diagram was estimated as o ( g ) with g for the number of multivalued components in the circuit . the results of testing the lineardesignmv algorithm on circuits of more than [digit] lgsynth [digit] multivalued components were presented"}, "present_kps": {"text": ["linearization", "submicron technologies", "vlsi circuits", "linear arithmetic polynomials", "planarization", "lineardesignmv algorithm", "lgsynth [digit] multivalued components"], "tokenized": ["linearization", "submicron technologies", "vlsi circuits", "linear arithmetic polynomials", "planarization", "lineardesignmv algorithm", "lgsynth [digit] multivalued components"]}, "absent_kps": {"text": ["circuit representation complexity", "linear planar decision diagrams", "linear circuit model"], "tokenized": ["circuit representation complexity", "linear planar decision diagrams", "linear circuit model"]}}
{"id": 218, "title": {"text": "a new approach to the problem of structural identification . ii .", "tokenized": "a new approach to the problem of structural identification . ii ."}, "abstract": {"text": "identification , which relies on the recognition of a decisive role of the human factor in the process of structural identification . potential possibilities of the suggested approach are illustrated by the statement of a new mathematical problem of structural identification", "tokenized": "identification , which relies on the recognition of a decisive role of the human factor in the process of structural identification . potential possibilities of the suggested approach are illustrated by the statement of a new mathematical problem of structural identification"}, "present_kps": {"text": ["structural identification", "human factor"], "tokenized": ["structural identification", "human factor"]}, "absent_kps": {"text": ["mathematical equations", "decision maker"], "tokenized": ["mathematical equations", "decision maker"]}}
{"id": 219, "title": {"text": "a method of determining a sequence of the best solutions to the problems of .", "tokenized": "a method of determining a sequence of the best solutions to the problems of ."}, "abstract": {"text": "a method of determining a sequence of the best solutions to the problems of optimization on finite sets was proposed . its complexity was estimated by a polynomial of the dimension of problem input , given number of sequence terms , and complexity of completing the design of the original extremal problem . the technique developed was applied to the typical problem of network reconstruction with the aim of increasing its throughput under restricted reconstruction costs", "tokenized": "a method of determining a sequence of the best solutions to the problems of optimization on finite sets was proposed . its complexity was estimated by a polynomial of the dimension of problem input , given number of sequence terms , and complexity of completing the design of the original extremal problem . the technique developed was applied to the typical problem of network reconstruction with the aim of increasing its throughput under restricted reconstruction costs"}, "present_kps": {"text": ["best solutions", "optimization", "finite sets", "complexity", "network reconstruction"], "tokenized": ["best solutions", "optimization", "finite sets", "complexity", "network reconstruction"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 220, "title": {"text": "stabilization of a linear object by frequency modulated pulsed signals .", "tokenized": "stabilization of a linear object by frequency modulated pulsed signals ."}, "abstract": {"text": "pulse frequency modulator in the feedback circuit is studied . conditions for the boundedness of the solutions of the system under any initial data are determined", "tokenized": "pulse frequency modulator in the feedback circuit is studied . conditions for the boundedness of the solutions of the system under any initial data are determined"}, "present_kps": {"text": ["stabilization", "frequency modulated pulsed signals", "feedback circuit"], "tokenized": ["stabilization", "frequency modulated pulsed signals", "feedback circuit"]}, "absent_kps": {"text": ["discrete systems", "linear stationary object", "solution boundedness", "control system"], "tokenized": ["discrete systems", "linear stationary object", "solution boundedness", "control system"]}}
{"id": 221, "title": {"text": "reachability sets of a class of multistep control processes their design .", "tokenized": "reachability sets of a class of multistep control processes their design ."}, "abstract": {"text": "set for determining the optimal control for a class of multistep control processes are designed", "tokenized": "set for determining the optimal control for a class of multistep control processes are designed"}, "present_kps": {"text": ["reachability sets", "multistep control processes", "optimal control"], "tokenized": ["reachability sets", "multistep control processes", "optimal control"]}, "absent_kps": {"text": ["discrete systems", "upper estimate", "iterative restriction algorithm"], "tokenized": ["discrete systems", "upper estimate", "iterative restriction algorithm"]}}
{"id": 222, "title": {"text": "generalized confidence sets for a statistically indeterminate random vector .", "tokenized": "generalized confidence sets for a statistically indeterminate random vector ."}, "abstract": {"text": "vector , the information on distribution parameters of which is incomplete . to obtain exact estimates and a detailed analysis of the problem , the notion is introduced of a generalized confidence set for a statistically indeterminate random vector . properties of generalized confidence sets are studied . it is shown that the standard method of estimation , which relies on the unification of confidence sets , leads in many cases to wider confidence estimates . for a normally distributed random vector with an inaccurately known mean value , generalized confidence sets are built tip and the dependence of sizes of a generalized confidence set on the forms and parameters of a set of possible mean values is examined", "tokenized": "vector , the information on distribution parameters of which is incomplete . to obtain exact estimates and a detailed analysis of the problem , the notion is introduced of a generalized confidence set for a statistically indeterminate random vector . properties of generalized confidence sets are studied . it is shown that the standard method of estimation , which relies on the unification of confidence sets , leads in many cases to wider confidence estimates . for a normally distributed random vector with an inaccurately known mean value , generalized confidence sets are built tip and the dependence of sizes of a generalized confidence set on the forms and parameters of a set of possible mean values is examined"}, "present_kps": {"text": ["generalized confidence sets", "statistically indeterminate random vector", "distribution parameters", "normally distributed random vector"], "tokenized": ["generalized confidence sets", "statistically indeterminate random vector", "distribution parameters", "normally distributed random vector"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 223, "title": {"text": "evolution of the high end computing market in the usa .", "tokenized": "evolution of the high end computing market in the usa ."}, "abstract": {"text": "market . the discussion combines historical analysis with strategic analysis to provide a framework to analyse a key component of the computer industry . this analysis begins from the perspective of government research and development spending then examines the confusion around the evolution of the high end computing market in the context of standard theories of technology strategy and new product innovation . rather than the high end market being ' dead ' , one should view the market as changing due to increased capability and competition from the low end personal computer market . the high end market is also responding to new product innovation from the introduction of new parallel computing architectures . in the conclusion , key leverage points in the market are identified and the trends in high end computing are highlighted with implications", "tokenized": "market . the discussion combines historical analysis with strategic analysis to provide a framework to analyse a key component of the computer industry . this analysis begins from the perspective of government research and development spending then examines the confusion around the evolution of the high end computing market in the context of standard theories of technology strategy and new product innovation . rather than the high end market being ' dead ' , one should view the market as changing due to increased capability and competition from the low end personal computer market . the high end market is also responding to new product innovation from the introduction of new parallel computing architectures . in the conclusion , key leverage points in the market are identified and the trends in high end computing are highlighted with implications"}, "present_kps": {"text": ["usa", "historical analysis", "strategic analysis", "computer industry", "government research", "development spending", "technology strategy", "new product innovation", "competition", "low end personal computer market", "parallel computing architectures"], "tokenized": ["usa", "historical analysis", "strategic analysis", "computer industry", "government research", "development spending", "technology strategy", "new product innovation", "competition", "low end personal computer market", "parallel computing architectures"]}, "absent_kps": {"text": ["supercomputing", "high end computing market evolution"], "tokenized": ["supercomputing", "high end computing market evolution"]}}
{"id": 224, "title": {"text": "strong active solution in non cooperative games .", "tokenized": "strong active solution in non cooperative games ."}, "abstract": {"text": "proposal , a new notion of equilibrium was proposed , its place among the known basic equilibria was established , and its application to the static and dynamic game problems was demonstrated", "tokenized": "proposal , a new notion of equilibrium was proposed , its place among the known basic equilibria was established , and its application to the static and dynamic game problems was demonstrated"}, "present_kps": {"text": ["strong active solution", "dynamic game problems"], "tokenized": ["strong active solution", "dynamic game problems"]}, "absent_kps": {"text": ["static game problems", "noncooperative games"], "tokenized": ["static game problems", "noncooperative games"]}}
{"id": 225, "title": {"text": "system embedding . control with reduced observer .", "tokenized": "system embedding . control with reduced observer ."}, "abstract": {"text": "separately and together with its control system were considered from the standpoint of designing the multivariable linear systems from the desired matrix transfer functions . the matrix equations defining the entire constructive class of solutions of the posed problems were obtained using the system embedding technology . as was demonstrated , control based on the reduced observer is capable to provide the desired response to the control input , as well as the response to the nonzero initial conditions , only for the directly measurable part of the components of the state vector . an illustrative example was presented", "tokenized": "separately and together with its control system were considered from the standpoint of designing the multivariable linear systems from the desired matrix transfer functions . the matrix equations defining the entire constructive class of solutions of the posed problems were obtained using the system embedding technology . as was demonstrated , control based on the reduced observer is capable to provide the desired response to the control input , as well as the response to the nonzero initial conditions , only for the directly measurable part of the components of the state vector . an illustrative example was presented"}, "present_kps": {"text": ["system embedding", "multivariable linear systems", "matrix transfer functions", "state vector"], "tokenized": ["system embedding", "multivariable linear systems", "matrix transfer functions", "state vector"]}, "absent_kps": {"text": ["reduced observer control", "reduced plant state observer design"], "tokenized": ["reduced observer control", "reduced plant state observer design"]}}
{"id": 226, "title": {"text": "spectral characteristics of the linear systems over a bounded time interval .", "tokenized": "spectral characteristics of the linear systems over a bounded time interval ."}, "abstract": {"text": "systems over a bounded time interval . singular characteristics of standard dynamic blocks , transcendental characteristic equations , and partial spectra of the singular functions were studied . relationship between the spectra under study and the classical frequency characteristic was demonstrated", "tokenized": "systems over a bounded time interval . singular characteristics of standard dynamic blocks , transcendental characteristic equations , and partial spectra of the singular functions were studied . relationship between the spectra under study and the classical frequency characteristic was demonstrated"}, "present_kps": {"text": ["spectral characteristics", "bounded time interval", "singular characteristics", "standard dynamic blocks", "transcendental characteristic equations", "partial spectra", "singular functions", "frequency characteristic"], "tokenized": ["spectral characteristics", "bounded time interval", "singular characteristics", "standard dynamic blocks", "transcendental characteristic equations", "partial spectra", "singular functions", "frequency characteristic"]}, "absent_kps": {"text": ["linear dynamic systems"], "tokenized": ["linear dynamic systems"]}}
{"id": 227, "title": {"text": "quantum computing with solids .", "tokenized": "quantum computing with solids ."}, "abstract": {"text": "building them from solid state devices will not be easy . the author outlines the challenges in scaling up the technology from lab experiments to practical devices", "tokenized": "building them from solid state devices will not be easy . the author outlines the challenges in scaling up the technology from lab experiments to practical devices"}, "present_kps": {"text": ["quantum computers", "solid state devices"], "tokenized": ["quantum computers", "solid state devices"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 228, "title": {"text": "the perils of privacy .", "tokenized": "the perils of privacy ."}, "abstract": {"text": "privacy abuse . what should happen to the names and addresses on a customer list if these details were obtained under a privacy policy which specified no disclosure to any third party should the personal data in the list be deemed to be an asset of a failing company which can be transferred to any future ( third party ) purchaser for its purposes or should the privacy policy take precedence over the commercial concerns of the purchaser", "tokenized": "privacy abuse . what should happen to the names and addresses on a customer list if these details were obtained under a privacy policy which specified no disclosure to any third party should the personal data in the list be deemed to be an asset of a failing company which can be transferred to any future ( third party ) purchaser for its purposes or should the privacy policy take precedence over the commercial concerns of the purchaser"}, "present_kps": {"text": ["privacy abuse", "customer list", "privacy policy", "disclosure"], "tokenized": ["privacy abuse", "customer list", "privacy policy", "disclosure"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 229, "title": {"text": "enterprise in focus at netsec [digit] .", "tokenized": "enterprise in focus at netsec [digit] ."}, "abstract": {"text": "balance to be struck between combatting cyber terrorism and safeguarding civil liberties post [digit] . [digit] . the author reports on the punditry and the pedagogy at the csi event , focusing on security in the enterprise", "tokenized": "balance to be struck between combatting cyber terrorism and safeguarding civil liberties post [digit] . [digit] . the author reports on the punditry and the pedagogy at the csi event , focusing on security in the enterprise"}, "present_kps": {"text": ["netsec [digit]", "csi"], "tokenized": ["netsec [digit]", "csi"]}, "absent_kps": {"text": ["enterprise security"], "tokenized": ["enterprise security"]}}
{"id": 230, "title": {"text": "trusted . . . or . . . trustworthy the search for a new paradigm for computer and .", "tokenized": "trusted . . . or . . . trustworthy the search for a new paradigm for computer and ."}, "abstract": {"text": "this paper sets out a number of major questions and challenges which include ( a ) just what is meant by trusted ' or trustworthy ' systems after [digit] years of experience , or more likely , lack of business level experience , with the ' trusted computer system ' criteria anyway ( b ) does anyone really care about the adoption of international standards for computer system security evaluation by it product and system manufacturers and suppliers ( is [digit] ) and , if so , how does it all relate to business risk management anyway ( is [digit] ) ( c ) with the explosion of adoption of the microcomputer and personal computer some [digit] years ago , has the industry abandoned all that it learnt about security during the mainframe era ' or whatever happened to multics ' and its lessons ( d ) has education kept up with security requirements by industry and government alike in the need for safe and secure operation of large scale and networked information systems on national and international bases , particularly where web or internet based information services are being proposed as the major next best thing ' in the it industry ( e ) has the fourth generation ' of computer professionals inherited the spirit of information systems management and control that resided by necessity with the last generation ' , the professionals who developed and created the applications for shared mainframe and minicomputer systems", "tokenized": "this paper sets out a number of major questions and challenges which include ( a ) just what is meant by trusted ' or trustworthy ' systems after [digit] years of experience , or more likely , lack of business level experience , with the ' trusted computer system ' criteria anyway ( b ) does anyone really care about the adoption of international standards for computer system security evaluation by it product and system manufacturers and suppliers ( is [digit] ) and , if so , how does it all relate to business risk management anyway ( is [digit] ) ( c ) with the explosion of adoption of the microcomputer and personal computer some [digit] years ago , has the industry abandoned all that it learnt about security during the mainframe era ' or whatever happened to multics ' and its lessons ( d ) has education kept up with security requirements by industry and government alike in the need for safe and secure operation of large scale and networked information systems on national and international bases , particularly where web or internet based information services are being proposed as the major next best thing ' in the it industry ( e ) has the fourth generation ' of computer professionals inherited the spirit of information systems management and control that resided by necessity with the last generation ' , the professionals who developed and created the applications for shared mainframe and minicomputer systems"}, "present_kps": {"text": ["international standards", "is [digit]", "is [digit]", "business risk management", "microcomputer", "personal computer", "multics", "education", "web", "internet based information services", "information systems management"], "tokenized": ["international standards", "is [digit]", "is [digit]", "business risk management", "microcomputer", "personal computer", "multics", "education", "web", "internet based information services", "information systems management"]}, "absent_kps": {"text": ["information systems control", "fourth generation computer professionals", "network security", "it manufacturers", "large scale information systems", "trustworthy systems", "trusted systems", "computer security"], "tokenized": ["information systems control", "fourth generation computer professionals", "network security", "it manufacturers", "large scale information systems", "trustworthy systems", "trusted systems", "computer security"]}}
{"id": 231, "title": {"text": "much ado about nothing win32 . perrun .", "tokenized": "much ado about nothing win32 . perrun ."}, "abstract": {"text": "such files . the author takes a look at the details surrounding the win32 . perrun virus and make clear exactly what it does . the main virus feature is its ability to affect jpeg image files ( compressed graphic images ) and to spread via affected jpeg files . the virus affects , or modifies , or alters jpeg files but does not infect them", "tokenized": "such files . the author takes a look at the details surrounding the win32 . perrun virus and make clear exactly what it does . the main virus feature is its ability to affect jpeg image files ( compressed graphic images ) and to spread via affected jpeg files . the virus affects , or modifies , or alters jpeg files but does not infect them"}, "present_kps": {"text": ["win32 . perrun", "virus", "compressed graphic images", "jpeg files"], "tokenized": ["win32 . perrun", "virus", "compressed graphic images", "jpeg files"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 232, "title": {"text": "information security policy what do international information security .", "tokenized": "information security policy what do international information security ."}, "abstract": {"text": "one of the most important information security controls , is the information security policy . this vital direction giving document is , however , not always easy to develop and the authors thereof battle with questions such as what constitutes a policy . this results in the policy authors turning to existing sources for guidance . one of these sources is the various international information security standards . these standards are a good starting point for determining what the information security policy should consist of , but should not be relied upon exclusively for guidance . firstly , they are not comprehensive in their coverage and furthermore , tending to rather address the processes needed for successfully implementing the information security policy . it is far more important the information security policy must fit in with the organisation ' s culture and must therefore be developed with this in mind", "tokenized": "one of the most important information security controls , is the information security policy . this vital direction giving document is , however , not always easy to develop and the authors thereof battle with questions such as what constitutes a policy . this results in the policy authors turning to existing sources for guidance . one of these sources is the various international information security standards . these standards are a good starting point for determining what the information security policy should consist of , but should not be relied upon exclusively for guidance . firstly , they are not comprehensive in their coverage and furthermore , tending to rather address the processes needed for successfully implementing the information security policy . it is far more important the information security policy must fit in with the organisation ' s culture and must therefore be developed with this in mind"}, "present_kps": {"text": ["information security policy", "international information security standards"], "tokenized": ["information security policy", "international information security standards"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 233, "title": {"text": "security crisis management the basics .", "tokenized": "security crisis management the basics ."}, "abstract": {"text": "security event is managed from the inception to the end . there ' s a lot written about how to manage a specific incident or how to deal with a point problem such as a firewall log , but little tends to be written about how to deal with the management of a security event as part of corporate crisis management . this article discusses the basics of security crisis management and of the logical steps required to ensure that a security crisis does not get out of hand", "tokenized": "security event is managed from the inception to the end . there ' s a lot written about how to manage a specific incident or how to deal with a point problem such as a firewall log , but little tends to be written about how to deal with the management of a security event as part of corporate crisis management . this article discusses the basics of security crisis management and of the logical steps required to ensure that a security crisis does not get out of hand"}, "present_kps": {"text": ["security crisis management", "security event", "firewall log", "corporate crisis management"], "tokenized": ["security crisis management", "security event", "firewall log", "corporate crisis management"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 234, "title": {"text": "a conceptual framework for evaluation of information technology investments .", "tokenized": "a conceptual framework for evaluation of information technology investments ."}, "abstract": {"text": "evaluation and selection problems to technology managers , because the new system must not only meet current information requirements of the organisation , but also the needs for future expansion . tangible and intangible benefits factors , as well as risks factors , must be identified and evaluated . the paper provides a review of ten major evaluation categories and available models , which fall under each category , showing their advantages and disadvantages in handling the above difficulties . this paper describes strategic implications involved in the selection decision , and the inherent difficulties in ( [digit] ) choosing or developing a model , ( [digit] ) obtaining realistic inputs for the model , and ( [digit] ) making tradeoffs among the conflicting factors . it proposes a conceptual framework to help the decision maker in choosing the most appropriate methodology in the evaluation process . it also offers a new model , called gahp , for the evaluation problem combining integer goal linear programming and analytic hierarchy process ( ahp ) in a single hybrid multiple objective multi criteria model . a goal programming methodology , with zero one integer variables and mixed integer constraints , is used to set goal target values against which information technology alternatives are evaluated and selected . ahp is used to structure the evaluation process providing pairwise comparison mechanisms to quantify subjective , nonmonetary , intangible benefits and risks factors , in deriving data for the model . a case illustration is provided showing how gahp can be formulated and solved", "tokenized": "evaluation and selection problems to technology managers , because the new system must not only meet current information requirements of the organisation , but also the needs for future expansion . tangible and intangible benefits factors , as well as risks factors , must be identified and evaluated . the paper provides a review of ten major evaluation categories and available models , which fall under each category , showing their advantages and disadvantages in handling the above difficulties . this paper describes strategic implications involved in the selection decision , and the inherent difficulties in ( [digit] ) choosing or developing a model , ( [digit] ) obtaining realistic inputs for the model , and ( [digit] ) making tradeoffs among the conflicting factors . it proposes a conceptual framework to help the decision maker in choosing the most appropriate methodology in the evaluation process . it also offers a new model , called gahp , for the evaluation problem combining integer goal linear programming and analytic hierarchy process ( ahp ) in a single hybrid multiple objective multi criteria model . a goal programming methodology , with zero one integer variables and mixed integer constraints , is used to set goal target values against which information technology alternatives are evaluated and selected . ahp is used to structure the evaluation process providing pairwise comparison mechanisms to quantify subjective , nonmonetary , intangible benefits and risks factors , in deriving data for the model . a case illustration is provided showing how gahp can be formulated and solved"}, "present_kps": {"text": ["information technology investments", "technology managers", "information requirements", "intangible benefits", "risks factors", "evaluation categories", "selection decision", "tradeoffs", "decision maker", "analytic hierarchy process", "hybrid multiple objective multi criteria model", "goal programming methodology", "zero one integer variables", "mixed integer constraints", "goal target values", "information technology alternatives", "pairwise comparison mechanisms"], "tokenized": ["information technology investments", "technology managers", "information requirements", "intangible benefits", "risks factors", "evaluation categories", "selection decision", "tradeoffs", "decision maker", "analytic hierarchy process", "hybrid multiple objective multi criteria model", "goal programming methodology", "zero one integer variables", "mixed integer constraints", "goal target values", "information technology alternatives", "pairwise comparison mechanisms"]}, "absent_kps": {"text": ["group decision process", "nonmonetary benefits"], "tokenized": ["group decision process", "nonmonetary benefits"]}}
{"id": 235, "title": {"text": "data storage re format . closely tracking a fast moving sector .", "tokenized": "data storage re format . closely tracking a fast moving sector ."}, "abstract": {"text": "many companies into consolidation or bankruptcy . gone are the days when companies raised millions of dollars to acquire large industrial buildings and transform them into glittering , high tech palaces filled with the latest telecommunication and data technology . whereas manufacturers of communication technology deliver the racked equipment in these , often mission critical , facilities , abb focuses mainly on the building infrastructure . besides the very important redundant power supply , abb also provides the redundant air conditioning and the security system", "tokenized": "many companies into consolidation or bankruptcy . gone are the days when companies raised millions of dollars to acquire large industrial buildings and transform them into glittering , high tech palaces filled with the latest telecommunication and data technology . whereas manufacturers of communication technology deliver the racked equipment in these , often mission critical , facilities , abb focuses mainly on the building infrastructure . besides the very important redundant power supply , abb also provides the redundant air conditioning and the security system"}, "present_kps": {"text": ["abb", "building infrastructure", "redundant power supply", "redundant air conditioning", "security system"], "tokenized": ["abb", "building infrastructure", "redundant power supply", "redundant air conditioning", "security system"]}, "absent_kps": {"text": ["installation", "mission critical facilities", "building management", "data centers", "engineering management", "commissioning", "project management"], "tokenized": ["installation", "mission critical facilities", "building management", "data centers", "engineering management", "commissioning", "project management"]}}
{"id": 236, "title": {"text": "industrial sup it for performance buildings .", "tokenized": "industrial sup it for performance buildings ."}, "abstract": {"text": "radical solution for the technical infrastructure that places the end user ' s processes at the center and integrates all the building ' s systems around their needs . the new solution is based on the realization that tasks like setting up an office meeting , registering a hotel guest or moving a patient in a hospital , can all benefit from the same industrial it concepts employed by abb to optimize manufacturing , for example in the automotive industry", "tokenized": "radical solution for the technical infrastructure that places the end user ' s processes at the center and integrates all the building ' s systems around their needs . the new solution is based on the realization that tasks like setting up an office meeting , registering a hotel guest or moving a patient in a hospital , can all benefit from the same industrial it concepts employed by abb to optimize manufacturing , for example in the automotive industry"}, "present_kps": {"text": ["industrial sup it", "technical infrastructure", "industrial it concepts", "abb"], "tokenized": ["industrial sup it", "technical infrastructure", "industrial it concepts", "abb"]}, "absent_kps": {"text": ["building management system", "building systems integration"], "tokenized": ["building management system", "building systems integration"]}}
{"id": 237, "title": {"text": "virtual engineering office a state of the art platform for engineering .", "tokenized": "virtual engineering office a state of the art platform for engineering ."}, "abstract": {"text": "a sales force in latin america , the design department in europe , and production in asia arrangements of this kind are the new business reality for today ' s global manufacturing companies . but how are such global operations to be effectively coordinated abb ' s answer was to develop and implement a new platform for high performance , real time collaboration . globally distributed engineering teams can now work together , regardless of time , location or the cad system they use , making abb easier to do business with , for customers as well as suppliers", "tokenized": "a sales force in latin america , the design department in europe , and production in asia arrangements of this kind are the new business reality for today ' s global manufacturing companies . but how are such global operations to be effectively coordinated abb ' s answer was to develop and implement a new platform for high performance , real time collaboration . globally distributed engineering teams can now work together , regardless of time , location or the cad system they use , making abb easier to do business with , for customers as well as suppliers"}, "present_kps": {"text": ["virtual engineering office", "state of the art", "business", "global manufacturing companies", "abb", "globally distributed engineering teams", "cad system"], "tokenized": ["virtual engineering office", "state of the art", "business", "global manufacturing companies", "abb", "globally distributed engineering teams", "cad system"]}, "absent_kps": {"text": ["engineering collaboration platform"], "tokenized": ["engineering collaboration platform"]}}
{"id": 238, "title": {"text": "post haste . 100th robotic containerization system installed in us mail sorting .", "tokenized": "post haste . 100th robotic containerization system installed in us mail sorting ."}, "abstract": {"text": "spot welding , machine tending , material handling , picking , packing , painting , palletizing , assembly . . . the list of tasks being performed by abb robots keeps on growing . adding to this portfolio is a new robot containerization system ( rcs ) that abb developed specifically for the united states postal service ( usps ) . the rcs has brought new levels of speed , accuracy , efficiency and productivity to the process of sorting and containerizing mail and packages . recently , the 100th abb rcs was installed at the usps processing and distribution center in columbus , ohio", "tokenized": "spot welding , machine tending , material handling , picking , packing , painting , palletizing , assembly . . . the list of tasks being performed by abb robots keeps on growing . adding to this portfolio is a new robot containerization system ( rcs ) that abb developed specifically for the united states postal service ( usps ) . the rcs has brought new levels of speed , accuracy , efficiency and productivity to the process of sorting and containerizing mail and packages . recently , the 100th abb rcs was installed at the usps processing and distribution center in columbus , ohio"}, "present_kps": {"text": ["robotic containerization system", "mail sorting", "abb robots", "united states postal service"], "tokenized": ["robotic containerization system", "mail sorting", "abb robots", "united states postal service"]}, "absent_kps": {"text": ["usa", "packages sorting", "mail sorting center"], "tokenized": ["usa", "packages sorting", "mail sorting center"]}}
{"id": 239, "title": {"text": "optimize sup it robot condition monitoring tool .", "tokenized": "optimize sup it robot condition monitoring tool ."}, "abstract": {"text": "increasingly to their builders for ways to measure the critical variables the robotic equivalent of a physical check up in order to monitor their condition and schedule maintenance more effectively . this is all the more essential considering the tremendous pressure there is to improve productivity in today ' s global markets . developed for abb robots with an s4 family controller and based on the company ' s broad process know how , optimize sup it robot condition monitoring offers maintenance routines with embedded checklists that give a clear indication of a robot ' s operating condition . it performs semi automatic measurements that support engineers during trouble shooting and enable action to be taken to prevent unplanned stops . by comparing these measurements with reference data , negative trends can be detected early and potential breakdowns predicted . armed with all these features , optimize sup it robot condition monitoring provides the ideal basis for reliability centered maintenance ( rcm ) for robots", "tokenized": "increasingly to their builders for ways to measure the critical variables the robotic equivalent of a physical check up in order to monitor their condition and schedule maintenance more effectively . this is all the more essential considering the tremendous pressure there is to improve productivity in today ' s global markets . developed for abb robots with an s4 family controller and based on the company ' s broad process know how , optimize sup it robot condition monitoring offers maintenance routines with embedded checklists that give a clear indication of a robot ' s operating condition . it performs semi automatic measurements that support engineers during trouble shooting and enable action to be taken to prevent unplanned stops . by comparing these measurements with reference data , negative trends can be detected early and potential breakdowns predicted . armed with all these features , optimize sup it robot condition monitoring provides the ideal basis for reliability centered maintenance ( rcm ) for robots"}, "present_kps": {"text": ["optimize sup it robot condition monitoring tool", "condition monitoring", "abb robots", "s4 family controller", "semi automatic measurements", "reliability centered maintenance"], "tokenized": ["optimize sup it robot condition monitoring tool", "condition monitoring", "abb robots", "s4 family controller", "semi automatic measurements", "reliability centered maintenance"]}, "absent_kps": {"text": ["maintenance scheduling"], "tokenized": ["maintenance scheduling"]}}
{"id": 240, "title": {"text": "pane relief . robotic solutions for car windshield assembly .", "tokenized": "pane relief . robotic solutions for car windshield assembly ."}, "abstract": {"text": "about how it ' s made . the idea that special manufacturing expertise might be required can hardly occur to anyone , but that ' s exactly what is needed to ensure crystal clear visibility , not to mention a perfect fit every time one is pressed into place on a car production line . comprising two thin glass sheets joined by a vinyl interlayer , windshields are assembled usually manually to very precise product and environmental specifications . to make sure this is done as perfectly as possible , the industry invests heavily in the equipment used for their fabrication . abb has now developed a robot based compact assembling system for the automatic assembly of laminated windshields that speeds up production and increases cost efficiency", "tokenized": "about how it ' s made . the idea that special manufacturing expertise might be required can hardly occur to anyone , but that ' s exactly what is needed to ensure crystal clear visibility , not to mention a perfect fit every time one is pressed into place on a car production line . comprising two thin glass sheets joined by a vinyl interlayer , windshields are assembled usually manually to very precise product and environmental specifications . to make sure this is done as perfectly as possible , the industry invests heavily in the equipment used for their fabrication . abb has now developed a robot based compact assembling system for the automatic assembly of laminated windshields that speeds up production and increases cost efficiency"}, "present_kps": {"text": ["manufacturing expertise", "car production line", "production", "abb", "compact assembling system", "cost efficiency"], "tokenized": ["manufacturing expertise", "car production line", "production", "abb", "compact assembling system", "cost efficiency"]}, "absent_kps": {"text": ["laminated windshields assembly automation", "car windshield assembly robots"], "tokenized": ["laminated windshields assembly automation", "car windshield assembly robots"]}}
{"id": 241, "title": {"text": "shaping the future . bendwizard a tool for off line programming of robotic .", "tokenized": "shaping the future . bendwizard a tool for off line programming of robotic ."}, "abstract": {"text": "setting up a robot to make metal cabinets or cases for desktop computers can be a complex operation . for instance , one expert might be required to carry out a feasibility study , and then another to actually program the robot . understandably , the need for so much expertise , and the time that ' s required , generally limits the usefulness of automation to high volume production . workshops producing parts in batches smaller than [digit] or so , or which rely heavily on semiskilled operators , are therefore often discouraged from investing in automation , and so miss out on its many advantages . what is needed is a software tool that operators without special knowledge of robotics , or with no more than rudimentary cad skills , can use . one which allows easy offline programming and simulation of the work cell on a pc", "tokenized": "setting up a robot to make metal cabinets or cases for desktop computers can be a complex operation . for instance , one expert might be required to carry out a feasibility study , and then another to actually program the robot . understandably , the need for so much expertise , and the time that ' s required , generally limits the usefulness of automation to high volume production . workshops producing parts in batches smaller than [digit] or so , or which rely heavily on semiskilled operators , are therefore often discouraged from investing in automation , and so miss out on its many advantages . what is needed is a software tool that operators without special knowledge of robotics , or with no more than rudimentary cad skills , can use . one which allows easy offline programming and simulation of the work cell on a pc"}, "present_kps": {"text": ["metal cabinets", "feasibility study", "high volume production", "workshops", "cad skills"], "tokenized": ["metal cabinets", "feasibility study", "high volume production", "workshops", "cad skills"]}, "absent_kps": {"text": ["bendwizard offline programming tool", "desktop computer cases", "robotic tending systems", "work cell simulation"], "tokenized": ["bendwizard offline programming tool", "desktop computer cases", "robotic tending systems", "work cell simulation"]}}
{"id": 242, "title": {"text": "press shop . industrial it solutions for the press shop .", "tokenized": "press shop . industrial it solutions for the press shop ."}, "abstract": {"text": "manufacturing efficiency . the competitive advantage belongs to those who understand the new requirements and opportunities , and who commit to integrated solutions that span the value chain all the way from demand to production . abb ' s automation and it expertise and the process know how gained from its long involvement with the automotive industry , have been brought together in new , state of the art software solutions for press shops . integrated into industrial it architecture , they allow the full potential of the shops to be realized , with advantages at every step in the supply chain", "tokenized": "manufacturing efficiency . the competitive advantage belongs to those who understand the new requirements and opportunities , and who commit to integrated solutions that span the value chain all the way from demand to production . abb ' s automation and it expertise and the process know how gained from its long involvement with the automotive industry , have been brought together in new , state of the art software solutions for press shops . integrated into industrial it architecture , they allow the full potential of the shops to be realized , with advantages at every step in the supply chain"}, "present_kps": {"text": ["press shops", "industrial it solutions", "manufacturing efficiency", "automation", "state of the art", "software solutions", "supply chain"], "tokenized": ["press shops", "industrial it solutions", "manufacturing efficiency", "automation", "state of the art", "software solutions", "supply chain"]}, "absent_kps": {"text": ["market globalisation", "car manufacturing business"], "tokenized": ["market globalisation", "car manufacturing business"]}}
{"id": 243, "title": {"text": "real time enterprise solutions for discrete manufacturing and consumer goods .", "tokenized": "real time enterprise solutions for discrete manufacturing and consumer goods ."}, "abstract": {"text": "thinking of a whole host of industries in recent years . however , one outcome , the outsourcing of noncore activities , has made the production of goods from order entry to final delivery more and more complex . suppliers , subsuppliers , producers and customers are therefore busy adopting a new , more collaborative approach . this is mainly taking the form of order driven planning and scheduling of production , but it is also being steered by a need to reduce inventories and working capital as well as a desire to increase throughput and optimize production", "tokenized": "thinking of a whole host of industries in recent years . however , one outcome , the outsourcing of noncore activities , has made the production of goods from order entry to final delivery more and more complex . suppliers , subsuppliers , producers and customers are therefore busy adopting a new , more collaborative approach . this is mainly taking the form of order driven planning and scheduling of production , but it is also being steered by a need to reduce inventories and working capital as well as a desire to increase throughput and optimize production"}, "present_kps": {"text": ["real time enterprise solutions", "discrete manufacturing", "consumer goods", "order driven planning"], "tokenized": ["real time enterprise solutions", "discrete manufacturing", "consumer goods", "order driven planning"]}, "absent_kps": {"text": ["core competencies", "customer satisfaction", "working capital reduction", "production scheduling", "inventories reduction"], "tokenized": ["core competencies", "customer satisfaction", "working capital reduction", "production scheduling", "inventories reduction"]}}
{"id": 244, "title": {"text": "extinction cross sections of realistic raindrops data bank established using .", "tokenized": "extinction cross sections of realistic raindrops data bank established using ."}, "abstract": {"text": "a new computer program is developed based on the t matrix method to generate a large number of total ( extinction ) cross sections ( tcs ) values of the realistic raindrops that are deformed due to a balance of the forces that act on a drop failing under gravity , and were described in shape by pruppacher and pitter ( [digit] ) . these data for various dimensions of the raindrops ( mean effective radius from [digit] to [digit] . [digit] mm ) , frequencies ( [digit] to [digit] ghz ) , ( horizontal and vertical ) polarizations , and temperatures ( [digit] , [digit] and [digit] degrees c ) are stored to establish a data bank . furthermore , a curve fitting technique , i . e . , interpolation of order [digit] , is implemented for the tcs values in the data bank . therefore , the interpolated tcs results can be obtained readily from the interpolation process with negligible or even null computational time and efforts . error analysis is carried out to show the high accuracy of the present analysis and applicability of the interpolation . at three operating frequencies of [digit] , [digit] . [digit] , and [digit] ghz locally used in singapore , some new tcs values are obtained from the new fast and efficient interpolation with a good accuracy", "tokenized": "a new computer program is developed based on the t matrix method to generate a large number of total ( extinction ) cross sections ( tcs ) values of the realistic raindrops that are deformed due to a balance of the forces that act on a drop failing under gravity , and were described in shape by pruppacher and pitter ( [digit] ) . these data for various dimensions of the raindrops ( mean effective radius from [digit] to [digit] . [digit] mm ) , frequencies ( [digit] to [digit] ghz ) , ( horizontal and vertical ) polarizations , and temperatures ( [digit] , [digit] and [digit] degrees c ) are stored to establish a data bank . furthermore , a curve fitting technique , i . e . , interpolation of order [digit] , is implemented for the tcs values in the data bank . therefore , the interpolated tcs results can be obtained readily from the interpolation process with negligible or even null computational time and efforts . error analysis is carried out to show the high accuracy of the present analysis and applicability of the interpolation . at three operating frequencies of [digit] , [digit] . [digit] , and [digit] ghz locally used in singapore , some new tcs values are obtained from the new fast and efficient interpolation with a good accuracy"}, "present_kps": {"text": ["extinction cross sections", "realistic raindrops", "data bank", "computer program", "t matrix method", "gravity", "mean effective radius", "[digit] to [digit] . [digit] mm", "[digit] to [digit] ghz", "[digit] ghz", "[digit] ghz", "temperature", "interpolation", "error analysis", "operating frequencies", "singapore"], "tokenized": ["extinction cross sections", "realistic raindrops", "data bank", "computer program", "t matrix method", "gravity", "mean effective radius", "[digit] to [digit] . [digit] mm", "[digit] to [digit] ghz", "[digit] ghz", "[digit] ghz", "temperature", "interpolation", "error analysis", "operating frequencies", "singapore"]}, "absent_kps": {"text": ["total cross sections", "shf", "em wave scattering", "[digit] c", "electromagnetic wave scattering", "[digit] . [digit] ghz", "ehf", "nonlinear curve fitting technique", "[digit] c", "vertical polarization", "horizontal polarization", "[digit] c"], "tokenized": ["total cross sections", "shf", "em wave scattering", "[digit] c", "electromagnetic wave scattering", "[digit] . [digit] ghz", "ehf", "nonlinear curve fitting technique", "[digit] c", "vertical polarization", "horizontal polarization", "[digit] c"]}}
{"id": 245, "title": {"text": "challenges and trends in discrete manufacturing .", "tokenized": "challenges and trends in discrete manufacturing ."}, "abstract": {"text": "turned out [digit] cars per day . nowadays , ford ' s plant on that same site still produces [digit] cars each day but with just [digit] workers . similar stories abound in the manufacturing industries technology revolution and evolution a shift from vertical integration , better business and production practices and improved industrial relations all have changed manufacturing beyond recognition . so what are the current challenges and trends in manufacturing certainly , the relentless advance of technology will continue , as will user pressure for more customized design or improved environmental friendliness . some trends are already with us and more , as yet indiscernible , will come . but one major , fundamental shift now resounding throughout industry is the way in which information involving every single aspect of the manufacturing process is being integrated into one seamless system", "tokenized": "turned out [digit] cars per day . nowadays , ford ' s plant on that same site still produces [digit] cars each day but with just [digit] workers . similar stories abound in the manufacturing industries technology revolution and evolution a shift from vertical integration , better business and production practices and improved industrial relations all have changed manufacturing beyond recognition . so what are the current challenges and trends in manufacturing certainly , the relentless advance of technology will continue , as will user pressure for more customized design or improved environmental friendliness . some trends are already with us and more , as yet indiscernible , will come . but one major , fundamental shift now resounding throughout industry is the way in which information involving every single aspect of the manufacturing process is being integrated into one seamless system"}, "present_kps": {"text": ["challenges", "trends", "discrete manufacturing", "technology revolution", "production practices", "industrial relations"], "tokenized": ["challenges", "trends", "discrete manufacturing", "technology revolution", "production practices", "industrial relations"]}, "absent_kps": {"text": ["business practices", "technology evolution", "automobile factory", "seamless manufacturing process"], "tokenized": ["business practices", "technology evolution", "automobile factory", "seamless manufacturing process"]}}
{"id": 246, "title": {"text": "on the beth properties of some intuitionistic modal logics .", "tokenized": "on the beth properties of some intuitionistic modal logics ."}, "abstract": {"text": "case , we define two different forms of the beth property for l , which are denoted by b1 and b2 in this paper we study the relation among b1 , b2 and the interpolation properties c1 and c2 . it turns out that c1 implies b1 , but contrary to the boolean case , is not equivalent to b1 . it is shown that b2 and c2 are independent , and moreover it comes out that , in contrast to classical case , there exists an extension of the intuitionistic modal logic of s sub [digit] type , that has not the property b2 . finally we give two algebraic properties , that characterize respectively b1 and b2", "tokenized": "case , we define two different forms of the beth property for l , which are denoted by b1 and b2 in this paper we study the relation among b1 , b2 and the interpolation properties c1 and c2 . it turns out that c1 implies b1 , but contrary to the boolean case , is not equivalent to b1 . it is shown that b2 and c2 are independent , and moreover it comes out that , in contrast to classical case , there exists an extension of the intuitionistic modal logic of s sub [digit] type , that has not the property b2 . finally we give two algebraic properties , that characterize respectively b1 and b2"}, "present_kps": {"text": ["beth properties", "intuitionistic modal logics", "interpolation properties"], "tokenized": ["beth properties", "intuitionistic modal logics", "interpolation properties"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 247, "title": {"text": "more constructions for boolean algebras .", "tokenized": "more constructions for boolean algebras ."}, "abstract": {"text": "the free product of two boolean algebras over a third , in zfc using pcf assuming squares we get results on ultraproducts . we also deal with the family of cardinalities and topological density of homomorphic images of boolean algebras ( you can translate it to topology on the cardinalities of closed subspaces ) and lastly we deal with inequalities between cardinal invariants , mainly d ( b ) sup kappa < b implies ind ( b ) > sup kappa v depth ( b ) > or log ( b )", "tokenized": "the free product of two boolean algebras over a third , in zfc using pcf assuming squares we get results on ultraproducts . we also deal with the family of cardinalities and topological density of homomorphic images of boolean algebras ( you can translate it to topology on the cardinalities of closed subspaces ) and lastly we deal with inequalities between cardinal invariants , mainly d ( b ) sup kappa < b implies ind ( b ) > sup kappa v depth ( b ) > or log ( b )"}, "present_kps": {"text": ["boolean algebras", "free product", "zfc", "ultraproducts", "homomorphic images", "cardinal invariants"], "tokenized": ["boolean algebras", "free product", "zfc", "ultraproducts", "homomorphic images", "cardinal invariants"]}, "absent_kps": {"text": ["prescribed behaviour"], "tokenized": ["prescribed behaviour"]}}
{"id": 248, "title": {"text": "it as a key enabler to law firm competitiveness .", "tokenized": "it as a key enabler to law firm competitiveness ."}, "abstract": {"text": "any market conditions . they have been consistently successful for several decades without ever needing to reexamine or change their basic operating model . however , gradual but inexorable change in client expectations and the business environment over recent years now means that more of the same is no longer enough . in future , law firms will increasingly need to exploit it more effectively in order to remain competitive . to do this , they will need to ensure that all their information systems function as an integrated whole and are available to their staff , clients and business partners . the authors set out the lessons to be learned for law firms in the light of the recent pa consulting survey", "tokenized": "any market conditions . they have been consistently successful for several decades without ever needing to reexamine or change their basic operating model . however , gradual but inexorable change in client expectations and the business environment over recent years now means that more of the same is no longer enough . in future , law firms will increasingly need to exploit it more effectively in order to remain competitive . to do this , they will need to ensure that all their information systems function as an integrated whole and are available to their staff , clients and business partners . the authors set out the lessons to be learned for law firms in the light of the recent pa consulting survey"}, "present_kps": {"text": ["law firms", "client expectations", "business environment", "information systems"], "tokenized": ["law firms", "client expectations", "business environment", "information systems"]}, "absent_kps": {"text": ["professional services firms"], "tokenized": ["professional services firms"]}}
{"id": 249, "title": {"text": "electronic signatures much ado .", "tokenized": "electronic signatures much ado ."}, "abstract": {"text": "for e commerce , the eu and the government continue apace to develop the legal framework . most recently , this has resulted in the electronic signatures regulations [digit] . these regulations were made on [digit] february [digit] and came into force on [digit] march [digit] . the regulations implement the european electronic signatures directive ( [digit] [digit] ec ) . critics may say that the regulations were implemented too late ( they were due to have been implemented by [digit] july [digit] ) , with too short a consultation period ( [digit] january [digit] to [digit] february [digit] ) and with an unconvincing case as to what they add to english law ( as to which , read on ) . the author explains the latest development on e signatures and the significance of certification service providers ( csps )", "tokenized": "for e commerce , the eu and the government continue apace to develop the legal framework . most recently , this has resulted in the electronic signatures regulations [digit] . these regulations were made on [digit] february [digit] and came into force on [digit] march [digit] . the regulations implement the european electronic signatures directive ( [digit] [digit] ec ) . critics may say that the regulations were implemented too late ( they were due to have been implemented by [digit] july [digit] ) , with too short a consultation period ( [digit] january [digit] to [digit] february [digit] ) and with an unconvincing case as to what they add to english law ( as to which , read on ) . the author explains the latest development on e signatures and the significance of certification service providers ( csps )"}, "present_kps": {"text": ["e commerce", "legal framework", "electronic signatures regulations [digit]", "european electronic signatures directive"], "tokenized": ["e commerce", "legal framework", "electronic signatures regulations [digit]", "european electronic signatures directive"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 250, "title": {"text": "naomi campbell drugs , distress and the data protection act .", "tokenized": "naomi campbell drugs , distress and the data protection act ."}, "abstract": {"text": "newspapers for damage and distress caused by breach of the data protection act [digit] . partner n . wildish and assistant m . turle of city law firm field fisher waterhouse discuss the case and the legal implications of which online publishers should be aware", "tokenized": "newspapers for damage and distress caused by breach of the data protection act [digit] . partner n . wildish and assistant m . turle of city law firm field fisher waterhouse discuss the case and the legal implications of which online publishers should be aware"}, "present_kps": {"text": ["naomi campbell", "drugs", "distress", "data protection act", "online publishers"], "tokenized": ["naomi campbell", "drugs", "distress", "data protection act", "online publishers"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 251, "title": {"text": "don ' t always believe what you reed optimisation techniques for web sites and .", "tokenized": "don ' t always believe what you reed optimisation techniques for web sites and ."}, "abstract": {"text": "on [digit] may [digit] , mr justice pumfrey gave judgment in the case of ( [digit] ) reed executive plc ( [digit] ) reed solutions plc versus ( [digit] ) reed business information limited ( [digit] ) reed elsevier ( uk ) limited ( [digit] ) totaljobs . com limited . the case explored for the first time in any detail the extent to which the use of various optimisation techniques for web sites could give rise to new forms of trade mark infringement and passing off . the author reports on the case and offers his comments", "tokenized": "on [digit] may [digit] , mr justice pumfrey gave judgment in the case of ( [digit] ) reed executive plc ( [digit] ) reed solutions plc versus ( [digit] ) reed business information limited ( [digit] ) reed elsevier ( uk ) limited ( [digit] ) totaljobs . com limited . the case explored for the first time in any detail the extent to which the use of various optimisation techniques for web sites could give rise to new forms of trade mark infringement and passing off . the author reports on the case and offers his comments"}, "present_kps": {"text": ["optimisation techniques", "web sites", "reed executive plc", "reed solutions plc", "reed business information limited", "totaljobs . com limited", "trade mark infringement", "passing off"], "tokenized": ["optimisation techniques", "web sites", "reed executive plc", "reed solutions plc", "reed business information limited", "totaljobs . com limited", "trade mark infringement", "passing off"]}, "absent_kps": {"text": ["reed elsevier limited"], "tokenized": ["reed elsevier limited"]}}
{"id": 252, "title": {"text": "finally some sensible european legislation on software .", "tokenized": "finally some sensible european legislation on software ."}, "abstract": {"text": "by patents of computer implemented inventions . the aim of this very important directive is to harmonise national patent laws relating to inventions using software . it follows an extensive consultation launched by the commission in october [digit] . the impetus behind the directive was the recognition at eu level of a total lack of unity between the european patent office and european national courts in deciding what was or was not deemed patentable when it came to the subject of computer programs", "tokenized": "by patents of computer implemented inventions . the aim of this very important directive is to harmonise national patent laws relating to inventions using software . it follows an extensive consultation launched by the commission in october [digit] . the impetus behind the directive was the recognition at eu level of a total lack of unity between the european patent office and european national courts in deciding what was or was not deemed patentable when it came to the subject of computer programs"}, "present_kps": {"text": ["national patent laws", "eu", "european patent office", "national courts", "computer programs"], "tokenized": ["national patent laws", "eu", "european patent office", "national courts", "computer programs"]}, "absent_kps": {"text": ["directive on the protection by patents of computer implemented inventions", "law harmonisation", "european commission"], "tokenized": ["directive on the protection by patents of computer implemented inventions", "law harmonisation", "european commission"]}}
{"id": 253, "title": {"text": "cyberobscenity and the ambit of english criminal law .", "tokenized": "cyberobscenity and the ambit of english criminal law ."}, "abstract": {"text": "in the author ' s submission , the court of appeal ' s decision in perrin was wrong . p published no material in england and wales , and should not have been convicted of any offence under english law , even if it were proved that he sought to attract english subscribers to his site . that may be an unpalatable conclusion but , if the content of foreign hosted internet sites is to be controlled , the only sensible way forward is through international agreement and cooperation . the council of europe ' s cybercrime convention provides some indication of the limited areas over which widespread international agreement might be achieved", "tokenized": "in the author ' s submission , the court of appeal ' s decision in perrin was wrong . p published no material in england and wales , and should not have been convicted of any offence under english law , even if it were proved that he sought to attract english subscribers to his site . that may be an unpalatable conclusion but , if the content of foreign hosted internet sites is to be controlled , the only sensible way forward is through international agreement and cooperation . the council of europe ' s cybercrime convention provides some indication of the limited areas over which widespread international agreement might be achieved"}, "present_kps": {"text": ["cyberobscenity", "criminal law", "court of appeal", "england", "internet sites", "international agreement", "council of europe", "cybercrime convention"], "tokenized": ["cyberobscenity", "criminal law", "court of appeal", "england", "internet sites", "international agreement", "council of europe", "cybercrime convention"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 254, "title": {"text": "e government .", "tokenized": "e government ."}, "abstract": {"text": "modernisation and electronic delivery of all public services by [digit] . the author makes it clear that e government is about transformation , not computers and hints at the special legal issues which may arise", "tokenized": "modernisation and electronic delivery of all public services by [digit] . the author makes it clear that e government is about transformation , not computers and hints at the special legal issues which may arise"}, "present_kps": {"text": ["e government", "modernisation", "electronic delivery", "public services", "legal issues"], "tokenized": ["e government", "modernisation", "electronic delivery", "public services", "legal issues"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 255, "title": {"text": "vendor qualifications for it staff and networking .", "tokenized": "vendor qualifications for it staff and networking ."}, "abstract": {"text": "of a job applicant ' s skills , but they do not always indicate the true extent of practical abilities", "tokenized": "of a job applicant ' s skills , but they do not always indicate the true extent of practical abilities"}, "present_kps": {"text": ["it staff", "job applicant", "practical abilities"], "tokenized": ["it staff", "job applicant", "practical abilities"]}, "absent_kps": {"text": ["vendor run accreditation schemes", "network administrators"], "tokenized": ["vendor run accreditation schemes", "network administrators"]}}
{"id": 256, "title": {"text": "evolution of litigation support systems .", "tokenized": "evolution of litigation support systems ."}, "abstract": {"text": "author responds to that paper and argues that printing , scanning and imaging e mails or other electronic ( rather than paper ) documents prior to listing and disclosure seems to be unnecessary , not ' proportionate ' ( from a costs point of view ) and not particularly helpful , to either side . he asks how litigation support systems might evolve to help and support the legal team in their task", "tokenized": "author responds to that paper and argues that printing , scanning and imaging e mails or other electronic ( rather than paper ) documents prior to listing and disclosure seems to be unnecessary , not ' proportionate ' ( from a costs point of view ) and not particularly helpful , to either side . he asks how litigation support systems might evolve to help and support the legal team in their task"}, "present_kps": {"text": ["litigation support systems", "e mail", "legal team"], "tokenized": ["litigation support systems", "e mail", "legal team"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 257, "title": {"text": "evicting orang utans from the office electronic storage of legal files .", "tokenized": "evicting orang utans from the office electronic storage of legal files ."}, "abstract": {"text": "to apply it to our stored files . first we consulted the law society rules governing storage of files on electronic media . the next step was for us to draw up a protocol for scanning the files . the benefits of the exercise have been significant . the area previously used for storage has been freed for other use . files are now available online , instantaneously . when we have needed to send out files to the client or following a change of solicitor , we have been able to do so almost immediately , by e mail , retaining a copy for our future reference . the files are protected from loss or deterioration , back up copies having been taken which are stored off site . the complete stored file archive can be put in your pocket ( in cd rom format ) or on a laptop , facilitating remote working", "tokenized": "to apply it to our stored files . first we consulted the law society rules governing storage of files on electronic media . the next step was for us to draw up a protocol for scanning the files . the benefits of the exercise have been significant . the area previously used for storage has been freed for other use . files are now available online , instantaneously . when we have needed to send out files to the client or following a change of solicitor , we have been able to do so almost immediately , by e mail , retaining a copy for our future reference . the files are protected from loss or deterioration , back up copies having been taken which are stored off site . the complete stored file archive can be put in your pocket ( in cd rom format ) or on a laptop , facilitating remote working"}, "present_kps": {"text": ["electronic storage", "legal files", "law society rules", "file archive", "cd rom"], "tokenized": ["electronic storage", "legal files", "law society rules", "file archive", "cd rom"]}, "absent_kps": {"text": ["paperless office", "file scanning"], "tokenized": ["paperless office", "file scanning"]}}
{"id": 258, "title": {"text": "electronic data exchange for real estate .", "tokenized": "electronic data exchange for real estate ."}, "abstract": {"text": "property industry is facing a period of unprecedented change . pisces ( property information systems common exchange ) is a property focused electronic data exchange standard . the standard is a set of definitions and rules to facilitate electronic transfer of data between key business areas and between different types of software packages that are used regularly by the property industry . it is not itself a piece of software but an enabling technology that allows software providers to prepare solutions within their own packages to transfer data between databases . this provides the attractive prospect of seamless transfer of data within and between systems and organisations", "tokenized": "property industry is facing a period of unprecedented change . pisces ( property information systems common exchange ) is a property focused electronic data exchange standard . the standard is a set of definitions and rules to facilitate electronic transfer of data between key business areas and between different types of software packages that are used regularly by the property industry . it is not itself a piece of software but an enabling technology that allows software providers to prepare solutions within their own packages to transfer data between databases . this provides the attractive prospect of seamless transfer of data within and between systems and organisations"}, "present_kps": {"text": ["electronic data exchange", "property industry", "pisces", "property information systems common exchange", "standard", "software packages", "databases", "seamless transfer"], "tokenized": ["electronic data exchange", "property industry", "pisces", "property information systems common exchange", "standard", "software packages", "databases", "seamless transfer"]}, "absent_kps": {"text": ["hm land registry"], "tokenized": ["hm land registry"]}}
{"id": 259, "title": {"text": "e mail and the legal profession .", "tokenized": "e mail and the legal profession ."}, "abstract": {"text": "legal profession is one that has embraced this new medium of communication . e mail is not without its drawbacks , however . due to the nature of the technologies behind the medium , it is a less secure form of communication than many of those traditionally used by the legal profession , including dx , facsimile , and standard and registered post . there are a number of ways in which e mails originating from the practice may be protected , including software encryption , hardware encryption and various methods of controlling and administering access to the e mails", "tokenized": "legal profession is one that has embraced this new medium of communication . e mail is not without its drawbacks , however . due to the nature of the technologies behind the medium , it is a less secure form of communication than many of those traditionally used by the legal profession , including dx , facsimile , and standard and registered post . there are a number of ways in which e mails originating from the practice may be protected , including software encryption , hardware encryption and various methods of controlling and administering access to the e mails"}, "present_kps": {"text": ["e mail", "legal profession", "software encryption", "hardware encryption"], "tokenized": ["e mail", "legal profession", "software encryption", "hardware encryption"]}, "absent_kps": {"text": ["access control", "secure communication"], "tokenized": ["access control", "secure communication"]}}
{"id": 260, "title": {"text": "spam solution .", "tokenized": "spam solution ."}, "abstract": {"text": "( dea ) . mailshell ' s free trial web based e mail service allows you , if you start getting spammed on that dea , just to delete the dea in mailshell , and all e mail thereafter sent to that address will automatically be junked ( though you can later restore that address if you want ) . mailshell allows any number of dea", "tokenized": "( dea ) . mailshell ' s free trial web based e mail service allows you , if you start getting spammed on that dea , just to delete the dea in mailshell , and all e mail thereafter sent to that address will automatically be junked ( though you can later restore that address if you want ) . mailshell allows any number of dea"}, "present_kps": {"text": ["mailshell", "web based e mail"], "tokenized": ["mailshell", "web based e mail"]}, "absent_kps": {"text": ["spam e mails", "disposable e mail addresses"], "tokenized": ["spam e mails", "disposable e mail addresses"]}}
{"id": 261, "title": {"text": "[digit] key tests in choosing your web site firm .", "tokenized": "[digit] key tests in choosing your web site firm ."}, "abstract": {"text": "their investment . the paper looks at factors involved when choosing a firm to help set up or improve a web site . ( [digit] ) look for a company that combines technical skills and business experience . ( [digit] ) look for a company that offers excellent customer service . ( [digit] ) check that the web site firm is committed to developing and proactively updating the web site . ( [digit] ) make sure the firm has a proven track record and a good portfolio . ( [digit] ) look for a company with both a breadth as well as depth of skills . ( [digit] ) make sure the firm can deliver work on target , in budget and to specification . ( [digit] ) ensure that you will enjoy working and feel comfortable with the web site firm staff", "tokenized": "their investment . the paper looks at factors involved when choosing a firm to help set up or improve a web site . ( [digit] ) look for a company that combines technical skills and business experience . ( [digit] ) look for a company that offers excellent customer service . ( [digit] ) check that the web site firm is committed to developing and proactively updating the web site . ( [digit] ) make sure the firm has a proven track record and a good portfolio . ( [digit] ) look for a company with both a breadth as well as depth of skills . ( [digit] ) make sure the firm can deliver work on target , in budget and to specification . ( [digit] ) ensure that you will enjoy working and feel comfortable with the web site firm staff"}, "present_kps": {"text": ["web site", "technical skills", "business experience", "customer service", "proactive updating"], "tokenized": ["web site", "technical skills", "business experience", "customer service", "proactive updating"]}, "absent_kps": {"text": ["return on investment", "legal firms"], "tokenized": ["return on investment", "legal firms"]}}
{"id": 262, "title": {"text": "why your web strategy is , err , wrong .", "tokenized": "why your web strategy is , err , wrong ."}, "abstract": {"text": "people have got it , err , wrong . like every other investment , when the time comes to sign the contract , the question that should be asked is not whether it is a good investment , but whether it is the best investment the firm can make with the money . the author argues that he would be surprised if any law firm web site he has seen yet would jump that particular hurdle", "tokenized": "people have got it , err , wrong . like every other investment , when the time comes to sign the contract , the question that should be asked is not whether it is a good investment , but whether it is the best investment the firm can make with the money . the author argues that he would be surprised if any law firm web site he has seen yet would jump that particular hurdle"}, "present_kps": {"text": ["web strategy", "law firm web site"], "tokenized": ["web strategy", "law firm web site"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 263, "title": {"text": "a humanist ' s legacy in medical informatics visions and accomplishments of .", "tokenized": "a humanist ' s legacy in medical informatics visions and accomplishments of ."}, "abstract": {"text": "the objective is to report on the work of prof . jean raoul scherrer , and show how his humanist vision , medical skills and scientific background have enabled and shaped the development of medical informatics over the last [digit] years . starting with the mainframe based patient centred hospital information system diogene in the 70s , prof . scherrer developed , implemented and evolved innovative concepts of man machine interfaces , distributed and federated environments , leading the way with information systems that obstinately focused on the support of care providers and patients . through a rigorous design of terminologies and ontologies , the diogene data would then serve as a basis for the development of clinical research , data mining , and lead to innovative natural language processing techniques . in parallel , prof . scherrer supported the development of medical image management , ranging from a distributed picture archiving and communication systems ( pacs ) to molecular imaging of protein electrophoreses . recognizing the need for improving the quality and trustworthiness of medical information of the web , prof . scherrer created the health on the net ( hon ) foundation . these achievements , made possible thanks to his visionary mind , deep humanism , creativity , generosity and determination , have made of prof . scherrer a true pioneer and leader of the human centered , patient oriented application of information technology for improving healthcare", "tokenized": "the objective is to report on the work of prof . jean raoul scherrer , and show how his humanist vision , medical skills and scientific background have enabled and shaped the development of medical informatics over the last [digit] years . starting with the mainframe based patient centred hospital information system diogene in the 70s , prof . scherrer developed , implemented and evolved innovative concepts of man machine interfaces , distributed and federated environments , leading the way with information systems that obstinately focused on the support of care providers and patients . through a rigorous design of terminologies and ontologies , the diogene data would then serve as a basis for the development of clinical research , data mining , and lead to innovative natural language processing techniques . in parallel , prof . scherrer supported the development of medical image management , ranging from a distributed picture archiving and communication systems ( pacs ) to molecular imaging of protein electrophoreses . recognizing the need for improving the quality and trustworthiness of medical information of the web , prof . scherrer created the health on the net ( hon ) foundation . these achievements , made possible thanks to his visionary mind , deep humanism , creativity , generosity and determination , have made of prof . scherrer a true pioneer and leader of the human centered , patient oriented application of information technology for improving healthcare"}, "present_kps": {"text": ["medical informatics", "man machine interfaces", "data mining", "natural language processing", "medical image management", "pacs"], "tokenized": ["medical informatics", "man machine interfaces", "data mining", "natural language processing", "medical image management", "pacs"]}, "absent_kps": {"text": ["professor jean raoul scherrer", "mainframe based patient centered hospital information system", "internet", "diogene system", "distributed systems", "federated systems"], "tokenized": ["professor jean raoul scherrer", "mainframe based patient centered hospital information system", "internet", "diogene system", "distributed systems", "federated systems"]}}
{"id": 264, "title": {"text": "medicine in the [digit] st century global problems , global solutions .", "tokenized": "medicine in the [digit] st century global problems , global solutions ."}, "abstract": {"text": "medicine and health care on the occasion of the opening of the private universitat fur medizinische informatik and technik tirol university for health informatics and technology tyrol ( limit ) at innsbruck , tyrol , austria . important application areas of information technology in medicine and health are appropriate individual access to medical knowledge , new engineering developments such as new radiant imaging methods and the implantable pacemaker defibrillator devices , mathematical modeling for understanding the workings of the human body , the computer based patient record , as well as new knowledge in molecular biology , human genetics , and biotechnology . challenges and responsibilities for medical informatics research include medical data privacy and intellectual property rights inherent in the content of the information systems", "tokenized": "medicine and health care on the occasion of the opening of the private universitat fur medizinische informatik and technik tirol university for health informatics and technology tyrol ( limit ) at innsbruck , tyrol , austria . important application areas of information technology in medicine and health are appropriate individual access to medical knowledge , new engineering developments such as new radiant imaging methods and the implantable pacemaker defibrillator devices , mathematical modeling for understanding the workings of the human body , the computer based patient record , as well as new knowledge in molecular biology , human genetics , and biotechnology . challenges and responsibilities for medical informatics research include medical data privacy and intellectual property rights inherent in the content of the information systems"}, "present_kps": {"text": ["medicine", "health care", "information technology", "engineering developments", "radiant imaging methods", "mathematical modeling", "human body", "computer based patient record", "molecular biology", "human genetics", "biotechnology", "medical informatics research", "medical data privacy", "intellectual property rights", "information systems"], "tokenized": ["medicine", "health care", "information technology", "engineering developments", "radiant imaging methods", "mathematical modeling", "human body", "computer based patient record", "molecular biology", "human genetics", "biotechnology", "medical informatics research", "medical data privacy", "intellectual property rights", "information systems"]}, "absent_kps": {"text": ["implantable defibrillator devices", "implantable pacemaker devices", "individual medical knowledge access"], "tokenized": ["implantable defibrillator devices", "implantable pacemaker devices", "individual medical knowledge access"]}}
{"id": 265, "title": {"text": "guidelines , the internet , and personal health insights from the canadian .", "tokenized": "guidelines , the internet , and personal health insights from the canadian ."}, "abstract": {"text": "the objectives are to summarize the insights gained in collaborative research in a canadian network of centres of excellence , devoted to the promotion of evidence based practice , and to relate this experience to internet support of health promotion and consumer health informatics . a subjective review of insights is undertaken . work directed the development of systems incorporating guidelines , care maps , etc . , for use by professionals met with limited acceptance . evidence based tools for health care consumers are a desirable complement but require radically different content and delivery modes . in addition to evidence based material offered by professionals , a wide array of internet based products and services provided by consumers for consumers emerged and proved a beneficial complement . the consumer driven products and services provided via the internet are a potentially important and beneficial complement of traditional health services . they affect the health consumer provider roles and require changes in healthcare practices", "tokenized": "the objectives are to summarize the insights gained in collaborative research in a canadian network of centres of excellence , devoted to the promotion of evidence based practice , and to relate this experience to internet support of health promotion and consumer health informatics . a subjective review of insights is undertaken . work directed the development of systems incorporating guidelines , care maps , etc . , for use by professionals met with limited acceptance . evidence based tools for health care consumers are a desirable complement but require radically different content and delivery modes . in addition to evidence based material offered by professionals , a wide array of internet based products and services provided by consumers for consumers emerged and proved a beneficial complement . the consumer driven products and services provided via the internet are a potentially important and beneficial complement of traditional health services . they affect the health consumer provider roles and require changes in healthcare practices"}, "present_kps": {"text": ["personal health", "collaborative research", "canadian network of centres of excellence", "evidence based practice", "internet support", "health promotion", "consumer health informatics", "health consumer provider roles"], "tokenized": ["personal health", "collaborative research", "canadian network of centres of excellence", "evidence based practice", "internet support", "health promotion", "consumer health informatics", "health consumer provider roles"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 266, "title": {"text": "iscsi poised to lower san costs .", "tokenized": "iscsi poised to lower san costs ."}, "abstract": {"text": "able to save money by using iscsi and ip systems rather than fibre channel technologies", "tokenized": "able to save money by using iscsi and ip systems rather than fibre channel technologies"}, "present_kps": {"text": ["iscsi", "san costs", "ip systems"], "tokenized": ["iscsi", "san costs", "ip systems"]}, "absent_kps": {"text": ["storage area networks"], "tokenized": ["storage area networks"]}}
{"id": 267, "title": {"text": "standard protocol for exchange of health checkup data based on sgml the .", "tokenized": "standard protocol for exchange of health checkup data based on sgml the ."}, "abstract": {"text": "the objectives are to develop a health medical data interchange model for efficient electronic exchange of data among health checkup facilities . a health checkup data markup language ( hdml ) was developed on the basis of the standard generalized markup language ( sgml ) , and a feasibility study carried out , involving data exchange between two health checkup facilities . the structure of hdml is described . the transfer of numerical lab data , summary findings and health status assessment was successful . hdml is an improvement to laboratory data exchange . further work has to address the exchange of qualitative and textual data", "tokenized": "the objectives are to develop a health medical data interchange model for efficient electronic exchange of data among health checkup facilities . a health checkup data markup language ( hdml ) was developed on the basis of the standard generalized markup language ( sgml ) , and a feasibility study carried out , involving data exchange between two health checkup facilities . the structure of hdml is described . the transfer of numerical lab data , summary findings and health status assessment was successful . hdml is an improvement to laboratory data exchange . further work has to address the exchange of qualitative and textual data"}, "present_kps": {"text": ["sgml", "data interchange model", "health checkup data markup language", "numerical lab data", "summary findings", "health status assessment"], "tokenized": ["sgml", "data interchange model", "health checkup data markup language", "numerical lab data", "summary findings", "health status assessment"]}, "absent_kps": {"text": ["health checkup data exchange"], "tokenized": ["health checkup data exchange"]}}
{"id": 268, "title": {"text": "development of a health guidance support system for lifestyle improvement .", "tokenized": "development of a health guidance support system for lifestyle improvement ."}, "abstract": {"text": "an assessment of the results of a questionnaire and medical examination or health checkup data . a system was developed that gathers data based on questions regarding weight gain , exercise , smoking , sleep , eating habits , salt intake , animal fat intake , snacks , alcohol , and oral hygiene , body mass index , resting blood pressure , fasting blood sugar , total cholesterol , triglycerides , uric acid and liver function tests . based on the relationships between the lifestyle data and the health checkup data , a health assessment sheet was generated for persons being allocated to a multiple risk factor syndrome group . health assessment and useful advice for lifestyle improvement were automatically extracted with the system , toward the high risk group for life style related diseases . the system is operational . in comparison with conventional , limited advice methods , we developed a practical system that defined the necessity for lifestyle improvement more clearly , and made giving advice easier", "tokenized": "an assessment of the results of a questionnaire and medical examination or health checkup data . a system was developed that gathers data based on questions regarding weight gain , exercise , smoking , sleep , eating habits , salt intake , animal fat intake , snacks , alcohol , and oral hygiene , body mass index , resting blood pressure , fasting blood sugar , total cholesterol , triglycerides , uric acid and liver function tests . based on the relationships between the lifestyle data and the health checkup data , a health assessment sheet was generated for persons being allocated to a multiple risk factor syndrome group . health assessment and useful advice for lifestyle improvement were automatically extracted with the system , toward the high risk group for life style related diseases . the system is operational . in comparison with conventional , limited advice methods , we developed a practical system that defined the necessity for lifestyle improvement more clearly , and made giving advice easier"}, "present_kps": {"text": ["health guidance support system", "lifestyle improvement", "questionnaire", "medical examination", "health checkup data", "weight gain", "exercise", "smoking", "sleep", "eating habits", "salt intake", "animal fat intake", "snacks", "alcohol", "oral hygiene", "body mass index", "resting blood pressure", "fasting blood sugar", "total cholesterol", "triglycerides", "uric acid", "liver function tests"], "tokenized": ["health guidance support system", "lifestyle improvement", "questionnaire", "medical examination", "health checkup data", "weight gain", "exercise", "smoking", "sleep", "eating habits", "salt intake", "animal fat intake", "snacks", "alcohol", "oral hygiene", "body mass index", "resting blood pressure", "fasting blood sugar", "total cholesterol", "triglycerides", "uric acid", "liver function tests"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 269, "title": {"text": "organization design the continuing influence of information technology .", "tokenized": "organization design the continuing influence of information technology ."}, "abstract": {"text": "information technology ( it ) has been a catalyst in the development of new forms of organizational structures . the article draws a historical linkage between the relative stability of an organization ' s task environment starting after the second world war to the present environmental instability that now characterizes many industries . specifically , the authors suggest that advances in it have enabled managers to adapt existing forms and create new models for organizational design that better fit requirements of an unstable environment . time has seemingly borne out this hypothesis as the bureaucratic structure evolved to the matrix to the network and now to the emerging shadow structure . it has gone from a support mechanism to a substitute for organizational structures in the form of the shadow structure . the article suggests that the evolving and expanding role of it will continue for organizations that face unstable environments", "tokenized": "information technology ( it ) has been a catalyst in the development of new forms of organizational structures . the article draws a historical linkage between the relative stability of an organization ' s task environment starting after the second world war to the present environmental instability that now characterizes many industries . specifically , the authors suggest that advances in it have enabled managers to adapt existing forms and create new models for organizational design that better fit requirements of an unstable environment . time has seemingly borne out this hypothesis as the bureaucratic structure evolved to the matrix to the network and now to the emerging shadow structure . it has gone from a support mechanism to a substitute for organizational structures in the form of the shadow structure . the article suggests that the evolving and expanding role of it will continue for organizations that face unstable environments"}, "present_kps": {"text": ["organization design", "information technology", "organizational structures", "environmental instability"], "tokenized": ["organization design", "information technology", "organizational structures", "environmental instability"]}, "absent_kps": {"text": ["organization task environment", "information processing perspective"], "tokenized": ["organization task environment", "information processing perspective"]}}
{"id": 270, "title": {"text": "knowledge based structures and organisational commitment .", "tokenized": "knowledge based structures and organisational commitment ."}, "abstract": {"text": "employing organisation , has attracted a substantial body of literature , relating the concept to various antecedents , including organisational structure , and to a range of consequences , including financially important performance factors such as productivity and staff turnover . the new areas of knowledge management and learning organisations offer substantial promise as imperatives for the organisation of business enterprises . as organisations in the contemporary environment adopt knowledge based structures to improve their competitive position , there is value in examining these structures against other performance related factors . theoretical knowledge based structures put forward by r . miles et al . ( [digit] ) and j . quinn et al . ( [digit] ) and an existing implementation are examined to determine common features inherent in these approaches . these features are posited as a typical form and their impact on organisational commitment and hence on individual and organisational performance is examined", "tokenized": "employing organisation , has attracted a substantial body of literature , relating the concept to various antecedents , including organisational structure , and to a range of consequences , including financially important performance factors such as productivity and staff turnover . the new areas of knowledge management and learning organisations offer substantial promise as imperatives for the organisation of business enterprises . as organisations in the contemporary environment adopt knowledge based structures to improve their competitive position , there is value in examining these structures against other performance related factors . theoretical knowledge based structures put forward by r . miles et al . ( [digit] ) and j . quinn et al . ( [digit] ) and an existing implementation are examined to determine common features inherent in these approaches . these features are posited as a typical form and their impact on organisational commitment and hence on individual and organisational performance is examined"}, "present_kps": {"text": ["knowledge based structures", "organisational commitment", "performance factors", "productivity", "staff turnover"], "tokenized": ["knowledge based structures", "organisational commitment", "performance factors", "productivity", "staff turnover"]}, "absent_kps": {"text": ["earning organisations", "emotional attachment"], "tokenized": ["earning organisations", "emotional attachment"]}}
{"id": 271, "title": {"text": "the evolution of information systems their impact on organizations and .", "tokenized": "the evolution of information systems their impact on organizations and ."}, "abstract": {"text": "information systems and organization structures have been highly interconnected with each other . over the years , information systems architectures as well as organization structures have evolved from centralized to more decentralized forms . this research looks at the evolution of both information systems and organization structures . in the process , it looks into the impact of computers on organizations , and examines the ways organization structures have changed , in association with changes in information system architectures . it also suggests logical linkages between information system architectures and their fit with certain organization structures and strategies . it concludes with some implications for emerging and future organizational forms , and provides a quick review of the effect of the internet on small businesses traditionally using stand alone computers", "tokenized": "information systems and organization structures have been highly interconnected with each other . over the years , information systems architectures as well as organization structures have evolved from centralized to more decentralized forms . this research looks at the evolution of both information systems and organization structures . in the process , it looks into the impact of computers on organizations , and examines the ways organization structures have changed , in association with changes in information system architectures . it also suggests logical linkages between information system architectures and their fit with certain organization structures and strategies . it concludes with some implications for emerging and future organizational forms , and provides a quick review of the effect of the internet on small businesses traditionally using stand alone computers"}, "present_kps": {"text": ["information system architectures"], "tokenized": ["information system architectures"]}, "absent_kps": {"text": ["information systems evolution"], "tokenized": ["information systems evolution"]}}
{"id": 272, "title": {"text": "in search of a general enterprise model .", "tokenized": "in search of a general enterprise model ."}, "abstract": {"text": "in models to support decision making . such reluctance could be overcome if a model could be used for several purposes rather than using a traditional single perspective model . this requires the development of a general enterprise model ( gem ) , which can be applied to a wide range of problem domains with unlimited scope . current enterprise modelling frameworks only deal effectively with nondynamic modelling issues whilst dynamic modelling issues have traditionally only been addressed at the operational level . although the majority of research in this area relates to manufacturing companies , the framework for a gem must be equally applicable to service and public sector organisations . the paper identifies five key design issues that need to be considered when constructing a gem . a framework for such a gem is presented based on a plug and play methodology and demonstrated by a simple case study", "tokenized": "in models to support decision making . such reluctance could be overcome if a model could be used for several purposes rather than using a traditional single perspective model . this requires the development of a general enterprise model ( gem ) , which can be applied to a wide range of problem domains with unlimited scope . current enterprise modelling frameworks only deal effectively with nondynamic modelling issues whilst dynamic modelling issues have traditionally only been addressed at the operational level . although the majority of research in this area relates to manufacturing companies , the framework for a gem must be equally applicable to service and public sector organisations . the paper identifies five key design issues that need to be considered when constructing a gem . a framework for such a gem is presented based on a plug and play methodology and demonstrated by a simple case study"}, "present_kps": {"text": ["general enterprise model", "decision making", "single perspective model", "gem", "problem domains", "enterprise modelling frameworks", "dynamic modelling issues", "operational level", "public sector organisations", "plug and play methodology", "case study"], "tokenized": ["general enterprise model", "decision making", "single perspective model", "gem", "problem domains", "enterprise modelling frameworks", "dynamic modelling issues", "operational level", "public sector organisations", "plug and play methodology", "case study"]}, "absent_kps": {"text": ["smes", "business process re engineering", "service sector organisations"], "tokenized": ["smes", "business process re engineering", "service sector organisations"]}}
{"id": 273, "title": {"text": "strategies for high throughput , templated zeolite synthesis .", "tokenized": "strategies for high throughput , templated zeolite synthesis ."}, "abstract": {"text": "are addressed . a model that relates materials function to the chemical composition of the zeolite and the structure directing agent is introduced . using this model , several monte carlo like design protocols are evaluated . multi round protocols are bound to be effective , and strategies that use a priori information about the structure directing libraries are found to be the best", "tokenized": "are addressed . a model that relates materials function to the chemical composition of the zeolite and the structure directing agent is introduced . using this model , several monte carlo like design protocols are evaluated . multi round protocols are bound to be effective , and strategies that use a priori information about the structure directing libraries are found to be the best"}, "present_kps": {"text": ["templated zeolite synthesis", "materials function", "chemical composition", "structure directing agent", "monte carlo like design protocols", "multi round protocols", "a priori information"], "tokenized": ["templated zeolite synthesis", "materials function", "chemical composition", "structure directing agent", "monte carlo like design protocols", "multi round protocols", "a priori information"]}, "absent_kps": {"text": ["phase dependent random gaussian variables", "material discovery", "voronoi diagram", "figure of merit", "catalytic selectivity", "high throughput strategies", "ligand libraries", "catalytic activity", "random energy model", "organo cation template molecules", "metropolis type method", "combinatorial methods", "reflecting boundary conditions", "small molecule design"], "tokenized": ["phase dependent random gaussian variables", "material discovery", "voronoi diagram", "figure of merit", "catalytic selectivity", "high throughput strategies", "ligand libraries", "catalytic activity", "random energy model", "organo cation template molecules", "metropolis type method", "combinatorial methods", "reflecting boundary conditions", "small molecule design"]}}
{"id": 274, "title": {"text": "variable structure intelligent control for pm synchronous servo motor drive .", "tokenized": "variable structure intelligent control for pm synchronous servo motor drive ."}, "abstract": {"text": "intelligent control is presented in this paper . a novel approach is proposed for the state estimation . a linear observer is firstly designed . then a neural network is used for compensating uncertainty . the parameter of the vsc scheme is adjusted online by a neural network . practical operating results from a pm synchronous motor ( pmsm ) illustrate the effectiveness and practicability of the proposed approach", "tokenized": "intelligent control is presented in this paper . a novel approach is proposed for the state estimation . a linear observer is firstly designed . then a neural network is used for compensating uncertainty . the parameter of the vsc scheme is adjusted online by a neural network . practical operating results from a pm synchronous motor ( pmsm ) illustrate the effectiveness and practicability of the proposed approach"}, "present_kps": {"text": ["variable structure intelligent control", "pm synchronous servo motor drive", "state estimation", "linear observer", "neural network"], "tokenized": ["variable structure intelligent control", "pm synchronous servo motor drive", "state estimation", "linear observer", "neural network"]}, "absent_kps": {"text": ["control design", "control performance", "uncertainty compensation", "discrete time systems"], "tokenized": ["control design", "control performance", "uncertainty compensation", "discrete time systems"]}}
{"id": 275, "title": {"text": "a nonlinear modulation strategy for hybrid ac dc power systems .", "tokenized": "a nonlinear modulation strategy for hybrid ac dc power systems ."}, "abstract": {"text": "ac power system with several dc links terminated in the presence of large disturbances is presented . the approach proposed in this paper is based on differential geometric theory , and the hvdc systems are taken as a variable admittance connected at the inverter or rectifier ac bus . after deriving the analytical description of the relationship between the variable admittance and active power flows of each generator , the traditional generator dynamic equations can thus be expressed with the variable admittance of hvdc systems as an additional state variable and changed to an affine form , which is suitable for global linearization method being used to determine its control variable . an important feature of the proposed method is that , the modulated dc power is an adaptive and non linear function of ac system states , and it can be realized by local feedback and less transmitted data from , adjacent generators . the design procedure is tested on a dual infeed hybrid ac dc system", "tokenized": "ac power system with several dc links terminated in the presence of large disturbances is presented . the approach proposed in this paper is based on differential geometric theory , and the hvdc systems are taken as a variable admittance connected at the inverter or rectifier ac bus . after deriving the analytical description of the relationship between the variable admittance and active power flows of each generator , the traditional generator dynamic equations can thus be expressed with the variable admittance of hvdc systems as an additional state variable and changed to an affine form , which is suitable for global linearization method being used to determine its control variable . an important feature of the proposed method is that , the modulated dc power is an adaptive and non linear function of ac system states , and it can be realized by local feedback and less transmitted data from , adjacent generators . the design procedure is tested on a dual infeed hybrid ac dc system"}, "present_kps": {"text": ["nonlinear modulation strategy", "hybrid ac dc power systems", "dc links", "differential geometric theory", "hvdc systems", "variable admittance", "inverter", "rectifier ac bus", "active power flows", "generator dynamic equations", "affine form", "global linearization method", "local feedback", "adjacent generators", "dual infeed hybrid ac dc system"], "tokenized": ["nonlinear modulation strategy", "hybrid ac dc power systems", "dc links", "differential geometric theory", "hvdc systems", "variable admittance", "inverter", "rectifier ac bus", "active power flows", "generator dynamic equations", "affine form", "global linearization method", "local feedback", "adjacent generators", "dual infeed hybrid ac dc system"]}, "absent_kps": {"text": ["multi machine ac power system", "transient stability", "nonlinear control strategy"], "tokenized": ["multi machine ac power system", "transient stability", "nonlinear control strategy"]}}
{"id": 276, "title": {"text": "mobile computing killer app competition .", "tokenized": "mobile computing killer app competition ."}, "abstract": {"text": "in engineering and computer science courses . the university of florida , in partnership with motorola , has held two mobile computing design competitions . in spring and fall [digit] , students in abdelsalam helal ' s mobile computing class designed killer apps for a motorola smart phone", "tokenized": "in engineering and computer science courses . the university of florida , in partnership with motorola , has held two mobile computing design competitions . in spring and fall [digit] , students in abdelsalam helal ' s mobile computing class designed killer apps for a motorola smart phone"}, "present_kps": {"text": ["mobile computing", "motorola", "design competitions", "smart phone"], "tokenized": ["mobile computing", "motorola", "design competitions", "smart phone"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 277, "title": {"text": "firewall card shields data .", "tokenized": "firewall card shields data ."}, "abstract": {"text": "offer enough security for large networks", "tokenized": "offer enough security for large networks"}, "present_kps": {"text": ["security", "large networks"], "tokenized": ["security", "large networks"]}, "absent_kps": {"text": ["pci card", "slotshield [digit] firewall"], "tokenized": ["pci card", "slotshield [digit] firewall"]}}
{"id": 278, "title": {"text": "standards for service discovery and delivery .", "tokenized": "standards for service discovery and delivery ."}, "abstract": {"text": "been hotly pursuing automatic configuration , now coined the broader term service discovery . jini , universal plug and play ( upnp ) , salutation , and service location protocol are among the front runners in this new race . however , choosing service discovery as the topic of the hour goes beyond the need for plug and play solutions or support for the soho ( small office home office ) user . service discovery ' s potential in mobile and pervasive computing environments motivated my choice", "tokenized": "been hotly pursuing automatic configuration , now coined the broader term service discovery . jini , universal plug and play ( upnp ) , salutation , and service location protocol are among the front runners in this new race . however , choosing service discovery as the topic of the hour goes beyond the need for plug and play solutions or support for the soho ( small office home office ) user . service discovery ' s potential in mobile and pervasive computing environments motivated my choice"}, "present_kps": {"text": ["service discovery", "jini", "universal plug and play", "salutation", "service location protocol", "pervasive computing"], "tokenized": ["service discovery", "jini", "universal plug and play", "salutation", "service location protocol", "pervasive computing"]}, "absent_kps": {"text": ["mobile computing"], "tokenized": ["mobile computing"]}}
{"id": 279, "title": {"text": "the role of speech input in wearable computing .", "tokenized": "the role of speech input in wearable computing ."}, "abstract": {"text": "computers , and as we saw in this magazine ' s first issue , several companies are promoting products that use limited speech interfaces for specific tasks . however , we must overcome several challenges to using speech recognition in more general contexts , and interface designers must be wary of applying the technology to situations where speech is inappropriate", "tokenized": "computers , and as we saw in this magazine ' s first issue , several companies are promoting products that use limited speech interfaces for specific tasks . however , we must overcome several challenges to using speech recognition in more general contexts , and interface designers must be wary of applying the technology to situations where speech is inappropriate"}, "present_kps": {"text": ["speech input", "wearable computing", "wearable computer", "speech interfaces", "speech recognition"], "tokenized": ["speech input", "wearable computing", "wearable computer", "speech interfaces", "speech recognition"]}, "absent_kps": {"text": ["mobile speech recognition", "background noise", "speech recognizers"], "tokenized": ["mobile speech recognition", "background noise", "speech recognizers"]}}
{"id": 280, "title": {"text": "the ubiquitous provisioning of internet services to portable devices .", "tokenized": "the ubiquitous provisioning of internet services to portable devices ."}, "abstract": {"text": "providing both standard and novel location and context dependent internet services to mobile clients . mobile agents are dynamic , asynchronous , and autonomous , making the ma programming paradigm suitable for developing novel middleware for mobility enabled services", "tokenized": "providing both standard and novel location and context dependent internet services to mobile clients . mobile agents are dynamic , asynchronous , and autonomous , making the ma programming paradigm suitable for developing novel middleware for mobility enabled services"}, "present_kps": {"text": ["internet services", "mobile clients", "mobile agents", "middleware", "mobility enabled services"], "tokenized": ["internet services", "mobile clients", "mobile agents", "middleware", "mobility enabled services"]}, "absent_kps": {"text": ["device miniaturization", "mobile telecommunications"], "tokenized": ["device miniaturization", "mobile telecommunications"]}}
{"id": 281, "title": {"text": "integrating virtual and physical context to support knowledge workers .", "tokenized": "integrating virtual and physical context to support knowledge workers ."}, "abstract": {"text": "computing system that monitors a user ' s interactions with the computer , an electronic whiteboard , and a variety of networked peripheral devices and data sources", "tokenized": "computing system that monitors a user ' s interactions with the computer , an electronic whiteboard , and a variety of networked peripheral devices and data sources"}, "present_kps": {"text": ["knowledge workers", "electronic whiteboard", "networked peripheral devices", "data sources"], "tokenized": ["knowledge workers", "electronic whiteboard", "networked peripheral devices", "data sources"]}, "absent_kps": {"text": ["kimura system", "pervasive computing"], "tokenized": ["kimura system", "pervasive computing"]}}
{"id": 282, "title": {"text": "data management in location dependent information services .", "tokenized": "data management in location dependent information services ."}, "abstract": {"text": "pervasive computing environments . they can provide local and nonlocal news , weather , and traffic reports as well as directory services . before they can be implemented on a large scale , however , several research issues must be addressed", "tokenized": "pervasive computing environments . they can provide local and nonlocal news , weather , and traffic reports as well as directory services . before they can be implemented on a large scale , however , several research issues must be addressed"}, "present_kps": {"text": ["data management", "location dependent information services", "pervasive computing", "news", "weather", "traffic reports", "directory services"], "tokenized": ["data management", "location dependent information services", "pervasive computing", "news", "weather", "traffic reports", "directory services"]}, "absent_kps": {"text": ["mobile computing", "wireless networks"], "tokenized": ["mobile computing", "wireless networks"]}}
{"id": 283, "title": {"text": "modeling privacy control in context aware systems .", "tokenized": "modeling privacy control in context aware systems ."}, "abstract": {"text": "privacy control . information spaces provide a way to organize information , resources , and services around important privacy relevant contextual factors . in this article , we describe a theoretical model for privacy control in context aware systems based on a core abstraction of information spaces . we have previously focused on deriving socially based privacy objectives in pervasive computing environments . building on ravi sandhu ' s four layer om am ( objectives , models , architectures , and mechanisms ) idea , we aim to use information spaces to construct a model for privacy control that supports our socially based privacy objectives . we also discuss how we can introduce decentralization , a desirable property for many pervasive computing systems , into our information space model , using unified privacy tagging", "tokenized": "privacy control . information spaces provide a way to organize information , resources , and services around important privacy relevant contextual factors . in this article , we describe a theoretical model for privacy control in context aware systems based on a core abstraction of information spaces . we have previously focused on deriving socially based privacy objectives in pervasive computing environments . building on ravi sandhu ' s four layer om am ( objectives , models , architectures , and mechanisms ) idea , we aim to use information spaces to construct a model for privacy control that supports our socially based privacy objectives . we also discuss how we can introduce decentralization , a desirable property for many pervasive computing systems , into our information space model , using unified privacy tagging"}, "present_kps": {"text": ["privacy control", "privacy", "context aware systems", "pervasive computing"], "tokenized": ["privacy control", "privacy", "context aware systems", "pervasive computing"]}, "absent_kps": {"text": ["smart office"], "tokenized": ["smart office"]}}
{"id": 284, "title": {"text": "conchat a context aware chat program .", "tokenized": "conchat a context aware chat program ."}, "abstract": {"text": "by providing contextual information and resolving potential semantic conflicts between users . conchat uses contextual information to improve electronic communication . using contextual cues , users can infer during a conversation what the other person is doing and what is happening in his or her immediate surroundings . for example , if a user learns that the other person is talking with somebody else or is involved in some urgent activity , he or she knows to expect a slower response . conversely , if the user learns that the other person is sitting in a meeting directly related to the conversation , he or she then knows to respond more quickly . also , by informing users about the other person ' s context and tagging potentially ambiguous chat messages , conchat explores how context can improve electronic communication by reducing semantic conflicts", "tokenized": "by providing contextual information and resolving potential semantic conflicts between users . conchat uses contextual information to improve electronic communication . using contextual cues , users can infer during a conversation what the other person is doing and what is happening in his or her immediate surroundings . for example , if a user learns that the other person is talking with somebody else or is involved in some urgent activity , he or she knows to expect a slower response . conversely , if the user learns that the other person is sitting in a meeting directly related to the conversation , he or she then knows to respond more quickly . also , by informing users about the other person ' s context and tagging potentially ambiguous chat messages , conchat explores how context can improve electronic communication by reducing semantic conflicts"}, "present_kps": {"text": ["conchat", "context aware chat program", "contextual information", "semantic conflicts", "contextual cues"], "tokenized": ["conchat", "context aware chat program", "contextual information", "semantic conflicts", "contextual cues"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 285, "title": {"text": "a context aware decision engine for content adaptation .", "tokenized": "a context aware decision engine for content adaptation ."}, "abstract": {"text": "challenges . to meet these challenges , this quality of service aware decision engine automatically negotiates for the appropriate adaptation decision for synthesizing an optimal content version", "tokenized": "challenges . to meet these challenges , this quality of service aware decision engine automatically negotiates for the appropriate adaptation decision for synthesizing an optimal content version"}, "present_kps": {"text": ["decision engine", "content adaptation", "quality of service aware", "adaptation decision", "optimal content version"], "tokenized": ["decision engine", "content adaptation", "quality of service aware", "adaptation decision", "optimal content version"]}, "absent_kps": {"text": ["mobile devices"], "tokenized": ["mobile devices"]}}
{"id": 286, "title": {"text": "reconfigurable context sensitive middleware for pervasive computing .", "tokenized": "reconfigurable context sensitive middleware for pervasive computing ."}, "abstract": {"text": "actions , and might need ad hoc communication support to dynamically discover new devices and engage in spontaneous information exchange . reconfigurable context sensitive middleware facilitates the development and runtime operations of context sensitive pervasive computing software", "tokenized": "actions , and might need ad hoc communication support to dynamically discover new devices and engage in spontaneous information exchange . reconfigurable context sensitive middleware facilitates the development and runtime operations of context sensitive pervasive computing software"}, "present_kps": {"text": ["reconfigurable context sensitive middleware", "middleware", "pervasive computing", "context sensitive pervasive computing"], "tokenized": ["reconfigurable context sensitive middleware", "middleware", "pervasive computing", "context sensitive pervasive computing"]}, "absent_kps": {"text": ["context sensitive applications"], "tokenized": ["context sensitive applications"]}}
{"id": 287, "title": {"text": "activity and location recognition using wearable sensors .", "tokenized": "activity and location recognition using wearable sensors ."}, "abstract": {"text": "inexpensive , wearable sensors , this dead reckoning method can determine a user ' s location , detect transitions between preselected locations , and recognize and classify sitting , standing , and walking behaviors . experiments demonstrate the proposed method ' s effectiveness", "tokenized": "inexpensive , wearable sensors , this dead reckoning method can determine a user ' s location , detect transitions between preselected locations , and recognize and classify sitting , standing , and walking behaviors . experiments demonstrate the proposed method ' s effectiveness"}, "present_kps": {"text": ["wearable sensors", "dead reckoning method", "user ' s location", "transitions", "preselected locations", "sitting", "standing", "walking"], "tokenized": ["wearable sensors", "dead reckoning method", "user ' s location", "transitions", "preselected locations", "sitting", "standing", "walking"]}, "absent_kps": {"text": ["angular velocity", "measured acceleration"], "tokenized": ["angular velocity", "measured acceleration"]}}
{"id": 288, "title": {"text": "analyzing the benefits of [digit] mm conveyor based amhs .", "tokenized": "analyzing the benefits of [digit] mm conveyor based amhs ."}, "abstract": {"text": "performance of such automation is still in question . software simulation that compares conveyor based continuous flow transport technology to conventional car based wafer lot delivery has detailed delivery time and throughput advantages to the former", "tokenized": "performance of such automation is still in question . software simulation that compares conveyor based continuous flow transport technology to conventional car based wafer lot delivery has detailed delivery time and throughput advantages to the former"}, "present_kps": {"text": ["[digit] mm", "software simulation", "conveyor based continuous flow transport technology", "car based wafer lot delivery", "delivery time", "throughput"], "tokenized": ["[digit] mm", "software simulation", "conveyor based continuous flow transport technology", "car based wafer lot delivery", "delivery time", "throughput"]}, "absent_kps": {"text": ["automated material handling system", "semiconductor fab", "wafer processing"], "tokenized": ["automated material handling system", "semiconductor fab", "wafer processing"]}}
{"id": 289, "title": {"text": "how to avoid merger pitfalls .", "tokenized": "how to avoid merger pitfalls ."}, "abstract": {"text": "crucial to the success of mergers", "tokenized": "crucial to the success of mergers"}, "present_kps": {"text": ["mergers"], "tokenized": ["mergers"]}, "absent_kps": {"text": ["kpmg", "it asset management", "consultancy"], "tokenized": ["kpmg", "it asset management", "consultancy"]}}
{"id": 290, "title": {"text": "labscape a smart environment for the cell biology laboratory .", "tokenized": "labscape a smart environment for the cell biology laboratory ."}, "abstract": {"text": "people who work in a cell biology laboratory . our goal in creating it was to simplify , laboratory work by making information available where it is needed and by collecting and organizing data where and when it is created into a formal representation that others can understand and process . by helping biologists produce a more complete record of their work with less effort , labscape is designed to foster improved collaboration in conjunction with increased individual efficiency and satisfaction . a user driven system , although technologically conservative , embraces a central goal of ubiquitous computing to enhance the ability to perform domain tasks through fluid interaction with computational resources . smart environments could soon replace the pen and paper commonly used in the laboratory setting", "tokenized": "people who work in a cell biology laboratory . our goal in creating it was to simplify , laboratory work by making information available where it is needed and by collecting and organizing data where and when it is created into a formal representation that others can understand and process . by helping biologists produce a more complete record of their work with less effort , labscape is designed to foster improved collaboration in conjunction with increased individual efficiency and satisfaction . a user driven system , although technologically conservative , embraces a central goal of ubiquitous computing to enhance the ability to perform domain tasks through fluid interaction with computational resources . smart environments could soon replace the pen and paper commonly used in the laboratory setting"}, "present_kps": {"text": ["labscape", "smart environment", "cell biology", "laboratory work", "ubiquitous computing"], "tokenized": ["labscape", "smart environment", "cell biology", "laboratory work", "ubiquitous computing"]}, "absent_kps": {"text": ["biochemical procedure", "experimental technologies"], "tokenized": ["biochemical procedure", "experimental technologies"]}}
{"id": 291, "title": {"text": "broadcasts keep staff in picture intranets .", "tokenized": "broadcasts keep staff in picture intranets ."}, "abstract": {"text": "twofourtv , explains how firms can benefit by linking their corporate intranets to broadcasting technology", "tokenized": "twofourtv , explains how firms can benefit by linking their corporate intranets to broadcasting technology"}, "present_kps": {"text": ["twofourtv", "corporate intranets", "broadcasting technology"], "tokenized": ["twofourtv", "corporate intranets", "broadcasting technology"]}, "absent_kps": {"text": ["streaming media"], "tokenized": ["streaming media"]}}
{"id": 292, "title": {"text": "java portability put to the test .", "tokenized": "java portability put to the test ."}, "abstract": {"text": "companies to assess the cross platform portability of applications written in java , and to help software vendors ensure that their solutions can run in heterogenous j2ee application server environments", "tokenized": "companies to assess the cross platform portability of applications written in java , and to help software vendors ensure that their solutions can run in heterogenous j2ee application server environments"}, "present_kps": {"text": ["cross platform portability"], "tokenized": ["cross platform portability"]}, "absent_kps": {"text": ["sun microsystems", "java verification program"], "tokenized": ["sun microsystems", "java verification program"]}}
{"id": 293, "title": {"text": "the eyes have it hotel security .", "tokenized": "the eyes have it hotel security ."}, "abstract": {"text": "from deterring criminals to observing staff interactions with clientele . but pitfalls can arise if the cctv system has not been properly integrated into the overall hotel security plan . cctv system designs at new hotel properties are often too sophisticated , too complicated , and too costly , and do not take into consideration the security realities of site management . these problems arise when the professionals designing or installing the system , including architects , construction engineers , integrators , and consultants , are not familiar with a hotel ' s operating strategies or security standards", "tokenized": "from deterring criminals to observing staff interactions with clientele . but pitfalls can arise if the cctv system has not been properly integrated into the overall hotel security plan . cctv system designs at new hotel properties are often too sophisticated , too complicated , and too costly , and do not take into consideration the security realities of site management . these problems arise when the professionals designing or installing the system , including architects , construction engineers , integrators , and consultants , are not familiar with a hotel ' s operating strategies or security standards"}, "present_kps": {"text": ["hotel security", "cctv system", "site management", "operating strategies"], "tokenized": ["hotel security", "cctv system", "site management", "operating strategies"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 294, "title": {"text": "online masquerade whose e mail is it .", "tokenized": "online masquerade whose e mail is it ."}, "abstract": {"text": "techniques and known vulnerabilities to spread from one computer to another with ease", "tokenized": "techniques and known vulnerabilities to spread from one computer to another with ease"}, "present_kps": {"text": ["e mail", "vulnerabilities"], "tokenized": ["e mail", "vulnerabilities"]}, "absent_kps": {"text": ["klez worm", "viruses"], "tokenized": ["klez worm", "viruses"]}}
{"id": 295, "title": {"text": "relativistic constraints on the distinguishability of orthogonal quantum states .", "tokenized": "relativistic constraints on the distinguishability of orthogonal quantum states ."}, "abstract": {"text": "quantum states are discussed . an explicit expression relating the probability of an error in distinguishing two orthogonal single photon states to their structure , the time t at which a measurement starts , and the interval of time t elapsed from the start of the measurement until the time at which the outcome is obtained by an observer is given as an example", "tokenized": "quantum states are discussed . an explicit expression relating the probability of an error in distinguishing two orthogonal single photon states to their structure , the time t at which a measurement starts , and the interval of time t elapsed from the start of the measurement until the time at which the outcome is obtained by an observer is given as an example"}, "present_kps": {"text": ["relativistic constraints", "orthogonal quantum states", "orthogonal single photon states", "observer"], "tokenized": ["relativistic constraints", "orthogonal quantum states", "orthogonal single photon states", "observer"]}, "absent_kps": {"text": ["special relativity", "time interval", "quantum state distinguishability", "quantum communication channels", "nonrelativistic quantum information theory"], "tokenized": ["special relativity", "time interval", "quantum state distinguishability", "quantum communication channels", "nonrelativistic quantum information theory"]}}
{"id": 296, "title": {"text": "rapid microwell polymerase chain reaction with subsequent ultrathin layer gel .", "tokenized": "rapid microwell polymerase chain reaction with subsequent ultrathin layer gel ."}, "abstract": {"text": "large scale genotyping , mapping and expression profiling require affordable , fully automated high throughput devices enabling rapid , high performance analysis using minute quantities of reagents . in this paper , we describe a new combination of microwell polymerase chain reaction ( pcr ) based dna amplification technique with automated ultrathin layer gel electrophoresis analysis of the resulting products . this technique decreases the reagent consumption ( total reaction volume [digit] . [digit] [digit] mu l ) , the time requirement of the pcr ( [digit] [digit] min ) and subsequent ultrathin layer gel electrophoresis based fragment analysis ( [digit] min ) by automating the current manual procedure and reducing the human intervention using sample loading robots and computerized real time data analysis . small aliquots ( [digit] . [digit] mu l ) of the submicroliter size pcr reaction were transferred onto loading membranes and analyzed by ultrathin layer gel electrophoresis which is a novel , high performance and automated microseparation technique . this system employs integrated scanning laser induced fluorescence avalanche photodiode detection and combines the advantages of conventional slab and capillary gel electrophoresis . visualization of the dna fragments was accomplished by in migratio complexation with ethidium bromide during the electrophoresis process also enabling real time imaging and data analysis", "tokenized": "large scale genotyping , mapping and expression profiling require affordable , fully automated high throughput devices enabling rapid , high performance analysis using minute quantities of reagents . in this paper , we describe a new combination of microwell polymerase chain reaction ( pcr ) based dna amplification technique with automated ultrathin layer gel electrophoresis analysis of the resulting products . this technique decreases the reagent consumption ( total reaction volume [digit] . [digit] [digit] mu l ) , the time requirement of the pcr ( [digit] [digit] min ) and subsequent ultrathin layer gel electrophoresis based fragment analysis ( [digit] min ) by automating the current manual procedure and reducing the human intervention using sample loading robots and computerized real time data analysis . small aliquots ( [digit] . [digit] mu l ) of the submicroliter size pcr reaction were transferred onto loading membranes and analyzed by ultrathin layer gel electrophoresis which is a novel , high performance and automated microseparation technique . this system employs integrated scanning laser induced fluorescence avalanche photodiode detection and combines the advantages of conventional slab and capillary gel electrophoresis . visualization of the dna fragments was accomplished by in migratio complexation with ethidium bromide during the electrophoresis process also enabling real time imaging and data analysis"}, "present_kps": {"text": ["rapid microwell polymerase chain reaction", "large scale genotyping", "expression profiling", "dna amplification", "ultrathin layer gel electrophoresis", "reagent consumption", "sample loading robots", "computerized real time data analysis", "automated microseparation", "complexation with ethidium bromide", "real time imaging"], "tokenized": ["rapid microwell polymerase chain reaction", "large scale genotyping", "expression profiling", "dna amplification", "ultrathin layer gel electrophoresis", "reagent consumption", "sample loading robots", "computerized real time data analysis", "automated microseparation", "complexation with ethidium bromide", "real time imaging"]}, "absent_kps": {"text": ["rapid high performance analysis", "integrated scanning lif apd detection", "automated electrophoresis analysis"], "tokenized": ["rapid high performance analysis", "integrated scanning lif apd detection", "automated electrophoresis analysis"]}}
{"id": 297, "title": {"text": "simple minds health care it .", "tokenized": "simple minds health care it ."}, "abstract": {"text": "it programme . can it deliver this time", "tokenized": "it programme . can it deliver this time"}, "present_kps": {"text": ["health care"], "tokenized": ["health care"]}, "absent_kps": {"text": ["uk nhs it programme", "strategy"], "tokenized": ["uk nhs it programme", "strategy"]}}
{"id": 298, "title": {"text": "absorption of long waves by nonresonant parametric microstructures .", "tokenized": "absorption of long waves by nonresonant parametric microstructures ."}, "abstract": {"text": "possibility of designing an active absorbing ( nonreflecting ) coating in the form of a thin layer with small scale stratification and fast time modulation of parameters . algorithms for space time modulation of the controlled layer structure are studied in detail for a one dimensional boundary value problem . these algorithms do not require wave field measurements , which eliminates the self excitation problem that is characteristic of active systems . the majority of the considered algorithms of parametric control transform the low frequency incident wave to high frequency waves of the technological band for which the waveguiding medium inside the layer is assumed to be opaque ( absorbing ) . the efficient use conditions are found for all the algorithms . it is shown that the absorbing layer can be as thin as desired with respect to the minimum spatial scale of the incident wave and ensures efficient absorption in a wide frequency interval ( starting from zero frequency ) that is bounded from above only by a finite space time resolution of the parameter control operations . the structure of a three dimensional parametric ' black coating whose efficiency is independent of the angle of incidence of an incoming wave is developed on the basis of the studied one dimensional problems . the general solution of the problem of diffraction of incident waves from such a coating is obtained . this solution is analyzed in detail for the case of a disk shaped element", "tokenized": "possibility of designing an active absorbing ( nonreflecting ) coating in the form of a thin layer with small scale stratification and fast time modulation of parameters . algorithms for space time modulation of the controlled layer structure are studied in detail for a one dimensional boundary value problem . these algorithms do not require wave field measurements , which eliminates the self excitation problem that is characteristic of active systems . the majority of the considered algorithms of parametric control transform the low frequency incident wave to high frequency waves of the technological band for which the waveguiding medium inside the layer is assumed to be opaque ( absorbing ) . the efficient use conditions are found for all the algorithms . it is shown that the absorbing layer can be as thin as desired with respect to the minimum spatial scale of the incident wave and ensures efficient absorption in a wide frequency interval ( starting from zero frequency ) that is bounded from above only by a finite space time resolution of the parameter control operations . the structure of a three dimensional parametric ' black coating whose efficiency is independent of the angle of incidence of an incoming wave is developed on the basis of the studied one dimensional problems . the general solution of the problem of diffraction of incident waves from such a coating is obtained . this solution is analyzed in detail for the case of a disk shaped element"}, "present_kps": {"text": ["thin layer", "small scale stratification", "fast time modulation", "space time modulation", "controlled layer structure", "one dimensional boundary value problem", "parametric control", "low frequency incident wave", "high frequency waves", "waveguiding medium", "absorbing layer", "angle of incidence", "one dimensional problems", "diffraction", "disk shaped element"], "tokenized": ["thin layer", "small scale stratification", "fast time modulation", "space time modulation", "controlled layer structure", "one dimensional boundary value problem", "parametric control", "low frequency incident wave", "high frequency waves", "waveguiding medium", "absorbing layer", "angle of incidence", "one dimensional problems", "diffraction", "disk shaped element"]}, "absent_kps": {"text": ["acoustical models", "nonreflecting coating", "active absorbing coating", "mechanical models"], "tokenized": ["acoustical models", "nonreflecting coating", "active absorbing coating", "mechanical models"]}}
{"id": 299, "title": {"text": "[digit] in house fulfillment systems report publishing .", "tokenized": "[digit] in house fulfillment systems report publishing ."}, "abstract": {"text": "to date on the current capabilities of the leading publication software packages", "tokenized": "to date on the current capabilities of the leading publication software packages"}, "present_kps": {"text": ["in house fulfillment system", "publication software packages"], "tokenized": ["in house fulfillment system", "publication software packages"]}, "absent_kps": {"text": ["survey", "suppliers"], "tokenized": ["survey", "suppliers"]}}
{"id": 300, "title": {"text": "writing the fulfillment rfp publishing .", "tokenized": "writing the fulfillment rfp publishing ."}, "abstract": {"text": "and daunting . here ' s a format that will make you look like a pro the first time out", "tokenized": "and daunting . here ' s a format that will make you look like a pro the first time out"}, "present_kps": {"text": ["fulfillment", "publisher"], "tokenized": ["fulfillment", "publisher"]}, "absent_kps": {"text": ["request for proposal"], "tokenized": ["request for proposal"]}}
{"id": 301, "title": {"text": "library services today and tomorrow lessons from ilumina , a digital library .", "tokenized": "library services today and tomorrow lessons from ilumina , a digital library ."}, "abstract": {"text": "this article is based on the emerging experience associated with a digital library of instructional resources , ilumina , in which the contributors of resources and the users of those resources are the same an open community of instructors in science , mathematics , engineering , and technology . moreover , it is not the resources , most of which will be distributed across the internet , but metadata about the resources that is the focus of the central ilumina repository and its support services for resource contributors and users . the distributed ilumina library is a community sharing library for repurposing and adding value to potentially useful , mostly non commercial instructional resources that are typically more granular in nature than commercially developed course materials . the experience of developing ilumina is raising a range of issues that have nothing to do with the place and time characteristics of the instructional context in which ilumina instructional resources are created or used . the issues instead have their locus in the democratization of both the professional roles of librarians and the quality assurance mechanisms associated with traditional peer review", "tokenized": "this article is based on the emerging experience associated with a digital library of instructional resources , ilumina , in which the contributors of resources and the users of those resources are the same an open community of instructors in science , mathematics , engineering , and technology . moreover , it is not the resources , most of which will be distributed across the internet , but metadata about the resources that is the focus of the central ilumina repository and its support services for resource contributors and users . the distributed ilumina library is a community sharing library for repurposing and adding value to potentially useful , mostly non commercial instructional resources that are typically more granular in nature than commercially developed course materials . the experience of developing ilumina is raising a range of issues that have nothing to do with the place and time characteristics of the instructional context in which ilumina instructional resources are created or used . the issues instead have their locus in the democratization of both the professional roles of librarians and the quality assurance mechanisms associated with traditional peer review"}, "present_kps": {"text": ["ilumina", "digital library", "internet", "metadata", "community sharing library", "professional roles", "librarians", "quality assurance", "peer review"], "tokenized": ["ilumina", "digital library", "internet", "metadata", "community sharing library", "professional roles", "librarians", "quality assurance", "peer review"]}, "absent_kps": {"text": ["user issues", "library automation", "academic library", "standards", "reusable software", "teaching resource sharing", "information resources", "distributed systems", "interoperability"], "tokenized": ["user issues", "library automation", "academic library", "standards", "reusable software", "teaching resource sharing", "information resources", "distributed systems", "interoperability"]}}
{"id": 302, "title": {"text": "the canadian national site licensing project .", "tokenized": "the canadian national site licensing project ."}, "abstract": {"text": "inter institutional agreement that launched the canadian national site licensing project ( cnslp ) , a three year pilot project aimed at bolstering the research and innovation capacity of the country ' s universities . cnslp tests the feasibility of licensing , on a national scale , electronic versions of scholarly publications in its initial phases the project is focused on full text electronic journals and research databases in science , engineering , health and environmental disciplines . this article provides an overview of the cnslp initiative , summarizes organizational and licensing accomplishments to date , and offers preliminary observations on challenges and opportunities for subsequent phases of the project", "tokenized": "inter institutional agreement that launched the canadian national site licensing project ( cnslp ) , a three year pilot project aimed at bolstering the research and innovation capacity of the country ' s universities . cnslp tests the feasibility of licensing , on a national scale , electronic versions of scholarly publications in its initial phases the project is focused on full text electronic journals and research databases in science , engineering , health and environmental disciplines . this article provides an overview of the cnslp initiative , summarizes organizational and licensing accomplishments to date , and offers preliminary observations on challenges and opportunities for subsequent phases of the project"}, "present_kps": {"text": ["canadian national site licensing project", "inter institutional agreement", "cnslp", "research and innovation", "full text electronic journals", "research databases"], "tokenized": ["canadian national site licensing project", "inter institutional agreement", "cnslp", "research and innovation", "full text electronic journals", "research databases"]}, "absent_kps": {"text": ["information resources", "academic libraries", "electronic scholarly publications"], "tokenized": ["information resources", "academic libraries", "electronic scholarly publications"]}}
{"id": 303, "title": {"text": "the uk ' s national electronic site licensing initiative ( nesli ) .", "tokenized": "the uk ' s national electronic site licensing initiative ( nesli ) ."}, "abstract": {"text": "( nesli ) to increase and improve access to electronic journals and to negotiate license agreements on behalf of academic libraries . the use of a model license agreement and the success of site licensing is discussed . highlights from an interim evaluation by the joint information systems committee ( jisc ) are noted and key issues and questions arising from the evaluation are identified", "tokenized": "( nesli ) to increase and improve access to electronic journals and to negotiate license agreements on behalf of academic libraries . the use of a model license agreement and the success of site licensing is discussed . highlights from an interim evaluation by the joint information systems committee ( jisc ) are noted and key issues and questions arising from the evaluation are identified"}, "present_kps": {"text": ["national electronic site licensing initiative", "nesli", "electronic journals", "license agreements", "academic libraries", "joint information systems committee", "jisc"], "tokenized": ["national electronic site licensing initiative", "nesli", "electronic journals", "license agreements", "academic libraries", "joint information systems committee", "jisc"]}, "absent_kps": {"text": ["icolc", "usage statistics"], "tokenized": ["icolc", "usage statistics"]}}
{"id": 304, "title": {"text": "the role of caul ( council of australian libraries ) in consortial purchasing .", "tokenized": "the role of caul ( council of australian libraries ) in consortial purchasing ."}, "abstract": {"text": "purposes of cooperative action and the sharing of information , assumed the role of consortial purchasing agent in [digit] on behalf of its members and associate organisations in australia and new zealand . this role continues to grow in tandem with the burgeoning of electronic publication and the acceptance of publishers of the advantages of dealing with consortia . the needs of the australian university community overlap significantly with consortia in north america and europe , but important differences are highlighted", "tokenized": "purposes of cooperative action and the sharing of information , assumed the role of consortial purchasing agent in [digit] on behalf of its members and associate organisations in australia and new zealand . this role continues to grow in tandem with the burgeoning of electronic publication and the acceptance of publishers of the advantages of dealing with consortia . the needs of the australian university community overlap significantly with consortia in north america and europe , but important differences are highlighted"}, "present_kps": {"text": ["consortial purchasing", "cooperative action", "australia", "new zealand", "electronic publication", "north america", "europe"], "tokenized": ["consortial purchasing", "cooperative action", "australia", "new zealand", "electronic publication", "north america", "europe"]}, "absent_kps": {"text": ["information sharing", "council of australian university librarians"], "tokenized": ["information sharing", "council of australian university librarians"]}}
{"id": 305, "title": {"text": "licensing experiences in the netherlands .", "tokenized": "licensing experiences in the netherlands ."}, "abstract": {"text": "connected with university policies to develop document servers and to make research publications available on the web . national agreements have been made with major publishers , such as elsevier science and kluwer academic , to provide access to a wide range of scientific information and to experiment with new ways of providing information and new business models", "tokenized": "connected with university policies to develop document servers and to make research publications available on the web . national agreements have been made with major publishers , such as elsevier science and kluwer academic , to provide access to a wide range of scientific information and to experiment with new ways of providing information and new business models"}, "present_kps": {"text": ["netherlands", "university policies", "document servers", "research publications", "web", "elsevier science", "kluwer academic", "scientific information", "business models"], "tokenized": ["netherlands", "university policies", "document servers", "research publications", "web", "elsevier science", "kluwer academic", "scientific information", "business models"]}, "absent_kps": {"text": ["licensing strategy", "university libraries"], "tokenized": ["licensing strategy", "university libraries"]}}
{"id": 306, "title": {"text": "international library consortia positive starts , promising futures .", "tokenized": "international library consortia positive starts , promising futures ."}, "abstract": {"text": "north america and globally . as this resurgent consortial movement has begun to mature , and as publishers and vendors have begun to adapt to consortial purchasing models , consortia have expanded their agendas for action . the movement to globalize consortia is traced ( including the development and current work of the international coalition of library consortia icolc ) . a methodology is explored to classify library consortia by articulating the key factors that affect and distinguish consortia as organizations within three major areas strategic , tactical , and practical ( or managerial ) concerns . common consortial values are examined , and a list of known international library consortia is presented", "tokenized": "north america and globally . as this resurgent consortial movement has begun to mature , and as publishers and vendors have begun to adapt to consortial purchasing models , consortia have expanded their agendas for action . the movement to globalize consortia is traced ( including the development and current work of the international coalition of library consortia icolc ) . a methodology is explored to classify library consortia by articulating the key factors that affect and distinguish consortia as organizations within three major areas strategic , tactical , and practical ( or managerial ) concerns . common consortial values are examined , and a list of known international library consortia is presented"}, "present_kps": {"text": ["international library consortia", "consortial purchasing models"], "tokenized": ["international library consortia", "consortial purchasing models"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 307, "title": {"text": "the open archives initiative realizing simple and effective digital library .", "tokenized": "the open archives initiative realizing simple and effective digital library ."}, "abstract": {"text": "the open archives initiative ( oai ) is dedicated to solving problems of digital library interoperability . its focus has been on defining simple protocols , most recently for the exchange of metadata from archives . the oai evolved out of a need to increase access to scholarly publications by supporting the creation of interoperable digital libraries . as a first step towards such interoperability , a metadata harvesting protocol was developed to support the streaming of metadata from one repository to another , ultimately to a provider of user services such as browsing , searching , or annotation . this article provides an overview of the mission , philosophy , and technical framework of the oai", "tokenized": "the open archives initiative ( oai ) is dedicated to solving problems of digital library interoperability . its focus has been on defining simple protocols , most recently for the exchange of metadata from archives . the oai evolved out of a need to increase access to scholarly publications by supporting the creation of interoperable digital libraries . as a first step towards such interoperability , a metadata harvesting protocol was developed to support the streaming of metadata from one repository to another , ultimately to a provider of user services such as browsing , searching , or annotation . this article provides an overview of the mission , philosophy , and technical framework of the oai"}, "present_kps": {"text": ["open archives initiative", "digital library interoperability", "protocols", "scholarly publications", "metadata harvesting protocol", "user services", "browsing", "searching", "annotation"], "tokenized": ["open archives initiative", "digital library interoperability", "protocols", "scholarly publications", "metadata harvesting protocol", "user services", "browsing", "searching", "annotation"]}, "absent_kps": {"text": ["exchange metadata", "streaming metadata"], "tokenized": ["exchange metadata", "streaming metadata"]}}
{"id": 308, "title": {"text": "content standards for electronic books the oebf publication structure and the .", "tokenized": "content standards for electronic books the oebf publication structure and the ."}, "abstract": {"text": "in the emerging world of electronic publishing how we create , distribute , and read books will be in a large part determined by an underlying framework of content standards that establishes the range of technological opportunities and constraints for publishing and reading systems . but efforts to develop content standards based on sound engineering models must skillfully negotiate competing and sometimes apparently irreconcilable objectives if they are to produce results relevant to the rapidly changing course of technology . the open ebook forum ' s publication structure , an xml based specification for electronic books , is an example of the sort of timely and innovative problem solving required for successful real world standards development . as a result of this effort , the electronic book industry will not only happen sooner and on a larger scale than it would have otherwise , but the electronic books it produces will be more functional , more interoperable , and more accessible to all readers . public interest participants have a critical role in this process", "tokenized": "in the emerging world of electronic publishing how we create , distribute , and read books will be in a large part determined by an underlying framework of content standards that establishes the range of technological opportunities and constraints for publishing and reading systems . but efforts to develop content standards based on sound engineering models must skillfully negotiate competing and sometimes apparently irreconcilable objectives if they are to produce results relevant to the rapidly changing course of technology . the open ebook forum ' s publication structure , an xml based specification for electronic books , is an example of the sort of timely and innovative problem solving required for successful real world standards development . as a result of this effort , the electronic book industry will not only happen sooner and on a larger scale than it would have otherwise , but the electronic books it produces will be more functional , more interoperable , and more accessible to all readers . public interest participants have a critical role in this process"}, "present_kps": {"text": ["content standards", "electronic books", "oebf publication structure", "electronic publishing", "xml based specification", "public interest participation"], "tokenized": ["content standards", "electronic books", "oebf publication structure", "electronic publishing", "xml based specification", "public interest participation"]}, "absent_kps": {"text": ["open ebook forum publication structure"], "tokenized": ["open ebook forum publication structure"]}}
{"id": 309, "title": {"text": "fuzzy modeling based on generalized conjunction operations .", "tokenized": "fuzzy modeling based on generalized conjunction operations ."}, "abstract": {"text": "operations is proposed . first , some methods for the construction of parametric generalized conjunction operations simpler than the known parametric classes of conjunctions are considered and discussed . second , several examples of function approximation by fuzzy models , based on the tuning of the parameters of the new conjunction operations , are given and their approximation performances are compared with the approaches based on a tuning of membership functions and other approaches proposed in the literature . it is seen that the tuning of the conjunction operations can be used for obtaining fuzzy models with a sufficiently good performance when the tuning of membership functions is not possible or not desirable", "tokenized": "operations is proposed . first , some methods for the construction of parametric generalized conjunction operations simpler than the known parametric classes of conjunctions are considered and discussed . second , several examples of function approximation by fuzzy models , based on the tuning of the parameters of the new conjunction operations , are given and their approximation performances are compared with the approaches based on a tuning of membership functions and other approaches proposed in the literature . it is seen that the tuning of the conjunction operations can be used for obtaining fuzzy models with a sufficiently good performance when the tuning of membership functions is not possible or not desirable"}, "present_kps": {"text": ["fuzzy modeling", "generalized conjunction operations", "function approximation", "tuning", "approximation performances", "membership functions"], "tokenized": ["fuzzy modeling", "generalized conjunction operations", "function approximation", "tuning", "approximation performances", "membership functions"]}, "absent_kps": {"text": ["fuzzy inference systems", "t norm"], "tokenized": ["fuzzy inference systems", "t norm"]}}
{"id": 310, "title": {"text": "project euclid and the role of research libraries in scholarly publishing .", "tokenized": "project euclid and the role of research libraries in scholarly publishing ."}, "abstract": {"text": "university library and duke university press is discussed in the broader contexts of the changing patterns of scholarly communication and the publishing scene of mathematics . specific aspects of the project such as partnerships and the creation of an economic model are presented as well as what it takes to be a publisher . libraries have gained important and relevant experience through the creation and management of digital libraries , but they need to develop further skills if they want to adopt a new role in the life cycle of scholarly communication", "tokenized": "university library and duke university press is discussed in the broader contexts of the changing patterns of scholarly communication and the publishing scene of mathematics . specific aspects of the project such as partnerships and the creation of an economic model are presented as well as what it takes to be a publisher . libraries have gained important and relevant experience through the creation and management of digital libraries , but they need to develop further skills if they want to adopt a new role in the life cycle of scholarly communication"}, "present_kps": {"text": ["project euclid", "research libraries", "scholarly publishing", "duke university press", "scholarly communication", "mathematics", "partnerships", "economic model"], "tokenized": ["project euclid", "research libraries", "scholarly publishing", "duke university press", "scholarly communication", "mathematics", "partnerships", "economic model"]}, "absent_kps": {"text": ["joint electronic journal publishing initiative", "cornell university library"], "tokenized": ["joint electronic journal publishing initiative", "cornell university library"]}}
{"id": 311, "title": {"text": "perspectives on scholarly online books the columbia university online books .", "tokenized": "perspectives on scholarly online books the columbia university online books ."}, "abstract": {"text": "the online books evaluation project at columbia university studied the potential for scholarly online books from [digit] to [digit] . issues included scholars ' interest in using online books , the role they might play in scholarly life , features that scholars and librarians sought in online books , the costs of producing and owning print and online books , and potential marketplace arrangements . scholars see potential for online books to make their research , learning , and teaching more efficient and effective . librarians see potential to serve their scholars better . librarians may face lower costs if they can serve their scholars with online books instead of print books . publishers may be able to offer scholars greater opportunities to use their books while enhancing their own profitability", "tokenized": "the online books evaluation project at columbia university studied the potential for scholarly online books from [digit] to [digit] . issues included scholars ' interest in using online books , the role they might play in scholarly life , features that scholars and librarians sought in online books , the costs of producing and owning print and online books , and potential marketplace arrangements . scholars see potential for online books to make their research , learning , and teaching more efficient and effective . librarians see potential to serve their scholars better . librarians may face lower costs if they can serve their scholars with online books instead of print books . publishers may be able to offer scholars greater opportunities to use their books while enhancing their own profitability"}, "present_kps": {"text": ["scholarly online books", "costs", "marketplace arrangements", "research", "learning", "print books"], "tokenized": ["scholarly online books", "costs", "marketplace arrangements", "research", "learning", "print books"]}, "absent_kps": {"text": ["columbia university online books evaluation project"], "tokenized": ["columbia university online books evaluation project"]}}
{"id": 312, "title": {"text": "the california digital library and the escholarship program .", "tokenized": "the california digital library and the escholarship program ."}, "abstract": {"text": "in scholarly publishing . an initiative of the university of california ( uc ) and a program of the california digital library , the escholarship program has stimulated significant interest in its short life . its modest but visible accomplishments garner praise from many quarters , within and beyond the university of california . in perhaps the best indication of its timeliness and momentum , there are more proposals submitted to escholarship today than the cdl can manage . this early success is due in part to the sheer power of an idea whose time has come , but also to the unique approach on which cdl was founded and the escholarship initiative was first launched", "tokenized": "in scholarly publishing . an initiative of the university of california ( uc ) and a program of the california digital library , the escholarship program has stimulated significant interest in its short life . its modest but visible accomplishments garner praise from many quarters , within and beyond the university of california . in perhaps the best indication of its timeliness and momentum , there are more proposals submitted to escholarship today than the cdl can manage . this early success is due in part to the sheer power of an idea whose time has come , but also to the unique approach on which cdl was founded and the escholarship initiative was first launched"}, "present_kps": {"text": ["california digital library", "escholarship program", "scholarly publishing", "university of california"], "tokenized": ["california digital library", "escholarship program", "scholarly publishing", "university of california"]}, "absent_kps": {"text": ["faculty led innovation"], "tokenized": ["faculty led innovation"]}}
{"id": 313, "title": {"text": "bioone a new model for scholarly publishing .", "tokenized": "bioone a new model for scholarly publishing ."}, "abstract": {"text": "the university of kansas , the big [digit] plus libraries consortium , the american institute of biological sciences , allen press , and sparc , the scholarly publishing and academic resources coalition . this partnership has created bioone , a database of [digit] full text society journals in the biological and environmental sciences , which was launched in april , [digit] . the genesis and development of the project is described and financial , technical , and intellectual property models for the project are discussed . collaborative strategies for the project are described", "tokenized": "the university of kansas , the big [digit] plus libraries consortium , the american institute of biological sciences , allen press , and sparc , the scholarly publishing and academic resources coalition . this partnership has created bioone , a database of [digit] full text society journals in the biological and environmental sciences , which was launched in april , [digit] . the genesis and development of the project is described and financial , technical , and intellectual property models for the project are discussed . collaborative strategies for the project are described"}, "present_kps": {"text": ["university of kansas", "big [digit] plus libraries consortium", "american institute of biological sciences", "biological sciences", "allen press", "sparc", "scholarly publishing and academic resources coalition", "environmental sciences", "intellectual property models", "collaborative strategies"], "tokenized": ["university of kansas", "big [digit] plus libraries consortium", "american institute of biological sciences", "biological sciences", "allen press", "sparc", "scholarly publishing and academic resources coalition", "environmental sciences", "intellectual property models", "collaborative strategies"]}, "absent_kps": {"text": ["scholarly publishing model", "financial models", "bioone full text society journal database", "electronic journal publishing project", "technical models"], "tokenized": ["scholarly publishing model", "financial models", "bioone full text society journal database", "electronic journal publishing project", "technical models"]}}
{"id": 314, "title": {"text": "symbiosis or alienation advancing the university press research library .", "tokenized": "symbiosis or alienation advancing the university press research library ."}, "abstract": {"text": "university presses and research libraries have a long tradition of collaboration . the rapidly expanding electronic scholarly communication environment offers important new opportunities for cooperation and for innovative new models of publishing . the economics of libraries and scholarly publishers have strained the working relationship and promoted debates on important information policy issues . this article explores the context for advancing the partnership , cites examples of joint efforts in electronic publishing , and presents an action plan for working together", "tokenized": "university presses and research libraries have a long tradition of collaboration . the rapidly expanding electronic scholarly communication environment offers important new opportunities for cooperation and for innovative new models of publishing . the economics of libraries and scholarly publishers have strained the working relationship and promoted debates on important information policy issues . this article explores the context for advancing the partnership , cites examples of joint efforts in electronic publishing , and presents an action plan for working together"}, "present_kps": {"text": ["electronic scholarly communication", "economics", "information policy", "electronic publishing"], "tokenized": ["electronic scholarly communication", "economics", "information policy", "electronic publishing"]}, "absent_kps": {"text": ["university press research library relationship"], "tokenized": ["university press research library relationship"]}}
{"id": 315, "title": {"text": "support vector machines model for classification of thermal error in machine .", "tokenized": "support vector machines model for classification of thermal error in machine ."}, "abstract": {"text": "this paper addresses a change in the concept of machine tool thermal error prediction which has been hitherto carried out by directly mapping them with the temperature of critical elements on the machine . the model developed herein using support vector machines , a powerful data training algorithm , seeks to account for the impact of specific operating conditions , in addition to temperature variation , on the effective prediction of thermal errors . several experiments were conducted to study the error pattern , which was found to change significantly with variation in operating conditions . this model attempts to classify the error based on operating conditions . once classified , the error is then predicted based on the temperature states . this paper also briefly describes the concept of the implementation of such a comprehensive model along with an on line error assessment and calibration system in a pc based open architecture controller environment , so that it could be employed in regular production for the purpose of periodic calibration of machine tools", "tokenized": "this paper addresses a change in the concept of machine tool thermal error prediction which has been hitherto carried out by directly mapping them with the temperature of critical elements on the machine . the model developed herein using support vector machines , a powerful data training algorithm , seeks to account for the impact of specific operating conditions , in addition to temperature variation , on the effective prediction of thermal errors . several experiments were conducted to study the error pattern , which was found to change significantly with variation in operating conditions . this model attempts to classify the error based on operating conditions . once classified , the error is then predicted based on the temperature states . this paper also briefly describes the concept of the implementation of such a comprehensive model along with an on line error assessment and calibration system in a pc based open architecture controller environment , so that it could be employed in regular production for the purpose of periodic calibration of machine tools"}, "present_kps": {"text": ["support vector machines model", "machine tool thermal error prediction", "data training algorithm", "error pattern", "pc based open architecture controller environment"], "tokenized": ["support vector machines model", "machine tool thermal error prediction", "data training algorithm", "error pattern", "pc based open architecture controller environment"]}, "absent_kps": {"text": ["online calibration system", "svm", "critical element temperature", "thermal error classification", "online error assessment"], "tokenized": ["online calibration system", "svm", "critical element temperature", "thermal error classification", "online error assessment"]}}
{"id": 316, "title": {"text": "adaptive and efficient mutual exclusion .", "tokenized": "adaptive and efficient mutual exclusion ."}, "abstract": {"text": "write operations the performance of the algorithms depends only on the point contention , i . e . , the number of processes that are concurrently active during algorithm execution ( and not on n , the total number of processes ) . our algorithm has o ( k ) remote step complexity and o ( log k ) system response time , where k is the point contention . the remote step complexity is the maximal number of steps performed by a process where a wait is counted as one step . the system response time is the time interval between subsequent entries to the critical section , where one time unit is the minimal interval in which every active process performs at least one step . the space complexity of this algorithm is o ( n log n ) , where n is the range of process names . we show how to make the space complexity of our algorithm depend solely on n , while preserving the other performance measures of the algorithm", "tokenized": "write operations the performance of the algorithms depends only on the point contention , i . e . , the number of processes that are concurrently active during algorithm execution ( and not on n , the total number of processes ) . our algorithm has o ( k ) remote step complexity and o ( log k ) system response time , where k is the point contention . the remote step complexity is the maximal number of steps performed by a process where a wait is counted as one step . the system response time is the time interval between subsequent entries to the critical section , where one time unit is the minimal interval in which every active process performs at least one step . the space complexity of this algorithm is o ( n log n ) , where n is the range of process names . we show how to make the space complexity of our algorithm depend solely on n , while preserving the other performance measures of the algorithm"}, "present_kps": {"text": ["write operations", "point contention", "algorithm execution", "remote step complexity", "system response time", "critical section", "minimal interval", "active process", "space complexity", "performance measures"], "tokenized": ["write operations", "point contention", "algorithm execution", "remote step complexity", "system response time", "critical section", "minimal interval", "active process", "space complexity", "performance measures"]}, "absent_kps": {"text": ["adaptive mutual exclusion", "read operations", "adaptive algorithms"], "tokenized": ["adaptive mutual exclusion", "read operations", "adaptive algorithms"]}}
{"id": 317, "title": {"text": "the congenial talking philosophers problem in computer networks .", "tokenized": "the congenial talking philosophers problem in computer networks ."}, "abstract": {"text": "shared by processes of the same group , but not by processes of different groups . for example , suppose data is stored in a cd jukebox . then , when a disc is loaded for access , users that need data on the disc can concurrently access the disc , while users that need data on a different disc have to wait until the current disc is unloaded . the design issues for group mutual exclusion have been modeled as the congenial talking philosophers problem , and solutions for shared memory models have been proposed ( y . j . young , [digit] p . keane and m . moir , [digit] ) . as in ordinary mutual exclusion and many other problems in distributed systems , however , techniques developed for shared memory do not necessarily apply to message passing ( and vice versa ) . we investigate solutions for congenial talking philosophers in computer networks where processes communicate by asynchronous message passing . we first present a solution that is a straightforward adaptation from g . ricart and a . k . agrawala ' s ( [digit] ) algorithm for ordinary mutual exclusion . then we show that the simple modification suffers a severe performance degradation that could cause the system to behave as though only one process of a group can be in the critical section at a time . we then present a more efficient and highly concurrent distributed algorithm for the problem , the first such solution in computer networks", "tokenized": "shared by processes of the same group , but not by processes of different groups . for example , suppose data is stored in a cd jukebox . then , when a disc is loaded for access , users that need data on the disc can concurrently access the disc , while users that need data on a different disc have to wait until the current disc is unloaded . the design issues for group mutual exclusion have been modeled as the congenial talking philosophers problem , and solutions for shared memory models have been proposed ( y . j . young , [digit] p . keane and m . moir , [digit] ) . as in ordinary mutual exclusion and many other problems in distributed systems , however , techniques developed for shared memory do not necessarily apply to message passing ( and vice versa ) . we investigate solutions for congenial talking philosophers in computer networks where processes communicate by asynchronous message passing . we first present a solution that is a straightforward adaptation from g . ricart and a . k . agrawala ' s ( [digit] ) algorithm for ordinary mutual exclusion . then we show that the simple modification suffers a severe performance degradation that could cause the system to behave as though only one process of a group can be in the critical section at a time . we then present a more efficient and highly concurrent distributed algorithm for the problem , the first such solution in computer networks"}, "present_kps": {"text": ["congenial talking philosophers problem", "computer networks", "group mutual exclusion", "shared memory models", "distributed systems", "process communication", "asynchronous message passing", "critical section", "concurrent distributed algorithm"], "tokenized": ["congenial talking philosophers problem", "computer networks", "group mutual exclusion", "shared memory models", "distributed systems", "process communication", "asynchronous message passing", "critical section", "concurrent distributed algorithm"]}, "absent_kps": {"text": ["resource sharing"], "tokenized": ["resource sharing"]}}
{"id": 318, "title": {"text": "universal dynamic synchronous self stabilization .", "tokenized": "universal dynamic synchronous self stabilization ."}, "abstract": {"text": "that is , a protocol that allows a distributed system to stabilize to a desired nonreactive behaviour ( as long as a protocol stabilizing to that behaviour exists ) . previous proposals required drastic increases in asymmetry and knowledge to work , whereas our protocol does not use any additional knowledge , and does not require more symmetry breaking conditions than available thus , it is also stabilizing with respect to dynamic changes in the topology . we prove an optimal quiescence time n d for a synchronous network of n processors and diameter d the protocol can be made finite state with a negligible loss in quiescence time . moreover , an optimal d [digit] protocol is given for the case of unique identifiers . as a consequence , we provide an effective proof technique that allows one to show whether self stabilization to a certain behaviour is possible under a wide range of models", "tokenized": "that is , a protocol that allows a distributed system to stabilize to a desired nonreactive behaviour ( as long as a protocol stabilizing to that behaviour exists ) . previous proposals required drastic increases in asymmetry and knowledge to work , whereas our protocol does not use any additional knowledge , and does not require more symmetry breaking conditions than available thus , it is also stabilizing with respect to dynamic changes in the topology . we prove an optimal quiescence time n d for a synchronous network of n processors and diameter d the protocol can be made finite state with a negligible loss in quiescence time . moreover , an optimal d [digit] protocol is given for the case of unique identifiers . as a consequence , we provide an effective proof technique that allows one to show whether self stabilization to a certain behaviour is possible under a wide range of models"}, "present_kps": {"text": ["universal dynamic synchronous self stabilization", "self stabilization", "distributed system", "nonreactive behaviour", "dynamic changes", "topology", "optimal quiescence time", "quiescence time", "synchronous network", "finite state", "unique identifiers", "proof technique"], "tokenized": ["universal dynamic synchronous self stabilization", "self stabilization", "distributed system", "nonreactive behaviour", "dynamic changes", "topology", "optimal quiescence time", "quiescence time", "synchronous network", "finite state", "unique identifiers", "proof technique"]}, "absent_kps": {"text": ["optimal protocol", "graph fibrations", "synchronous self stabilizing protocol", "anonymous networks"], "tokenized": ["optimal protocol", "graph fibrations", "synchronous self stabilizing protocol", "anonymous networks"]}}
{"id": 319, "title": {"text": "randomized two process wait free test and set .", "tokenized": "randomized two process wait free test and set ."}, "abstract": {"text": "two process wait free test and set . it is implemented with two [digit] valued single writer single reader atomic variables . a test and set takes at most [digit] expected elementary steps , while a reset takes exactly [digit] elementary step . based on a finite state analysis , the proofs of correctness and expected length are compressed into one table", "tokenized": "two process wait free test and set . it is implemented with two [digit] valued single writer single reader atomic variables . a test and set takes at most [digit] expected elementary steps , while a reset takes exactly [digit] elementary step . based on a finite state analysis , the proofs of correctness and expected length are compressed into one table"}, "present_kps": {"text": ["randomized two process wait free test and set", "[digit] valued single writer single reader atomic variables", "expected elementary steps", "finite state analysis"], "tokenized": ["randomized two process wait free test and set", "[digit] valued single writer single reader atomic variables", "expected elementary steps", "finite state analysis"]}, "absent_kps": {"text": ["randomized algorithm", "correctness proofs", "fault tolerance", "shared memory", "wait free read write registers", "asynchronous distributed protocols", "symmetry breaking"], "tokenized": ["randomized algorithm", "correctness proofs", "fault tolerance", "shared memory", "wait free read write registers", "asynchronous distributed protocols", "symmetry breaking"]}}
{"id": 320, "title": {"text": "identification of evolving fuzzy rule based models .", "tokenized": "identification of evolving fuzzy rule based models ."}, "abstract": {"text": "proposed . er models implement a method for the noniterative update of both the rule base structure and parameters by incremental unsupervised learning . the rule base evolves by adding more informative rules than those that previously formed the model . in addition , existing rules can be replaced with new rules based on ranking using the informative potential of the data . in this way , the rule base structure is inherited and updated when new informative data become available , rather than being completely retrained . the adaptive nature of these evolving rule based models , in combination with the highly transparent and compact form of fuzzy rules , makes them a promising candidate for modeling and control of complex processes , competitive to neural networks . the approach has been tested on a benchmark problem and on an air conditioning component modeling application using data from an installation serving a real building . the results illustrate the viability and efficiency of the approach", "tokenized": "proposed . er models implement a method for the noniterative update of both the rule base structure and parameters by incremental unsupervised learning . the rule base evolves by adding more informative rules than those that previously formed the model . in addition , existing rules can be replaced with new rules based on ranking using the informative potential of the data . in this way , the rule base structure is inherited and updated when new informative data become available , rather than being completely retrained . the adaptive nature of these evolving rule based models , in combination with the highly transparent and compact form of fuzzy rules , makes them a promising candidate for modeling and control of complex processes , competitive to neural networks . the approach has been tested on a benchmark problem and on an air conditioning component modeling application using data from an installation serving a real building . the results illustrate the viability and efficiency of the approach"}, "present_kps": {"text": ["identification", "evolving fuzzy rule based models", "fuzzy rules", "noniterative update", "rule base structure", "incremental unsupervised learning", "ranking", "informative potential", "complex processes", "air conditioning component modeling"], "tokenized": ["identification", "evolving fuzzy rule based models", "fuzzy rules", "noniterative update", "rule base structure", "incremental unsupervised learning", "ranking", "informative potential", "complex processes", "air conditioning component modeling"]}, "absent_kps": {"text": ["knowledge extraction", "performance analysis", "adaptive nonlinear control", "behavior modeling", "robotics", "forecasting", "fault detection", "fault diagnostics"], "tokenized": ["knowledge extraction", "performance analysis", "adaptive nonlinear control", "behavior modeling", "robotics", "forecasting", "fault detection", "fault diagnostics"]}}
{"id": 321, "title": {"text": "aim for the enterprise microsoft project [digit] .", "tokenized": "aim for the enterprise microsoft project [digit] ."}, "abstract": {"text": "enterprise debut . its new web based collaboration tools and improved scalability with olap support make it much easier to manage multiple web projects with disparate workgroups and budgets", "tokenized": "enterprise debut . its new web based collaboration tools and improved scalability with olap support make it much easier to manage multiple web projects with disparate workgroups and budgets"}, "present_kps": {"text": ["microsoft project [digit]", "web based collaboration tools", "scalability", "olap support", "workgroups", "budgets"], "tokenized": ["microsoft project [digit]", "web based collaboration tools", "scalability", "olap support", "workgroups", "budgets"]}, "absent_kps": {"text": ["multiple web project management"], "tokenized": ["multiple web project management"]}}
{"id": 322, "title": {"text": "central hub for design assets adobe golive [digit] . [digit] .", "tokenized": "central hub for design assets adobe golive [digit] . [digit] ."}, "abstract": {"text": "[digit] . [digit] features a flexible gui environment combined with a comprehensive workgroup and collaboration server , plus tight integration with leading design tools", "tokenized": "[digit] . [digit] features a flexible gui environment combined with a comprehensive workgroup and collaboration server , plus tight integration with leading design tools"}, "present_kps": {"text": ["adobe golive [digit] . [digit]", "gui", "collaboration server"], "tokenized": ["adobe golive [digit] . [digit]", "gui", "collaboration server"]}, "absent_kps": {"text": ["real", "web authoring", "workgroup server", "macromedia swf format", "flash", "animation and scripting tool", "application servers", "livemotion [digit] . [digit]", "design centric dynamic content", "web publishing environment", "java", "workgroup environment"], "tokenized": ["real", "web authoring", "workgroup server", "macromedia swf format", "flash", "animation and scripting tool", "application servers", "livemotion [digit] . [digit]", "design centric dynamic content", "web publishing environment", "java", "workgroup environment"]}}
{"id": 323, "title": {"text": "reaching for five nines activewatch and siteseer .", "tokenized": "reaching for five nines activewatch and siteseer ."}, "abstract": {"text": "uptime . to attain such availability , your web site must be down no more than about five minutes per year . technologies like raid , clustering , and load balancing make this easier , but to actually track uptime , maintain auditable records , and discover patterns in failures to prevent downtime in the future , you ' ll need to set up external monitoring . because your internet connection is a key factor in measuring uptime , you must monitor your site from the internet itself , beyond your firewall . you could monitor with custom software on remote hosts , or you could use one of the two reasonably priced services available mercury interactive ' s activewatch and freshwater software ' s siteseer . ( freshwater software has been a subsidiary of mercury interactive for about a year now . ) the two services offer a slightly different mix of features and target different markets . both services offer availability and performance monitoring from several remote locations , alerts to email or pager , and periodic reports . they differ in what ' s most easily monitored , and in the way you interact with the services", "tokenized": "uptime . to attain such availability , your web site must be down no more than about five minutes per year . technologies like raid , clustering , and load balancing make this easier , but to actually track uptime , maintain auditable records , and discover patterns in failures to prevent downtime in the future , you ' ll need to set up external monitoring . because your internet connection is a key factor in measuring uptime , you must monitor your site from the internet itself , beyond your firewall . you could monitor with custom software on remote hosts , or you could use one of the two reasonably priced services available mercury interactive ' s activewatch and freshwater software ' s siteseer . ( freshwater software has been a subsidiary of mercury interactive for about a year now . ) the two services offer a slightly different mix of features and target different markets . both services offer availability and performance monitoring from several remote locations , alerts to email or pager , and periodic reports . they differ in what ' s most easily monitored , and in the way you interact with the services"}, "present_kps": {"text": ["web site", "auditable records", "downtime", "external monitoring", "internet connection", "performance monitoring", "remote locations", "periodic reports"], "tokenized": ["web site", "auditable records", "downtime", "external monitoring", "internet connection", "performance monitoring", "remote locations", "periodic reports"]}, "absent_kps": {"text": ["uptime tracking", "mercury interactive activewatch", "email alerts", "pager alerts", "freshwater software siteseer", "availability monitoring", "failure pattern discovery"], "tokenized": ["uptime tracking", "mercury interactive activewatch", "email alerts", "pager alerts", "freshwater software siteseer", "availability monitoring", "failure pattern discovery"]}}
{"id": 324, "title": {"text": "accessible streaming content .", "tokenized": "accessible streaming content ."}, "abstract": {"text": "article provides some tips and tactics for making your streaming media accessible . accessibility of streaming content for people with disabilities is often not part of the spec for multimedia projects , but it certainly affects your quality of service . most of the resources available on web accessibility deal with html . fortunately , rich media and streaming content developers have a growing number of experts to turn to for information and assistance . the essentials of providing accessible streaming content are simple blind and visually impaired people need audio to discern important visual detail and interface elements , while deaf and hard of hearing people need text to access sound effects and dialog . actually implementing these principles is quite a challenge , though . now due to a relatively new law in the us , known as section [digit] , dealing with accessibility issues is becoming an essential part of publishing on the web", "tokenized": "article provides some tips and tactics for making your streaming media accessible . accessibility of streaming content for people with disabilities is often not part of the spec for multimedia projects , but it certainly affects your quality of service . most of the resources available on web accessibility deal with html . fortunately , rich media and streaming content developers have a growing number of experts to turn to for information and assistance . the essentials of providing accessible streaming content are simple blind and visually impaired people need audio to discern important visual detail and interface elements , while deaf and hard of hearing people need text to access sound effects and dialog . actually implementing these principles is quite a challenge , though . now due to a relatively new law in the us , known as section [digit] , dealing with accessibility issues is becoming an essential part of publishing on the web"}, "present_kps": {"text": ["accessible streaming content", "streaming media", "multimedia projects", "web accessibility", "html", "streaming content developers", "visually impaired people", "visual detail", "interface elements", "hard of hearing people", "sound effects", "section [digit]", "accessibility issues"], "tokenized": ["accessible streaming content", "streaming media", "multimedia projects", "web accessibility", "html", "streaming content developers", "visually impaired people", "visual detail", "interface elements", "hard of hearing people", "sound effects", "section [digit]", "accessibility issues"]}, "absent_kps": {"text": ["quality service", "united states", "deaf people", "blind people", "web site", "disabled users", "content providers", "web publishing"], "tokenized": ["quality service", "united states", "deaf people", "blind people", "web site", "disabled users", "content providers", "web publishing"]}}
{"id": 325, "title": {"text": "what you get is what you see web performance monitoring .", "tokenized": "what you get is what you see web performance monitoring ."}, "abstract": {"text": "a complete view . don ' t neglect the big picture because you ' re too busy concentrating on details . the increasing complexity of web sites and the content they provide has consequently increased the complexity of the infrastructure that supports them . but with some knowledge of networking , a handful of useful tools , and the insight that those tools provide , designing and operating for optimal performance and reliability is within your grasp", "tokenized": "a complete view . don ' t neglect the big picture because you ' re too busy concentrating on details . the increasing complexity of web sites and the content they provide has consequently increased the complexity of the infrastructure that supports them . but with some knowledge of networking , a handful of useful tools , and the insight that those tools provide , designing and operating for optimal performance and reliability is within your grasp"}, "present_kps": {"text": ["web performance", "web sites", "networking", "reliability"], "tokenized": ["web performance", "web sites", "networking", "reliability"]}, "absent_kps": {"text": ["web infrastructure"], "tokenized": ["web infrastructure"]}}
{"id": 326, "title": {"text": "the culture of usability .", "tokenized": "the culture of usability ."}, "abstract": {"text": "site development , it ' s time to recognize that the standard approach falls short . it is possible to do less work and get better results while spending less money . by bringing usability testing in house and breaking tests into more manageable sessions , you can vastly improve your online offering without affecting your profit margin", "tokenized": "site development , it ' s time to recognize that the standard approach falls short . it is possible to do less work and get better results while spending less money . by bringing usability testing in house and breaking tests into more manageable sessions , you can vastly improve your online offering without affecting your profit margin"}, "present_kps": {"text": [], "tokenized": []}, "absent_kps": {"text": ["usability testing program", "web site"], "tokenized": ["usability testing program", "web site"]}}
{"id": 327, "title": {"text": "debugging web applications .", "tokenized": "debugging web applications ."}, "abstract": {"text": "applications by arming yourself with the right tools and programming practices . a wide variety of debugging tools have been written with web developers in mind", "tokenized": "applications by arming yourself with the right tools and programming practices . a wide variety of debugging tools have been written with web developers in mind"}, "present_kps": {"text": ["programming"], "tokenized": ["programming"]}, "absent_kps": {"text": ["web application debugging tools"], "tokenized": ["web application debugging tools"]}}
{"id": 328, "title": {"text": "unsafe at any speed .", "tokenized": "unsafe at any speed ."}, "abstract": {"text": "takes a looser approach . its c language incorporates c like concepts , including pointers and memory management . but is unsafe code really a boon to programmers , or is it a step backward", "tokenized": "takes a looser approach . its c language incorporates c like concepts , including pointers and memory management . but is unsafe code really a boon to programmers , or is it a step backward"}, "present_kps": {"text": ["c like concepts", "pointers", "memory management"], "tokenized": ["c like concepts", "pointers", "memory management"]}, "absent_kps": {"text": ["microsoft c language", "sun java secure sandbox programming model"], "tokenized": ["microsoft c language", "sun java secure sandbox programming model"]}}
{"id": 329, "title": {"text": "building digital collections at the oac current strategies with a view to .", "tokenized": "building digital collections at the oac current strategies with a view to ."}, "abstract": {"text": "providing a context for the exploration of user defined virtual collections , the article describes the history and recent development of the online archive of california ( oac ) . stating that usability and user needs are primary factors in digital resource development , issues explored include collaborations to build digital collections , reliance upon professional standards for description and encoding , system architecture , interface design , the need for user tools , and the role of archivists as interpreters in the digital environment", "tokenized": "providing a context for the exploration of user defined virtual collections , the article describes the history and recent development of the online archive of california ( oac ) . stating that usability and user needs are primary factors in digital resource development , issues explored include collaborations to build digital collections , reliance upon professional standards for description and encoding , system architecture , interface design , the need for user tools , and the role of archivists as interpreters in the digital environment"}, "present_kps": {"text": ["digital collections", "oac", "user defined virtual collections", "history", "online archive of california", "user needs", "digital resource", "professional standards", "system architecture", "interface design", "user tools", "digital environment"], "tokenized": ["digital collections", "oac", "user defined virtual collections", "history", "online archive of california", "user needs", "digital resource", "professional standards", "system architecture", "interface design", "user tools", "digital environment"]}, "absent_kps": {"text": ["metadata standards", "encoded archival description", "future uses", "archival descriptive standards", "user studies", "best practices"], "tokenized": ["metadata standards", "encoded archival description", "future uses", "archival descriptive standards", "user studies", "best practices"]}}
{"id": 330, "title": {"text": "nuts and bolts implementing descriptive standards to enable virtual .", "tokenized": "nuts and bolts implementing descriptive standards to enable virtual ."}, "abstract": {"text": "to date , online archival information systems have relied heavily on legacy finding aids for data to encode and provide to end users , despite fairly strong indications in the archival literature that such legacy data is problematic even as a mediated access tool . archivists have only just begun to study the utility of archival descriptive data for end users in unmediated settings such as via the web . the ability of future archival information systems to respond to the expectations and needs of end users is inextricably linked to archivists getting their collective data house in order . the general international standard archival description ( isad ( g ) ) offers the profession a place from which to start extricating ourselves from the idiosyncracies of our legacy data and description practices", "tokenized": "to date , online archival information systems have relied heavily on legacy finding aids for data to encode and provide to end users , despite fairly strong indications in the archival literature that such legacy data is problematic even as a mediated access tool . archivists have only just begun to study the utility of archival descriptive data for end users in unmediated settings such as via the web . the ability of future archival information systems to respond to the expectations and needs of end users is inextricably linked to archivists getting their collective data house in order . the general international standard archival description ( isad ( g ) ) offers the profession a place from which to start extricating ourselves from the idiosyncracies of our legacy data and description practices"}, "present_kps": {"text": ["descriptive standards", "online archival information systems", "archival information systems", "end users", "archival literature", "legacy data", "mediated access tool", "archivists", "archival descriptive data", "collective data house", "general international standard archival description", "isad"], "tokenized": ["descriptive standards", "online archival information systems", "archival information systems", "end users", "archival literature", "legacy data", "mediated access tool", "archivists", "archival descriptive data", "collective data house", "general international standard archival description", "isad"]}, "absent_kps": {"text": ["online archive of california", "virtual collections", "oac"], "tokenized": ["online archive of california", "virtual collections", "oac"]}}
{"id": 331, "title": {"text": "learning weights for the quasi weighted means .", "tokenized": "learning weights for the quasi weighted means ."}, "abstract": {"text": "quasi linear means ) when a set of examples is given . we consider first a simple case , the learning of weights for weighted means , and then we extend the approach to the more general case of a quasi weighted mean . we consider the case of a known arbitrary generator f . the paper finishes considering the use of parametric functions that are suitable when the values to aggregate are measure values or ratio", "tokenized": "quasi linear means ) when a set of examples is given . we consider first a simple case , the learning of weights for weighted means , and then we extend the approach to the more general case of a quasi weighted mean . we consider the case of a known arbitrary generator f . the paper finishes considering the use of parametric functions that are suitable when the values to aggregate are measure values or ratio"}, "present_kps": {"text": ["learning", "quasi weighted means", "quasi linear means", "parametric functions", "measure values"], "tokenized": ["learning", "quasi weighted means", "quasi linear means", "parametric functions", "measure values"]}, "absent_kps": {"text": ["ratio values"], "tokenized": ["ratio values"]}}
{"id": 332, "title": {"text": "prospecting virtual collections .", "tokenized": "prospecting virtual collections ."}, "abstract": {"text": "digital archives . archivists and curators as archivists and curators do not construct virtual collections rather they enable virtual collections through the application of descriptive and other standards . virtual collections are constructed by end users", "tokenized": "digital archives . archivists and curators as archivists and curators do not construct virtual collections rather they enable virtual collections through the application of descriptive and other standards . virtual collections are constructed by end users"}, "present_kps": {"text": ["virtual collections", "digital archives", "digitization", "archivists", "curators", "end users"], "tokenized": ["virtual collections", "digital archives", "digitization", "archivists", "curators", "end users"]}, "absent_kps": {"text": ["descriptive standards", "digital collections"], "tokenized": ["descriptive standards", "digital collections"]}}
{"id": 333, "title": {"text": "union outreach a pilgrim ' s progress .", "tokenized": "union outreach a pilgrim ' s progress ."}, "abstract": {"text": "rejuvenation , archivists are challenged to ensure that the organizational , political , and cultural changes labor unions are experiencing are fully documented . the article examines the need for labor archivists to reach out actively to unions and the problems they face in getting their message across , not only to union leadership but also to union members . outreach by labor archivists is vital on three critical fronts the need to secure union funding in support of labor archival programs obtaining union cooperation in reviewing and amending obsolete deposit agreements and coordinating efforts with unions to save the records of closing district and local union offices . attempting to resolve these outstanding issues , labor archivists are pulled between two distinct institutional cultures ( one academic in nature , the other enmeshed in a union bureaucracy ) and often have their own labor archival programs compromised by the internal dynamics and politics inherent in administering large academic libraries and unions . if labor archivists are to be successful , they must find their collective voice within the labor movement and establish their relevancy to unions during a period of momentous change and restructuring . moreover , archivists need to give greater thought to designing and implementing outreach programs that bridge the fundamental disconnect between union bureaucracies and the rank and file , and unions and the public", "tokenized": "rejuvenation , archivists are challenged to ensure that the organizational , political , and cultural changes labor unions are experiencing are fully documented . the article examines the need for labor archivists to reach out actively to unions and the problems they face in getting their message across , not only to union leadership but also to union members . outreach by labor archivists is vital on three critical fronts the need to secure union funding in support of labor archival programs obtaining union cooperation in reviewing and amending obsolete deposit agreements and coordinating efforts with unions to save the records of closing district and local union offices . attempting to resolve these outstanding issues , labor archivists are pulled between two distinct institutional cultures ( one academic in nature , the other enmeshed in a union bureaucracy ) and often have their own labor archival programs compromised by the internal dynamics and politics inherent in administering large academic libraries and unions . if labor archivists are to be successful , they must find their collective voice within the labor movement and establish their relevancy to unions during a period of momentous change and restructuring . moreover , archivists need to give greater thought to designing and implementing outreach programs that bridge the fundamental disconnect between union bureaucracies and the rank and file , and unions and the public"}, "present_kps": {"text": ["archivists", "cultural changes", "labor unions", "labor archivists", "union leadership", "union members", "union funding", "labor archival programs", "union cooperation", "obsolete deposit agreements", "union offices", "institutional cultures", "union bureaucracy", "internal dynamics", "large academic libraries", "collective voice"], "tokenized": ["archivists", "cultural changes", "labor unions", "labor archivists", "union leadership", "union members", "union funding", "labor archival programs", "union cooperation", "obsolete deposit agreements", "union offices", "institutional cultures", "union bureaucracy", "internal dynamics", "large academic libraries", "collective voice"]}, "absent_kps": {"text": ["political changes", "american labor movement"], "tokenized": ["political changes", "american labor movement"]}}
{"id": 334, "title": {"text": "the impact of ead adoption on archival programs a pilot survey of early .", "tokenized": "the impact of ead adoption on archival programs a pilot survey of early ."}, "abstract": {"text": "the article reports the results of a survey conducted to assess the impact that the implementation of encoded archival description ( ead ) has on archival programs . by gathering data related to the funding , staffing , and evaluation of ead programs and about institutional goals for ead implementation , the study explored how ead has affected the operations of the institutions which are utilizing it and the extent to which ead has become a part of regular repository functions", "tokenized": "the article reports the results of a survey conducted to assess the impact that the implementation of encoded archival description ( ead ) has on archival programs . by gathering data related to the funding , staffing , and evaluation of ead programs and about institutional goals for ead implementation , the study explored how ead has affected the operations of the institutions which are utilizing it and the extent to which ead has become a part of regular repository functions"}, "present_kps": {"text": ["ead adoption", "archival programs", "encoded archival description", "funding", "staffing", "ead programs", "institutional goals", "ead implementation", "regular repository functions"], "tokenized": ["ead adoption", "archival programs", "encoded archival description", "funding", "staffing", "ead programs", "institutional goals", "ead implementation", "regular repository functions"]}, "absent_kps": {"text": ["diffusion of innovation", "archival descriptive standards"], "tokenized": ["diffusion of innovation", "archival descriptive standards"]}}
{"id": 335, "title": {"text": "k [digit] instruction and digital access to archival materials .", "tokenized": "k [digit] instruction and digital access to archival materials ."}, "abstract": {"text": "both student learning and archival practice , although it can not replace direct physical access to records . the article compares a variety of electronic and nonelectronic projects to promote teaching with primary source materials . the article also examines some of the different historiographical and pedagogical approaches used in archival web sites geared for k [digit] instruction , focusing on differences between the educational sites sponsored by the library of congress and the national archives and records administration", "tokenized": "both student learning and archival practice , although it can not replace direct physical access to records . the article compares a variety of electronic and nonelectronic projects to promote teaching with primary source materials . the article also examines some of the different historiographical and pedagogical approaches used in archival web sites geared for k [digit] instruction , focusing on differences between the educational sites sponsored by the library of congress and the national archives and records administration"}, "present_kps": {"text": ["k [digit] instruction", "digital access", "archival materials", "student learning", "archival practice", "direct physical access", "nonelectronic projects", "primary source materials", "pedagogical approaches", "archival web", "educational sites", "library of congress", "national archives and records administration"], "tokenized": ["k [digit] instruction", "digital access", "archival materials", "student learning", "archival practice", "direct physical access", "nonelectronic projects", "primary source materials", "pedagogical approaches", "archival web", "educational sites", "library of congress", "national archives and records administration"]}, "absent_kps": {"text": ["electronic projects", "historiographical approaches"], "tokenized": ["electronic projects", "historiographical approaches"]}}
{"id": 336, "title": {"text": "the archival imagination of david bearman , revisited .", "tokenized": "the archival imagination of david bearman , revisited ."}, "abstract": {"text": "david bearman as avant garde . archivist l . henry ( [digit] ) has sharply criticized bearman for being irreverent toward the archival theory and practice outlined by classical american archivist t . r . schellenberg . although bearman is sometimes credited ( and sometimes berated ) for establishing a new paradigm centered on the archival management of electronic records , his methods and strategies are intended to encompass all forms of record keeping . the article provides general observations on bearman ' s archival imagination , lists some of its components , and addresses elements of henry ' s critique . although the long lasting impact of bearman ' s imagination upon the archival profession might be questioned , it nonetheless deserves continued consideration by archivists and inclusion as a component of graduate archival education", "tokenized": "david bearman as avant garde . archivist l . henry ( [digit] ) has sharply criticized bearman for being irreverent toward the archival theory and practice outlined by classical american archivist t . r . schellenberg . although bearman is sometimes credited ( and sometimes berated ) for establishing a new paradigm centered on the archival management of electronic records , his methods and strategies are intended to encompass all forms of record keeping . the article provides general observations on bearman ' s archival imagination , lists some of its components , and addresses elements of henry ' s critique . although the long lasting impact of bearman ' s imagination upon the archival profession might be questioned , it nonetheless deserves continued consideration by archivists and inclusion as a component of graduate archival education"}, "present_kps": {"text": ["archival imagination", "david bearman", "archival theory", "classical american archivist", "schellenberg", "archival management", "electronic records", "record keeping", "archival profession", "graduate archival education"], "tokenized": ["archival imagination", "david bearman", "archival theory", "classical american archivist", "schellenberg", "archival management", "electronic records", "record keeping", "archival profession", "graduate archival education"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 337, "title": {"text": "pattern recognition strategies for molecular surfaces . ii . surface .", "tokenized": "pattern recognition strategies for molecular surfaces . ii . surface ."}, "abstract": {"text": "for pt . i see ibid . , vol . [digit] , p . [digit] [digit] ( [digit] ) . fuzzy logic based algorithms for the quantitative treatment of complementarity of molecular surfaces are presented . therein , the overlapping surface patches defined in part i of this series are used . the identification of complementary surface patches can be considered as a first step for the solution of molecular docking problems . standard technologies can then be used for further optimization of the resulting complex structures . the algorithms are applied to [digit] biomolecular complexes . after the optimization with a downhill simplex method , for all these complexes one structure was found , which is in very good agreement with the experimental results", "tokenized": "for pt . i see ibid . , vol . [digit] , p . [digit] [digit] ( [digit] ) . fuzzy logic based algorithms for the quantitative treatment of complementarity of molecular surfaces are presented . therein , the overlapping surface patches defined in part i of this series are used . the identification of complementary surface patches can be considered as a first step for the solution of molecular docking problems . standard technologies can then be used for further optimization of the resulting complex structures . the algorithms are applied to [digit] biomolecular complexes . after the optimization with a downhill simplex method , for all these complexes one structure was found , which is in very good agreement with the experimental results"}, "present_kps": {"text": ["pattern recognition strategies", "molecular surfaces", "fuzzy logic based algorithms", "quantitative treatment", "overlapping surface", "optimization", "biomolecular complexes", "downhill simplex method"], "tokenized": ["pattern recognition strategies", "molecular surfaces", "fuzzy logic based algorithms", "quantitative treatment", "overlapping surface", "optimization", "biomolecular complexes", "downhill simplex method"]}, "absent_kps": {"text": ["surface complementarity"], "tokenized": ["surface complementarity"]}}
{"id": 338, "title": {"text": "pattern recognition strategies for molecular surfaces . i . pattern generation .", "tokenized": "pattern recognition strategies for molecular surfaces . i . pattern generation ."}, "abstract": {"text": "a new method for the characterization of molecules based on the model approach of molecular surfaces is presented . we use the topographical properties of the surface as well as the electrostatic potential , the local lipophilicity hydrophilicity , and the hydrogen bond density on the surface for characterization . the definition and the calculation method for these properties are reviewed . the surface is segmented into overlapping patches with similar molecular properties . these patches can be used to represent the characteristic local features of the molecule in a way that is beyond the atomistic resolution but can nevertheless be applied for the analysis of partial similarities of different molecules as well as for the identification of molecular complementarity in a very general sense . the patch representation can be used for different applications , which will be demonstrated in subsequent articles", "tokenized": "a new method for the characterization of molecules based on the model approach of molecular surfaces is presented . we use the topographical properties of the surface as well as the electrostatic potential , the local lipophilicity hydrophilicity , and the hydrogen bond density on the surface for characterization . the definition and the calculation method for these properties are reviewed . the surface is segmented into overlapping patches with similar molecular properties . these patches can be used to represent the characteristic local features of the molecule in a way that is beyond the atomistic resolution but can nevertheless be applied for the analysis of partial similarities of different molecules as well as for the identification of molecular complementarity in a very general sense . the patch representation can be used for different applications , which will be demonstrated in subsequent articles"}, "present_kps": {"text": ["pattern recognition strategies", "molecular surfaces", "pattern generation", "model approach", "topographical properties", "electrostatic potential", "local lipophilicity hydrophilicity", "lipophilicity", "hydrophilicity", "hydrogen bond density", "overlapping patches", "molecular properties", "local features", "atomistic resolution", "partial similarities", "molecular complementarity", "patch representation"], "tokenized": ["pattern recognition strategies", "molecular surfaces", "pattern generation", "model approach", "topographical properties", "electrostatic potential", "local lipophilicity hydrophilicity", "lipophilicity", "hydrophilicity", "hydrogen bond density", "overlapping patches", "molecular properties", "local features", "atomistic resolution", "partial similarities", "molecular complementarity", "patch representation"]}, "absent_kps": {"text": ["segmented surface", "fuzzy set theory"], "tokenized": ["segmented surface", "fuzzy set theory"]}}
{"id": 339, "title": {"text": "an efficient parallel algorithm for the calculation of canonical mp2 energies .", "tokenized": "an efficient parallel algorithm for the calculation of canonical mp2 energies ."}, "abstract": {"text": "efficient calculation of canonical mp2 energies . it is based on the saebo almlof direct integral transformation , coupled with an efficient prescreening of the ao integrals . the parallel algorithm avoids synchronization delays by spawning a second set of slaves during the bin sort prior to the second half transformation . results are presented for systems with up to [digit] basis functions . mp2 energies for molecules with [digit] [digit] basis functions can be routinely calculated to microhartree accuracy on a small number of processors ( [digit] [digit] ) in a matter of minutes with modern pc based parallel computers", "tokenized": "efficient calculation of canonical mp2 energies . it is based on the saebo almlof direct integral transformation , coupled with an efficient prescreening of the ao integrals . the parallel algorithm avoids synchronization delays by spawning a second set of slaves during the bin sort prior to the second half transformation . results are presented for systems with up to [digit] basis functions . mp2 energies for molecules with [digit] [digit] basis functions can be routinely calculated to microhartree accuracy on a small number of processors ( [digit] [digit] ) in a matter of minutes with modern pc based parallel computers"}, "present_kps": {"text": ["parallel algorithm", "canonical mp2 energies", "mp2 energies", "saebo almlof direct integral transformation", "ao integrals", "synchronization delays", "second half transformation", "basis functions", "microhartree accuracy", "pc based parallel computers"], "tokenized": ["parallel algorithm", "canonical mp2 energies", "mp2 energies", "saebo almlof direct integral transformation", "ao integrals", "synchronization delays", "second half transformation", "basis functions", "microhartree accuracy", "pc based parallel computers"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 340, "title": {"text": "a method for correlations analysis of coordinates applications for molecular .", "tokenized": "a method for correlations analysis of coordinates applications for molecular ."}, "abstract": {"text": "we describe a new method to analyze multiple correlations between subsets of coordinates that represent a sample . the correlation is established only between specific regions of interest at the coordinates . first , the region ( s ) of interest are selected at each molecular coordinate . next , a correlation matrix is constructed for the selected regions . the matrix is subject to further analysis , illuminating the multidimensional structural characteristics that exist in the conformational space . the method ' s abilities are demonstrated in several examples it is used to analyze the conformational space of complex molecules , it is successfully applied to compare related conformational spaces , and it is used to analyze a diverse set of protein folding trajectories", "tokenized": "we describe a new method to analyze multiple correlations between subsets of coordinates that represent a sample . the correlation is established only between specific regions of interest at the coordinates . first , the region ( s ) of interest are selected at each molecular coordinate . next , a correlation matrix is constructed for the selected regions . the matrix is subject to further analysis , illuminating the multidimensional structural characteristics that exist in the conformational space . the method ' s abilities are demonstrated in several examples it is used to analyze the conformational space of complex molecules , it is successfully applied to compare related conformational spaces , and it is used to analyze a diverse set of protein folding trajectories"}, "present_kps": {"text": ["regions of interest", "molecular coordinate", "correlation matrix", "multidimensional structural characteristics", "conformational spaces", "complex molecules", "protein folding trajectories"], "tokenized": ["regions of interest", "molecular coordinate", "correlation matrix", "multidimensional structural characteristics", "conformational spaces", "complex molecules", "protein folding trajectories"]}, "absent_kps": {"text": ["molecular conformations", "multiple correlation analysis"], "tokenized": ["molecular conformations", "multiple correlation analysis"]}}
{"id": 341, "title": {"text": "genetic algorithm guided selection variable selection and subset selection .", "tokenized": "genetic algorithm guided selection variable selection and subset selection ."}, "abstract": {"text": "method utilizes a simple encoding scheme which can represent both compounds and variables used to construct a qsar qspr model . a genetic algorithm is then utilized to simultaneously optimize the encoded variables that include both descriptors and compound subsets . the gas method generates multiple models each applying to a subset of the compounds . typically the subsets represent clusters with different chemotypes . also a procedure based on molecular similarity is presented to determine which model should be applied to a given test set compound . the variable selection method implemented in gas has been tested and compared using the selwood data set ( n [digit] compounds nu [digit] descriptors ) . the results showed that the method is comparable to other published methods . the subset selection method implemented in gas has been first tested using an artificial data set ( n [digit] points nu [digit] descriptor ) to examine its ability to subset data points and second applied to analyze the xlogp data set ( n [digit] compounds nu [digit] descriptors ) . the method is able to correctly identify artificial data points belonging to various subsets . the analysis of the xlogp data set shows that the subset selection method can be useful in improving a qsar qspr model when the variable selection method fails", "tokenized": "method utilizes a simple encoding scheme which can represent both compounds and variables used to construct a qsar qspr model . a genetic algorithm is then utilized to simultaneously optimize the encoded variables that include both descriptors and compound subsets . the gas method generates multiple models each applying to a subset of the compounds . typically the subsets represent clusters with different chemotypes . also a procedure based on molecular similarity is presented to determine which model should be applied to a given test set compound . the variable selection method implemented in gas has been tested and compared using the selwood data set ( n [digit] compounds nu [digit] descriptors ) . the results showed that the method is comparable to other published methods . the subset selection method implemented in gas has been first tested using an artificial data set ( n [digit] points nu [digit] descriptor ) to examine its ability to subset data points and second applied to analyze the xlogp data set ( n [digit] compounds nu [digit] descriptors ) . the method is able to correctly identify artificial data points belonging to various subsets . the analysis of the xlogp data set shows that the subset selection method can be useful in improving a qsar qspr model when the variable selection method fails"}, "present_kps": {"text": ["variable selection", "variables", "subset selection", "encoding scheme", "compounds", "qsar qspr model", "optimization", "descriptors", "compound subsets", "multiple models", "clusters", "chemotypes", "molecular similarity", "selwood data set", "xlogp data set", "artificial data points"], "tokenized": ["variable selection", "variables", "subset selection", "encoding scheme", "compounds", "qsar qspr model", "optimization", "descriptors", "compound subsets", "multiple models", "clusters", "chemotypes", "molecular similarity", "selwood data set", "xlogp data set", "artificial data points"]}, "absent_kps": {"text": ["genetic algorithm guided selection method"], "tokenized": ["genetic algorithm guided selection method"]}}
{"id": 342, "title": {"text": "a formal model of computing with words .", "tokenized": "a formal model of computing with words ."}, "abstract": {"text": "are generalizations of classical automata where the knowledge about the system ' s next state is vague or uncertain . it is worth noting that like classical automata , fuzzy automata can only process strings of input symbols . therefore , such fuzzy automata are still ( abstract ) devices for computing with values , although a certain vagueness or uncertainty are involved in the process of computation . we introduce a new kind of fuzzy automata whose inputs are instead strings of fuzzy subsets of the input alphabet . these new fuzzy automata may serve as formal models of computing with words . we establish an extension principle from computing with values to computing with words . this principle indicates that computing with words can be implemented with computing with values with the price of a big amount of extra computations", "tokenized": "are generalizations of classical automata where the knowledge about the system ' s next state is vague or uncertain . it is worth noting that like classical automata , fuzzy automata can only process strings of input symbols . therefore , such fuzzy automata are still ( abstract ) devices for computing with values , although a certain vagueness or uncertainty are involved in the process of computation . we introduce a new kind of fuzzy automata whose inputs are instead strings of fuzzy subsets of the input alphabet . these new fuzzy automata may serve as formal models of computing with words . we establish an extension principle from computing with values to computing with words . this principle indicates that computing with words can be implemented with computing with values with the price of a big amount of extra computations"}, "present_kps": {"text": ["formal model", "computing with words", "fuzzy automata", "fuzzy subsets", "input alphabet", "extension principle"], "tokenized": ["formal model", "computing with words", "fuzzy automata", "fuzzy subsets", "input alphabet", "extension principle"]}, "absent_kps": {"text": ["pushdown automata"], "tokenized": ["pushdown automata"]}}
{"id": 343, "title": {"text": "using molecular equivalence numbers to visually explore structural features .", "tokenized": "using molecular equivalence numbers to visually explore structural features ."}, "abstract": {"text": "a molecular equivalence number ( meqnum ) classifies a molecule with respect to a class of structural features or topological shapes such as its cyclic system or its set of functional groups . meqnums can be used to organize molecular structures into nonoverlapping , yet highly relatable classes . we illustrate the construction of some different types of meqnums and present via examples some methods of comparing diverse chemical libraries based on meqnums . in the examples we compare a library which is a random sample from the mdl drug data report ( mddr ) with a library which is a random sample from the available chemical directory ( acd ) . in our analyses , we discover some interesting features of the topological shape of a molecule and its set of functional groups that are strongly linked with compounds occurring in the mddr but not in the acd . we also illustrate the utility of molecular equivalence indices in delineating the structural domain over which an sar conclusion is valid", "tokenized": "a molecular equivalence number ( meqnum ) classifies a molecule with respect to a class of structural features or topological shapes such as its cyclic system or its set of functional groups . meqnums can be used to organize molecular structures into nonoverlapping , yet highly relatable classes . we illustrate the construction of some different types of meqnums and present via examples some methods of comparing diverse chemical libraries based on meqnums . in the examples we compare a library which is a random sample from the mdl drug data report ( mddr ) with a library which is a random sample from the available chemical directory ( acd ) . in our analyses , we discover some interesting features of the topological shape of a molecule and its set of functional groups that are strongly linked with compounds occurring in the mddr but not in the acd . we also illustrate the utility of molecular equivalence indices in delineating the structural domain over which an sar conclusion is valid"}, "present_kps": {"text": ["molecular equivalence number", "structural features", "topological shapes", "cyclic system", "functional groups", "chemical libraries", "mdl drug data report", "available chemical directory", "molecular equivalence indices"], "tokenized": ["molecular equivalence number", "structural features", "topological shapes", "cyclic system", "functional groups", "chemical libraries", "mdl drug data report", "available chemical directory", "molecular equivalence indices"]}, "absent_kps": {"text": ["nonoverlapping relatable classes", "molecule classification"], "tokenized": ["nonoverlapping relatable classes", "molecule classification"]}}
{"id": 344, "title": {"text": "on the use of neural network ensembles in qsar and qspr .", "tokenized": "on the use of neural network ensembles in qsar and qspr ."}, "abstract": {"text": "methods have not been widely adopted in structure activity and structure property correlation . neural networks are inherently unstable , in that small changes in the training set and or training parameters can lead to large changes in their generalization performance . recent research has shown that by capitalizing on the diversity of the individual models , ensemble techniques can minimize uncertainty and produce more stable and accurate predictors . in this work , we present a critical assessment of the most common ensemble technique known as bootstrap aggregation , or bagging , as applied to qsar and qspr . although aggregation does offer definitive advantages , we demonstrate that bagging may not be the best possible choice and that simpler techniques such as retraining with the full sample can often produce superior results . these findings are rationalized using krogh and vedelsby ' s ( [digit] ) decomposition of the generalization error into a term that measures the average generalization performance of the individual networks and a term that measures the diversity among them . for networks that are designed to resist over fitting , the benefits of aggregation are clear but not overwhelming", "tokenized": "methods have not been widely adopted in structure activity and structure property correlation . neural networks are inherently unstable , in that small changes in the training set and or training parameters can lead to large changes in their generalization performance . recent research has shown that by capitalizing on the diversity of the individual models , ensemble techniques can minimize uncertainty and produce more stable and accurate predictors . in this work , we present a critical assessment of the most common ensemble technique known as bootstrap aggregation , or bagging , as applied to qsar and qspr . although aggregation does offer definitive advantages , we demonstrate that bagging may not be the best possible choice and that simpler techniques such as retraining with the full sample can often produce superior results . these findings are rationalized using krogh and vedelsby ' s ( [digit] ) decomposition of the generalization error into a term that measures the average generalization performance of the individual networks and a term that measures the diversity among them . for networks that are designed to resist over fitting , the benefits of aggregation are clear but not overwhelming"}, "present_kps": {"text": ["neural network ensembles", "qsar", "qspr", "structure property correlation", "training set", "training parameters", "generalization performance", "uncertainty", "bootstrap aggregation", "bagging", "retraining"], "tokenized": ["neural network ensembles", "qsar", "qspr", "structure property correlation", "training set", "training parameters", "generalization performance", "uncertainty", "bootstrap aggregation", "bagging", "retraining"]}, "absent_kps": {"text": ["structure activity correlation", "generalization error decomposition"], "tokenized": ["structure activity correlation", "generalization error decomposition"]}}
{"id": 345, "title": {"text": "median partitioning a novel method for the selection of representative subsets .", "tokenized": "median partitioning a novel method for the selection of representative subsets ."}, "abstract": {"text": "a method termed median partitioning ( mp ) has been developed to select diverse sets of molecules from large compound pools . unlike many other methods for subset selection , the mp approach does not depend on pairwise comparison of molecules and can therefore be applied to very large compound collections . the only time limiting step is the calculation of molecular descriptors for database compounds . mp employs arrays of property descriptors with little correlation to divide large compound pools into partitions from which representative molecules can be selected . in each of n subsequent steps , a population of molecules is divided into subpopulations above and below the median value of a property descriptor until a desired number of [digit] sup n partitions are obtained . for descriptor evaluation and selection , an entropy formulation was embedded in a genetic algorithm . mp has been applied to generate a subset of the available chemicals directory , and the results have been compared with cell based partitioning", "tokenized": "a method termed median partitioning ( mp ) has been developed to select diverse sets of molecules from large compound pools . unlike many other methods for subset selection , the mp approach does not depend on pairwise comparison of molecules and can therefore be applied to very large compound collections . the only time limiting step is the calculation of molecular descriptors for database compounds . mp employs arrays of property descriptors with little correlation to divide large compound pools into partitions from which representative molecules can be selected . in each of n subsequent steps , a population of molecules is divided into subpopulations above and below the median value of a property descriptor until a desired number of [digit] sup n partitions are obtained . for descriptor evaluation and selection , an entropy formulation was embedded in a genetic algorithm . mp has been applied to generate a subset of the available chemicals directory , and the results have been compared with cell based partitioning"}, "present_kps": {"text": ["median partitioning", "molecules", "large compound pools", "time limiting step", "molecular descriptors", "database compounds", "entropy formulation", "genetic algorithm", "available chemicals directory", "cell based partitioning"], "tokenized": ["median partitioning", "molecules", "large compound pools", "time limiting step", "molecular descriptors", "database compounds", "entropy formulation", "genetic algorithm", "available chemicals directory", "cell based partitioning"]}, "absent_kps": {"text": ["property descriptor array", "representative subset selection"], "tokenized": ["property descriptor array", "representative subset selection"]}}
{"id": 346, "title": {"text": "chemical information based scaling of molecular descriptors a universal .", "tokenized": "chemical information based scaling of molecular descriptors a universal ."}, "abstract": {"text": "scaling is a difficult issue for any analysis of chemical properties or molecular topology when disparate descriptors are involved . to compare properties across different data sets , a common scale must be defined . using several publicly available databases ( acd , cmc , mddr , and nci ) as a basis , we propose to define chemically meaningful scales for a number of molecular properties and topology descriptors . these chemically derived scaling functions have several advantages . first , it is possible to define chemically relevant scales , greatly simplifying similarity and diversity analyses across data sets . second , this approach provides a convenient method for setting descriptor boundaries that define chemically reasonable topology spaces . for example , descriptors can be scaled so that compounds with little potential for biological activity , bioavailability , or other drug like characteristics are easily identified as outliers . we have compiled scaling values for [digit] molecular descriptors . in addition the 10th and 90th percentile values for each descriptor have been calculated for use in outlier filtering", "tokenized": "scaling is a difficult issue for any analysis of chemical properties or molecular topology when disparate descriptors are involved . to compare properties across different data sets , a common scale must be defined . using several publicly available databases ( acd , cmc , mddr , and nci ) as a basis , we propose to define chemically meaningful scales for a number of molecular properties and topology descriptors . these chemically derived scaling functions have several advantages . first , it is possible to define chemically relevant scales , greatly simplifying similarity and diversity analyses across data sets . second , this approach provides a convenient method for setting descriptor boundaries that define chemically reasonable topology spaces . for example , descriptors can be scaled so that compounds with little potential for biological activity , bioavailability , or other drug like characteristics are easily identified as outliers . we have compiled scaling values for [digit] molecular descriptors . in addition the 10th and 90th percentile values for each descriptor have been calculated for use in outlier filtering"}, "present_kps": {"text": ["chemical information based scaling", "molecular descriptors", "chemical properties", "molecular topology", "data sets", "databases", "diversity analyses", "descriptor boundaries", "biological activity", "bioavailability", "drug like characteristics", "outliers"], "tokenized": ["chemical information based scaling", "molecular descriptors", "chemical properties", "molecular topology", "data sets", "databases", "diversity analyses", "descriptor boundaries", "biological activity", "bioavailability", "drug like characteristics", "outliers"]}, "absent_kps": {"text": ["library analysis", "library design", "similarity analyses", "universal chemical scale"], "tokenized": ["library analysis", "library design", "similarity analyses", "universal chemical scale"]}}
{"id": 347, "title": {"text": "mtd pls a pls based variant of the mtd method . ii . mapping ligand receptor .", "tokenized": "mtd pls a pls based variant of the mtd method . ii . mapping ligand receptor ."}, "abstract": {"text": "the pls variant of the mtd method ( t . i . oprea et al . , sar qsar environ . res . [digit] , [digit] , [digit] [digit] ) was applied to a series of [digit] acetylcholinesterase hydrolysis substrates . statistically significant mtd pls models ( q sup [digit] between [digit] . [digit] and [digit] . [digit] ) are in agreement with previous mtd models , with the advantage that local contributions are understood beyond the occupancy nonoccupancy interpretation in mtd . a chemically intuitive approach further forces mtd pls coefficients to assume only negative ( or zero ) values for fragmental volume descriptors and positive ( or zero ) values for fragmental hydrophobicity descriptors . this further separates the various kinds of local interactions at each vertex of the mtd hypermolecule , making this method suitable for medicinal chemistry synthesis planning", "tokenized": "the pls variant of the mtd method ( t . i . oprea et al . , sar qsar environ . res . [digit] , [digit] , [digit] [digit] ) was applied to a series of [digit] acetylcholinesterase hydrolysis substrates . statistically significant mtd pls models ( q sup [digit] between [digit] . [digit] and [digit] . [digit] ) are in agreement with previous mtd models , with the advantage that local contributions are understood beyond the occupancy nonoccupancy interpretation in mtd . a chemically intuitive approach further forces mtd pls coefficients to assume only negative ( or zero ) values for fragmental volume descriptors and positive ( or zero ) values for fragmental hydrophobicity descriptors . this further separates the various kinds of local interactions at each vertex of the mtd hypermolecule , making this method suitable for medicinal chemistry synthesis planning"}, "present_kps": {"text": ["pls based variant", "acetylcholinesterase hydrolysis substrates", "mtd pls models", "chemically intuitive approach", "fragmental volume descriptors", "fragmental hydrophobicity descriptors", "hypermolecule", "medicinal chemistry synthesis planning"], "tokenized": ["pls based variant", "acetylcholinesterase hydrolysis substrates", "mtd pls models", "chemically intuitive approach", "fragmental volume descriptors", "fragmental hydrophobicity descriptors", "hypermolecule", "medicinal chemistry synthesis planning"]}, "absent_kps": {"text": ["hydrogen bonding", "ligand receptor interactions mapping", "minimum topological difference method", "steric misfit", "additive approach", "ligand binding affinity", "regression coefficients", "intermolecular force categories", "enzymatic acetic acid esters hydrolysis", "statistical model stability", "polarizabilities"], "tokenized": ["hydrogen bonding", "ligand receptor interactions mapping", "minimum topological difference method", "steric misfit", "additive approach", "ligand binding affinity", "regression coefficients", "intermolecular force categories", "enzymatic acetic acid esters hydrolysis", "statistical model stability", "polarizabilities"]}}
{"id": 348, "title": {"text": "prediction of ultraviolet spectral absorbance using quantitative .", "tokenized": "prediction of ultraviolet spectral absorbance using quantitative ."}, "abstract": {"text": "high performance liquid chromatography ( hplc ) with ultraviolet ( uv ) spectrophotometric detection is a common method for analyzing reaction products in organic chemistry . this procedure would benefit from a computational model for predicting the relative response of organic molecules . models are now reported for the prediction of the integrated uv absorbance for a diverse set of organic compounds using a quantitative structure property relationship ( qspr ) approach . a seven descriptor linear correlation with a squared correlation coefficient ( r sup [digit] ) of [digit] . [digit] is reported for a data set of [digit] . compounds . using the sum of zindo oscillator strengths in the integration range as an additional descriptor allowed reduction in the number of descriptors producing a robust model for [digit] compounds with five descriptors and a squared correlation coefficient [digit] . [digit] . the descriptors used in the models are discussed with respect to the physical nature of the uv absorption process", "tokenized": "high performance liquid chromatography ( hplc ) with ultraviolet ( uv ) spectrophotometric detection is a common method for analyzing reaction products in organic chemistry . this procedure would benefit from a computational model for predicting the relative response of organic molecules . models are now reported for the prediction of the integrated uv absorbance for a diverse set of organic compounds using a quantitative structure property relationship ( qspr ) approach . a seven descriptor linear correlation with a squared correlation coefficient ( r sup [digit] ) of [digit] . [digit] is reported for a data set of [digit] . compounds . using the sum of zindo oscillator strengths in the integration range as an additional descriptor allowed reduction in the number of descriptors producing a robust model for [digit] compounds with five descriptors and a squared correlation coefficient [digit] . [digit] . the descriptors used in the models are discussed with respect to the physical nature of the uv absorption process"}, "present_kps": {"text": ["high performance liquid chromatography", "reaction products", "organic chemistry", "computational model", "relative response", "quantitative structure property relationship", "seven descriptor linear correlation", "squared correlation coefficient", "zindo oscillator strengths"], "tokenized": ["high performance liquid chromatography", "reaction products", "organic chemistry", "computational model", "relative response", "quantitative structure property relationship", "seven descriptor linear correlation", "squared correlation coefficient", "zindo oscillator strengths"]}, "absent_kps": {"text": ["configuration interaction calculation", "codessa program", "ultraviolet spectral absorbance prediction", "combinatorial chemistry", "generic quantitation", "mos f package", "ultraviolet spectrophotometric detection"], "tokenized": ["configuration interaction calculation", "codessa program", "ultraviolet spectral absorbance prediction", "combinatorial chemistry", "generic quantitation", "mos f package", "ultraviolet spectrophotometric detection"]}}
{"id": 349, "title": {"text": "assessment of the macrocyclic effect for the complexation of crown ethers with .", "tokenized": "assessment of the macrocyclic effect for the complexation of crown ethers with ."}, "abstract": {"text": "the substructural molecular fragments method ( solov ' ev , v . p . varnek , a . a . wipff , g . j . chem . inf . comput . sci . [digit] , [digit] , [digit] [digit] ) was applied to assess stability constants ( logk ) of the complexes of crown ethers , polyethers , and glymes with na sup , k sup , and cs sup in methanol . one hundred forty seven computational models including different fragment sets coupled with linear or nonlinear fitting equations were applied for the data sets containing [digit] ( na sup ) , [digit] ( k sup ) , and [digit] ( cs sup ) compounds . to account for the macrocyclic effect for crown ethers , an additional cyclicity descriptor was used . predicted stability constants both for macrocyclic compounds and for their open chain analogues are in good agreement with the experimental data reported earlier and with those studied experimentally in this work . the macrocyclic effect as a function of cation and ligand is quantitatively estimated for all studied crown ethers", "tokenized": "the substructural molecular fragments method ( solov ' ev , v . p . varnek , a . a . wipff , g . j . chem . inf . comput . sci . [digit] , [digit] , [digit] [digit] ) was applied to assess stability constants ( logk ) of the complexes of crown ethers , polyethers , and glymes with na sup , k sup , and cs sup in methanol . one hundred forty seven computational models including different fragment sets coupled with linear or nonlinear fitting equations were applied for the data sets containing [digit] ( na sup ) , [digit] ( k sup ) , and [digit] ( cs sup ) compounds . to account for the macrocyclic effect for crown ethers , an additional cyclicity descriptor was used . predicted stability constants both for macrocyclic compounds and for their open chain analogues are in good agreement with the experimental data reported earlier and with those studied experimentally in this work . the macrocyclic effect as a function of cation and ligand is quantitatively estimated for all studied crown ethers"}, "present_kps": {"text": ["macrocyclic effect", "complexation", "crown ethers", "substructural molecular fragments method", "stability constants", "computational models", "different fragment sets", "nonlinear fitting equations", "cyclicity descriptor", "open chain analogues"], "tokenized": ["macrocyclic effect", "complexation", "crown ethers", "substructural molecular fragments method", "stability constants", "computational models", "different fragment sets", "nonlinear fitting equations", "cyclicity descriptor", "open chain analogues"]}, "absent_kps": {"text": ["structure property tool", "data mining", "molecular graph decomposition", "thermodynamic parameters", "trail program", "linear fitting equations", "augmented atom", "quantitative structure properties relationship", "statistical parameters", "alkali cations"], "tokenized": ["structure property tool", "data mining", "molecular graph decomposition", "thermodynamic parameters", "trail program", "linear fitting equations", "augmented atom", "quantitative structure properties relationship", "statistical parameters", "alkali cations"]}}
{"id": 350, "title": {"text": "improving the predicting power of partial order based qsars through linear .", "tokenized": "improving the predicting power of partial order based qsars through linear ."}, "abstract": {"text": "partial order theory ( pot ) is an attractive and operationally simple method that allows ordering of compounds , based on selected structural and or electronic descriptors ( modeled order ) , or based on their end points , e . g . , solubility ( experimental order ) . if the modeled order resembles the experimental order , compounds that are not experimentally investigated can be assigned a position in the model that eventually might lead to a prediction of an end point value . however , in the application of pot in quantitative structure activity relationship modeling , only the compounds directly comparable to the noninvestigated compounds are applied . to explore the possibilities of improving the methodology , the theory is extended by application of the so called linear extensions of the model order . the study show that partial ordering combined with linear extensions appears as a promising tool providing probability distribution curves in the range of possible end point values for compounds not being experimentally investigated", "tokenized": "partial order theory ( pot ) is an attractive and operationally simple method that allows ordering of compounds , based on selected structural and or electronic descriptors ( modeled order ) , or based on their end points , e . g . , solubility ( experimental order ) . if the modeled order resembles the experimental order , compounds that are not experimentally investigated can be assigned a position in the model that eventually might lead to a prediction of an end point value . however , in the application of pot in quantitative structure activity relationship modeling , only the compounds directly comparable to the noninvestigated compounds are applied . to explore the possibilities of improving the methodology , the theory is extended by application of the so called linear extensions of the model order . the study show that partial ordering combined with linear extensions appears as a promising tool providing probability distribution curves in the range of possible end point values for compounds not being experimentally investigated"}, "present_kps": {"text": ["partial order theory", "electronic descriptors", "modeled order", "end points", "solubilities", "quantitative structure activity relationships", "linear extensions"], "tokenized": ["partial order theory", "electronic descriptors", "modeled order", "end points", "solubilities", "quantitative structure activity relationships", "linear extensions"]}, "absent_kps": {"text": ["combinatorial rule", "predicting power improvement", "graphical representation", "structural descriptors", "most probable linear order", "organic compounds", "partially ordered set", "hasse diagram"], "tokenized": ["combinatorial rule", "predicting power improvement", "graphical representation", "structural descriptors", "most probable linear order", "organic compounds", "partially ordered set", "hasse diagram"]}}
{"id": 351, "title": {"text": "novel ze isomerism descriptors derived from molecular topology and their .", "tokenized": "novel ze isomerism descriptors derived from molecular topology and their ."}, "abstract": {"text": "we introduce several series of novel ze isomerism descriptors derived directly from two dimensional molecular topology . these descriptors make use of a quantity named ze isomerism correction , which is added to the vertex degrees of atoms connected by double bonds in z and e configurations . this approach is similar to the one described previously for topological chirality descriptors ( golbraikh , a . , et al . j . chem . inf . comput . sci . [digit] , [digit] , [digit] [digit] ) . the ze isomerism descriptors include modified molecular connectivity indices , overall zagreb indices , extended connectivity , overall connectivity , and topological charge indices . they can be either real or complex numbers . mathematical properties of different subgroups of ze isomerism descriptors are discussed . these descriptors circumvent the inability of conventional topological indices to distinguish between z and e isomers . the applicability of ze isomerism descriptors to qsar analysis is demonstrated in the studies of a series of [digit] anticancer agents inhibiting tubulin polymerization", "tokenized": "we introduce several series of novel ze isomerism descriptors derived directly from two dimensional molecular topology . these descriptors make use of a quantity named ze isomerism correction , which is added to the vertex degrees of atoms connected by double bonds in z and e configurations . this approach is similar to the one described previously for topological chirality descriptors ( golbraikh , a . , et al . j . chem . inf . comput . sci . [digit] , [digit] , [digit] [digit] ) . the ze isomerism descriptors include modified molecular connectivity indices , overall zagreb indices , extended connectivity , overall connectivity , and topological charge indices . they can be either real or complex numbers . mathematical properties of different subgroups of ze isomerism descriptors are discussed . these descriptors circumvent the inability of conventional topological indices to distinguish between z and e isomers . the applicability of ze isomerism descriptors to qsar analysis is demonstrated in the studies of a series of [digit] anticancer agents inhibiting tubulin polymerization"}, "present_kps": {"text": ["ze isomerism descriptors", "two dimensional molecular topology", "ze isomerism correction", "vertex degrees", "modified molecular connectivity indices", "overall zagreb indices", "extended connectivity", "overall connectivity", "topological charge indices", "complex numbers", "qsar analysis", "anticancer agents", "tubulin polymerization"], "tokenized": ["ze isomerism descriptors", "two dimensional molecular topology", "ze isomerism correction", "vertex degrees", "modified molecular connectivity indices", "overall zagreb indices", "extended connectivity", "overall connectivity", "topological charge indices", "complex numbers", "qsar analysis", "anticancer agents", "tubulin polymerization"]}, "absent_kps": {"text": ["double bond connected atoms", "molecular graphs", "descriptor pharmacophore", "combinatorial chemical libraries", "chemical databases", "computer assisted drug design", "toxicities", "quantitative structure activity relationship"], "tokenized": ["double bond connected atoms", "molecular graphs", "descriptor pharmacophore", "combinatorial chemical libraries", "chemical databases", "computer assisted drug design", "toxicities", "quantitative structure activity relationship"]}}
{"id": 352, "title": {"text": "computer mediated communication and university international students .", "tokenized": "computer mediated communication and university international students ."}, "abstract": {"text": "the international students and faculty members of a small southwest university being surveyed and interviewed . the data collection procedure blends qualitative and quantitative data . a strong consensus was found that supports the study ' s premise that there is an association between the use of computer mediated communication ( cmc ) and teaching and learning performance of international students . both groups believe cmc to be an effective teaching and learning tool by increasing the frequency and quality of communication between students and instructors improving language skills through increased writing and communication opportunities allowing students and instructors to stay current and to compete effectively providing alternative teaching and learning methods to increase students ' confidence in their ability to communicate effectively with peers and instructors and improving the instructors ' pedagogical focus and questioning techniques", "tokenized": "the international students and faculty members of a small southwest university being surveyed and interviewed . the data collection procedure blends qualitative and quantitative data . a strong consensus was found that supports the study ' s premise that there is an association between the use of computer mediated communication ( cmc ) and teaching and learning performance of international students . both groups believe cmc to be an effective teaching and learning tool by increasing the frequency and quality of communication between students and instructors improving language skills through increased writing and communication opportunities allowing students and instructors to stay current and to compete effectively providing alternative teaching and learning methods to increase students ' confidence in their ability to communicate effectively with peers and instructors and improving the instructors ' pedagogical focus and questioning techniques"}, "present_kps": {"text": ["computer mediated communication", "university international students", "faculty members", "small southwest university", "data collection procedure", "quantitative data", "cmc", "teaching", "learning performance", "instructors", "language skills", "communication opportunities", "peers", "pedagogical focus", "questioning techniques"], "tokenized": ["computer mediated communication", "university international students", "faculty members", "small southwest university", "data collection procedure", "quantitative data", "cmc", "teaching", "learning performance", "instructors", "language skills", "communication opportunities", "peers", "pedagogical focus", "questioning techniques"]}, "absent_kps": {"text": ["student confidence", "qualitative data"], "tokenized": ["student confidence", "qualitative data"]}}
{"id": 353, "title": {"text": "uncertainty bounds and their use in the design of interval type [digit] fuzzy logic .", "tokenized": "uncertainty bounds and their use in the design of interval type [digit] fuzzy logic ."}, "abstract": {"text": "we derive inner and outer bound sets for the type reduced set of an interval type [digit] fuzzy logic system ( fls ) , based on a new mathematical interpretation of the karnik mendel iterative procedure for computing the type reduced set . the bound sets can not only provide estimates about the uncertainty contained in the output of an interval type [digit] fls , but can also be used to design an interval type [digit] fls . we demonstrate , by means of a simulation experiment , that the resulting system can operate without type reduction and can achieve similar performance to one that uses type reduction . therefore , our new design method , based on the bound sets , can relieve the computation burden of an interval type [digit] fls during its operation , which makes an interval type [digit] fls useful for real time applications", "tokenized": "we derive inner and outer bound sets for the type reduced set of an interval type [digit] fuzzy logic system ( fls ) , based on a new mathematical interpretation of the karnik mendel iterative procedure for computing the type reduced set . the bound sets can not only provide estimates about the uncertainty contained in the output of an interval type [digit] fls , but can also be used to design an interval type [digit] fls . we demonstrate , by means of a simulation experiment , that the resulting system can operate without type reduction and can achieve similar performance to one that uses type reduction . therefore , our new design method , based on the bound sets , can relieve the computation burden of an interval type [digit] fls during its operation , which makes an interval type [digit] fls useful for real time applications"}, "present_kps": {"text": ["uncertainty bounds", "outer bound sets", "type reduced set", "interval type [digit] fuzzy logic systems", "karnik mendel iterative procedure", "real time applications"], "tokenized": ["uncertainty bounds", "outer bound sets", "type reduced set", "interval type [digit] fuzzy logic systems", "karnik mendel iterative procedure", "real time applications"]}, "absent_kps": {"text": ["inner bound sets", "time series forecasting"], "tokenized": ["inner bound sets", "time series forecasting"]}}
{"id": 354, "title": {"text": "entrepreneurs in action a web case model .", "tokenized": "entrepreneurs in action a web case model ."}, "abstract": {"text": "compliance and control , characteristics which stifle the creative and entrepreneurial instincts of the children who are subjected to these tactics . the article explores a different approach to education , one that involves capturing the interest of the student through the use of problem and project based instruction delivered via the internet . called entrepreneurs in action , this program seeks to involve students in a problem at the outset and to promote the learning of traditional subject areas as a process of the problem solving activities that are undertaken . the program ' s details are explained , from elementary school through university level courses , and the authors outline their plans to test the efficacy of the program at each level", "tokenized": "compliance and control , characteristics which stifle the creative and entrepreneurial instincts of the children who are subjected to these tactics . the article explores a different approach to education , one that involves capturing the interest of the student through the use of problem and project based instruction delivered via the internet . called entrepreneurs in action , this program seeks to involve students in a problem at the outset and to promote the learning of traditional subject areas as a process of the problem solving activities that are undertaken . the program ' s details are explained , from elementary school through university level courses , and the authors outline their plans to test the efficacy of the program at each level"}, "present_kps": {"text": ["entrepreneurs in action", "web case model", "entrepreneurial instincts", "project based instruction", "internet", "traditional subject areas", "problem solving activities", "elementary school", "university level courses"], "tokenized": ["entrepreneurs in action", "web case model", "entrepreneurial instincts", "project based instruction", "internet", "traditional subject areas", "problem solving activities", "elementary school", "university level courses"]}, "absent_kps": {"text": ["america", "traditional schooling"], "tokenized": ["america", "traditional schooling"]}}
{"id": 355, "title": {"text": "factors contributing to preservice teachers ' discomfort in a web based course .", "tokenized": "factors contributing to preservice teachers ' discomfort in a web based course ."}, "abstract": {"text": "a report is given of a qualitative emergent design study of a science , technology , society interaction ( sts ) web enhanced course . students ' discomfort during the pilot test provided insight into the intellectual scaffolding that preservice secondary science teachers needed to optimize their performance when required to develop understanding through open ended inquiry in a web environment . eight factors identified contributed to student discomfort computer skills , paradigm shifts , trust , time management , thinking about their own thinking , systematic inquiry , self assessment , and scientific discourse . these factors suggested developing understanding through inquiry by conducting a self designed , open ended , systematic inquiry required autonomous learning involving metacognitive skills and time management skills . to the extent in which students either came into the course with this scaffolding , or developed it during the course , they were successful in learning about sts and its relationship to science teaching . changes in the web site made to accommodate learners ' needs as they surfaced are described", "tokenized": "a report is given of a qualitative emergent design study of a science , technology , society interaction ( sts ) web enhanced course . students ' discomfort during the pilot test provided insight into the intellectual scaffolding that preservice secondary science teachers needed to optimize their performance when required to develop understanding through open ended inquiry in a web environment . eight factors identified contributed to student discomfort computer skills , paradigm shifts , trust , time management , thinking about their own thinking , systematic inquiry , self assessment , and scientific discourse . these factors suggested developing understanding through inquiry by conducting a self designed , open ended , systematic inquiry required autonomous learning involving metacognitive skills and time management skills . to the extent in which students either came into the course with this scaffolding , or developed it during the course , they were successful in learning about sts and its relationship to science teaching . changes in the web site made to accommodate learners ' needs as they surfaced are described"}, "present_kps": {"text": ["web based course", "qualitative emergent design study", "sts", "web enhanced course", "intellectual scaffolding", "preservice secondary science teachers", "open ended inquiry", "web environment", "student discomfort", "computer skills", "paradigm shifts", "trust", "time management", "thinking", "systematic inquiry", "self assessment", "scientific discourse", "autonomous learning", "metacognitive skills", "time management skills", "science teaching"], "tokenized": ["web based course", "qualitative emergent design study", "sts", "web enhanced course", "intellectual scaffolding", "preservice secondary science teachers", "open ended inquiry", "web environment", "student discomfort", "computer skills", "paradigm shifts", "trust", "time management", "thinking", "systematic inquiry", "self assessment", "scientific discourse", "autonomous learning", "metacognitive skills", "time management skills", "science teaching"]}, "absent_kps": {"text": ["preservice teacher discomfort", "science technology society interaction course"], "tokenized": ["preservice teacher discomfort", "science technology society interaction course"]}}
{"id": 356, "title": {"text": "recommendations for implementing internet inquiry projects .", "tokenized": "recommendations for implementing internet inquiry projects ."}, "abstract": {"text": "who are interested in implementing internet inquiry projects . four classes of ninth and tenth grade honors students ( n [digit] ) participated in an internet inquiry project in which they were presented with an ecology question that required them to make a decision based on information that they gathered , analyzed , and synthesized from the internet and their textbook . students then composed papers with a rationale for their decision . students in one group had access to pre selected relevant web sites , access to the entire internet , and were provided with less online support . students in the other group had access to only pre selected relevant web sites , but were provided with more online support . two of the most important recommendations were [digit] ) to provide students with more online support and [digit] ) to provide students with pre selected relevant web sites and allow them to search the internet for information", "tokenized": "who are interested in implementing internet inquiry projects . four classes of ninth and tenth grade honors students ( n [digit] ) participated in an internet inquiry project in which they were presented with an ecology question that required them to make a decision based on information that they gathered , analyzed , and synthesized from the internet and their textbook . students then composed papers with a rationale for their decision . students in one group had access to pre selected relevant web sites , access to the entire internet , and were provided with less online support . students in the other group had access to only pre selected relevant web sites , but were provided with more online support . two of the most important recommendations were [digit] ) to provide students with more online support and [digit] ) to provide students with pre selected relevant web sites and allow them to search the internet for information"}, "present_kps": {"text": ["internet inquiry projects", "honors students", "ecology question", "pre selected relevant web sites", "online support"], "tokenized": ["internet inquiry projects", "honors students", "ecology question", "pre selected relevant web sites", "online support"]}, "absent_kps": {"text": ["teachers"], "tokenized": ["teachers"]}}
{"id": 357, "title": {"text": "alien rescue a problem based hypermedia learning environment for middle school .", "tokenized": "alien rescue a problem based hypermedia learning environment for middle school ."}, "abstract": {"text": "the article describes an innovative hypermedia product for sixth graders in space science alien rescue . using a problem based learning approach that is highly interactive , alien rescue engages students in scientific investigations aimed at finding solutions to complex and meaningful problems . problem based learning ( pbl ) is an instructional strategy proven to be effective in medical and business fields , and it is increasingly popular in education . however , using pbl in k [digit] classrooms is challenging and requires access to rich knowledge bases and cognitive tools . alien rescue is designed to provide such cognitive support for successful use of pbl in sixth grade classrooms . the design and development of alien rescue is guided by current educational research . research is an integral part of this project . results of formative evaluation and research studies are being integrated into the development and improvement of the program . alien rescue is designed in accordance with the national science standards and the texas essential knowledge and skills ( teks ) for science . so far alien rescue has been field tested by approximately [digit] sixth graders . more use in middle schools is in progress and more research on its use is planned", "tokenized": "the article describes an innovative hypermedia product for sixth graders in space science alien rescue . using a problem based learning approach that is highly interactive , alien rescue engages students in scientific investigations aimed at finding solutions to complex and meaningful problems . problem based learning ( pbl ) is an instructional strategy proven to be effective in medical and business fields , and it is increasingly popular in education . however , using pbl in k [digit] classrooms is challenging and requires access to rich knowledge bases and cognitive tools . alien rescue is designed to provide such cognitive support for successful use of pbl in sixth grade classrooms . the design and development of alien rescue is guided by current educational research . research is an integral part of this project . results of formative evaluation and research studies are being integrated into the development and improvement of the program . alien rescue is designed in accordance with the national science standards and the texas essential knowledge and skills ( teks ) for science . so far alien rescue has been field tested by approximately [digit] sixth graders . more use in middle schools is in progress and more research on its use is planned"}, "present_kps": {"text": ["alien rescue", "problem based hypermedia learning environment", "middle schools", "sixth graders", "space science", "scientific investigations", "pbl", "instructional strategy", "business fields", "k [digit] classrooms", "rich knowledge bases", "cognitive tools", "cognitive support", "educational research", "formative evaluation"], "tokenized": ["alien rescue", "problem based hypermedia learning environment", "middle schools", "sixth graders", "space science", "scientific investigations", "pbl", "instructional strategy", "business fields", "k [digit] classrooms", "rich knowledge bases", "cognitive tools", "cognitive support", "educational research", "formative evaluation"]}, "absent_kps": {"text": ["medical fields", "middle school science"], "tokenized": ["medical fields", "middle school science"]}}
{"id": 358, "title": {"text": "project based learning teachers learning and using high tech to preserve cajun .", "tokenized": "project based learning teachers learning and using high tech to preserve cajun ."}, "abstract": {"text": "using project based learning pedagogy in edtc [digit] advances in educational technology , the author has trained inservice teachers in southwestern louisiana with an advanced computer multimedia program called director ( r ) ( macromedia , inc . ) . the content of this course focused on modeling the project based learning pedagogy and researching acadian ' s traditions and legacy . with the multi functions of microcomputers , new technologies were used to preserve and celebrate the local culture with superiority of text , graphics , animation , sound , and video . the article describes how several groups of school teachers in the surrounding areas of a regional state university of louisiana learned computer multimedia using project based learning and integrated their learning into local cultural heritage", "tokenized": "using project based learning pedagogy in edtc [digit] advances in educational technology , the author has trained inservice teachers in southwestern louisiana with an advanced computer multimedia program called director ( r ) ( macromedia , inc . ) . the content of this course focused on modeling the project based learning pedagogy and researching acadian ' s traditions and legacy . with the multi functions of microcomputers , new technologies were used to preserve and celebrate the local culture with superiority of text , graphics , animation , sound , and video . the article describes how several groups of school teachers in the surrounding areas of a regional state university of louisiana learned computer multimedia using project based learning and integrated their learning into local cultural heritage"}, "present_kps": {"text": ["project based learning", "teachers", "project based learning pedagogy", "edtc [digit] advances in educational technology", "inservice teachers", "advanced computer multimedia program", "computer multimedia", "director", "macromedia", "new technologies", "local culture", "school teachers", "regional state university", "local cultural heritage"], "tokenized": ["project based learning", "teachers", "project based learning pedagogy", "edtc [digit] advances in educational technology", "inservice teachers", "advanced computer multimedia program", "computer multimedia", "director", "macromedia", "new technologies", "local culture", "school teachers", "regional state university", "local cultural heritage"]}, "absent_kps": {"text": ["cajun culture", "acadian traditions"], "tokenized": ["cajun culture", "acadian traditions"]}}
{"id": 359, "title": {"text": "presentation media , information complexity , and learning outcomes .", "tokenized": "presentation media , information complexity , and learning outcomes ."}, "abstract": {"text": "combinations . educators have observed that visuals enhance learning which suggests that multimedia presentations should be superior to text only and text with static pictures in facilitating optimal human information processing and , therefore , comprehension . the article reports the findings from a [digit] ( text only , overhead slides , and multimedia presentation ) [digit] ( high and low information complexity ) factorial experiment . subjects read a text script , viewed an acetate overhead slide presentation , or viewed a multimedia presentation depicting the greenhouse effect ( low complexity ) or photocopier operation ( high complexity ) . multimedia was superior to text only and overhead slides for comprehension . information complexity diminished comprehension and perceived presentation quality . multimedia was able to reduce the negative impact of information complexity on comprehension and increase the extent of sustained attention to the presentation . these findings suggest that multimedia presentations invoke the use of both the verbal and visual working memory channels resulting in a reduction of the cognitive load imposed by increased information complexity . moreover , multimedia superiority in facilitating comprehension goes beyond its ability to increase sustained attention the quality and effectiveness of information processing attained ( i . e . , use of verbal and visual working memory ) is also significant", "tokenized": "combinations . educators have observed that visuals enhance learning which suggests that multimedia presentations should be superior to text only and text with static pictures in facilitating optimal human information processing and , therefore , comprehension . the article reports the findings from a [digit] ( text only , overhead slides , and multimedia presentation ) [digit] ( high and low information complexity ) factorial experiment . subjects read a text script , viewed an acetate overhead slide presentation , or viewed a multimedia presentation depicting the greenhouse effect ( low complexity ) or photocopier operation ( high complexity ) . multimedia was superior to text only and overhead slides for comprehension . information complexity diminished comprehension and perceived presentation quality . multimedia was able to reduce the negative impact of information complexity on comprehension and increase the extent of sustained attention to the presentation . these findings suggest that multimedia presentations invoke the use of both the verbal and visual working memory channels resulting in a reduction of the cognitive load imposed by increased information complexity . moreover , multimedia superiority in facilitating comprehension goes beyond its ability to increase sustained attention the quality and effectiveness of information processing attained ( i . e . , use of verbal and visual working memory ) is also significant"}, "present_kps": {"text": ["presentation media", "information complexity", "learning outcomes", "educators", "multimedia presentation", "multimedia presentations", "static pictures", "optimal human information processing", "overhead slides", "text script", "acetate overhead slide presentation", "greenhouse effect", "photocopier operation", "sustained attention", "visual working memory channel", "cognitive load", "multimedia superiority"], "tokenized": ["presentation media", "information complexity", "learning outcomes", "educators", "multimedia presentation", "multimedia presentations", "static pictures", "optimal human information processing", "overhead slides", "text script", "acetate overhead slide presentation", "greenhouse effect", "photocopier operation", "sustained attention", "visual working memory channel", "cognitive load", "multimedia superiority"]}, "absent_kps": {"text": ["verbal working memory channel", "cognitive processing limitations", "human working memory", "information presentation modality combinations", "multimedia computing"], "tokenized": ["verbal working memory channel", "cognitive processing limitations", "human working memory", "information presentation modality combinations", "multimedia computing"]}}
{"id": 360, "title": {"text": "real time tissue characterization on the basis of in vivo raman spectra .", "tokenized": "real time tissue characterization on the basis of in vivo raman spectra ."}, "abstract": {"text": "dedicated software that can perform the necessary signal processing and subsequent ( multivariate ) data analysis , enabling clinically relevant parameters to be extracted and made available in real time . here we describe the design and implementation of a software package that allows for real time signal processing and data analysis of raman spectra . the design is based on automatic data exchange between grams , a spectroscopic data acquisition and analysis program , and matlab , a program designed for array based calculations . the data analysis software has a modular design providing great flexibility in developing custom data analysis routines for different applications . the implementation is illustrated by a computationally demanding application for the classification of skin spectra using principal component analysis and linear discriminant analysis", "tokenized": "dedicated software that can perform the necessary signal processing and subsequent ( multivariate ) data analysis , enabling clinically relevant parameters to be extracted and made available in real time . here we describe the design and implementation of a software package that allows for real time signal processing and data analysis of raman spectra . the design is based on automatic data exchange between grams , a spectroscopic data acquisition and analysis program , and matlab , a program designed for array based calculations . the data analysis software has a modular design providing great flexibility in developing custom data analysis routines for different applications . the implementation is illustrated by a computationally demanding application for the classification of skin spectra using principal component analysis and linear discriminant analysis"}, "present_kps": {"text": ["real time tissue characterization", "dedicated software", "automatic data exchange", "grams", "matlab", "array based calculations", "data analysis software", "modular design", "computationally demanding application", "linear discriminant analysis"], "tokenized": ["real time tissue characterization", "dedicated software", "automatic data exchange", "grams", "matlab", "array based calculations", "data analysis software", "modular design", "computationally demanding application", "linear discriminant analysis"]}, "absent_kps": {"text": ["multivariate data analysis", "skin spectra classification", "clinically relevant parameters extraction", "clinical diagnosis"], "tokenized": ["multivariate data analysis", "skin spectra classification", "clinically relevant parameters extraction", "clinical diagnosis"]}}
{"id": 361, "title": {"text": "loudspeaker voice coil inductance losses circuit models , parameter estimation , .", "tokenized": "loudspeaker voice coil inductance losses circuit models , parameter estimation , ."}, "abstract": {"text": "when the series resistance is separated and treated as a separate element , it is shown that losses in an inductor require the ratio of the flux to mmf in the core to be frequency dependent . for small signal operation , this dependence leads to a circuit model composed of a lossless inductor and a resistor in parallel , both of which are frequency dependent . mathematical expressions for these elements are derived under the assumption that the ratio of core flux to mmf varies as omega sup n [digit] , where n is a constant . a linear regression technique is described for extracting the model parameters from measured data . experimental data are presented to justify the model for the lossy inductance of a loudspeaker voice coil . a spice example is presented to illustrate the effects of voice coil inductor losses on the frequency response of a typical driver", "tokenized": "when the series resistance is separated and treated as a separate element , it is shown that losses in an inductor require the ratio of the flux to mmf in the core to be frequency dependent . for small signal operation , this dependence leads to a circuit model composed of a lossless inductor and a resistor in parallel , both of which are frequency dependent . mathematical expressions for these elements are derived under the assumption that the ratio of core flux to mmf varies as omega sup n [digit] , where n is a constant . a linear regression technique is described for extracting the model parameters from measured data . experimental data are presented to justify the model for the lossy inductance of a loudspeaker voice coil . a spice example is presented to illustrate the effects of voice coil inductor losses on the frequency response of a typical driver"}, "present_kps": {"text": ["loudspeaker voice coil inductance losses", "circuit models", "parameter estimation", "series resistance", "small signal operation", "lossless inductor", "linear regression", "lossy inductance", "spice", "frequency response"], "tokenized": ["loudspeaker voice coil inductance losses", "circuit models", "parameter estimation", "series resistance", "small signal operation", "lossless inductor", "linear regression", "lossy inductance", "spice", "frequency response"]}, "absent_kps": {"text": ["loudspeaker driver", "core flux to mmf ratio"], "tokenized": ["loudspeaker driver", "core flux to mmf ratio"]}}
{"id": 362, "title": {"text": "complexity transitions in global algorithms for sparse linear systems over .", "tokenized": "complexity transitions in global algorithms for sparse linear systems over ."}, "abstract": {"text": "we study the computational complexity of a very basic problem , namely that of finding solutions to a very large set of random linear equations in a finite galois field modulo q . using tools from statistical mechanics we are able to identify phase transitions in the structure of the solution space and to connect them to the changes in the performance of a global algorithm , namely gaussian elimination . crossing phase boundaries produces a dramatic increase in memory and cpu requirements necessary for the algorithms . in turn , this causes the saturation of the upper bounds for the running time . we illustrate the results on the specific problem of integer factorization , which is of central interest for deciphering messages encrypted with the rsa cryptosystem", "tokenized": "we study the computational complexity of a very basic problem , namely that of finding solutions to a very large set of random linear equations in a finite galois field modulo q . using tools from statistical mechanics we are able to identify phase transitions in the structure of the solution space and to connect them to the changes in the performance of a global algorithm , namely gaussian elimination . crossing phase boundaries produces a dramatic increase in memory and cpu requirements necessary for the algorithms . in turn , this causes the saturation of the upper bounds for the running time . we illustrate the results on the specific problem of integer factorization , which is of central interest for deciphering messages encrypted with the rsa cryptosystem"}, "present_kps": {"text": ["complexity transitions", "global algorithms", "sparse linear systems", "random linear equations", "finite galois field", "statistical mechanics", "gaussian elimination", "phase boundaries", "integer factorization", "encryption", "rsa cryptosystem"], "tokenized": ["complexity transitions", "global algorithms", "sparse linear systems", "random linear equations", "finite galois field", "statistical mechanics", "gaussian elimination", "phase boundaries", "integer factorization", "encryption", "rsa cryptosystem"]}, "absent_kps": {"text": ["disordered systems", "message deciphering", "finite fields"], "tokenized": ["disordered systems", "message deciphering", "finite fields"]}}
{"id": 363, "title": {"text": "noise effect on memory recall in dynamical neural network model of hippocampus .", "tokenized": "noise effect on memory recall in dynamical neural network model of hippocampus ."}, "abstract": {"text": "and aihara ( [digit] ) for the memory recall of dynamical patterns in the hippocampus and the entorhinal cortex the noise effect is important since the release of transmitters at synaptic clefts , the operation of gate of ion channels and so on are known as stochastic phenomena . we consider two kinds of noise effect due to a deterministic noise and a stochastic noise . by numerical simulations , we find that reasonable values of noise give better performance on the memory recall of dynamical patterns . furthermore we investigate the effect of the strength of external inputs on the memory recall", "tokenized": "and aihara ( [digit] ) for the memory recall of dynamical patterns in the hippocampus and the entorhinal cortex the noise effect is important since the release of transmitters at synaptic clefts , the operation of gate of ion channels and so on are known as stochastic phenomena . we consider two kinds of noise effect due to a deterministic noise and a stochastic noise . by numerical simulations , we find that reasonable values of noise give better performance on the memory recall of dynamical patterns . furthermore we investigate the effect of the strength of external inputs on the memory recall"}, "present_kps": {"text": ["noise effect", "memory recall", "dynamical neural network model", "hippocampus", "dynamical patterns", "entorhinal cortex", "synaptic clefts", "gate of ion channels", "stochastic phenomena", "deterministic noise", "stochastic noise", "numerical simulations"], "tokenized": ["noise effect", "memory recall", "dynamical neural network model", "hippocampus", "dynamical patterns", "entorhinal cortex", "synaptic clefts", "gate of ion channels", "stochastic phenomena", "deterministic noise", "stochastic noise", "numerical simulations"]}, "absent_kps": {"text": ["brain functions", "inhibitory connection", "synaptic strength"], "tokenized": ["brain functions", "inhibitory connection", "synaptic strength"]}}
{"id": 364, "title": {"text": "fuzzy polynomial neural networks hybrid architectures of fuzzy modeling .", "tokenized": "fuzzy polynomial neural networks hybrid architectures of fuzzy modeling ."}, "abstract": {"text": "modeling architecture combining polynomial neural networks ( pnns ) and fuzzy neural networks ( fnns ) . the development of the fpnns dwells on the technologies of computational intelligence ( ci ) , namely fuzzy sets , neural networks , and genetic algorithms . the structure of the fpnn results from a synergistic usage of fnn and pnn . fnns contribute to the formation of the premise part of the rule based structure of the fpnn . the consequence part of the fpnn is designed using pnns . the structure of the pnn is not fixed in advance as it usually takes place in the case of conventional neural networks , but becomes organized dynamically to meet the required approximation error . we exploit a group method of data handling ( gmdh ) to produce this dynamic topology of the network . the performance of the fpnn is quantified through experimentation that exploits standard data already used in fuzzy modeling . the obtained experimental results reveal that the proposed networks exhibit high accuracy and generalization capabilities in comparison to other similar fuzzy models", "tokenized": "modeling architecture combining polynomial neural networks ( pnns ) and fuzzy neural networks ( fnns ) . the development of the fpnns dwells on the technologies of computational intelligence ( ci ) , namely fuzzy sets , neural networks , and genetic algorithms . the structure of the fpnn results from a synergistic usage of fnn and pnn . fnns contribute to the formation of the premise part of the rule based structure of the fpnn . the consequence part of the fpnn is designed using pnns . the structure of the pnn is not fixed in advance as it usually takes place in the case of conventional neural networks , but becomes organized dynamically to meet the required approximation error . we exploit a group method of data handling ( gmdh ) to produce this dynamic topology of the network . the performance of the fpnn is quantified through experimentation that exploits standard data already used in fuzzy modeling . the obtained experimental results reveal that the proposed networks exhibit high accuracy and generalization capabilities in comparison to other similar fuzzy models"}, "present_kps": {"text": ["fuzzy polynomial neural networks", "hybrid architectures", "fuzzy modeling", "computational intelligence", "fuzzy sets", "genetic algorithms", "group method of data handling", "gmdh", "dynamic topology"], "tokenized": ["fuzzy polynomial neural networks", "hybrid architectures", "fuzzy modeling", "computational intelligence", "fuzzy sets", "genetic algorithms", "group method of data handling", "gmdh", "dynamic topology"]}, "absent_kps": {"text": ["standard backpropagation", "membership functions", "genetic optimization", "highly nonlinear rule based models", "learning rates", "fuzzy inference method", "learning", "momentum coefficients"], "tokenized": ["standard backpropagation", "membership functions", "genetic optimization", "highly nonlinear rule based models", "learning rates", "fuzzy inference method", "learning", "momentum coefficients"]}}
{"id": 365, "title": {"text": "mems applications in computer disk drive dual stage servo systems .", "tokenized": "mems applications in computer disk drive dual stage servo systems ."}, "abstract": {"text": "combined with a self tuning scheme to compensate variations in the microactuator ' s ( ma ' s ) resonance mode . section i of the paper describes the design and fabrication of a prototype microactuator with an integrated gimbal structure . section ii presents a decoupled track following controller design and a self tuning control scheme to compensate for the ma ' s resonance mode variations", "tokenized": "combined with a self tuning scheme to compensate variations in the microactuator ' s ( ma ' s ) resonance mode . section i of the paper describes the design and fabrication of a prototype microactuator with an integrated gimbal structure . section ii presents a decoupled track following controller design and a self tuning control scheme to compensate for the ma ' s resonance mode variations"}, "present_kps": {"text": ["mems", "computer disk drive dual stage servo systems", "self tuning scheme", "microactuator", "track following controller design"], "tokenized": ["mems", "computer disk drive dual stage servo systems", "self tuning scheme", "microactuator", "track following controller design"]}, "absent_kps": {"text": ["electrostatic design", "hard disk drives", "servo control", "fabrication process", "decoupled discrete time pole placement design method"], "tokenized": ["electrostatic design", "hard disk drives", "servo control", "fabrication process", "decoupled discrete time pole placement design method"]}}
{"id": 366, "title": {"text": "nuclear magnetic resonance molecular photography .", "tokenized": "nuclear magnetic resonance molecular photography ."}, "abstract": {"text": "of [digit] [digit] [digit] bits in a spin state of a molecular system and then retrieving the stored information as a stack of nuclear magnetic resonance spectra . the system used is a nematic liquid crystal , the protons of which act as spin clusters with strong intramolecular interactions . the technique used is a programmable multifrequency irradiation with low amplitude . when it is applied to the liquid crystal , a large number of coherent long lived sup [digit] h response signals can be excited , resulting in a spectrum showing many sharp peaks with controllable frequencies and amplitudes . the spectral resolution is enhanced by using a second weak pulse with a [digit] degrees phase shift , so that the [digit] bits of information can be retrieved as a set of well resolved pseudo 2d spectra reproducing the input pattern", "tokenized": "of [digit] [digit] [digit] bits in a spin state of a molecular system and then retrieving the stored information as a stack of nuclear magnetic resonance spectra . the system used is a nematic liquid crystal , the protons of which act as spin clusters with strong intramolecular interactions . the technique used is a programmable multifrequency irradiation with low amplitude . when it is applied to the liquid crystal , a large number of coherent long lived sup [digit] h response signals can be excited , resulting in a spectrum showing many sharp peaks with controllable frequencies and amplitudes . the spectral resolution is enhanced by using a second weak pulse with a [digit] degrees phase shift , so that the [digit] bits of information can be retrieved as a set of well resolved pseudo 2d spectra reproducing the input pattern"}, "present_kps": {"text": ["[digit] bit", "nematic liquid crystal", "spin clusters", "strong intramolecular interactions", "programmable multifrequency irradiation", "low amplitude", "coherent long lived sup [digit] h response signals", "spectral resolution", "second weak pulse", "pseudo 2d spectra"], "tokenized": ["[digit] bit", "nematic liquid crystal", "spin clusters", "strong intramolecular interactions", "programmable multifrequency irradiation", "low amplitude", "coherent long lived sup [digit] h response signals", "spectral resolution", "second weak pulse", "pseudo 2d spectra"]}, "absent_kps": {"text": ["spin dynamics", "coupled spins", "proton spin", "dipole dipole interactions", "information storage", "spin locking", "nmr molecular photography", "molecular system spin state", "2d pattern", "spin echoes", "high content molecular information processing", "hilbert spaces"], "tokenized": ["spin dynamics", "coupled spins", "proton spin", "dipole dipole interactions", "information storage", "spin locking", "nmr molecular photography", "molecular system spin state", "2d pattern", "spin echoes", "high content molecular information processing", "hilbert spaces"]}}
{"id": 367, "title": {"text": "novel active noise reducing headset using earshell vibration control .", "tokenized": "novel active noise reducing headset using earshell vibration control ."}, "abstract": {"text": "varying from aviation communication to consumer audio . current anr systems use passive attenuation at high frequencies and loudspeaker based active noise control at low frequencies to achieve broadband noise reduction . this paper presents a novel anr headset in which the external noise transmitted to the user ' s ear via earshell vibration is reduced by controlling the vibration of the earshell using force actuators acting against an inertial mass or the earshell headband . model based theoretical analysis using velocity feedback control showed that current piezoelectric actuators provide sufficient force but require lower stiffness for improved low frequency performance . control simulations based on experimental data from a laboratory headset showed that good performance can potentially be achieved in practice by a robust feedback controller , while a single frequency real time control experiment verified that noise reduction can be achieved using earshell vibration control", "tokenized": "varying from aviation communication to consumer audio . current anr systems use passive attenuation at high frequencies and loudspeaker based active noise control at low frequencies to achieve broadband noise reduction . this paper presents a novel anr headset in which the external noise transmitted to the user ' s ear via earshell vibration is reduced by controlling the vibration of the earshell using force actuators acting against an inertial mass or the earshell headband . model based theoretical analysis using velocity feedback control showed that current piezoelectric actuators provide sufficient force but require lower stiffness for improved low frequency performance . control simulations based on experimental data from a laboratory headset showed that good performance can potentially be achieved in practice by a robust feedback controller , while a single frequency real time control experiment verified that noise reduction can be achieved using earshell vibration control"}, "present_kps": {"text": ["active noise reducing headset", "earshell vibration control", "aviation communication", "consumer audio", "passive attenuation", "broadband noise reduction", "force actuators", "inertial mass", "velocity feedback control", "piezoelectric actuators", "stiffness", "robust feedback controller", "single frequency real time control"], "tokenized": ["active noise reducing headset", "earshell vibration control", "aviation communication", "consumer audio", "passive attenuation", "broadband noise reduction", "force actuators", "inertial mass", "velocity feedback control", "piezoelectric actuators", "stiffness", "robust feedback controller", "single frequency real time control"]}, "absent_kps": {"text": ["external noise transmission"], "tokenized": ["external noise transmission"]}}
{"id": 368, "title": {"text": "theoretical and experimental investigations on coherence of traffic noise .", "tokenized": "theoretical and experimental investigations on coherence of traffic noise ."}, "abstract": {"text": "high rise buildings a method for theoretically calculating the coherence between sound pressure inside a rectangular room in a high rise building and that outside the open window of the room is proposed . the traffic noise transmitted into a room is generally dominated by low frequency components , to which active noise control ( anc ) technology may find an application . however , good coherence between reference and error signals is essential for an effective noise reduction and should be checked first . based on traffic noise prediction methods , wave theory , and mode coupling theory , the results of this paper enabled one to determine the potentials and limitations of anc used to reduce such a transmission . experimental coherence results are shown for two similar , empty rectangular rooms located on the 17th and 30th floors of a [digit] floor high rise building . the calculated results with the proposed method are generally in good agreement with the experimental results and demonstrate the usefulness of the method for predicting the coherence", "tokenized": "high rise buildings a method for theoretically calculating the coherence between sound pressure inside a rectangular room in a high rise building and that outside the open window of the room is proposed . the traffic noise transmitted into a room is generally dominated by low frequency components , to which active noise control ( anc ) technology may find an application . however , good coherence between reference and error signals is essential for an effective noise reduction and should be checked first . based on traffic noise prediction methods , wave theory , and mode coupling theory , the results of this paper enabled one to determine the potentials and limitations of anc used to reduce such a transmission . experimental coherence results are shown for two similar , empty rectangular rooms located on the 17th and 30th floors of a [digit] floor high rise building . the calculated results with the proposed method are generally in good agreement with the experimental results and demonstrate the usefulness of the method for predicting the coherence"}, "present_kps": {"text": ["high rise buildings", "sound pressure", "rectangular room", "open window", "low frequency components", "traffic noise prediction methods", "wave theory", "mode coupling theory"], "tokenized": ["high rise buildings", "sound pressure", "rectangular room", "open window", "low frequency components", "traffic noise prediction methods", "wave theory", "mode coupling theory"]}, "absent_kps": {"text": ["active noise control technology", "traffic noise transmission"], "tokenized": ["active noise control technology", "traffic noise transmission"]}}
{"id": 369, "title": {"text": "high density remote storage the ohio state university libraries depository .", "tokenized": "high density remote storage the ohio state university libraries depository ."}, "abstract": {"text": "the ohio state university libraries . opened in [digit] , it has the capacity to house nearly [digit] . [digit] million items in only [digit] square feet by shelving books by size on [digit] foot tall shelving . a sophisticated climate control system extends the life of stored materials up to [digit] times . an online catalog record for each item informs patrons that the item is located in a remote location . regular courier deliveries from the storage facility bring requested materials to patrons with minimal delay", "tokenized": "the ohio state university libraries . opened in [digit] , it has the capacity to house nearly [digit] . [digit] million items in only [digit] square feet by shelving books by size on [digit] foot tall shelving . a sophisticated climate control system extends the life of stored materials up to [digit] times . an online catalog record for each item informs patrons that the item is located in a remote location . regular courier deliveries from the storage facility bring requested materials to patrons with minimal delay"}, "present_kps": {"text": ["high density remote storage", "ohio state university libraries", "shelving", "climate control system", "stored materials", "online catalog record", "patrons", "remote location", "courier deliveries"], "tokenized": ["high density remote storage", "ohio state university libraries", "shelving", "climate control system", "stored materials", "online catalog record", "patrons", "remote location", "courier deliveries"]}, "absent_kps": {"text": ["high density off site book storage facility", "circulation"], "tokenized": ["high density off site book storage facility", "circulation"]}}
{"id": 370, "title": {"text": "hours of operation and service in academic libraries toward a national .", "tokenized": "hours of operation and service in academic libraries toward a national ."}, "abstract": {"text": "in an effort toward establishing a standard for academic library hours , the article surveys and compares hours of operation and service for arl libraries and ipeds survey respondents . the article ranks the arl ( association for research libraries ) libraries according to hours of operation and reference hours and then briefly discusses such issues as libraries offering twenty four access and factors affecting service hour decisions", "tokenized": "in an effort toward establishing a standard for academic library hours , the article surveys and compares hours of operation and service for arl libraries and ipeds survey respondents . the article ranks the arl ( association for research libraries ) libraries according to hours of operation and reference hours and then briefly discusses such issues as libraries offering twenty four access and factors affecting service hour decisions"}, "present_kps": {"text": ["academic library hours", "arl libraries", "ipeds survey respondents", "association for research libraries"], "tokenized": ["academic library hours", "arl libraries", "ipeds survey respondents", "association for research libraries"]}, "absent_kps": {"text": ["integrated post secondary education data system", "operation service hours"], "tokenized": ["integrated post secondary education data system", "operation service hours"]}}
{"id": 371, "title": {"text": "using the web to answer legal reference questions .", "tokenized": "using the web to answer legal reference questions ."}, "abstract": {"text": "the author highlights three basic legal web sites and outlines useful subject specific web sites that focus on statutes and regulations , case law and attorney directories", "tokenized": "the author highlights three basic legal web sites and outlines useful subject specific web sites that focus on statutes and regulations , case law and attorney directories"}, "present_kps": {"text": ["legal reference questions", "case law", "attorney directories"], "tokenized": ["legal reference questions", "case law", "attorney directories"]}, "absent_kps": {"text": ["world wide web", "nonlaw librarians"], "tokenized": ["world wide web", "nonlaw librarians"]}}
{"id": 372, "title": {"text": "the service side of systems librarianship .", "tokenized": "the service side of systems librarianship ."}, "abstract": {"text": "online catalogs and the internet are making library accessibility more convenient , the need for library buildings and professionals has not diminished . typical duties of a systems librarian and the effects of new technology on librarianship are discussed . services provided to other constituencies on campus and the blurring relationship between the library and computer services are also presented", "tokenized": "online catalogs and the internet are making library accessibility more convenient , the need for library buildings and professionals has not diminished . typical duties of a systems librarian and the effects of new technology on librarianship are discussed . services provided to other constituencies on campus and the blurring relationship between the library and computer services are also presented"}, "present_kps": {"text": ["service side", "systems librarianship", "online catalogs", "internet"], "tokenized": ["service side", "systems librarianship", "online catalogs", "internet"]}, "absent_kps": {"text": ["small academic library"], "tokenized": ["small academic library"]}}
{"id": 373, "title": {"text": "defining electronic librarianship a content analysis of job advertisements .", "tokenized": "defining electronic librarianship a content analysis of job advertisements ."}, "abstract": {"text": "issues surrounding this new electronic , end user environment have major ramifications and require expert knowledge . electronic services librarians and electronic resources librarians are two specialized titles that have recently emerged within the field of librarianship to fill this niche . job advertisements listed in american libraries from january [digit] to december [digit] were examined to identify responsibilities , qualifications , organizational and salary information relating to the newly emerging role of electronic librarian", "tokenized": "issues surrounding this new electronic , end user environment have major ramifications and require expert knowledge . electronic services librarians and electronic resources librarians are two specialized titles that have recently emerged within the field of librarianship to fill this niche . job advertisements listed in american libraries from january [digit] to december [digit] were examined to identify responsibilities , qualifications , organizational and salary information relating to the newly emerging role of electronic librarian"}, "present_kps": {"text": ["electronic librarianship", "content analysis", "job advertisements", "electronic services librarians", "electronic resources librarians", "american libraries", "responsibilities", "qualifications", "salary information"], "tokenized": ["electronic librarianship", "content analysis", "job advertisements", "electronic services librarians", "electronic resources librarians", "american libraries", "responsibilities", "qualifications", "salary information"]}, "absent_kps": {"text": ["electronic end user environment", "organizational information"], "tokenized": ["electronic end user environment", "organizational information"]}}
{"id": 374, "title": {"text": "customer in reach and library strategic systems the case of illiad .", "tokenized": "customer in reach and library strategic systems the case of illiad ."}, "abstract": {"text": "at virginia tech is creating systems and services that enable our customers to reach past our walls at anytime from anywhere . customer in reach enables virginia tech faculty , students , and staff anywhere in the world to obtain information and services heretofore available only to our on campus customers . illiad , virginia tech ' s interlibrary borrowing system , is the library strategic system that attains this goal . the principles that guided development of illiad are widely applicable", "tokenized": "at virginia tech is creating systems and services that enable our customers to reach past our walls at anytime from anywhere . customer in reach enables virginia tech faculty , students , and staff anywhere in the world to obtain information and services heretofore available only to our on campus customers . illiad , virginia tech ' s interlibrary borrowing system , is the library strategic system that attains this goal . the principles that guided development of illiad are widely applicable"}, "present_kps": {"text": ["customer in reach", "library strategic systems", "illiad", "virginia tech", "interlibrary borrowing system"], "tokenized": ["customer in reach", "library strategic systems", "illiad", "virginia tech", "interlibrary borrowing system"]}, "absent_kps": {"text": ["interlibrary loan department"], "tokenized": ["interlibrary loan department"]}}
{"id": 375, "title": {"text": "nuvox shows staying power with new cash , new market .", "tokenized": "nuvox shows staying power with new cash , new market ."}, "abstract": {"text": "positions itself for the long run with [digit] . [digit] million in funding and a new credit facility", "tokenized": "positions itself for the long run with [digit] . [digit] million in funding and a new credit facility"}, "present_kps": {"text": [], "tokenized": []}, "absent_kps": {"text": ["telecom", "competitive carrier market", "nuvox communications", "investors"], "tokenized": ["telecom", "competitive carrier market", "nuvox communications", "investors"]}}
{"id": 376, "title": {"text": "improvements and critique on sugeno ' s and yasukawa ' s qualitative modeling .", "tokenized": "improvements and critique on sugeno ' s and yasukawa ' s qualitative modeling ."}, "abstract": {"text": "approach . we propose some easily implementable solutions for the unclear details of the original paper , such as trapezoid approximation of membership functions , rule creation from sample data points , and selection of important variables . we further suggest an improved parameter identification algorithm to be applied instead of the original one . these details are crucial concerning the method ' s performance as it is shown in a comparative analysis and helps to improve the accuracy of the built up model . finally , we propose a possible further rule base reduction which can be applied successfully in certain cases . this improvement reduces the time requirement of the method by up to [digit] % in our experiments", "tokenized": "approach . we propose some easily implementable solutions for the unclear details of the original paper , such as trapezoid approximation of membership functions , rule creation from sample data points , and selection of important variables . we further suggest an improved parameter identification algorithm to be applied instead of the original one . these details are crucial concerning the method ' s performance as it is shown in a comparative analysis and helps to improve the accuracy of the built up model . finally , we propose a possible further rule base reduction which can be applied successfully in certain cases . this improvement reduces the time requirement of the method by up to [digit] % in our experiments"}, "present_kps": {"text": ["qualitative modeling", "trapezoid approximation", "membership functions", "rule creation", "parameter identification algorithm", "rule base reduction"], "tokenized": ["qualitative modeling", "trapezoid approximation", "membership functions", "rule creation", "parameter identification algorithm", "rule base reduction"]}, "absent_kps": {"text": ["fuzzy modeling", "sugeno yasukawa method"], "tokenized": ["fuzzy modeling", "sugeno yasukawa method"]}}
{"id": 377, "title": {"text": "the plot thins thin client computer systems and academic libraries .", "tokenized": "the plot thins thin client computer systems and academic libraries ."}, "abstract": {"text": "of compelling reasons to do so . for starters , thin client devices are far less expensive than most pcs . more importantly , thin client computing devices are believed to be far less expensive to manage and support than traditional pcs", "tokenized": "of compelling reasons to do so . for starters , thin client devices are far less expensive than most pcs . more importantly , thin client computing devices are believed to be far less expensive to manage and support than traditional pcs"}, "present_kps": {"text": ["thin client computer systems", "academic libraries"], "tokenized": ["thin client computer systems", "academic libraries"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 378, "title": {"text": "academic libraries and community making the connection .", "tokenized": "academic libraries and community making the connection ."}, "abstract": {"text": "broader community . i highlight interesting projects reported on in the literature ( such as the through our parents ' eyes project ) and report on others . i look at challenges to community partnerships and recommendations for making them succeed . although i focus on links with the broader community , i also took at methods for increasing cooperation among various units on campus , so that the needs of campus community groups such as distance education students or disabled students are effectively addressed . though academic libraries are my focus , we can learn a lot from the community building efforts of public libraries", "tokenized": "broader community . i highlight interesting projects reported on in the literature ( such as the through our parents ' eyes project ) and report on others . i look at challenges to community partnerships and recommendations for making them succeed . although i focus on links with the broader community , i also took at methods for increasing cooperation among various units on campus , so that the needs of campus community groups such as distance education students or disabled students are effectively addressed . though academic libraries are my focus , we can learn a lot from the community building efforts of public libraries"}, "present_kps": {"text": ["academic libraries", "community partnerships", "campus community groups", "distance education students", "disabled students", "public libraries"], "tokenized": ["academic libraries", "community partnerships", "campus community groups", "distance education students", "disabled students", "public libraries"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 379, "title": {"text": "using internet search engines to estimate word frequency .", "tokenized": "using internet search engines to estimate word frequency ."}, "abstract": {"text": "cost effective alternative for estimating word frequencies . frequency estimates for [digit] words were obtained and compared across four methods ( [digit] ) internet search engines , ( [digit] ) the kucera and francis ( [digit] ) analysis of a traditional linguistic corpus , ( [digit] ) the celex english linguistic database ( baayen et al . , [digit] ) , and ( [digit] ) participant ratings of familiarity . the results showed that internet search engines produced frequency estimates that were highly consistent with those reported by kucera and francis and those calculated from celex , highly consistent across search engines , and very reliable over a [digit] month period of time . additional results suggested that internet search engines are an excellent option when traditional word frequency analyses do not contain the necessary data ( e . g . , estimates for forenames and slang ) . in contrast , participants ' familiarity judgments did not correspond well with the more objective estimates of word frequency . researchers are advised to use search engines with large databases ( e . g . , altavista ) to ensure the greatest representativeness of the frequency estimates", "tokenized": "cost effective alternative for estimating word frequencies . frequency estimates for [digit] words were obtained and compared across four methods ( [digit] ) internet search engines , ( [digit] ) the kucera and francis ( [digit] ) analysis of a traditional linguistic corpus , ( [digit] ) the celex english linguistic database ( baayen et al . , [digit] ) , and ( [digit] ) participant ratings of familiarity . the results showed that internet search engines produced frequency estimates that were highly consistent with those reported by kucera and francis and those calculated from celex , highly consistent across search engines , and very reliable over a [digit] month period of time . additional results suggested that internet search engines are an excellent option when traditional word frequency analyses do not contain the necessary data ( e . g . , estimates for forenames and slang ) . in contrast , participants ' familiarity judgments did not correspond well with the more objective estimates of word frequency . researchers are advised to use search engines with large databases ( e . g . , altavista ) to ensure the greatest representativeness of the frequency estimates"}, "present_kps": {"text": ["internet search engines", "linguistic corpus", "celex english linguistic database", "large databases"], "tokenized": ["internet search engines", "linguistic corpus", "celex english linguistic database", "large databases"]}, "absent_kps": {"text": ["word frequency estimation", "participant familiarity ratings"], "tokenized": ["word frequency estimation", "participant familiarity ratings"]}}
{"id": 380, "title": {"text": "visual word identification thresholds for the [digit] fragmented words of the .", "tokenized": "visual word identification thresholds for the [digit] fragmented words of the ."}, "abstract": {"text": "word difficulty varies from language to language therefore , normative data of verbal stimuli can not be imported directly from another language . we present mean identification thresholds for the [digit] screen fragmented words corresponding to the total set of snodgrass and vanderwart ( [digit] ) pictures . individual words were fragmented in eight levels using turbo pascal , and the resulting program was implemented on a pc microcomputer . the words were presented individually to a group of [digit] spanish observers , using a controlled time procedure . an unspecific learning effect was found showing that performance improved due to practice with the task . finally , of the [digit] psycholinguistic variables that previous researchers have shown to affect word identification , only imagery accounted for a significant amount of variance in the threshold values", "tokenized": "word difficulty varies from language to language therefore , normative data of verbal stimuli can not be imported directly from another language . we present mean identification thresholds for the [digit] screen fragmented words corresponding to the total set of snodgrass and vanderwart ( [digit] ) pictures . individual words were fragmented in eight levels using turbo pascal , and the resulting program was implemented on a pc microcomputer . the words were presented individually to a group of [digit] spanish observers , using a controlled time procedure . an unspecific learning effect was found showing that performance improved due to practice with the task . finally , of the [digit] psycholinguistic variables that previous researchers have shown to affect word identification , only imagery accounted for a significant amount of variance in the threshold values"}, "present_kps": {"text": ["visual word identification thresholds", "word identification", "fragmented words", "word difficulty", "verbal stimuli", "mean identification thresholds", "screen fragmented words", "turbo pascal", "pc microcomputer", "spanish", "controlled time procedure", "unspecific learning effect", "psycholinguistic variables"], "tokenized": ["visual word identification thresholds", "word identification", "fragmented words", "word difficulty", "verbal stimuli", "mean identification thresholds", "screen fragmented words", "turbo pascal", "pc microcomputer", "spanish", "controlled time procedure", "unspecific learning effect", "psycholinguistic variables"]}, "absent_kps": {"text": ["snodgrass and vanderwart pictures"], "tokenized": ["snodgrass and vanderwart pictures"]}}
{"id": 381, "title": {"text": "a web accessible database of characteristics of the [digit] , [digit] basic japanese kanji .", "tokenized": "a web accessible database of characteristics of the [digit] , [digit] basic japanese kanji ."}, "abstract": {"text": "kanji ( jooyoo kanji hyo ) , including specifications of pronunciation . this list was established as the standard for kanji usage in print . the database for [digit] , [digit] basic japanese kanji provides [digit] cells that explain in detail the various characteristics of kanji . means , standard deviations , distributions , and information related to previous research concerning these kanji are provided in this paper . the database is saved as a microsoft excel [digit] file for windows . this kanji database is accessible on the web site of the oxford text archive , oxford university ( http ota . ahds . ac . uk ) . using this database , researchers and educators will be able to conduct planned experiments and organize classroom instruction on the basis of the known characteristics of selected kanji", "tokenized": "kanji ( jooyoo kanji hyo ) , including specifications of pronunciation . this list was established as the standard for kanji usage in print . the database for [digit] , [digit] basic japanese kanji provides [digit] cells that explain in detail the various characteristics of kanji . means , standard deviations , distributions , and information related to previous research concerning these kanji are provided in this paper . the database is saved as a microsoft excel [digit] file for windows . this kanji database is accessible on the web site of the oxford text archive , oxford university ( http ota . ahds . ac . uk ) . using this database , researchers and educators will be able to conduct planned experiments and organize classroom instruction on the basis of the known characteristics of selected kanji"}, "present_kps": {"text": ["web accessible database", "basic japanese kanji", "jooyoo kanji hyo", "pronunciation", "cells", "means", "standard deviations", "distributions", "microsoft excel [digit] file for windows", "classroom instruction"], "tokenized": ["web accessible database", "basic japanese kanji", "jooyoo kanji hyo", "pronunciation", "cells", "means", "standard deviations", "distributions", "microsoft excel [digit] file for windows", "classroom instruction"]}, "absent_kps": {"text": ["oxford text archive web site", "kanji usage print"], "tokenized": ["oxford text archive web site", "kanji usage print"]}}
{"id": 382, "title": {"text": "full screen ultrafast video modes over clocked by simple vesa routines and .", "tokenized": "full screen ultrafast video modes over clocked by simple vesa routines and ."}, "abstract": {"text": "fast full screen presentation of stimuli is necessary in psychological research . although spitczok von brisinski ( [digit] ) introduced a method that achieved ultrafast display by reprogramming the registers , he could not produce an acceptable full screen display . in this report , the author introduces a new method combining vesa routine calling with register reprogramming that can yield a display at [digit] [digit] resolution , with a refresh rate of about [digit] hz", "tokenized": "fast full screen presentation of stimuli is necessary in psychological research . although spitczok von brisinski ( [digit] ) introduced a method that achieved ultrafast display by reprogramming the registers , he could not produce an acceptable full screen display . in this report , the author introduces a new method combining vesa routine calling with register reprogramming that can yield a display at [digit] [digit] resolution , with a refresh rate of about [digit] hz"}, "present_kps": {"text": ["full screen ultrafast video modes", "psychological research", "vesa routine calling", "register reprogramming"], "tokenized": ["full screen ultrafast video modes", "psychological research", "vesa routine calling", "register reprogramming"]}, "absent_kps": {"text": ["fast full screen stimuli presentation", "ms dos"], "tokenized": ["fast full screen stimuli presentation", "ms dos"]}}
{"id": 383, "title": {"text": "measuring keyboard response delays by comparing keyboard and joystick inputs .", "tokenized": "measuring keyboard response delays by comparing keyboard and joystick inputs ."}, "abstract": {"text": "are used as response devices in psychological experiments . in the past , the proposed method has been to check the characteristics independently by means of external measurement equipment . however , with the availability of different pc models and the rapid pace of model change , there is an urgent need for the development of convenient and accurate methods of checking . the method proposed consists of raising the precision of the pc ' s clock to the microsecond level and using a joystick connected to the midi terminal of a sound board to give the pc an independent timing function . statistical processing of the data provided by this method makes it possible to estimate accurately the keyboard scanning interval time and the average keyboard delay time . the results showed that measured keyboard delay times varied from [digit] to [digit] msec , depending on the keyboard model , with most values being less than [digit] msec", "tokenized": "are used as response devices in psychological experiments . in the past , the proposed method has been to check the characteristics independently by means of external measurement equipment . however , with the availability of different pc models and the rapid pace of model change , there is an urgent need for the development of convenient and accurate methods of checking . the method proposed consists of raising the precision of the pc ' s clock to the microsecond level and using a joystick connected to the midi terminal of a sound board to give the pc an independent timing function . statistical processing of the data provided by this method makes it possible to estimate accurately the keyboard scanning interval time and the average keyboard delay time . the results showed that measured keyboard delay times varied from [digit] to [digit] msec , depending on the keyboard model , with most values being less than [digit] msec"}, "present_kps": {"text": ["joystick inputs", "psychological experiments", "checking", "model change", "midi terminal", "sound board", "independent timing function", "keyboard scanning interval time", "average keyboard delay time"], "tokenized": ["joystick inputs", "psychological experiments", "checking", "model change", "midi terminal", "sound board", "independent timing function", "keyboard scanning interval time", "average keyboard delay time"]}, "absent_kps": {"text": ["keyboard inputs", "pc keyboards", "keyboard response delay measurement", "pc clock precision", "statistical data processing"], "tokenized": ["keyboard inputs", "pc keyboards", "keyboard response delay measurement", "pc clock precision", "statistical data processing"]}}
{"id": 384, "title": {"text": "computer program to generate operant schedules .", "tokenized": "computer program to generate operant schedules ."}, "abstract": {"text": "students can use the program to experience schedules of reinforcement that are typically used with nonhuman subjects . accumulative recording of a student ' s response can be shown on the screen and or printed with the computer ' s printer . the program can also be used to program operant schedules for animal subjects . the program was tested with human subjects experiencing fixed ratio , variable ratio , fixed interval , and variable interval schedules . performance for human subjects on a given schedule was similar to performance for nonhuman subjects on the same schedule", "tokenized": "students can use the program to experience schedules of reinforcement that are typically used with nonhuman subjects . accumulative recording of a student ' s response can be shown on the screen and or printed with the computer ' s printer . the program can also be used to program operant schedules for animal subjects . the program was tested with human subjects experiencing fixed ratio , variable ratio , fixed interval , and variable interval schedules . performance for human subjects on a given schedule was similar to performance for nonhuman subjects on the same schedule"}, "present_kps": {"text": ["computer program", "nonhuman subjects", "animal subjects", "human subjects", "variable interval schedules"], "tokenized": ["computer program", "nonhuman subjects", "animal subjects", "human subjects", "variable interval schedules"]}, "absent_kps": {"text": ["variable ratio schedules", "cumulative student response recording", "fixed ratio schedules", "reinforcement schedule programming", "fixed interval schedules", "operant schedule generation"], "tokenized": ["variable ratio schedules", "cumulative student response recording", "fixed ratio schedules", "reinforcement schedule programming", "fixed interval schedules", "operant schedule generation"]}}
{"id": 385, "title": {"text": "on line homework quiz exam applet freely available java software for .", "tokenized": "on line homework quiz exam applet freely available java software for ."}, "abstract": {"text": "the homework quiz exam applet is a freely available java program that can be used to evaluate student performance on line for any content authored by a teacher . it has database connectivity so that student scores are automatically recorded . it allows several different types of questions . each question can be linked to images and detailed story problems . three levels of feedback are provided to student responses . it allows teachers to randomize the sequence of questions and to randomize which of several options is the correct answer in multiple choice questions . the creation and editing of questions involves menu selections , button presses , and the typing of content no programming knowledge is required . the code is open source in order to encourage modifications that will meet individual pedagogical needs", "tokenized": "the homework quiz exam applet is a freely available java program that can be used to evaluate student performance on line for any content authored by a teacher . it has database connectivity so that student scores are automatically recorded . it allows several different types of questions . each question can be linked to images and detailed story problems . three levels of feedback are provided to student responses . it allows teachers to randomize the sequence of questions and to randomize which of several options is the correct answer in multiple choice questions . the creation and editing of questions involves menu selections , button presses , and the typing of content no programming knowledge is required . the code is open source in order to encourage modifications that will meet individual pedagogical needs"}, "present_kps": {"text": ["freely available java software", "database connectivity", "images", "detailed story problems", "feedback", "multiple choice questions", "menu selections", "button presses", "individual pedagogical needs"], "tokenized": ["freely available java software", "database connectivity", "images", "detailed story problems", "feedback", "multiple choice questions", "menu selections", "button presses", "individual pedagogical needs"]}, "absent_kps": {"text": ["teacher authored content", "randomized question sequence", "online homework quiz exam applet", "automatic student score recording", "typing content", "question editing", "online student performance evaluation", "question creation"], "tokenized": ["teacher authored content", "randomized question sequence", "online homework quiz exam applet", "automatic student score recording", "typing content", "question editing", "online student performance evaluation", "question creation"]}}
{"id": 386, "title": {"text": "wextor a web based tool for generating and visualizing experimental designs .", "tokenized": "wextor a web based tool for generating and visualizing experimental designs ."}, "abstract": {"text": "wextor is a javascript based experiment generator and teaching tool on the world wide web that can be used to design laboratory and web experiments in a guided step by step process . it dynamically creates the customized web pages and javascripts needed for the experimental procedure and provides experimenters with a print ready visual display of their experimental design . wextor flexibly supports complete and incomplete factorial designs with between subjects , within subjects , and quasi experimental factors , as well as mixed designs . the software implements client side response time measurement and contains a content wizard for creating interactive materials , as well as dependent measures ( graphical scales , multiple choice items , etc . ) , on the experiment pages . however , it does not aim to replace a full fledged html editor . several methodological features specifically needed in web experimental design have been implemented in the web based tool and are described in this paper . wextor is platform independent . the created web pages can be uploaded to any type of web server in which data may be recorded in logfiles or via a database . the current version of wextor is freely available for educational and noncommercial purposes . its web address is http www . genpsylab . unizh . ch wextor index . html", "tokenized": "wextor is a javascript based experiment generator and teaching tool on the world wide web that can be used to design laboratory and web experiments in a guided step by step process . it dynamically creates the customized web pages and javascripts needed for the experimental procedure and provides experimenters with a print ready visual display of their experimental design . wextor flexibly supports complete and incomplete factorial designs with between subjects , within subjects , and quasi experimental factors , as well as mixed designs . the software implements client side response time measurement and contains a content wizard for creating interactive materials , as well as dependent measures ( graphical scales , multiple choice items , etc . ) , on the experiment pages . however , it does not aim to replace a full fledged html editor . several methodological features specifically needed in web experimental design have been implemented in the web based tool and are described in this paper . wextor is platform independent . the created web pages can be uploaded to any type of web server in which data may be recorded in logfiles or via a database . the current version of wextor is freely available for educational and noncommercial purposes . its web address is http www . genpsylab . unizh . ch wextor index . html"}, "present_kps": {"text": ["wextor", "web based tool", "javascript based experiment generator", "teaching tool", "world wide web", "customized web pages", "print ready visual display", "factorial designs", "client side response time measurement", "content wizard", "html", "web server", "logfiles", "database"], "tokenized": ["wextor", "web based tool", "javascript based experiment generator", "teaching tool", "world wide web", "customized web pages", "print ready visual display", "factorial designs", "client side response time measurement", "content wizard", "html", "web server", "logfiles", "database"]}, "absent_kps": {"text": ["free software", "experimental design visualization"], "tokenized": ["free software", "experimental design visualization"]}}
{"id": 387, "title": {"text": "adaptive neural fuzzy control for interpolated nonlinear systems .", "tokenized": "adaptive neural fuzzy control for interpolated nonlinear systems ."}, "abstract": {"text": "practical importance . we propose an adaptive control methodology for a class of nonlinear systems with a time varying structure . this class of systems is composed of interpolations of nonlinear subsystems which are input output feedback linearizable . both indirect and direct adaptive control methods are developed , where the spatially localized models ( in the form of takagi sugeno fuzzy systems or radial basis function neural networks ) are used as online approximators to learn the unknown dynamics of the system . without assumptions on rate of change of system dynamics , the proposed adaptive control methods guarantee that all internal signals of the system are bounded and the tracking error is asymptotically stable . the performance of the adaptive controller is demonstrated using a jet engine control problem", "tokenized": "practical importance . we propose an adaptive control methodology for a class of nonlinear systems with a time varying structure . this class of systems is composed of interpolations of nonlinear subsystems which are input output feedback linearizable . both indirect and direct adaptive control methods are developed , where the spatially localized models ( in the form of takagi sugeno fuzzy systems or radial basis function neural networks ) are used as online approximators to learn the unknown dynamics of the system . without assumptions on rate of change of system dynamics , the proposed adaptive control methods guarantee that all internal signals of the system are bounded and the tracking error is asymptotically stable . the performance of the adaptive controller is demonstrated using a jet engine control problem"}, "present_kps": {"text": ["adaptive neural fuzzy control", "interpolated nonlinear systems", "spatially localized models", "takagi sugeno fuzzy systems", "radial basis function neural networks", "online approximators", "unknown dynamics", "tracking error", "jet engine control"], "tokenized": ["adaptive neural fuzzy control", "interpolated nonlinear systems", "spatially localized models", "takagi sugeno fuzzy systems", "radial basis function neural networks", "online approximators", "unknown dynamics", "tracking error", "jet engine control"]}, "absent_kps": {"text": ["input output feedback linearizable systems", "time varying systems", "direct control", "stability analysis", "indirect control"], "tokenized": ["input output feedback linearizable systems", "time varying systems", "direct control", "stability analysis", "indirect control"]}}
{"id": 388, "title": {"text": "epsych interactive demonstrations and experiments in psychology .", "tokenized": "epsych interactive demonstrations and experiments in psychology ."}, "abstract": {"text": "development , is intended to teach students about the discipline of psychology . the site presumes little prior knowledge about the field and so may be used in introductory classes , but it incorporates sufficient depth of coverage to be useful in more advanced classes as well . numerous interactive and dynamic elements are incorporated into various modules , orientations , and guidebooks . these elements include java based experiments and demonstrations , video clips , and animated diagrams . rapid access to all material is provided through a layer based navigation system that allows users to visit various worlds of the mind . active learning is encouraged , by challenging students with puzzles and problems and by providing the opportunity to dig deeper to learn more about the phenomena at hand", "tokenized": "development , is intended to teach students about the discipline of psychology . the site presumes little prior knowledge about the field and so may be used in introductory classes , but it incorporates sufficient depth of coverage to be useful in more advanced classes as well . numerous interactive and dynamic elements are incorporated into various modules , orientations , and guidebooks . these elements include java based experiments and demonstrations , video clips , and animated diagrams . rapid access to all material is provided through a layer based navigation system that allows users to visit various worlds of the mind . active learning is encouraged , by challenging students with puzzles and problems and by providing the opportunity to dig deeper to learn more about the phenomena at hand"}, "present_kps": {"text": ["epsych", "interactive demonstrations", "teaching", "java based experiments", "video clips", "animated diagrams", "layer based navigation system", "worlds of the mind", "active learning"], "tokenized": ["epsych", "interactive demonstrations", "teaching", "java based experiments", "video clips", "animated diagrams", "layer based navigation system", "worlds of the mind", "active learning"]}, "absent_kps": {"text": ["psychology experiments", "web site"], "tokenized": ["psychology experiments", "web site"]}}
{"id": 389, "title": {"text": "information architecture without internal theory an inductive design process .", "tokenized": "information architecture without internal theory an inductive design process ."}, "abstract": {"text": "inductive process . although top level goals , user attributes and available content are periodically considered , the process involves bottom up design activities . ia is inductive partly because it lacks internal theory , and partly because it is an activity that supports emergent phenomena ( user experiences ) from basic design components . the nature of ia design is well described by constructive induction ( ci ) , a design process that involves locating the best representational framework for the design problem , identifying a solution within that framework and translating it back to the design problem at hand . the future of ia , if it remains inductive or develops a body of theory ( or both ) , is considered", "tokenized": "inductive process . although top level goals , user attributes and available content are periodically considered , the process involves bottom up design activities . ia is inductive partly because it lacks internal theory , and partly because it is an activity that supports emergent phenomena ( user experiences ) from basic design components . the nature of ia design is well described by constructive induction ( ci ) , a design process that involves locating the best representational framework for the design problem , identifying a solution within that framework and translating it back to the design problem at hand . the future of ia , if it remains inductive or develops a body of theory ( or both ) , is considered"}, "present_kps": {"text": ["internal theory", "inductive design process", "bottom up design activities", "emergent phenomena", "user experiences", "constructive induction"], "tokenized": ["internal theory", "inductive design process", "bottom up design activities", "emergent phenomena", "user experiences", "constructive induction"]}, "absent_kps": {"text": ["information architecture design"], "tokenized": ["information architecture design"]}}
{"id": 390, "title": {"text": "information architecture for the web the ia matrix approach to designing .", "tokenized": "information architecture for the web the ia matrix approach to designing ."}, "abstract": {"text": "the article presents a matrix that can serve as a tool for designing the information architecture of a web portal in a logical and systematic manner . the information architect begins by inputting the portal ' s objective , target user , and target content . the matrix then determines the most appropriate information architecture attributes for the portal by filling in the applied information architecture portion of the matrix . the article discusses how the matrix works using the example of a children ' s web portal to provide access to museum information", "tokenized": "the article presents a matrix that can serve as a tool for designing the information architecture of a web portal in a logical and systematic manner . the information architect begins by inputting the portal ' s objective , target user , and target content . the matrix then determines the most appropriate information architecture attributes for the portal by filling in the applied information architecture portion of the matrix . the article discusses how the matrix works using the example of a children ' s web portal to provide access to museum information"}, "present_kps": {"text": ["information architecture", "target user", "target content", "children ' s web portal", "museum information"], "tokenized": ["information architecture", "target user", "target content", "children ' s web portal", "museum information"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 391, "title": {"text": "information architecture notes toward a new curriculum .", "tokenized": "information architecture notes toward a new curriculum ."}, "abstract": {"text": "professional practice . however , if it is to become a profession , it must develop a means of educating new information architects . lessons from other fields suggest that professional education typically evolves along a predictable path , from apprenticeships to trade schools to college and university level education . information architecture education may develop more quickly to meet the growing demands of the information society . several pedagogical approaches employed in other fields may be adopted for information architecture education , as long as the resulting curricula provide an interdisciplinary approach and balance instruction in technical and design skills with consideration of theoretical concepts . key content areas are information organization , graphic . design , computer science , user and usability studies , and communication . certain logistics must be worked out , including where information architecture studies should be housed and what kinds of degrees should be offered and at what levels . the successful information architecture curriculum will be flexible and adaptable in order to meet the changing needs of students and the marketplace", "tokenized": "professional practice . however , if it is to become a profession , it must develop a means of educating new information architects . lessons from other fields suggest that professional education typically evolves along a predictable path , from apprenticeships to trade schools to college and university level education . information architecture education may develop more quickly to meet the growing demands of the information society . several pedagogical approaches employed in other fields may be adopted for information architecture education , as long as the resulting curricula provide an interdisciplinary approach and balance instruction in technical and design skills with consideration of theoretical concepts . key content areas are information organization , graphic . design , computer science , user and usability studies , and communication . certain logistics must be worked out , including where information architecture studies should be housed and what kinds of degrees should be offered and at what levels . the successful information architecture curriculum will be flexible and adaptable in order to meet the changing needs of students and the marketplace"}, "present_kps": {"text": ["professional practice", "information architects", "professional education", "information architecture education", "pedagogical approaches", "information organization", "computer science", "usability studies"], "tokenized": ["professional practice", "information architects", "professional education", "information architecture education", "pedagogical approaches", "information organization", "computer science", "usability studies"]}, "absent_kps": {"text": ["graphic design"], "tokenized": ["graphic design"]}}
{"id": 392, "title": {"text": "information architecture in jasist just where did we come from .", "tokenized": "information architecture in jasist just where did we come from ."}, "abstract": {"text": "has been simultaneously drawn out yet rapid . those with an eye on history are quick to point to wurman ' s [digit] use of the term architecture of information , but it has only been in the last [digit] years that ia has become the source of sufficient interest for people to label themselves professionally as information architects . the impetus for this recent emergence of ia can be traced to a historical summit , supported by asis t in may [digit] at boston . it was here that several hundred of us gathered to thrash out the questions of just what ia was and what this new field might become . at the time of the summit , invited to present a short talk on my return journey from the annual acm sigchi conference , i entered the summit expecting little and convinced that ia was nothing new . i left [digit] days later refreshed , not just by the enthusiasm of the attendees for this term but by ia ' s potential to unify the disparate perspectives and orientations of professionals from a range of disciplines . it was at this summit that the idea for the special issue took root . i proposed the idea to don kraft , hoping he would find someone else to run with it . as luck would have it , i ended up taking charge of it myself , with initial support from david blair . from the suggestion to the finished product has been the best part of [digit] years , and in that time more than [digit] volunteers reviewed over [digit] submissions", "tokenized": "has been simultaneously drawn out yet rapid . those with an eye on history are quick to point to wurman ' s [digit] use of the term architecture of information , but it has only been in the last [digit] years that ia has become the source of sufficient interest for people to label themselves professionally as information architects . the impetus for this recent emergence of ia can be traced to a historical summit , supported by asis t in may [digit] at boston . it was here that several hundred of us gathered to thrash out the questions of just what ia was and what this new field might become . at the time of the summit , invited to present a short talk on my return journey from the annual acm sigchi conference , i entered the summit expecting little and convinced that ia was nothing new . i left [digit] days later refreshed , not just by the enthusiasm of the attendees for this term but by ia ' s potential to unify the disparate perspectives and orientations of professionals from a range of disciplines . it was at this summit that the idea for the special issue took root . i proposed the idea to don kraft , hoping he would find someone else to run with it . as luck would have it , i ended up taking charge of it myself , with initial support from david blair . from the suggestion to the finished product has been the best part of [digit] years , and in that time more than [digit] volunteers reviewed over [digit] submissions"}, "present_kps": {"text": ["information architecture"], "tokenized": ["information architecture"]}, "absent_kps": {"text": ["information systems", "controlled vocabularies", "qualified information architect", "cd rom", "web sites", "metadata fields"], "tokenized": ["information systems", "controlled vocabularies", "qualified information architect", "cd rom", "web sites", "metadata fields"]}}
{"id": 393, "title": {"text": "the impact of the internet on public library use an analysis of the current .", "tokenized": "the impact of the internet on public library use an analysis of the current ."}, "abstract": {"text": "the potential impact of the internet on the public ' s demand for the services and resources of public libraries is an issue of critical importance . the research reported in this article provides baseline data concerning the evolving relationship between the public ' s use of the library and its use of the internet . the authors developed a consumer model of the american adult market for information services and resources , segmented by use ( or nonuse ) of the public library and by access ( or lack of access ) to , and use ( or nonuse ) of , the internet . a national random digit dialing telephone survey collected data to estimate the size of each of six market segments , and to describe their usage choices between the public library and the internet . the analyses presented in this article provide estimates of the size and demographics of each of the market segments describe why people are currently using the public library and the internet identify the decision criteria people use in their choices of which provider to use identify areas in which libraries and the internet appear to be competing and areas in which they appear to be complementary and identify reasons why people choose not to use the public library and or the internet . the data suggest that some differentiation between the library and the internet is taking place , which may very well have an impact on consumer choices between the two . longitudinal research is necessary to fully reveal trends in these usage choices , which have implications for all types of libraries in planning and policy development", "tokenized": "the potential impact of the internet on the public ' s demand for the services and resources of public libraries is an issue of critical importance . the research reported in this article provides baseline data concerning the evolving relationship between the public ' s use of the library and its use of the internet . the authors developed a consumer model of the american adult market for information services and resources , segmented by use ( or nonuse ) of the public library and by access ( or lack of access ) to , and use ( or nonuse ) of , the internet . a national random digit dialing telephone survey collected data to estimate the size of each of six market segments , and to describe their usage choices between the public library and the internet . the analyses presented in this article provide estimates of the size and demographics of each of the market segments describe why people are currently using the public library and the internet identify the decision criteria people use in their choices of which provider to use identify areas in which libraries and the internet appear to be competing and areas in which they appear to be complementary and identify reasons why people choose not to use the public library and or the internet . the data suggest that some differentiation between the library and the internet is taking place , which may very well have an impact on consumer choices between the two . longitudinal research is necessary to fully reveal trends in these usage choices , which have implications for all types of libraries in planning and policy development"}, "present_kps": {"text": ["internet", "public libraries", "public library", "baseline data", "consumer model", "american adult market", "national random digit dialing telephone survey", "decision criteria", "longitudinal research"], "tokenized": ["internet", "public libraries", "public library", "baseline data", "consumer model", "american adult market", "national random digit dialing telephone survey", "decision criteria", "longitudinal research"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 394, "title": {"text": "duality revisited construction of fractional frequency distributions based on .", "tokenized": "duality revisited construction of fractional frequency distributions based on ."}, "abstract": {"text": "fractional frequency distributions of , for example , authors with a certain ( fractional ) number of papers are very irregular , and therefore not easy to model or to explain . the article gives a first attempt to this by as suming two simple lotka laws ( with exponent [digit] ) one for the number of authors with n papers ( total count here ) and one for the number of papers with n authors , n in n . based on an earlier made convolution model of egghe , interpreted and reworked now for discrete scores , we are able to produce theoretical fractional frequency distributions with only one parameter , which are in very close agreement with the practical ones as found in a large dataset produced earlier by rao ( [digit] ) . the article also shows that ( irregular ) fractional frequency distributions are a consequence of lotka ' s law , and are not examples of breakdowns of this famous historical law", "tokenized": "fractional frequency distributions of , for example , authors with a certain ( fractional ) number of papers are very irregular , and therefore not easy to model or to explain . the article gives a first attempt to this by as suming two simple lotka laws ( with exponent [digit] ) one for the number of authors with n papers ( total count here ) and one for the number of papers with n authors , n in n . based on an earlier made convolution model of egghe , interpreted and reworked now for discrete scores , we are able to produce theoretical fractional frequency distributions with only one parameter , which are in very close agreement with the practical ones as found in a large dataset produced earlier by rao ( [digit] ) . the article also shows that ( irregular ) fractional frequency distributions are a consequence of lotka ' s law , and are not examples of breakdowns of this famous historical law"}, "present_kps": {"text": ["convolution model", "discrete scores"], "tokenized": ["convolution model", "discrete scores"]}, "absent_kps": {"text": ["dual lotka laws", "irregular fractional frequency distributions"], "tokenized": ["dual lotka laws", "irregular fractional frequency distributions"]}}
{"id": 395, "title": {"text": "relevance of web documents ghosts consensus method .", "tokenized": "relevance of web documents ghosts consensus method ."}, "abstract": {"text": "systems is often called digital democracy . such an approach implies the utilization of the majority opinion of internet users to determine the most relevant documents for example , citation index usage for sorting of search results ( google . com ) or an enrichment of a query with terms that are asked frequently in relation with the query ' s theme . digital democracy is an effective instrument in many cases , but it has an unavoidable shortcoming , which is a matter of principle the average intellectual and cultural level of internet users is very low everyone knows what kind of information is dominant in internet query statistics . therefore , when one searches the internet by means of digital democracy systems , one gets answers that reflect an underlying assumption that the user ' s mind potential is very low , and that his cultural interests are not demanding . thus , it is more correct to use the term digital ochlocracy to refer to internet search systems with digital democracy . based on the well known mathematical mechanism of linear programming , we propose a method to solve the indicated problem", "tokenized": "systems is often called digital democracy . such an approach implies the utilization of the majority opinion of internet users to determine the most relevant documents for example , citation index usage for sorting of search results ( google . com ) or an enrichment of a query with terms that are asked frequently in relation with the query ' s theme . digital democracy is an effective instrument in many cases , but it has an unavoidable shortcoming , which is a matter of principle the average intellectual and cultural level of internet users is very low everyone knows what kind of information is dominant in internet query statistics . therefore , when one searches the internet by means of digital democracy systems , one gets answers that reflect an underlying assumption that the user ' s mind potential is very low , and that his cultural interests are not demanding . thus , it is more correct to use the term digital ochlocracy to refer to internet search systems with digital democracy . based on the well known mathematical mechanism of linear programming , we propose a method to solve the indicated problem"}, "present_kps": {"text": ["ghosts consensus method", "digital democracy", "majority opinion", "citation index usage", "search results", "internet query statistics", "digital ochlocracy", "internet search systems", "linear programming"], "tokenized": ["ghosts consensus method", "digital democracy", "majority opinion", "citation index usage", "search results", "internet query statistics", "digital ochlocracy", "internet search systems", "linear programming"]}, "absent_kps": {"text": ["world wide web"], "tokenized": ["world wide web"]}}
{"id": 396, "title": {"text": "note on deterministic inventory lot size models under inflation with shortages .", "tokenized": "note on deterministic inventory lot size models under inflation with shortages ."}, "abstract": {"text": "for original paper see h . l . yang et al . , ibid . , vol . [digit] , p . [digit] [digit] ( [digit] ) . yang et al . extended the lot size models to allow for inflation and fluctuating demand . for this model they proved that the optimal replenishment schedule exists and is unique . they also proposed an algorithm to find the optimal policy . the present paper provides examples , which show that the optimal replenishment schedule and consequently the overall optimal policy may not exist", "tokenized": "for original paper see h . l . yang et al . , ibid . , vol . [digit] , p . [digit] [digit] ( [digit] ) . yang et al . extended the lot size models to allow for inflation and fluctuating demand . for this model they proved that the optimal replenishment schedule exists and is unique . they also proposed an algorithm to find the optimal policy . the present paper provides examples , which show that the optimal replenishment schedule and consequently the overall optimal policy may not exist"}, "present_kps": {"text": ["deterministic inventory lot size models", "inflation", "fluctuating demand", "optimal replenishment schedule"], "tokenized": ["deterministic inventory lot size models", "inflation", "fluctuating demand", "optimal replenishment schedule"]}, "absent_kps": {"text": ["optimal scheduling parameters", "optimal policy algorithm"], "tokenized": ["optimal scheduling parameters", "optimal policy algorithm"]}}
{"id": 397, "title": {"text": "designing a screening experiment for highly reliable products .", "tokenized": "designing a screening experiment for highly reliable products ."}, "abstract": {"text": "reliable products is one of the great challenges . by using a resolution iii experiment together with degradation test , tseng et al . ( [digit] ) presented a case study of improving the reliability of fluorescent lamps . however , in conducting such an experiment , they did not address the problem of how to choose the optimal settings of variables , such as sample size , inspection frequency , and termination time for each run , which are influential to the correct identification of significant factors and the experimental cost . assuming that the product ' s degradation paths satisfy wiener processes , this paper proposes a systematic approach to the aforementioned problem . first , an identification rule is proposed . next , under the constraints of a minimum probability of correct decision and a maximum probability of incorrect decision of the proposed identification rule , the optimum test plan can be obtained by minimizing the total experimental cost . an example is provided to illustrate the proposed method", "tokenized": "reliable products is one of the great challenges . by using a resolution iii experiment together with degradation test , tseng et al . ( [digit] ) presented a case study of improving the reliability of fluorescent lamps . however , in conducting such an experiment , they did not address the problem of how to choose the optimal settings of variables , such as sample size , inspection frequency , and termination time for each run , which are influential to the correct identification of significant factors and the experimental cost . assuming that the product ' s degradation paths satisfy wiener processes , this paper proposes a systematic approach to the aforementioned problem . first , an identification rule is proposed . next , under the constraints of a minimum probability of correct decision and a maximum probability of incorrect decision of the proposed identification rule , the optimum test plan can be obtained by minimizing the total experimental cost . an example is provided to illustrate the proposed method"}, "present_kps": {"text": ["screening experiment", "highly reliable products", "degradation tests", "fluorescent lamps", "inspection frequency", "termination time", "wiener process", "identification rule", "minimum probability of correct decision", "maximum probability of incorrect decision"], "tokenized": ["screening experiment", "highly reliable products", "degradation tests", "fluorescent lamps", "inspection frequency", "termination time", "wiener process", "identification rule", "minimum probability of correct decision", "maximum probability of incorrect decision"]}, "absent_kps": {"text": ["optimal test plan", "resolution iii design"], "tokenized": ["optimal test plan", "resolution iii design"]}}
{"id": 398, "title": {"text": "analysis and efficient implementation of a linguistic fuzzy c means .", "tokenized": "analysis and efficient implementation of a linguistic fuzzy c means ."}, "abstract": {"text": "vectors of fuzzy numbers as inputs . this algorithm is based on the extension principle and the decomposition theorem . it turns out that using the extension principle to extend the capability of the standard membership update equation to deal with a linguistic vector has a huge computational complexity . in order to cope with this problem , an efficient method based on fuzzy arithmetic and optimization has been developed and analyzed . we also carefully examine and prove that the algorithm behaves in a way similar to the fcm in the degenerate linguistic case . synthetic data sets and the iris data set have been used to illustrate the behavior of this linguistic version of the fcm", "tokenized": "vectors of fuzzy numbers as inputs . this algorithm is based on the extension principle and the decomposition theorem . it turns out that using the extension principle to extend the capability of the standard membership update equation to deal with a linguistic vector has a huge computational complexity . in order to cope with this problem , an efficient method based on fuzzy arithmetic and optimization has been developed and analyzed . we also carefully examine and prove that the algorithm behaves in a way similar to the fcm in the degenerate linguistic case . synthetic data sets and the iris data set have been used to illustrate the behavior of this linguistic version of the fcm"}, "present_kps": {"text": ["fuzzy numbers", "extension principle", "decomposition theorem", "linguistic vectors", "computational complexity", "fuzzy arithmetic", "optimization"], "tokenized": ["fuzzy numbers", "extension principle", "decomposition theorem", "linguistic vectors", "computational complexity", "fuzzy arithmetic", "optimization"]}, "absent_kps": {"text": ["linguistic fuzzy c means algorithm"], "tokenized": ["linguistic fuzzy c means algorithm"]}}
{"id": 399, "title": {"text": "warranty reserves for nonstationary sales processes .", "tokenized": "warranty reserves for nonstationary sales processes ."}, "abstract": {"text": "warranty period , is of importance to the manufacturer . costs associated with replacement or repair of the product are usually drawn from a warranty reserve fund created by the manufacturer . considering a stochastic sales process , first and second moments ( and thereby the variance ) are derived for the manufacturer ' s total discounted warranty cost of a single sale for single component items under four different warranty policies from a manufacturer ' s point of view . these servicing strategies represent a renewable free replacement , nonrenewable free replacement , renewable pro rata , and a nonrenewable minimal repair warranty plans . the results are extended to determine the mean and variance of total discounted warranty costs for the total sales over the life cycle of the product . furthermore , using a normal approximation , warranty reserves necessary for a certain protection level , so that reserves are not completely depleted , are found . results and their managerial implications are studied through an extensive example", "tokenized": "warranty period , is of importance to the manufacturer . costs associated with replacement or repair of the product are usually drawn from a warranty reserve fund created by the manufacturer . considering a stochastic sales process , first and second moments ( and thereby the variance ) are derived for the manufacturer ' s total discounted warranty cost of a single sale for single component items under four different warranty policies from a manufacturer ' s point of view . these servicing strategies represent a renewable free replacement , nonrenewable free replacement , renewable pro rata , and a nonrenewable minimal repair warranty plans . the results are extended to determine the mean and variance of total discounted warranty costs for the total sales over the life cycle of the product . furthermore , using a normal approximation , warranty reserves necessary for a certain protection level , so that reserves are not completely depleted , are found . results and their managerial implications are studied through an extensive example"}, "present_kps": {"text": ["warranty reserves", "nonstationary sales processes", "stochastic sales process", "second moments", "variance", "total discounted warranty cost", "total discounted warranty costs", "single component items", "servicing strategies", "renewable free replacement", "nonrenewable free replacement", "renewable pro rata", "nonrenewable minimal repair warranty plans", "normal approximation", "managerial implications"], "tokenized": ["warranty reserves", "nonstationary sales processes", "stochastic sales process", "second moments", "variance", "total discounted warranty cost", "total discounted warranty costs", "single component items", "servicing strategies", "renewable free replacement", "nonrenewable free replacement", "renewable pro rata", "nonrenewable minimal repair warranty plans", "normal approximation", "managerial implications"]}, "absent_kps": {"text": ["product repair", "product life cycle", "product failure", "warranty costs estimation", "product replacement", "first moments"], "tokenized": ["product repair", "product life cycle", "product failure", "warranty costs estimation", "product replacement", "first moments"]}}
{"id": 400, "title": {"text": "a multimodal data collection tool using realbasic and mac os x .", "tokenized": "a multimodal data collection tool using realbasic and mac os x ."}, "abstract": {"text": "a configuration tool that builds a data collection procedure for investigating the effectiveness of sonified graphs . the advantage of using realbasic with the mac os x system is that it provides rapid development of stimulus presentation , direct recording of data to files , and control over other procedural issues . the program can be made to run natively on the new mac os x system , older mac os systems , and windows ( 98se , me , [digit] pro ) . with modification , similar programs could be used to present any number of visual auditory stimulus combinations , complete with questions for each stimulus", "tokenized": "a configuration tool that builds a data collection procedure for investigating the effectiveness of sonified graphs . the advantage of using realbasic with the mac os x system is that it provides rapid development of stimulus presentation , direct recording of data to files , and control over other procedural issues . the program can be made to run natively on the new mac os x system , older mac os systems , and windows ( 98se , me , [digit] pro ) . with modification , similar programs could be used to present any number of visual auditory stimulus combinations , complete with questions for each stimulus"}, "present_kps": {"text": ["multimodal data collection tool", "data collection", "realbasic", "configuration tool", "sonified graphs", "stimulus presentation", "windows", "auditory stimulus"], "tokenized": ["multimodal data collection tool", "data collection", "realbasic", "configuration tool", "sonified graphs", "stimulus presentation", "windows", "auditory stimulus"]}, "absent_kps": {"text": ["psychology", "direct data recording", "mac os x environment", "visual stimulus", "visual data comprehension"], "tokenized": ["psychology", "direct data recording", "mac os x environment", "visual stimulus", "visual data comprehension"]}}
{"id": 401, "title": {"text": "toward an experimental timing standards lab benchmarking precision in the real .", "tokenized": "toward an experimental timing standards lab benchmarking precision in the real ."}, "abstract": {"text": "much discussion has taken place over the relative merits of various platforms and operating systems for real time data collection . most would agree that , provided great care is taken , many are capable of millisecond timing precision . however , to date , much of this work has focused on the theoretical aspects of raw performance . it is our belief that researchers would be better informed if they could place confidence limits on their own specific paradigms in situ and without modification . to this end , we have developed a millisecond precision test rig that can control and time experiments on a second presentation machine . we report on the specialist hardware and software used . we elucidate the importance of the approach in relation to real world experimentation", "tokenized": "much discussion has taken place over the relative merits of various platforms and operating systems for real time data collection . most would agree that , provided great care is taken , many are capable of millisecond timing precision . however , to date , much of this work has focused on the theoretical aspects of raw performance . it is our belief that researchers would be better informed if they could place confidence limits on their own specific paradigms in situ and without modification . to this end , we have developed a millisecond precision test rig that can control and time experiments on a second presentation machine . we report on the specialist hardware and software used . we elucidate the importance of the approach in relation to real world experimentation"}, "present_kps": {"text": ["experimental timing standards lab", "benchmarking precision", "operating systems", "real time data collection", "millisecond timing precision"], "tokenized": ["experimental timing standards lab", "benchmarking precision", "operating systems", "real time data collection", "millisecond timing precision"]}, "absent_kps": {"text": ["performance evaluation", "event generation software"], "tokenized": ["performance evaluation", "event generation software"]}}
{"id": 402, "title": {"text": "a server side program for delivering experiments with animations .", "tokenized": "a server side program for delivering experiments with animations ."}, "abstract": {"text": "capable of delivering an experiment composed of discrete animation sequences in various file formats , collecting a discrete or continuous response from the observer , evaluating the appropriateness of the response , and ensuring that the user is not proceeding at an unreasonable rate . most parameters of the program are controllable by experimenter edited text files or simple switches in the program code , thereby minimizing the need for programming to create new experiments . a simple demonstration experiment is discussed and is freely available", "tokenized": "capable of delivering an experiment composed of discrete animation sequences in various file formats , collecting a discrete or continuous response from the observer , evaluating the appropriateness of the response , and ensuring that the user is not proceeding at an unreasonable rate . most parameters of the program are controllable by experimenter edited text files or simple switches in the program code , thereby minimizing the need for programming to create new experiments . a simple demonstration experiment is discussed and is freely available"}, "present_kps": {"text": ["server side program", "discrete animation sequences", "file formats", "experimenter edited text files"], "tokenized": ["server side program", "discrete animation sequences", "file formats", "experimenter edited text files"]}, "absent_kps": {"text": ["animation experiment delivery", "web based psychological experiments", "internet"], "tokenized": ["animation experiment delivery", "web based psychological experiments", "internet"]}}
{"id": 403, "title": {"text": "using netcloak to develop server side web based experiments without writing cgi .", "tokenized": "using netcloak to develop server side web based experiments without writing cgi ."}, "abstract": {"text": "server side experiments use the web server , rather than the participant ' s browser , to handle tasks such as random assignment , eliminating inconsistencies with java and other client side applications . heretofore , experimenters wishing to create server side experiments have had to write programs to create common gateway interface ( cgi ) scripts in programming languages such as perl and c . netcloak uses simple , html like commands to create cgis . we used netcloak to implement an experiment on probability estimation . measurements of time on task and participants ' ip addresses assisted quality control . without prior training , in less than [digit] month , we were able to use netcloak to design and create a web based experiment and to help graduate students create three web based experiments of their own", "tokenized": "server side experiments use the web server , rather than the participant ' s browser , to handle tasks such as random assignment , eliminating inconsistencies with java and other client side applications . heretofore , experimenters wishing to create server side experiments have had to write programs to create common gateway interface ( cgi ) scripts in programming languages such as perl and c . netcloak uses simple , html like commands to create cgis . we used netcloak to implement an experiment on probability estimation . measurements of time on task and participants ' ip addresses assisted quality control . without prior training , in less than [digit] month , we were able to use netcloak to design and create a web based experiment and to help graduate students create three web based experiments of their own"}, "present_kps": {"text": ["netcloak", "server side web based experiments", "web server", "random assignment", "java", "client side applications", "perl", "html", "probability estimation", "ip addresses", "quality control", "graduate students"], "tokenized": ["netcloak", "server side web based experiments", "web server", "random assignment", "java", "client side applications", "perl", "html", "probability estimation", "ip addresses", "quality control", "graduate students"]}, "absent_kps": {"text": ["psychology", "common gateway interface scripts", "cgi programs", "c language", "internet", "behavioral data"], "tokenized": ["psychology", "common gateway interface scripts", "cgi programs", "c language", "internet", "behavioral data"]}}
{"id": 404, "title": {"text": "open courseware and shared knowledge in higher education .", "tokenized": "open courseware and shared knowledge in higher education ."}, "abstract": {"text": "developed world today maintain one , two , or several learning management systems ( lmss ) , which are courseware products that provide students and faculty with web based tools to manage course related applications . since the mid 1990s , two predominant models of web courseware management systems have emerged commercial and noncommercial . some of the commercial products available today were created in academia as noncommercial but have since become commercially encumbered . other products remain noncommercial but are struggling to survive in a world of fierce commercial competition . this article argues for an ethics of pedagogy in higher education that would be based on the guiding assumptions of the non proprietary , peer to peer , open source software movement", "tokenized": "developed world today maintain one , two , or several learning management systems ( lmss ) , which are courseware products that provide students and faculty with web based tools to manage course related applications . since the mid 1990s , two predominant models of web courseware management systems have emerged commercial and noncommercial . some of the commercial products available today were created in academia as noncommercial but have since become commercially encumbered . other products remain noncommercial but are struggling to survive in a world of fierce commercial competition . this article argues for an ethics of pedagogy in higher education that would be based on the guiding assumptions of the non proprietary , peer to peer , open source software movement"}, "present_kps": {"text": ["open courseware", "shared knowledge", "higher education", "learning management systems", "web courseware management systems", "commercial products", "ethics", "open source software"], "tokenized": ["open courseware", "shared knowledge", "higher education", "learning management systems", "web courseware management systems", "commercial products", "ethics", "open source software"]}, "absent_kps": {"text": ["university", "internet", "college"], "tokenized": ["university", "internet", "college"]}}
{"id": 405, "title": {"text": "web based experiments controlled by javascript an example from probability .", "tokenized": "web based experiments controlled by javascript an example from probability ."}, "abstract": {"text": "javascript programs can be used to control web experiments . this technique is illustrated by an experiment that tested the effects of advice on performance in the classic probability learning paradigm . previous research reported that people tested via the web or in the lab tended to match the probabilities of their responses to the probabilities that those responses would be reinforced . the optimal strategy , however , is to consistently choose the more frequent event probability matching produces suboptimal performance . we investigated manipulations we reasoned should improve performance . a horse race scenario in which participants predicted the winner in each of a series of races between two horses was compared with an abstract scenario used previously . ten groups of learners received different amounts of advice , including all combinations of ( [digit] ) explicit instructions concerning the optimal strategy , ( [digit] ) explicit instructions concerning a monetary sum to maximize , and ( [digit] ) accurate information concerning the probabilities of events . the results showed minimal effects of horse race versus abstract scenario . both advice concerning the optimal strategy and probability information contributed significantly to performance in the task . this paper includes a brief tutorial on javascript , explaining with simple examples how to assemble a browser based experiment", "tokenized": "javascript programs can be used to control web experiments . this technique is illustrated by an experiment that tested the effects of advice on performance in the classic probability learning paradigm . previous research reported that people tested via the web or in the lab tended to match the probabilities of their responses to the probabilities that those responses would be reinforced . the optimal strategy , however , is to consistently choose the more frequent event probability matching produces suboptimal performance . we investigated manipulations we reasoned should improve performance . a horse race scenario in which participants predicted the winner in each of a series of races between two horses was compared with an abstract scenario used previously . ten groups of learners received different amounts of advice , including all combinations of ( [digit] ) explicit instructions concerning the optimal strategy , ( [digit] ) explicit instructions concerning a monetary sum to maximize , and ( [digit] ) accurate information concerning the probabilities of events . the results showed minimal effects of horse race versus abstract scenario . both advice concerning the optimal strategy and probability information contributed significantly to performance in the task . this paper includes a brief tutorial on javascript , explaining with simple examples how to assemble a browser based experiment"}, "present_kps": {"text": ["web based experiments", "javascript", "probability", "advice", "probability learning", "explicit instructions", "browser based experiment"], "tokenized": ["web based experiments", "javascript", "probability", "advice", "probability learning", "explicit instructions", "browser based experiment"]}, "absent_kps": {"text": ["internet based research"], "tokenized": ["internet based research"]}}
{"id": 406, "title": {"text": "using latent semantic analysis to assess reader strategies .", "tokenized": "using latent semantic analysis to assess reader strategies ."}, "abstract": {"text": "based on verbal protocols that utilized latent semantic analysis ( lsa ) . students were given self explanation reading training ( sert ) , which teaches strategies that facilitate self explanation during reading , such as elaboration based on world knowledge and bridging between text sentences . during a computerized version of sert practice , students read texts and typed self explanations into a computer after each sentence . the use of sert strategies during this practice was assessed by determining the extent to which students used the information in the current sentence versus the prior text or world knowledge in their self explanations . this assessment was made on the basis of human judgments and lsa . both human judgments and lsa were remarkably similar and indicated that students who were not complying with sert tended to paraphrase the text sentences , whereas students who were compliant with sert tended to explain the sentences in terms of what they knew about the world and of information provided in the prior text context . the similarity between human judgments and lsa indicates that lsa will be useful in accounting for reading strategies in a web based version of sert", "tokenized": "based on verbal protocols that utilized latent semantic analysis ( lsa ) . students were given self explanation reading training ( sert ) , which teaches strategies that facilitate self explanation during reading , such as elaboration based on world knowledge and bridging between text sentences . during a computerized version of sert practice , students read texts and typed self explanations into a computer after each sentence . the use of sert strategies during this practice was assessed by determining the extent to which students used the information in the current sentence versus the prior text or world knowledge in their self explanations . this assessment was made on the basis of human judgments and lsa . both human judgments and lsa were remarkably similar and indicated that students who were not complying with sert tended to paraphrase the text sentences , whereas students who were compliant with sert tended to explain the sentences in terms of what they knew about the world and of information provided in the prior text context . the similarity between human judgments and lsa indicates that lsa will be useful in accounting for reading strategies in a web based version of sert"}, "present_kps": {"text": ["latent semantic analysis", "verbal protocols", "self explanation reading training", "elaboration", "world knowledge", "human judgments"], "tokenized": ["latent semantic analysis", "verbal protocols", "self explanation reading training", "elaboration", "world knowledge", "human judgments"]}, "absent_kps": {"text": ["text sentence bridging", "reader strategy assessment", "computer based procedure"], "tokenized": ["text sentence bridging", "reader strategy assessment", "computer based procedure"]}}
{"id": 407, "title": {"text": "personality research on the internet a comparison of web based and traditional .", "tokenized": "personality research on the internet a comparison of web based and traditional ."}, "abstract": {"text": "students , faculty , and researchers have become increasingly comfortable with the internet , and many of them are interested in using the web to collect data . few published studies have investigated the differences between web based data and data collected with more traditional methods . in order to investigate these potential differences , two important factors were crossed in this study whether the data were collected on line or not and whether the data were collected in a group setting at a fixed time or individually at a time of the respondent ' s choosing . the visions of morality scale ( shelton and mcadams , [digit] ) was used , and the participants were assigned to one of four conditions in class web survey , in class paper and pencil survey take home web survey , and take home paper and pencil survey . no significant differences in scores were found for any condition however , response rates were affected by the type of survey administered , with the take home web based instrument having the lowest response rate . therefore , researchers need to be aware that different modes of administration may affect subject attrition and may , therefore , confound investigations of other independent variables", "tokenized": "students , faculty , and researchers have become increasingly comfortable with the internet , and many of them are interested in using the web to collect data . few published studies have investigated the differences between web based data and data collected with more traditional methods . in order to investigate these potential differences , two important factors were crossed in this study whether the data were collected on line or not and whether the data were collected in a group setting at a fixed time or individually at a time of the respondent ' s choosing . the visions of morality scale ( shelton and mcadams , [digit] ) was used , and the participants were assigned to one of four conditions in class web survey , in class paper and pencil survey take home web survey , and take home paper and pencil survey . no significant differences in scores were found for any condition however , response rates were affected by the type of survey administered , with the take home web based instrument having the lowest response rate . therefore , researchers need to be aware that different modes of administration may affect subject attrition and may , therefore , confound investigations of other independent variables"}, "present_kps": {"text": ["personality research", "internet", "data collection", "visions of morality scale", "in class web survey", "in class paper and pencil survey", "take home web survey", "take home paper and pencil survey", "response rates", "web based instruments", "administration", "subject attrition"], "tokenized": ["personality research", "internet", "data collection", "visions of morality scale", "in class web survey", "in class paper and pencil survey", "take home web survey", "take home paper and pencil survey", "response rates", "web based instruments", "administration", "subject attrition"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 408, "title": {"text": "implications of document level literacy skills for web site design .", "tokenized": "implications of document level literacy skills for web site design ."}, "abstract": {"text": "information on the web have placed a tremendous amount of information at the fingertips of millions of people . although most of this information is at least intended to be accurate , there is much that is rumor , innuendo , urban legend , and outright falsehood . this raises problems especially for students ( of all ages ) trying to do research or learn about some topic . finding accurate , credible information requires document level literacy skills , such as integration , sourcing , corroboration , and search . this paper discusses these skills and offers a list of simple ways that designers of educational web sites can help their visitors utilize these skills", "tokenized": "information on the web have placed a tremendous amount of information at the fingertips of millions of people . although most of this information is at least intended to be accurate , there is much that is rumor , innuendo , urban legend , and outright falsehood . this raises problems especially for students ( of all ages ) trying to do research or learn about some topic . finding accurate , credible information requires document level literacy skills , such as integration , sourcing , corroboration , and search . this paper discusses these skills and offers a list of simple ways that designers of educational web sites can help their visitors utilize these skills"}, "present_kps": {"text": ["document level literacy skills", "rumor", "innuendo", "urban legend", "falsehood", "students", "integration", "sourcing", "corroboration", "search"], "tokenized": ["document level literacy skills", "rumor", "innuendo", "urban legend", "falsehood", "students", "integration", "sourcing", "corroboration", "search"]}, "absent_kps": {"text": ["accurate credible information", "educational web site design"], "tokenized": ["accurate credible information", "educational web site design"]}}
{"id": 409, "title": {"text": "fuzzy control of multivariable process by modified error decoupling .", "tokenized": "fuzzy control of multivariable process by modified error decoupling ."}, "abstract": {"text": "outputs ) multivariable process systems is given . the proposed control system consists of two parts , single loop fuzzy controllers in each loop and a centralized decoupling unit . the fuzzy control system uses feedback control to minimize the error in the loop and the decoupler uses an adaptive technique to mitigate loop interactions . the decoupler predicts the interacting loop changes and modifies the input ( error ) of the loop controller . the controller was tested on the simulation model of single component vaporizer process", "tokenized": "outputs ) multivariable process systems is given . the proposed control system consists of two parts , single loop fuzzy controllers in each loop and a centralized decoupling unit . the fuzzy control system uses feedback control to minimize the error in the loop and the decoupler uses an adaptive technique to mitigate loop interactions . the decoupler predicts the interacting loop changes and modifies the input ( error ) of the loop controller . the controller was tested on the simulation model of single component vaporizer process"}, "present_kps": {"text": ["multivariable process", "modified error decoupling", "single loop fuzzy controllers", "centralized decoupling unit", "feedback control", "single component vaporizer process"], "tokenized": ["multivariable process", "modified error decoupling", "single loop fuzzy controllers", "centralized decoupling unit", "feedback control", "single component vaporizer process"]}, "absent_kps": {"text": ["squared multivariable process systems", "square multivariable process systems", "set point changes", "load changes", "loop interaction mitigation", "error minimization"], "tokenized": ["squared multivariable process systems", "square multivariable process systems", "set point changes", "load changes", "loop interaction mitigation", "error minimization"]}}
{"id": 410, "title": {"text": "improving computer security for authentication of users influence of proactive .", "tokenized": "improving computer security for authentication of users influence of proactive ."}, "abstract": {"text": "entering a user name password combination is a widely used procedure for identification and authentication in computer systems . however , it is a notoriously weak method , in that the passwords adopted by many users are easy to crack . in an attempt to , improve security , proactive password checking may be used , in which passwords must meet several criteria to be more resistant to cracking . in two experiments , we examined the influence of proactive password restrictions on the time that it took to generate an acceptable password and to use it subsequently to log in . the required length was a minimum of five characters in experiment i and eight characters in experiment [digit] . in both experiments , one condition had only the length restriction , and the other had additional restrictions . the additional restrictions greatly increased the time it took to generate the password but had only a small effect on the time it took to use it subsequently to log in . for the five character passwords , [digit] % were cracked when no other restrictions were imposed , and this was reduced to [digit] % with the additional restrictions . for the eight character passwords , [digit] % were cracked with no other restrictions , and [digit] . [digit] % with restrictions . the results indicate that increasing the minimum character length reduces crackability and increases security , regardless of whether additional restrictions are imposed", "tokenized": "entering a user name password combination is a widely used procedure for identification and authentication in computer systems . however , it is a notoriously weak method , in that the passwords adopted by many users are easy to crack . in an attempt to , improve security , proactive password checking may be used , in which passwords must meet several criteria to be more resistant to cracking . in two experiments , we examined the influence of proactive password restrictions on the time that it took to generate an acceptable password and to use it subsequently to log in . the required length was a minimum of five characters in experiment i and eight characters in experiment [digit] . in both experiments , one condition had only the length restriction , and the other had additional restrictions . the additional restrictions greatly increased the time it took to generate the password but had only a small effect on the time it took to use it subsequently to log in . for the five character passwords , [digit] % were cracked when no other restrictions were imposed , and this was reduced to [digit] % with the additional restrictions . for the eight character passwords , [digit] % were cracked with no other restrictions , and [digit] . [digit] % with restrictions . the results indicate that increasing the minimum character length reduces crackability and increases security , regardless of whether additional restrictions are imposed"}, "present_kps": {"text": ["computer security", "proactive password checking", "proactive password restrictions", "length restriction", "five character passwords", "eight character passwords"], "tokenized": ["computer security", "proactive password checking", "proactive password restrictions", "length restriction", "five character passwords", "eight character passwords"]}, "absent_kps": {"text": ["user authentication"], "tokenized": ["user authentication"]}}
{"id": 411, "title": {"text": "multidimensional data visualization .", "tokenized": "multidimensional data visualization ."}, "abstract": {"text": "( e . g . , histograms or scatter plots ) . available software packages ( e . g . , data desk [digit] . [digit] , matlab [digit] . [digit] , sas jmp [digit] . [digit] , spss [digit] . [digit] ) are capable of producing three dimensional scatter plots with ( varying degrees of ) user interactivity . we constructed our own data visualization application with the visualization toolkit ( schroeder et al . , [digit] ) and tcl tk to display multivariate data through the application of glyphs ( ware , [digit] ) . a glyph is a visual object onto which many data parameters may be mapped , each with a different visual attribute ( e . g . , size or color ) . we used our multi dimensional data viewer to explore data from several psycholinguistic experiments . the graphical interface provides flexibility when users dynamically explore the multidimensional image rendered from raw experimental data . we highlight advantages of multidimensional data visualization and consider some potential limitations", "tokenized": "( e . g . , histograms or scatter plots ) . available software packages ( e . g . , data desk [digit] . [digit] , matlab [digit] . [digit] , sas jmp [digit] . [digit] , spss [digit] . [digit] ) are capable of producing three dimensional scatter plots with ( varying degrees of ) user interactivity . we constructed our own data visualization application with the visualization toolkit ( schroeder et al . , [digit] ) and tcl tk to display multivariate data through the application of glyphs ( ware , [digit] ) . a glyph is a visual object onto which many data parameters may be mapped , each with a different visual attribute ( e . g . , size or color ) . we used our multi dimensional data viewer to explore data from several psycholinguistic experiments . the graphical interface provides flexibility when users dynamically explore the multidimensional image rendered from raw experimental data . we highlight advantages of multidimensional data visualization and consider some potential limitations"}, "present_kps": {"text": ["multidimensional data visualization", "user interactivity", "visualization toolkit", "tcl tk", "glyphs", "visual object", "data parameters", "visual attribute", "multi dimensional data viewer", "psycholinguistic experiments", "graphical interface", "multidimensional image rendering"], "tokenized": ["multidimensional data visualization", "user interactivity", "visualization toolkit", "tcl tk", "glyphs", "visual object", "data parameters", "visual attribute", "multi dimensional data viewer", "psycholinguistic experiments", "graphical interface", "multidimensional image rendering"]}, "absent_kps": {"text": ["multivariate data display", "3d scatter plots"], "tokenized": ["multivariate data display", "3d scatter plots"]}}
{"id": 412, "title": {"text": "fitting mixed effects models for repeated ordinal outcomes with the nlmixed .", "tokenized": "fitting mixed effects models for repeated ordinal outcomes with the nlmixed ."}, "abstract": {"text": "this paper presents an analysis of repeated ordinal outcomes arising from two psychological studies . the first case is a repeated measures analysis of variance the second is a mixed effects regression . in a longitudinal design . in both , the subject specific variation is modeled by including random effects in the linear predictor ( inside a link function ) of a generalized linear model . the nlmixed procedure in sas is used to fit the mixed effects models for the categorical response data . the presentation emphasizes the parallel between the model . specifications and the sas statements . the purpose of this paper is to facilitate the use of mixed effects models in the analysis of repeated ordinal outcomes", "tokenized": "this paper presents an analysis of repeated ordinal outcomes arising from two psychological studies . the first case is a repeated measures analysis of variance the second is a mixed effects regression . in a longitudinal design . in both , the subject specific variation is modeled by including random effects in the linear predictor ( inside a link function ) of a generalized linear model . the nlmixed procedure in sas is used to fit the mixed effects models for the categorical response data . the presentation emphasizes the parallel between the model . specifications and the sas statements . the purpose of this paper is to facilitate the use of mixed effects models in the analysis of repeated ordinal outcomes"}, "present_kps": {"text": ["repeated ordinal outcomes", "psychological studies", "repeated measures analysis of variance", "mixed effects regression", "longitudinal design", "random effects", "linear predictor", "generalized linear model", "nlmixed procedure", "categorical response data"], "tokenized": ["repeated ordinal outcomes", "psychological studies", "repeated measures analysis of variance", "mixed effects regression", "longitudinal design", "random effects", "linear predictor", "generalized linear model", "nlmixed procedure", "categorical response data"]}, "absent_kps": {"text": ["model specifications", "mixed effects model fitting", "subject specific variation modeling"], "tokenized": ["model specifications", "mixed effects model fitting", "subject specific variation modeling"]}}
{"id": 413, "title": {"text": "teaching psychology as a laboratory science in the age of the internet .", "tokenized": "teaching psychology as a laboratory science in the age of the internet ."}, "abstract": {"text": "psychology . with the advent of experiment generators , students can create well designed experiments and can test sophisticated hypotheses from the start of their undergraduate training . characteristics of new net based experiment generators are discussed and compared with traditional stand alone generators . a call is made to formally evaluate the instructional effectiveness of the wide range of experiment generators now available . specifically , software should be evaluated in terms of known learning outcomes , using appropriate control groups . the many inherent differences between any two software programs should be made clear . the teacher ' s instructional method should be fully described and held constant between comparisons . finally , the often complex interaction between the teacher ' s instructional method and the pedagogical details of the software must be considered", "tokenized": "psychology . with the advent of experiment generators , students can create well designed experiments and can test sophisticated hypotheses from the start of their undergraduate training . characteristics of new net based experiment generators are discussed and compared with traditional stand alone generators . a call is made to formally evaluate the instructional effectiveness of the wide range of experiment generators now available . specifically , software should be evaluated in terms of known learning outcomes , using appropriate control groups . the many inherent differences between any two software programs should be made clear . the teacher ' s instructional method should be fully described and held constant between comparisons . finally , the often complex interaction between the teacher ' s instructional method and the pedagogical details of the software must be considered"}, "present_kps": {"text": ["laboratory science", "internet", "well designed experiments", "undergraduate training", "net based experiment generators", "stand alone generators", "instructional effectiveness", "software", "known learning outcomes", "control groups", "pedagogical details"], "tokenized": ["laboratory science", "internet", "well designed experiments", "undergraduate training", "net based experiment generators", "stand alone generators", "instructional effectiveness", "software", "known learning outcomes", "control groups", "pedagogical details"]}, "absent_kps": {"text": ["computers", "teacher instructional method", "experimental psychology teaching", "hypothesis testing"], "tokenized": ["computers", "teacher instructional method", "experimental psychology teaching", "hypothesis testing"]}}
{"id": 414, "title": {"text": "capturing niche markets with copper .", "tokenized": "capturing niche markets with copper ."}, "abstract": {"text": "cable of best option to gain access and deliver desired services . the article discusses how operators can use network edge devices to serve new customers . niche market segments represent a significant opportunity for cable tv delivery of television and high speed internet signals . but the existing telecommunications infrastructure in those developments frequently presents unique challenges for the service provider to overcome", "tokenized": "cable of best option to gain access and deliver desired services . the article discusses how operators can use network edge devices to serve new customers . niche market segments represent a significant opportunity for cable tv delivery of television and high speed internet signals . but the existing telecommunications infrastructure in those developments frequently presents unique challenges for the service provider to overcome"}, "present_kps": {"text": ["niche markets", "network edge devices"], "tokenized": ["niche markets", "network edge devices"]}, "absent_kps": {"text": ["last mile access", "copper cables", "twisted copper pair"], "tokenized": ["last mile access", "copper cables", "twisted copper pair"]}}
{"id": 415, "title": {"text": "fresh voices , big ideas ibm internship program .", "tokenized": "fresh voices , big ideas ibm internship program ."}, "abstract": {"text": "in an [digit] week summer internship program and challenging them to develop innovative technology ideas", "tokenized": "in an [digit] week summer internship program and challenging them to develop innovative technology ideas"}, "present_kps": {"text": ["internship program"], "tokenized": ["internship program"]}, "absent_kps": {"text": ["computer science students", "ibm business managers", "patents", "mba college students"], "tokenized": ["computer science students", "ibm business managers", "patents", "mba college students"]}}
{"id": 416, "title": {"text": "down up it projects .", "tokenized": "down up it projects ."}, "abstract": {"text": "with big it projects that will position their companies to succeed when the economy soars again", "tokenized": "with big it projects that will position their companies to succeed when the economy soars again"}, "present_kps": {"text": [], "tokenized": []}, "absent_kps": {"text": ["morgan stanley", "staples", "strategic technology projects", "caterpillar", "ford", "victoria ' s secret", "walgreen"], "tokenized": ["morgan stanley", "staples", "strategic technology projects", "caterpillar", "ford", "victoria ' s secret", "walgreen"]}}
{"id": 417, "title": {"text": "an automated parallel image registration technique based on the correlation of .", "tokenized": "an automated parallel image registration technique based on the correlation of ."}, "abstract": {"text": "with the increasing importance of multiple multiplatform remote sensing missions , fast and automatic integration of digital data from disparate sources has become critical to the success of these endeavors . our work utilizes maxima of wavelet coefficients to form the basic features of a correlation based automatic registration algorithm . our wavelet based registration algorithm is tested successfully with data from the national oceanic and atmospheric administration ( noaa ) advanced very high resolution radiometer ( avhrr ) and the landsat thematic mapper ( tm ) , which differ by translation and or rotation . by the choice of high frequency wavelet features , this method is similar to an edge based correlation method , but by exploiting the multiresolution nature of a wavelet decomposition , our method achieves higher computational speeds for comparable accuracies . this algorithm has been implemented on a single instruction multiple data ( simd ) massively parallel computer , the maspar mp [digit] , as well as on the crayt3d , the cray t3e , and a beowulf cluster of pentium workstations", "tokenized": "with the increasing importance of multiple multiplatform remote sensing missions , fast and automatic integration of digital data from disparate sources has become critical to the success of these endeavors . our work utilizes maxima of wavelet coefficients to form the basic features of a correlation based automatic registration algorithm . our wavelet based registration algorithm is tested successfully with data from the national oceanic and atmospheric administration ( noaa ) advanced very high resolution radiometer ( avhrr ) and the landsat thematic mapper ( tm ) , which differ by translation and or rotation . by the choice of high frequency wavelet features , this method is similar to an edge based correlation method , but by exploiting the multiresolution nature of a wavelet decomposition , our method achieves higher computational speeds for comparable accuracies . this algorithm has been implemented on a single instruction multiple data ( simd ) massively parallel computer , the maspar mp [digit] , as well as on the crayt3d , the cray t3e , and a beowulf cluster of pentium workstations"}, "present_kps": {"text": ["automated parallel image registration", "correlation", "remote sensing", "automatic registration algorithm", "avhrr", "landsat thematic mapper", "wavelet feature", "wavelet decomposition"], "tokenized": ["automated parallel image registration", "correlation", "remote sensing", "automatic registration algorithm", "avhrr", "landsat thematic mapper", "wavelet feature", "wavelet decomposition"]}, "absent_kps": {"text": ["terrain mapping", "optical imaging", "microwave radiometry", "land surface", "simd massively parallel computing", "geophysical measurement technique", "image processing"], "tokenized": ["terrain mapping", "optical imaging", "microwave radiometry", "land surface", "simd massively parallel computing", "geophysical measurement technique", "image processing"]}}
{"id": 418, "title": {"text": "design of pid type controllers using multiobjective genetic algorithms .", "tokenized": "design of pid type controllers using multiobjective genetic algorithms ."}, "abstract": {"text": "of specifications to be satisfied are given . the designer has to adjust the parameters of the pid controller such that the feedback interconnection of the plant and the controller satisfies the specifications . these specifications are usually competitive and any acceptable solution requires a tradeoff among them . an approach for adjusting the parameters of a pid controller based on multiobjective optimization and genetic algorithms is presented in this paper . the mrcd ( multiobjective robust control design ) genetic algorithm has been employed . the approach can be easily generalized to design multivariable coupled and decentralized pid loops and has been successfully validated for a large number of experimental cases", "tokenized": "of specifications to be satisfied are given . the designer has to adjust the parameters of the pid controller such that the feedback interconnection of the plant and the controller satisfies the specifications . these specifications are usually competitive and any acceptable solution requires a tradeoff among them . an approach for adjusting the parameters of a pid controller based on multiobjective optimization and genetic algorithms is presented in this paper . the mrcd ( multiobjective robust control design ) genetic algorithm has been employed . the approach can be easily generalized to design multivariable coupled and decentralized pid loops and has been successfully validated for a large number of experimental cases"}, "present_kps": {"text": ["pid type controllers", "multiobjective genetic algorithms", "feedback interconnection", "multiobjective robust control design", "decentralized pid loops"], "tokenized": ["pid type controllers", "multiobjective genetic algorithms", "feedback interconnection", "multiobjective robust control design", "decentralized pid loops"]}, "absent_kps": {"text": ["tuning methods", "multivariable coupled pid loops"], "tokenized": ["tuning methods", "multivariable coupled pid loops"]}}
{"id": 419, "title": {"text": "temelin casts its shadow nuclear power plant .", "tokenized": "temelin casts its shadow nuclear power plant ."}, "abstract": {"text": "rather than technical . this paper discusses the problems of turbogenerator vibrations and how they were diagnosed . the paper also discusses some of the other problems of commissioning the power plant . the simulator used for training new staff is also mentioned", "tokenized": "rather than technical . this paper discusses the problems of turbogenerator vibrations and how they were diagnosed . the paper also discusses some of the other problems of commissioning the power plant . the simulator used for training new staff is also mentioned"}, "present_kps": {"text": ["turbogenerator vibrations"], "tokenized": ["turbogenerator vibrations"]}, "absent_kps": {"text": ["temelin nuclear plant", "power plant commissioning", "czech republic", "training simulator"], "tokenized": ["temelin nuclear plant", "power plant commissioning", "czech republic", "training simulator"]}}
{"id": 420, "title": {"text": "how should team captains order golfers on the final day of the ryder cup .", "tokenized": "how should team captains order golfers on the final day of the ryder cup ."}, "abstract": {"text": "i used game theory to examine how team captains should select their slates for the final day of the ryder cup matches . under the assumption that golfers have different abilities and are not influenced by pressure or momentum , i found that drawing names from a hat will do no worse than any other strategy", "tokenized": "i used game theory to examine how team captains should select their slates for the final day of the ryder cup matches . under the assumption that golfers have different abilities and are not influenced by pressure or momentum , i found that drawing names from a hat will do no worse than any other strategy"}, "present_kps": {"text": ["game theory", "slate"], "tokenized": ["game theory", "slate"]}, "absent_kps": {"text": ["golf", "golfer ordering", "ryder cup final day"], "tokenized": ["golf", "golfer ordering", "ryder cup final day"]}}
{"id": 421, "title": {"text": "mount sinai hospital uses integer programming to allocate operating room time .", "tokenized": "mount sinai hospital uses integer programming to allocate operating room time ."}, "abstract": {"text": "room time to the five surgical divisions at toronto ' s mount sinai hospital . the hospital has used this approach for several years and credits it with both administrative savings and the ability to produce quickly an equitable master surgical schedule", "tokenized": "room time to the five surgical divisions at toronto ' s mount sinai hospital . the hospital has used this approach for several years and credits it with both administrative savings and the ability to produce quickly an equitable master surgical schedule"}, "present_kps": {"text": ["mount sinai hospital", "integer programming", "toronto"], "tokenized": ["mount sinai hospital", "integer programming", "toronto"]}, "absent_kps": {"text": ["canada", "ontario", "post solution heuristic", "operating room time allocation"], "tokenized": ["canada", "ontario", "post solution heuristic", "operating room time allocation"]}}
{"id": 422, "title": {"text": "using the small business innovation research program to turn your ideas into .", "tokenized": "using the small business innovation research program to turn your ideas into ."}, "abstract": {"text": "the us government ' s small business innovation research program helps small businesses transform new ideas into commercial products . the program provides an ideal means for businesses and universities to obtaining funding for cooperative projects . rules and information for the program are readily available , and i will give a few helpful hints to provide guidance", "tokenized": "the us government ' s small business innovation research program helps small businesses transform new ideas into commercial products . the program provides an ideal means for businesses and universities to obtaining funding for cooperative projects . rules and information for the program are readily available , and i will give a few helpful hints to provide guidance"}, "present_kps": {"text": ["small business innovation research program", "businesses", "us government", "universities", "funding", "cooperative projects"], "tokenized": ["small business innovation research program", "businesses", "us government", "universities", "funding", "cooperative projects"]}, "absent_kps": {"text": ["usa", "commercial product development"], "tokenized": ["usa", "commercial product development"]}}
{"id": 423, "title": {"text": "student consulting projects benefit faculty and industry .", "tokenized": "student consulting projects benefit faculty and industry ."}, "abstract": {"text": "insight into the activities of firms in the community . these projects benefit faculty by providing clear feedback on the real capabilities of students , a broad connection to local industry , and material for case studies and research . they benefit companies by stimulating new thinking regarding their activities and delivering results they can use . projects provide insights into the end user modeling mode of or ms practice . projects support continuous improvement as the lessons gained from a crop of projects enable better teaching during the next course offering , which in turn leads to better projects and further insights into teaching", "tokenized": "insight into the activities of firms in the community . these projects benefit faculty by providing clear feedback on the real capabilities of students , a broad connection to local industry , and material for case studies and research . they benefit companies by stimulating new thinking regarding their activities and delivering results they can use . projects provide insights into the end user modeling mode of or ms practice . projects support continuous improvement as the lessons gained from a crop of projects enable better teaching during the next course offering , which in turn leads to better projects and further insights into teaching"}, "present_kps": {"text": ["student consulting projects"], "tokenized": ["student consulting projects"]}, "absent_kps": {"text": ["student capability feedback", "or ms tools", "case study material", "student placements"], "tokenized": ["student capability feedback", "or ms tools", "case study material", "student placements"]}}
{"id": 424, "title": {"text": "in search of strategic operations research management science .", "tokenized": "in search of strategic operations research management science ."}, "abstract": {"text": "competitive advantage . we found evidence of strategic or ms in the literature of strategic information systems ( sis ) and or ms . we examined [digit] early examples of sis , many of which contained or ms work . many of the most successful had high or ms content , while the least successful contained none . the inclusion of or ms work may be a key to sustaining an advantage from information technology . we also examined the edelman prize finalist articles published between [digit] and [digit] . we found that [digit] of the [digit] private sector applications meet our definition of strategic or ms", "tokenized": "competitive advantage . we found evidence of strategic or ms in the literature of strategic information systems ( sis ) and or ms . we examined [digit] early examples of sis , many of which contained or ms work . many of the most successful had high or ms content , while the least successful contained none . the inclusion of or ms work may be a key to sustaining an advantage from information technology . we also examined the edelman prize finalist articles published between [digit] and [digit] . we found that [digit] of the [digit] private sector applications meet our definition of strategic or ms"}, "present_kps": {"text": ["operations research", "management science", "strategic or ms", "strategic information systems", "sis"], "tokenized": ["operations research", "management science", "strategic or ms", "strategic information systems", "sis"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 425, "title": {"text": "baseball , optimization , and the world wide web .", "tokenized": "baseball , optimization , and the world wide web ."}, "abstract": {"text": "the most closely watched american sports traditions . while play off race statistics , such as games back and magic number , are informative , they are overly conservative and do not account for the remaining schedule of games . using optimization techniques , one can model schedule effects explicitly and determine precisely when a team has secured a play off spot or has been eliminated from contention . the riot baseball play off races web site developed at the university of california , berkeley , provides automatic updates of new , optimization based play off race statistics each day of the major league baseball season . in developing the site , we found that we could determine the first place elimination status of all teams in a division using a single linear programming formulation , since a minimum win threshold for teams finishing in first place applies to all teams in a division . we identified a similar ( but weaker ) result for the problem of play off elimination with wildcard teams", "tokenized": "the most closely watched american sports traditions . while play off race statistics , such as games back and magic number , are informative , they are overly conservative and do not account for the remaining schedule of games . using optimization techniques , one can model schedule effects explicitly and determine precisely when a team has secured a play off spot or has been eliminated from contention . the riot baseball play off races web site developed at the university of california , berkeley , provides automatic updates of new , optimization based play off race statistics each day of the major league baseball season . in developing the site , we found that we could determine the first place elimination status of all teams in a division using a single linear programming formulation , since a minimum win threshold for teams finishing in first place applies to all teams in a division . we identified a similar ( but weaker ) result for the problem of play off elimination with wildcard teams"}, "present_kps": {"text": ["optimization", "world wide web", "play off race statistics", "games back", "magic number", "riot baseball play off races web site", "linear programming", "minimum win threshold"], "tokenized": ["optimization", "world wide web", "play off race statistics", "games back", "magic number", "riot baseball play off races web site", "linear programming", "minimum win threshold"]}, "absent_kps": {"text": ["lp", "pennant race", "baseball play off spot competition", "game schedule"], "tokenized": ["lp", "pennant race", "baseball play off spot competition", "game schedule"]}}
{"id": 426, "title": {"text": "from revenue management concepts to software systems .", "tokenized": "from revenue management concepts to software systems ."}, "abstract": {"text": "systems for more than [digit] airlines , pros revenue management , inc . had the opportunity to develop rm systems for three companies in nonairline industries . pros research and design department designed the opportunity analysis study ( oas ) , a mix of or ms , consulting , and software development practices to determine the applicability of rm in new business situations . pros executed oass with the three companies . in all three cases , the oas supported the value of rm and led to contracts for implementation of rm systems", "tokenized": "systems for more than [digit] airlines , pros revenue management , inc . had the opportunity to develop rm systems for three companies in nonairline industries . pros research and design department designed the opportunity analysis study ( oas ) , a mix of or ms , consulting , and software development practices to determine the applicability of rm in new business situations . pros executed oass with the three companies . in all three cases , the oas supported the value of rm and led to contracts for implementation of rm systems"}, "present_kps": {"text": ["revenue management concepts", "software systems", "pros revenue management", "inc", "rm systems", "opportunity analysis study", "oas", "or ms", "software development practices"], "tokenized": ["revenue management concepts", "software systems", "pros revenue management", "inc", "rm systems", "opportunity analysis study", "oas", "or ms", "software development practices"]}, "absent_kps": {"text": ["consulting practices"], "tokenized": ["consulting practices"]}}
{"id": 427, "title": {"text": "lower bounds on the information rate of secret sharing schemes with homogeneous .", "tokenized": "lower bounds on the information rate of secret sharing schemes with homogeneous ."}, "abstract": {"text": "we present some new lower bounds on the optimal information rate and on the optimal average information rate of secret sharing schemes with homogeneous access structure . these bounds are found by using some covering constructions and a new parameter , the k degree of a participant , that is introduced in this paper . our bounds improve the previous ones in almost all cases", "tokenized": "we present some new lower bounds on the optimal information rate and on the optimal average information rate of secret sharing schemes with homogeneous access structure . these bounds are found by using some covering constructions and a new parameter , the k degree of a participant , that is introduced in this paper . our bounds improve the previous ones in almost all cases"}, "present_kps": {"text": ["lower bounds", "information rate", "secret sharing schemes", "optimal information rate", "optimal average information rate", "homogeneous access structure", "k degree"], "tokenized": ["lower bounds", "information rate", "secret sharing schemes", "optimal information rate", "optimal average information rate", "homogeneous access structure", "k degree"]}, "absent_kps": {"text": ["cryptography"], "tokenized": ["cryptography"]}}
{"id": 428, "title": {"text": "a self adjusting quality of service control scheme .", "tokenized": "a self adjusting quality of service control scheme ."}, "abstract": {"text": "with the goal of optimizing the system reward as a result of servicing different priority clients with varying workload , qos and reward penalty requirements . our scheme is based on resource partitioning and designated degrade qos areas such that system resources are partitioned into priority areas each of which is reserved specifically to serve only clients in a corresponding class with no qos degradation , plus one degraded qos area into which all clients can be admitted with qos adjustment being applied only to the lowest priority clients . we show that the best partition is dictated by the workload and the reward penalty characteristics of clients in difference priority classes . the analysis results can be used by a qos manager to optimize the system total reward dynamically in response to changing workloads at run time . we demonstrate the validity of our scheme by means of simulation and comparing the proposed qos self adjusting scheme with those that do not use resource partitioning or designated degraded qos areas", "tokenized": "with the goal of optimizing the system reward as a result of servicing different priority clients with varying workload , qos and reward penalty requirements . our scheme is based on resource partitioning and designated degrade qos areas such that system resources are partitioned into priority areas each of which is reserved specifically to serve only clients in a corresponding class with no qos degradation , plus one degraded qos area into which all clients can be admitted with qos adjustment being applied only to the lowest priority clients . we show that the best partition is dictated by the workload and the reward penalty characteristics of clients in difference priority classes . the analysis results can be used by a qos manager to optimize the system total reward dynamically in response to changing workloads at run time . we demonstrate the validity of our scheme by means of simulation and comparing the proposed qos self adjusting scheme with those that do not use resource partitioning or designated degraded qos areas"}, "present_kps": {"text": ["self adjusting quality of service control scheme", "priority clients", "resource partitioning", "simulation"], "tokenized": ["self adjusting quality of service control scheme", "priority clients", "resource partitioning", "simulation"]}, "absent_kps": {"text": ["multimedia systems", "resource reservation", "performance evaluation"], "tokenized": ["multimedia systems", "resource reservation", "performance evaluation"]}}
{"id": 429, "title": {"text": "fusion of qualitative bond graph and genetic algorithms a fault diagnosis .", "tokenized": "fusion of qualitative bond graph and genetic algorithms a fault diagnosis ."}, "abstract": {"text": "in this paper , the problem of fault diagnosis via integration of genetic algorithms ( ga ' s ) and qualitative bond graphs ( qbg ' s ) is addressed . we suggest that ga ' s can be used to search for possible fault components among a system of qualitative equations . the qbg is adopted as the modeling scheme to generate a set of qualitative equations . the qualitative bond graph provides a unified approach for modeling engineering systems , in particular , mechatronic systems . in order to demonstrate the performance of the proposed algorithm , we have tested the proposed algorithm on an in house designed and built floating disc experimental setup . results from fault diagnosis in the floating disc system are presented and discussed . additional measurements will be required to localize the fault when more than one fault candidate is inferred . fault diagnosis is activated by a fault detection mechanism when a discrepancy between measured abnormal behavior and predicted system behavior is observed . the fault detection mechanism is not presented here", "tokenized": "in this paper , the problem of fault diagnosis via integration of genetic algorithms ( ga ' s ) and qualitative bond graphs ( qbg ' s ) is addressed . we suggest that ga ' s can be used to search for possible fault components among a system of qualitative equations . the qbg is adopted as the modeling scheme to generate a set of qualitative equations . the qualitative bond graph provides a unified approach for modeling engineering systems , in particular , mechatronic systems . in order to demonstrate the performance of the proposed algorithm , we have tested the proposed algorithm on an in house designed and built floating disc experimental setup . results from fault diagnosis in the floating disc system are presented and discussed . additional measurements will be required to localize the fault when more than one fault candidate is inferred . fault diagnosis is activated by a fault detection mechanism when a discrepancy between measured abnormal behavior and predicted system behavior is observed . the fault detection mechanism is not presented here"}, "present_kps": {"text": ["qualitative bond graph", "genetic algorithms", "fault diagnosis", "fault components", "qualitative equations", "engineering systems", "mechatronic systems", "floating disc", "measured abnormal behavior", "predicted system behavior"], "tokenized": ["qualitative bond graph", "genetic algorithms", "fault diagnosis", "fault components", "qualitative equations", "engineering systems", "mechatronic systems", "floating disc", "measured abnormal behavior", "predicted system behavior"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 430, "title": {"text": "there is no optimal routing policy for the torus .", "tokenized": "there is no optimal routing policy for the torus ."}, "abstract": {"text": "message from among a number of acceptable output channels . an optimal routing policy is a policy that maximizes the probability of a message reaching its destination without delays . optimal routing policies have been proposed for several regular networks , including the mesh and the hypercube . an open problem in interconnection network research has been the identification of an optimal routing policy for the torus . in this paper , we show that there is no optimal routing policy for the torus . our result is demonstrated by presenting a detailed example in which the best choice of output channel is dependent on the probability of each channel being available . this result settles , in the negative , a conjecture by j . wu ( [digit] ) concerning an optimal routing policy for the torus", "tokenized": "message from among a number of acceptable output channels . an optimal routing policy is a policy that maximizes the probability of a message reaching its destination without delays . optimal routing policies have been proposed for several regular networks , including the mesh and the hypercube . an open problem in interconnection network research has been the identification of an optimal routing policy for the torus . in this paper , we show that there is no optimal routing policy for the torus . our result is demonstrated by presenting a detailed example in which the best choice of output channel is dependent on the probability of each channel being available . this result settles , in the negative , a conjecture by j . wu ( [digit] ) concerning an optimal routing policy for the torus"}, "present_kps": {"text": ["optimal routing policy", "torus", "hypercube"], "tokenized": ["optimal routing policy", "torus", "hypercube"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 431, "title": {"text": "optimal online algorithm for scheduling on two identical machines with machine .", "tokenized": "optimal online algorithm for scheduling on two identical machines with machine ."}, "abstract": {"text": "this paper considers the online scheduling on two identical machines with machine availability constraints for minimizing makespan . we assume that machine m sub j is unavailable during period from s sub j to t sub j ( [digit] < or s sub j < t sub j ) , j [digit] , [digit] , and the unavailable periods of two machines do not overlap . we show that the competitive ratio of list scheduling is [digit] . we further give an optimal algorithm with a competitive ratio [digit] [digit]", "tokenized": "this paper considers the online scheduling on two identical machines with machine availability constraints for minimizing makespan . we assume that machine m sub j is unavailable during period from s sub j to t sub j ( [digit] < or s sub j < t sub j ) , j [digit] , [digit] , and the unavailable periods of two machines do not overlap . we show that the competitive ratio of list scheduling is [digit] . we further give an optimal algorithm with a competitive ratio [digit] [digit]"}, "present_kps": {"text": ["optimal online algorithm", "machine availability constraints", "list scheduling"], "tokenized": ["optimal online algorithm", "machine availability constraints", "list scheduling"]}, "absent_kps": {"text": ["identical machines scheduling", "makespan minimisation"], "tokenized": ["identical machines scheduling", "makespan minimisation"]}}
{"id": 432, "title": {"text": "an efficient retrieval selection algorithm for video servers with random .", "tokenized": "an efficient retrieval selection algorithm for video servers with random ."}, "abstract": {"text": "random duplicated assignment ( rda ) is an approach in which video data is stored by assigning a number of copies of each data block to different , randomly chosen disks . it has been shown that this approach results in smaller response times and lower disk and ram costs compared to the well known disk stripping techniques . based on this storage approach , one has to determine , for each given batch of data blocks , from which disk each of the data blocks is to be retrieved . this is to be done in such a way that the maximum load of the disks is minimized . the problem is called the retrieval selection problem ( rsp ) . in this paper , we propose a new efficient algorithm for rsp . this algorithm is based on the breadth first search approach and is able to guarantee optimal solutions for rsp in o ( n sup [digit] mn ) , where m and n correspond to the number of data blocks and the number of disks , respectively . we show that our proposed algorithm has a lower time complexity than an existing algorithm , called the mfs algorithm", "tokenized": "random duplicated assignment ( rda ) is an approach in which video data is stored by assigning a number of copies of each data block to different , randomly chosen disks . it has been shown that this approach results in smaller response times and lower disk and ram costs compared to the well known disk stripping techniques . based on this storage approach , one has to determine , for each given batch of data blocks , from which disk each of the data blocks is to be retrieved . this is to be done in such a way that the maximum load of the disks is minimized . the problem is called the retrieval selection problem ( rsp ) . in this paper , we propose a new efficient algorithm for rsp . this algorithm is based on the breadth first search approach and is able to guarantee optimal solutions for rsp in o ( n sup [digit] mn ) , where m and n correspond to the number of data blocks and the number of disks , respectively . we show that our proposed algorithm has a lower time complexity than an existing algorithm , called the mfs algorithm"}, "present_kps": {"text": ["efficient retrieval selection algorithm", "video servers", "copies", "data block", "randomly chosen disks", "response times", "ram costs", "maximum load", "breadth first search", "optimal solutions", "time complexity"], "tokenized": ["efficient retrieval selection algorithm", "video servers", "copies", "data block", "randomly chosen disks", "response times", "ram costs", "maximum load", "breadth first search", "optimal solutions", "time complexity"]}, "absent_kps": {"text": ["disk costs", "random duplicated assignment storage technique"], "tokenized": ["disk costs", "random duplicated assignment storage technique"]}}
{"id": 433, "title": {"text": "edit distance of run length encoded strings .", "tokenized": "edit distance of run length encoded strings ."}, "abstract": {"text": "respectively . we present a simple o ( x l y k ) time algorithm that computes their edit distance", "tokenized": "respectively . we present a simple o ( x l y k ) time algorithm that computes their edit distance"}, "present_kps": {"text": ["edit distance", "run length encoded strings", "algorithm"], "tokenized": ["edit distance", "run length encoded strings", "algorithm"]}, "absent_kps": {"text": ["computation time", "encoded lengths"], "tokenized": ["computation time", "encoded lengths"]}}
{"id": 434, "title": {"text": "fault tolerant hamiltonian laceability of hypercubes .", "tokenized": "fault tolerant hamiltonian laceability of hypercubes ."}, "abstract": {"text": "n > or [digit] and f is a subset of edges with f < or n [digit] . we prove that there exists a hamiltonian path in q sub n f between any two vertices of different partite sets . moreover , there exists a path of length [digit] sup n [digit] between any two vertices of the same partite set . assume that n > or [digit] and f is a subset of edges with f < or n [digit] . we prove that there exists a hamiltonian path in q sub n v f between any two vertices in the partite set without v . furthermore , all bounds are tight", "tokenized": "n > or [digit] and f is a subset of edges with f < or n [digit] . we prove that there exists a hamiltonian path in q sub n f between any two vertices of different partite sets . moreover , there exists a path of length [digit] sup n [digit] between any two vertices of the same partite set . assume that n > or [digit] and f is a subset of edges with f < or n [digit] . we prove that there exists a hamiltonian path in q sub n v f between any two vertices in the partite set without v . furthermore , all bounds are tight"}, "present_kps": {"text": ["fault tolerant hamiltonian laceability", "hypercubes", "hamiltonian path", "vertices", "partite sets"], "tokenized": ["fault tolerant hamiltonian laceability", "hypercubes", "hamiltonian path", "vertices", "partite sets"]}, "absent_kps": {"text": ["edge subset", "bipartite graph", "tight bounds"], "tokenized": ["edge subset", "bipartite graph", "tight bounds"]}}
{"id": 435, "title": {"text": "an identity based society oriented signature scheme with anonymous signers .", "tokenized": "an identity based society oriented signature scheme with anonymous signers ."}, "abstract": {"text": "guillou quisquater ( [digit] ) signature scheme . the scheme is identity based and the signatures are verified with respect to only one identity . that is , the verifier does not have to know the identity of the co signers , but just that of the organization they represent", "tokenized": "guillou quisquater ( [digit] ) signature scheme . the scheme is identity based and the signatures are verified with respect to only one identity . that is , the verifier does not have to know the identity of the co signers , but just that of the organization they represent"}, "present_kps": {"text": ["identity based society oriented signature scheme", "anonymous signers"], "tokenized": ["identity based society oriented signature scheme", "anonymous signers"]}, "absent_kps": {"text": ["signature verification"], "tokenized": ["signature verification"]}}
{"id": 436, "title": {"text": "operational phase space probability distribution in quantum communication .", "tokenized": "operational phase space probability distribution in quantum communication ."}, "abstract": {"text": "operational phase space probability distributions are useful tools for describing quantum mechanical systems , including quantum communication and quantum information processing systems . it is shown that quantum communication channels with gaussian noise and quantum teleportation of continuous variables are described by operational phase space probability distributions . the relation of operational phase space probability distribution to the extended phase space formalism proposed by chountasis and vourdas ( [digit] ) is discussed", "tokenized": "operational phase space probability distributions are useful tools for describing quantum mechanical systems , including quantum communication and quantum information processing systems . it is shown that quantum communication channels with gaussian noise and quantum teleportation of continuous variables are described by operational phase space probability distributions . the relation of operational phase space probability distribution to the extended phase space formalism proposed by chountasis and vourdas ( [digit] ) is discussed"}, "present_kps": {"text": ["operational phase space probability distribution", "quantum mechanical systems", "quantum information processing systems", "gaussian noise", "quantum teleportation", "continuous variables", "extended phase space formalism"], "tokenized": ["operational phase space probability distribution", "quantum mechanical systems", "quantum information processing systems", "gaussian noise", "quantum teleportation", "continuous variables", "extended phase space formalism"]}, "absent_kps": {"text": ["quantum communication theory"], "tokenized": ["quantum communication theory"]}}
{"id": 437, "title": {"text": "embedding of level continuous fuzzy sets on banach spaces .", "tokenized": "embedding of level continuous fuzzy sets on banach spaces ."}, "abstract": {"text": "showing the existence of an isometric embedding between the classf sub c ( x ) of compact convex and level continuous fuzzy sets on a real separable banach space x and c ( [digit] , [digit] b ( x ) ) , the banach space of real continuous functions defined on the cartesian product between [digit] , [digit] and the unit ball b ( x ) in the dual space x . also , by using this embedding , we give some applications to the characterization of relatively compact subsets of f sub c ( x ) . in particular , an ascoli arzela type theorem is proved and applied to solving the cauchy problem x ( t ) f ( t , x ( t ) ) , x ( t sub [digit] ) x sub [digit] on f sub c ( x )", "tokenized": "showing the existence of an isometric embedding between the classf sub c ( x ) of compact convex and level continuous fuzzy sets on a real separable banach space x and c ( [digit] , [digit] b ( x ) ) , the banach space of real continuous functions defined on the cartesian product between [digit] , [digit] and the unit ball b ( x ) in the dual space x . also , by using this embedding , we give some applications to the characterization of relatively compact subsets of f sub c ( x ) . in particular , an ascoli arzela type theorem is proved and applied to solving the cauchy problem x ( t ) f ( t , x ( t ) ) , x ( t sub [digit] ) x sub [digit] on f sub c ( x )"}, "present_kps": {"text": ["level continuous fuzzy sets", "isometric embedding", "real separable banach space", "real continuous functions", "cartesian product", "unit ball", "dual space", "ascoli arzela type theorem", "cauchy problem"], "tokenized": ["level continuous fuzzy sets", "isometric embedding", "real separable banach space", "real continuous functions", "cartesian product", "unit ball", "dual space", "ascoli arzela type theorem", "cauchy problem"]}, "absent_kps": {"text": ["compact convex fuzzy sets"], "tokenized": ["compact convex fuzzy sets"]}}
{"id": 438, "title": {"text": "correlation of intuitionistic fuzzy sets by centroid method .", "tokenized": "correlation of intuitionistic fuzzy sets by centroid method ."}, "abstract": {"text": "intuitionistic fuzzy sets by means of centroid . this value obtained from our formula tell us not only the strength of relationship between the intuitionistic fuzzy sets , but also whether the intuitionistic fuzzy sets are positively or negatively related . this approach looks better than previous methods which only evaluate the strength of the relation . furthermore , we extend the centroid method to interval valued intuitionistic fuzzy sets . the value of the correlation coefficient between interval valued intuitionistic fuzzy sets lies in the interval [digit] , [digit] , as computed from our formula", "tokenized": "intuitionistic fuzzy sets by means of centroid . this value obtained from our formula tell us not only the strength of relationship between the intuitionistic fuzzy sets , but also whether the intuitionistic fuzzy sets are positively or negatively related . this approach looks better than previous methods which only evaluate the strength of the relation . furthermore , we extend the centroid method to interval valued intuitionistic fuzzy sets . the value of the correlation coefficient between interval valued intuitionistic fuzzy sets lies in the interval [digit] , [digit] , as computed from our formula"}, "present_kps": {"text": ["intuitionistic fuzzy sets", "centroid method", "interval valued intuitionistic fuzzy sets", "correlation coefficient"], "tokenized": ["intuitionistic fuzzy sets", "centroid method", "interval valued intuitionistic fuzzy sets", "correlation coefficient"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 439, "title": {"text": "neighborhood operator systems and approximations .", "tokenized": "neighborhood operator systems and approximations ."}, "abstract": {"text": "notion of equivalence relation in rough set approximation space with various categories of k step neighborhood systems . based on a binary relation on a finite universe , six families of binary relations are obtained , and the corresponding six classes of k step neighborhood systems are derived . extensions of pawlak ' s ( [digit] ) rough set approximation operators based on such neighborhood systems are proposed . properties of neighborhood operator systems and rough set approximation operators are investigated , and their connections are examined", "tokenized": "notion of equivalence relation in rough set approximation space with various categories of k step neighborhood systems . based on a binary relation on a finite universe , six families of binary relations are obtained , and the corresponding six classes of k step neighborhood systems are derived . extensions of pawlak ' s ( [digit] ) rough set approximation operators based on such neighborhood systems are proposed . properties of neighborhood operator systems and rough set approximation operators are investigated , and their connections are examined"}, "present_kps": {"text": ["neighborhood operator systems", "equivalence relation", "rough set approximation space", "k step neighborhood systems", "binary relation", "finite universe"], "tokenized": ["neighborhood operator systems", "equivalence relation", "rough set approximation space", "k step neighborhood systems", "binary relation", "finite universe"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 440, "title": {"text": "model predictive control helps to regulate slow processes robust barrel .", "tokenized": "model predictive control helps to regulate slow processes robust barrel ."}, "abstract": {"text": "slow temperature control is a challenging control problem . the problem becomes even more challenging when multiple zones are involved , such as in barrel temperature control for extruders . often , strict closed loop performance requirements ( such as fast startup with no overshoot and maintaining tight temperature control during production ) are given for such applications . when characteristics of the system are examined , it becomes clear that a commonly used proportional plus integral plus derivative ( pid ) controller can not meet such performance specifications for this kind of system . the system either will overshoot or not maintain the temperature within the specified range during the production run . in order to achieve the required performance , a control strategy that utilizes techniques such as model predictive control , autotuning , and multiple parameter pid is formulated . this control strategy proves to be very effective in achieving the desired specifications , and is very robust", "tokenized": "slow temperature control is a challenging control problem . the problem becomes even more challenging when multiple zones are involved , such as in barrel temperature control for extruders . often , strict closed loop performance requirements ( such as fast startup with no overshoot and maintaining tight temperature control during production ) are given for such applications . when characteristics of the system are examined , it becomes clear that a commonly used proportional plus integral plus derivative ( pid ) controller can not meet such performance specifications for this kind of system . the system either will overshoot or not maintain the temperature within the specified range during the production run . in order to achieve the required performance , a control strategy that utilizes techniques such as model predictive control , autotuning , and multiple parameter pid is formulated . this control strategy proves to be very effective in achieving the desired specifications , and is very robust"}, "present_kps": {"text": ["model predictive control", "extruders", "autotuning", "multiple parameter pid"], "tokenized": ["model predictive control", "extruders", "autotuning", "multiple parameter pid"]}, "absent_kps": {"text": ["slow processes regulation", "robust barrel temperature control"], "tokenized": ["slow processes regulation", "robust barrel temperature control"]}}
{"id": 441, "title": {"text": "numerical representation of binary relations with a multiplicative error .", "tokenized": "numerical representation of binary relations with a multiplicative error ."}, "abstract": {"text": "this paper studies the case of the representation of a binary relation via a numerical function with threshold ( error ) depending on both compared alternatives . the error is considered to be multiplicative , its value being either directly or inversely proportional to the values of the numerical function . for the first case , it is proved that a binary relation is a semiorder . moreover , any semiorder can be represented in this form . in the second case , the corresponding binary relation is an interval order", "tokenized": "this paper studies the case of the representation of a binary relation via a numerical function with threshold ( error ) depending on both compared alternatives . the error is considered to be multiplicative , its value being either directly or inversely proportional to the values of the numerical function . for the first case , it is proved that a binary relation is a semiorder . moreover , any semiorder can be represented in this form . in the second case , the corresponding binary relation is an interval order"}, "present_kps": {"text": ["numerical representation", "binary relations", "error", "numerical function", "threshold", "semiorder", "interval order"], "tokenized": ["numerical representation", "binary relations", "error", "numerical function", "threshold", "semiorder", "interval order"]}, "absent_kps": {"text": ["multiplicative error function"], "tokenized": ["multiplicative error function"]}}
{"id": 442, "title": {"text": "a pretopological approach for structural analysis .", "tokenized": "a pretopological approach for structural analysis ."}, "abstract": {"text": "encountered in structural analysis . this approach is based upon the pretopological concepts of pseudoclosure and minimal closed subsets . the advantage of this approach is that it provides a framework which is general enough to model and formulate different types of connections that exist between the elements of a population . in addition , it has enabled us to develop a new structural analysis algorithm . an explanation of the definitions and properties of the pretopological concepts applied in this work is first shown and illustrated in sample settings . the structural analysis algorithm is then described and the results obtained in an economic study of the impact of geographic proximity on scientific collaborations are presented", "tokenized": "encountered in structural analysis . this approach is based upon the pretopological concepts of pseudoclosure and minimal closed subsets . the advantage of this approach is that it provides a framework which is general enough to model and formulate different types of connections that exist between the elements of a population . in addition , it has enabled us to develop a new structural analysis algorithm . an explanation of the definitions and properties of the pretopological concepts applied in this work is first shown and illustrated in sample settings . the structural analysis algorithm is then described and the results obtained in an economic study of the impact of geographic proximity on scientific collaborations are presented"}, "present_kps": {"text": ["pretopological approach", "structural analysis", "pseudoclosure", "minimal closed subsets", "connections", "economic study", "geographic proximity", "scientific collaborations"], "tokenized": ["pretopological approach", "structural analysis", "pseudoclosure", "minimal closed subsets", "connections", "economic study", "geographic proximity", "scientific collaborations"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 443, "title": {"text": "on batch constructing b sup trees algorithm and its performance evaluation .", "tokenized": "on batch constructing b sup trees algorithm and its performance evaluation ."}, "abstract": {"text": "or adding a new index to an existing database since both of them should handle an enormous volume of data . in this paper , we propose an algorithm for batch constructing the b sup tree , the most widely used index structure in database systems . the main characteristic of our algorithm is to simultaneously process all the key values to be placed on each b tree page when accessing the page . this avoids the overhead due to accessing the same page multiple times , which results from applying the b tree insertion algorithm repeatedly . for performance evaluation , we have analyzed our algorithm in terms of the number of disk accesses . the results show that the number of disk accesses excluding those in the relocation process is identical to the number of pages belonging to the b sup tree . considering that the relocation process is an unavoidable preprocessing step for batch constructing of b sup trees , our algorithm requires just one disk access per b tree page , and therefore turns out to be optimal . we also present the performance tendency in relation with different parameter values via simulation . finally , we show the performance enhancement effect of our algorithm , compared with the one using repeated insertions through experiments", "tokenized": "or adding a new index to an existing database since both of them should handle an enormous volume of data . in this paper , we propose an algorithm for batch constructing the b sup tree , the most widely used index structure in database systems . the main characteristic of our algorithm is to simultaneously process all the key values to be placed on each b tree page when accessing the page . this avoids the overhead due to accessing the same page multiple times , which results from applying the b tree insertion algorithm repeatedly . for performance evaluation , we have analyzed our algorithm in terms of the number of disk accesses . the results show that the number of disk accesses excluding those in the relocation process is identical to the number of pages belonging to the b sup tree . considering that the relocation process is an unavoidable preprocessing step for batch constructing of b sup trees , our algorithm requires just one disk access per b tree page , and therefore turns out to be optimal . we also present the performance tendency in relation with different parameter values via simulation . finally , we show the performance enhancement effect of our algorithm , compared with the one using repeated insertions through experiments"}, "present_kps": {"text": ["index structure", "b tree page", "b tree insertion algorithm", "disk accesses", "relocation process", "simulation"], "tokenized": ["index structure", "b tree page", "b tree insertion algorithm", "disk accesses", "relocation process", "simulation"]}, "absent_kps": {"text": ["algorithm performance evaluation", "b tree batch construction", "database bulk loading", "page access"], "tokenized": ["algorithm performance evaluation", "b tree batch construction", "database bulk loading", "page access"]}}
{"id": 444, "title": {"text": "synthetic simultaneity natural and artificial .", "tokenized": "synthetic simultaneity natural and artificial ."}, "abstract": {"text": "larger than the critical times for control of the system , a problem exists . i show a simple approach to mitigating this problem by basing the controller ' s decisions not on the observations themselves but on our projections as to what the observations will be at the time our controls reach the controlled system . finally , i argue that synthetic simultaneity explains libet ' s ( [digit] ) results better than libet ' s explanation", "tokenized": "larger than the critical times for control of the system , a problem exists . i show a simple approach to mitigating this problem by basing the controller ' s decisions not on the observations themselves but on our projections as to what the observations will be at the time our controls reach the controlled system . finally , i argue that synthetic simultaneity explains libet ' s ( [digit] ) results better than libet ' s explanation"}, "present_kps": {"text": ["synthetic simultaneity", "critical times", "observations"], "tokenized": ["synthetic simultaneity", "critical times", "observations"]}, "absent_kps": {"text": ["time delays", "controller decisions", "control loops"], "tokenized": ["time delays", "controller decisions", "control loops"]}}
{"id": 445, "title": {"text": "maclp multi agent constraint logic programming .", "tokenized": "maclp multi agent constraint logic programming ."}, "abstract": {"text": "complex problems in order to solve them more efficiently , or for problems distributed in nature . however , many industrial applications , besides their distributed nature , also involve a large number of parameters and constraints , i . e . they are combinatorial . solving such particularly hard problems efficiently requires programming tools that combine mas technology with a programming schema that facilitates the modeling and solution of constraints . this paper presents maclp ( multi agent constraint logic programming ) , a logic programming platform for building , in a declarative way , multi agent systems with constraint solving capabilities . maclp extends cspcons , a logic programming system that permits distributed program execution through communicating sequential prolog processes with constraints , by providing all the necessary facilities for communication between agents . these facilities abstract from the programmer all the low level details of the communication and allow him to focus on the development of the agent itself", "tokenized": "complex problems in order to solve them more efficiently , or for problems distributed in nature . however , many industrial applications , besides their distributed nature , also involve a large number of parameters and constraints , i . e . they are combinatorial . solving such particularly hard problems efficiently requires programming tools that combine mas technology with a programming schema that facilitates the modeling and solution of constraints . this paper presents maclp ( multi agent constraint logic programming ) , a logic programming platform for building , in a declarative way , multi agent systems with constraint solving capabilities . maclp extends cspcons , a logic programming system that permits distributed program execution through communicating sequential prolog processes with constraints , by providing all the necessary facilities for communication between agents . these facilities abstract from the programmer all the low level details of the communication and allow him to focus on the development of the agent itself"}, "present_kps": {"text": ["multi agent constraint logic programming", "parameters", "hard problems", "multi agent systems", "constraint solving", "distributed program execution", "communicating sequential prolog processes"], "tokenized": ["multi agent constraint logic programming", "parameters", "hard problems", "multi agent systems", "constraint solving", "distributed program execution", "communicating sequential prolog processes"]}, "absent_kps": {"text": ["combinatorial problems"], "tokenized": ["combinatorial problems"]}}
{"id": 446, "title": {"text": "self organizing feature maps predicting sea levels .", "tokenized": "self organizing feature maps predicting sea levels ."}, "abstract": {"text": "feature maps is introduced . for that purpose the maps are transformed from an unsupervised learning procedure to a supervised one . two concepts , originally developed to solve the problems of convergence of other network types , are proposed to be applied to kohonen networks a functional relationship between the number of neurons and the number of learning examples and a criterion to break off learning . the latter one can be shown to be conform with the process of self organization by using u matrices for visualization of the learning procedure . the predictions made using these neural models are compared for accuracy with observations and with the prognoses prepared using six models two hydrodynamic models , a statistical model , a nearest neighbor model , the persistence model , and the verbal forecasts that are broadcast and kept on record by the sea level forecast service of the federal maritime and hydrography agency ( bsh ) in hamburg . before training the maps , the meteorological and oceanographic situation has to be condensed as well as possible , and the weight and learning vectors have to be made as small as possible . the self organizing feature maps predict sea levels better than all six models of comparison", "tokenized": "feature maps is introduced . for that purpose the maps are transformed from an unsupervised learning procedure to a supervised one . two concepts , originally developed to solve the problems of convergence of other network types , are proposed to be applied to kohonen networks a functional relationship between the number of neurons and the number of learning examples and a criterion to break off learning . the latter one can be shown to be conform with the process of self organization by using u matrices for visualization of the learning procedure . the predictions made using these neural models are compared for accuracy with observations and with the prognoses prepared using six models two hydrodynamic models , a statistical model , a nearest neighbor model , the persistence model , and the verbal forecasts that are broadcast and kept on record by the sea level forecast service of the federal maritime and hydrography agency ( bsh ) in hamburg . before training the maps , the meteorological and oceanographic situation has to be condensed as well as possible , and the weight and learning vectors have to be made as small as possible . the self organizing feature maps predict sea levels better than all six models of comparison"}, "present_kps": {"text": ["self organizing feature maps", "kohonen networks", "neurons", "u matrices", "visualization", "hydrodynamic models", "statistical model", "nearest neighbor model", "persistence model", "verbal forecasts", "sea level forecast service", "federal maritime and hydrography agency", "oceanographic situation", "learning vectors"], "tokenized": ["self organizing feature maps", "kohonen networks", "neurons", "u matrices", "visualization", "hydrodynamic models", "statistical model", "nearest neighbor model", "persistence model", "verbal forecasts", "sea level forecast service", "federal maritime and hydrography agency", "oceanographic situation", "learning vectors"]}, "absent_kps": {"text": ["supervised learning", "meteorological situation", "sea level prediction"], "tokenized": ["supervised learning", "meteorological situation", "sea level prediction"]}}
{"id": 447, "title": {"text": "selecting rail grade crossing investments with a decision support system .", "tokenized": "selecting rail grade crossing investments with a decision support system ."}, "abstract": {"text": "rail related analysis tools that assist fra officials , metropolitan planning organizations ( mpos ) , state department of transportation ( dot ) , and other constituents in evaluating the cost and benefits of potential infrastructure projects . to meet agency objectives , the fra wants to add a high speed rail grade crossing analysis tool to its package of rail and rail related intermodal software products . this paper presents a conceptual decision support system ( dss ) that can assist officials in achieving this goal . the paper first introduces the fra ' s objectives and the role of cost benefit analysis in achieving these objectives . next , there is a discussion of the models needed to assess the feasibility of proposed high speed rail grade crossing investments and the presentation of a decision support system ( dss ) that can deliver these models transparently to users . then , the paper illustrates a system session and examines the potential benefits from system use", "tokenized": "rail related analysis tools that assist fra officials , metropolitan planning organizations ( mpos ) , state department of transportation ( dot ) , and other constituents in evaluating the cost and benefits of potential infrastructure projects . to meet agency objectives , the fra wants to add a high speed rail grade crossing analysis tool to its package of rail and rail related intermodal software products . this paper presents a conceptual decision support system ( dss ) that can assist officials in achieving this goal . the paper first introduces the fra ' s objectives and the role of cost benefit analysis in achieving these objectives . next , there is a discussion of the models needed to assess the feasibility of proposed high speed rail grade crossing investments and the presentation of a decision support system ( dss ) that can deliver these models transparently to users . then , the paper illustrates a system session and examines the potential benefits from system use"}, "present_kps": {"text": ["decision support system", "metropolitan planning organizations", "department of transportation", "infrastructure projects", "high speed rail grade crossing analysis tool", "rail related intermodal software products", "cost benefit analysis"], "tokenized": ["decision support system", "metropolitan planning organizations", "department of transportation", "infrastructure projects", "high speed rail grade crossing analysis tool", "rail related intermodal software products", "cost benefit analysis"]}, "absent_kps": {"text": ["rail intermodal software products", "federal railroad administration", "rail grade crossing investment selection"], "tokenized": ["rail intermodal software products", "federal railroad administration", "rail grade crossing investment selection"]}}
{"id": 448, "title": {"text": "a study on meaning processing of dialogue with an example of development of .", "tokenized": "a study on meaning processing of dialogue with an example of development of ."}, "abstract": {"text": "this paper describes an approach to processing meaning instead of processing information in computing . human intellectual activity is supported by linguistic activities in the brain . therefore , processing the meaning of language instead of processing information should allow us to realize human intelligence on a computer . as an example of the proposed framework for processing meaning , we build a travel consultation dialogue system which can understand utterance by a user and retrieve information through dialogue . through a simulation example of the system , we show that both information processing and language processing are integrated", "tokenized": "this paper describes an approach to processing meaning instead of processing information in computing . human intellectual activity is supported by linguistic activities in the brain . therefore , processing the meaning of language instead of processing information should allow us to realize human intelligence on a computer . as an example of the proposed framework for processing meaning , we build a travel consultation dialogue system which can understand utterance by a user and retrieve information through dialogue . through a simulation example of the system , we show that both information processing and language processing are integrated"}, "present_kps": {"text": ["meaning processing", "human intellectual activity", "linguistic activities", "travel consultation dialogue system", "information processing", "language processing"], "tokenized": ["meaning processing", "human intellectual activity", "linguistic activities", "travel consultation dialogue system", "information processing", "language processing"]}, "absent_kps": {"text": ["user utterance understanding", "information retrieval"], "tokenized": ["user utterance understanding", "information retrieval"]}}
{"id": 449, "title": {"text": "from a biological to a computational model for the autonomous behavior of an .", "tokenized": "from a biological to a computational model for the autonomous behavior of an ."}, "abstract": {"text": "endowing an autonomous system like a robot with intelligent behavior is difficult for several reasons . first , behavior is such a wide topic that a general framework paradigm of inspiration must be chosen in order to obtain a consistent model . such a framework can be , for example , biological modeling or an artificial intelligence approach . second , a general framework is not sufficient to determine a fully specified program to be implemented in a robot . many choices , tuning and tests must be carried out before obtaining a robust system . a biological model is presented , based on the definition of cortex like automata , representing elementary functions in the perceptive , motor or associative domain . these automata are connected in a network whose architecture , functioning and learning rules are described in a cortical framework . second , the computational model derived from that biological model is specified . the way units exchange and compute variables through links is explained , with reference to corresponding biological elements . it is then easier to report experiments allowing an autonomous system to learn regularities of a simple environment and to exploit them to satisfy some internal drives . even if additional biological hints can be added , this model allow us to better understand how a biological model can be implemented and how biological properties can emerge from a distributed set of units", "tokenized": "endowing an autonomous system like a robot with intelligent behavior is difficult for several reasons . first , behavior is such a wide topic that a general framework paradigm of inspiration must be chosen in order to obtain a consistent model . such a framework can be , for example , biological modeling or an artificial intelligence approach . second , a general framework is not sufficient to determine a fully specified program to be implemented in a robot . many choices , tuning and tests must be carried out before obtaining a robust system . a biological model is presented , based on the definition of cortex like automata , representing elementary functions in the perceptive , motor or associative domain . these automata are connected in a network whose architecture , functioning and learning rules are described in a cortical framework . second , the computational model derived from that biological model is specified . the way units exchange and compute variables through links is explained , with reference to corresponding biological elements . it is then easier to report experiments allowing an autonomous system to learn regularities of a simple environment and to exploit them to satisfy some internal drives . even if additional biological hints can be added , this model allow us to better understand how a biological model can be implemented and how biological properties can emerge from a distributed set of units"}, "present_kps": {"text": ["computational model", "autonomous behavior", "autonomous system", "robot", "intelligent behavior", "biological model", "tuning", "tests", "robust system", "cortex like automata", "elementary functions", "associative domain", "architecture", "learning rules", "links", "simple environment", "internal drives"], "tokenized": ["computational model", "autonomous behavior", "autonomous system", "robot", "intelligent behavior", "biological model", "tuning", "tests", "robust system", "cortex like automata", "elementary functions", "associative domain", "architecture", "learning rules", "links", "simple environment", "internal drives"]}, "absent_kps": {"text": ["regularity learning", "variable exchange", "motor domain", "perceptive domain", "variable computation", "animat"], "tokenized": ["regularity learning", "variable exchange", "motor domain", "perceptive domain", "variable computation", "animat"]}}
{"id": 450, "title": {"text": "nissan v . nissan trademark dispute .", "tokenized": "nissan v . nissan trademark dispute ."}, "abstract": {"text": "a greedy opportunist this paper discusses the case of uzi nissan , who is locked in a multimillion dollar legal battle over whether or not his use of the nissan . com internet domain name infringes upon japan ' s nissan motor co . ' s trademark . at the heart of the matter is the impact of the global internet on trademark law , which traditionally has been strongly influenced by geographic considerations . the paper discusses the background to the case from both sides and the issues involved", "tokenized": "a greedy opportunist this paper discusses the case of uzi nissan , who is locked in a multimillion dollar legal battle over whether or not his use of the nissan . com internet domain name infringes upon japan ' s nissan motor co . ' s trademark . at the heart of the matter is the impact of the global internet on trademark law , which traditionally has been strongly influenced by geographic considerations . the paper discusses the background to the case from both sides and the issues involved"}, "present_kps": {"text": ["trademark dispute", "uzi nissan", "nissan . com internet domain name", "global internet", "trademark law"], "tokenized": ["trademark dispute", "uzi nissan", "nissan . com internet domain name", "global internet", "trademark law"]}, "absent_kps": {"text": ["nissan motor company trademark"], "tokenized": ["nissan motor company trademark"]}}
{"id": 451, "title": {"text": "design pid controllers for desired time domain or frequency domain response .", "tokenized": "design pid controllers for desired time domain or frequency domain response ."}, "abstract": {"text": "control systems , are usually specified in terms of time domain response , such as overshoot and rise time , or frequency domain response , such as resonance peak and stability margin . although numerous methods have been developed for the design of the proportional integral derivative ( pid ) controller , little work has been done in relation to the quantitative time domain and frequency domain responses . in this paper , we study the following problem given a nominal stable process with time delay , we design a suboptimal pid controller to achieve the required time domain response or frequency domain response for the nominal system or the uncertain system . an h sub infinity pid controller is developed based on optimal control theory and the parameters are derived analytically . its properties are investigated and compared with that of two developed suboptimal controllers an h sub [digit] pid controller and a maclaurin pid controller", "tokenized": "control systems , are usually specified in terms of time domain response , such as overshoot and rise time , or frequency domain response , such as resonance peak and stability margin . although numerous methods have been developed for the design of the proportional integral derivative ( pid ) controller , little work has been done in relation to the quantitative time domain and frequency domain responses . in this paper , we study the following problem given a nominal stable process with time delay , we design a suboptimal pid controller to achieve the required time domain response or frequency domain response for the nominal system or the uncertain system . an h sub infinity pid controller is developed based on optimal control theory and the parameters are derived analytically . its properties are investigated and compared with that of two developed suboptimal controllers an h sub [digit] pid controller and a maclaurin pid controller"}, "present_kps": {"text": ["frequency domain response", "time domain response", "overshoot", "rise time", "resonance peak", "stability margin", "nominal stable process", "h sub infinity pid controller", "optimal control", "suboptimal controller", "h sub [digit] pid controller", "maclaurin pid controller"], "tokenized": ["frequency domain response", "time domain response", "overshoot", "rise time", "resonance peak", "stability margin", "nominal stable process", "h sub infinity pid controller", "optimal control", "suboptimal controller", "h sub [digit] pid controller", "maclaurin pid controller"]}, "absent_kps": {"text": ["proportional integral derivative controller", "process control systems"], "tokenized": ["proportional integral derivative controller", "process control systems"]}}
{"id": 452, "title": {"text": "virtual borders , real laws internet activity and treaties .", "tokenized": "virtual borders , real laws internet activity and treaties ."}, "abstract": {"text": "worked steadily to extend control over online activities that they believe affect their interests , even when the activities occur outside their borders . these usually involve what governments regard as their domain protecting public order , enforcing commercial laws , and , occasionally , protecting consumer interests . methods have included assertions or legal jurisdiction based on where material is accessible instead of where it originates , and the blocking of sites , service providers , or entire high level domains from access by citizens . such instances are mentioned in this article . whilst larger companies are able to defend themselves against overseas lawsuits , individuals and smaller organizations lack the resources to defend what are often normal business activities at home , but could violate the laws of local jurisdictions in countries around the world . the problems of libel are discussed as are the blocking of certain sites by certain countries . efforts to draw up internet treaties are also mentioned", "tokenized": "worked steadily to extend control over online activities that they believe affect their interests , even when the activities occur outside their borders . these usually involve what governments regard as their domain protecting public order , enforcing commercial laws , and , occasionally , protecting consumer interests . methods have included assertions or legal jurisdiction based on where material is accessible instead of where it originates , and the blocking of sites , service providers , or entire high level domains from access by citizens . such instances are mentioned in this article . whilst larger companies are able to defend themselves against overseas lawsuits , individuals and smaller organizations lack the resources to defend what are often normal business activities at home , but could violate the laws of local jurisdictions in countries around the world . the problems of libel are discussed as are the blocking of certain sites by certain countries . efforts to draw up internet treaties are also mentioned"}, "present_kps": {"text": ["internet activity", "online activities", "legal jurisdiction", "lawsuits", "internet treaties"], "tokenized": ["internet activity", "online activities", "legal jurisdiction", "lawsuits", "internet treaties"]}, "absent_kps": {"text": ["public order protection", "commercial laws enforcement", "internet sites blocking", "consumer interests protection", "national governments"], "tokenized": ["public order protection", "commercial laws enforcement", "internet sites blocking", "consumer interests protection", "national governments"]}}
{"id": 453, "title": {"text": "a better ballot box .", "tokenized": "a better ballot box ."}, "abstract": {"text": "issues . the problems observed in the november [digit] us election accelerated existing trends to get rid of lever machines , punch cards , and hand counted paper ballots and replace them with mark sense balloting , internet , and automatic teller machine ( atm ) kiosk style computer based systems . an estimated us [digit] [digit] billion will be spent in the united states and canada to update voting systems during the next decade . voting online might enable citizens to vote even if they are unable to get to the polls . yet making these methods work right turns out to be considerably more difficult than originally thought . new electronic voting systems pose risks as well as solutions . as it turns out , many of the voting products currently for sale provide less accountability , poorer reliability , and greater opportunity for widespread fraud than those already in use . this paper discusses the technology available and how to ensure accurate ballots", "tokenized": "issues . the problems observed in the november [digit] us election accelerated existing trends to get rid of lever machines , punch cards , and hand counted paper ballots and replace them with mark sense balloting , internet , and automatic teller machine ( atm ) kiosk style computer based systems . an estimated us [digit] [digit] billion will be spent in the united states and canada to update voting systems during the next decade . voting online might enable citizens to vote even if they are unable to get to the polls . yet making these methods work right turns out to be considerably more difficult than originally thought . new electronic voting systems pose risks as well as solutions . as it turns out , many of the voting products currently for sale provide less accountability , poorer reliability , and greater opportunity for widespread fraud than those already in use . this paper discusses the technology available and how to ensure accurate ballots"}, "present_kps": {"text": ["ballot box", "mark sense balloting", "electronic voting"], "tokenized": ["ballot box", "mark sense balloting", "electronic voting"]}, "absent_kps": {"text": ["automatic teller machine computer based voting system", "online voting", "atm kiosk style computer based voting systems"], "tokenized": ["automatic teller machine computer based voting system", "online voting", "atm kiosk style computer based voting systems"]}}
{"id": 454, "title": {"text": "putting pen to screen on tablet pcs .", "tokenized": "putting pen to screen on tablet pcs ."}, "abstract": {"text": "specifications , handheld computers may be about to leap into the ring with today ' s laptops . they will be about the size of the smaller laptops , will be at least as powerful , and maybe their biggest selling point will be able to handle handwritten text . the tablet pcs will be amply configured , general purpose machines with more than enough power to run the full blown windows xp operating system . in particular , they will allow handwritten text to be entered onto a digitizing tablet and recognized , a functionality that ' s called pen based computing . the tablet pc will far outpace the computing power of existing small devices such as pdas ( personal digital assistants ) , including those variants based on microsoft ' s own pocket pc operating system", "tokenized": "specifications , handheld computers may be about to leap into the ring with today ' s laptops . they will be about the size of the smaller laptops , will be at least as powerful , and maybe their biggest selling point will be able to handle handwritten text . the tablet pcs will be amply configured , general purpose machines with more than enough power to run the full blown windows xp operating system . in particular , they will allow handwritten text to be entered onto a digitizing tablet and recognized , a functionality that ' s called pen based computing . the tablet pc will far outpace the computing power of existing small devices such as pdas ( personal digital assistants ) , including those variants based on microsoft ' s own pocket pc operating system"}, "present_kps": {"text": ["tablet pc", "handheld computers", "handwritten text", "windows xp operating system", "digitizing tablet", "pen based computing", "microsoft"], "tokenized": ["tablet pc", "handheld computers", "handwritten text", "windows xp operating system", "digitizing tablet", "pen based computing", "microsoft"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 455, "title": {"text": "horizontal waypoint guidance design using optimal control .", "tokenized": "horizontal waypoint guidance design using optimal control ."}, "abstract": {"text": "guidance to waypoint line segments in sequence . the line following guidance is designed using an lqr ( linear quadratic regulator ) . then , the optimal waypoint changing points are derived by minimizing the accelerations required for changing the waypoint line segments . also derived is a sufficient condition for the stability bound of ground speed changes based on the lyapunov stability theorem . simulation results show that the proposed algorithm can effectively guide a vehicle along the sequence of waypoint line segments", "tokenized": "guidance to waypoint line segments in sequence . the line following guidance is designed using an lqr ( linear quadratic regulator ) . then , the optimal waypoint changing points are derived by minimizing the accelerations required for changing the waypoint line segments . also derived is a sufficient condition for the stability bound of ground speed changes based on the lyapunov stability theorem . simulation results show that the proposed algorithm can effectively guide a vehicle along the sequence of waypoint line segments"}, "present_kps": {"text": ["waypoint line segments", "line following guidance", "lqr", "linear quadratic regulator", "optimal waypoint changing points", "stability bound", "ground speed changes", "lyapunov stability theorem"], "tokenized": ["waypoint line segments", "line following guidance", "lqr", "linear quadratic regulator", "optimal waypoint changing points", "stability bound", "ground speed changes", "lyapunov stability theorem"]}, "absent_kps": {"text": ["unmanned flying vehicle", "threat avoidance", "terrain masking", "attack directions", "horizontal waypoint guidance algorithm", "target location arrival time"], "tokenized": ["unmanned flying vehicle", "threat avoidance", "terrain masking", "attack directions", "horizontal waypoint guidance algorithm", "target location arrival time"]}}
{"id": 456, "title": {"text": "separation and tracking of multiple broadband sources with one electromagnetic .", "tokenized": "separation and tracking of multiple broadband sources with one electromagnetic ."}, "abstract": {"text": "a structure for adaptively separating , enhancing and tracking uncorrelated sources with an electromagnetic vector sensor ( emvs ) is presented . the structure consists of a set of parallel spatial processors , one for each individual source . two stages of processing are involved in each spatial processor . the first preprocessing stage rejects all other sources except the one of interest , while the second stage is an adaptive one for maximizing the signal to noise ratio ( snr ) and tracking the desired source . the preprocessings are designed using the latest source parameter estimates obtained from the source trackers , and a redesign is activated periodically or whenever any source has been detected by the source trackers to have made significant movement . compared with conventional adaptive beamforming , the algorithm has the advantage that no a priori information on any desired signal location is needed , the sources are separated at maximum snr , and their locations are available . the structure is also well suited for parallel implementation . numerical examples are included to illustrate the capability and performance of the algorithm", "tokenized": "a structure for adaptively separating , enhancing and tracking uncorrelated sources with an electromagnetic vector sensor ( emvs ) is presented . the structure consists of a set of parallel spatial processors , one for each individual source . two stages of processing are involved in each spatial processor . the first preprocessing stage rejects all other sources except the one of interest , while the second stage is an adaptive one for maximizing the signal to noise ratio ( snr ) and tracking the desired source . the preprocessings are designed using the latest source parameter estimates obtained from the source trackers , and a redesign is activated periodically or whenever any source has been detected by the source trackers to have made significant movement . compared with conventional adaptive beamforming , the algorithm has the advantage that no a priori information on any desired signal location is needed , the sources are separated at maximum snr , and their locations are available . the structure is also well suited for parallel implementation . numerical examples are included to illustrate the capability and performance of the algorithm"}, "present_kps": {"text": ["uncorrelated sources", "electromagnetic vector sensor", "parallel spatial processors", "preprocessing stage", "signal to noise ratio", "maximum snr", "parallel implementation"], "tokenized": ["uncorrelated sources", "electromagnetic vector sensor", "parallel spatial processors", "preprocessing stage", "signal to noise ratio", "maximum snr", "parallel implementation"]}, "absent_kps": {"text": ["signal source location", "adaptive second stage", "multiple broadband sources separation", "multiple broadband sources tracking", "adaptive source enhancement", "snr maximization", "single em vector sensor"], "tokenized": ["signal source location", "adaptive second stage", "multiple broadband sources separation", "multiple broadband sources tracking", "adaptive source enhancement", "snr maximization", "single em vector sensor"]}}
{"id": 457, "title": {"text": "recursive state estimation for multiple switching models with unknown .", "tokenized": "recursive state estimation for multiple switching models with unknown ."}, "abstract": {"text": "this work considers hybrid systems with continuous valued target states and discrete valued regime variable . the changes ( switches ) of the regime variable are modeled by a finite state markov chain with unknown and random transition probabilities following dirichlet distributions . our work analytically derives the marginal posterior distribution of the states and regime variables , the transition probabilities being integrated out . this leads to a variety of recursive hybrid state estimation schemes which are an appealing intuitive and straightforward extension of standard algorithms . their performance is illustrated by a maneuvering target tracking example", "tokenized": "this work considers hybrid systems with continuous valued target states and discrete valued regime variable . the changes ( switches ) of the regime variable are modeled by a finite state markov chain with unknown and random transition probabilities following dirichlet distributions . our work analytically derives the marginal posterior distribution of the states and regime variables , the transition probabilities being integrated out . this leads to a variety of recursive hybrid state estimation schemes which are an appealing intuitive and straightforward extension of standard algorithms . their performance is illustrated by a maneuvering target tracking example"}, "present_kps": {"text": ["recursive state estimation", "multiple switching models", "hybrid systems", "continuous valued target states", "discrete valued regime variable", "finite state markov chain", "random transition probabilities", "dirichlet distributions", "marginal posterior distribution", "maneuvering target tracking"], "tokenized": ["recursive state estimation", "multiple switching models", "hybrid systems", "continuous valued target states", "discrete valued regime variable", "finite state markov chain", "random transition probabilities", "dirichlet distributions", "marginal posterior distribution", "maneuvering target tracking"]}, "absent_kps": {"text": ["unknown transition probabilities"], "tokenized": ["unknown transition probabilities"]}}
{"id": 458, "title": {"text": "matlab code for plotting ambiguity functions .", "tokenized": "matlab code for plotting ambiguity functions ."}, "abstract": {"text": "signals is presented . the program makes use of matlab ' s sparse matrix operations , and avoids loops . the program could be useful as a pedagogical tool in radar courses teaching pulse compression", "tokenized": "signals is presented . the program makes use of matlab ' s sparse matrix operations , and avoids loops . the program could be useful as a pedagogical tool in radar courses teaching pulse compression"}, "present_kps": {"text": ["matlab code", "sparse matrix operations", "pedagogical tool", "radar courses", "pulse compression"], "tokenized": ["matlab code", "sparse matrix operations", "pedagogical tool", "radar courses", "pulse compression"]}, "absent_kps": {"text": ["doppler shifted signal version", "ambiguity functions plotting", "radar signals", "matched filter response"], "tokenized": ["doppler shifted signal version", "ambiguity functions plotting", "radar signals", "matched filter response"]}}
{"id": 459, "title": {"text": "incremental motion control of linear synchronous motor .", "tokenized": "incremental motion control of linear synchronous motor ."}, "abstract": {"text": "specified by the trapezoidal velocity profile using multisegment sliding mode control ( mssmc ) , is proposed to control a permanent magnet linear synchronous motor ( pmlsm ) servo drive system . first , the structure and operating principle of the pmlsm are described in detail . second , a field oriented control pmlsm servo drive is introduced . then , each segment of the multisegment switching surfaces is designed to match the corresponding part of the trapezoidal velocity profile , thus the motor dynamics on the specified segment switching surface have the desired velocity or acceleration corresponding part of the trapezoidal velocity profile . in addition , the proposed control system is implemented in a pc based computer control system . finally , the effectiveness of the proposed pmlsm servo drive system is demonstrated by some simulated and experimental results", "tokenized": "specified by the trapezoidal velocity profile using multisegment sliding mode control ( mssmc ) , is proposed to control a permanent magnet linear synchronous motor ( pmlsm ) servo drive system . first , the structure and operating principle of the pmlsm are described in detail . second , a field oriented control pmlsm servo drive is introduced . then , each segment of the multisegment switching surfaces is designed to match the corresponding part of the trapezoidal velocity profile , thus the motor dynamics on the specified segment switching surface have the desired velocity or acceleration corresponding part of the trapezoidal velocity profile . in addition , the proposed control system is implemented in a pc based computer control system . finally , the effectiveness of the proposed pmlsm servo drive system is demonstrated by some simulated and experimental results"}, "present_kps": {"text": ["incremental motion control", "linear synchronous motor", "trapezoidal velocity profile", "multisegment sliding mode control", "servo drive system", "field oriented control", "multisegment switching surfaces", "motor dynamics"], "tokenized": ["incremental motion control", "linear synchronous motor", "trapezoidal velocity profile", "multisegment sliding mode control", "servo drive system", "field oriented control", "multisegment switching surfaces", "motor dynamics"]}, "absent_kps": {"text": ["permanent magnet motor"], "tokenized": ["permanent magnet motor"]}}
{"id": 460, "title": {"text": "feedforward maximum power point tracking of pv systems using fuzzy controller .", "tokenized": "feedforward maximum power point tracking of pv systems using fuzzy controller ."}, "abstract": {"text": "interleaved dual boost ( idb ) converter fed photovoltaic ( pv ) system using fuzzy controller . the tracking algorithm changes the duty ratio of the converter such that the solar cell array ( sca ) voltage equals the voltage corresponding to the mp point at that solar insolation . this is done by the feedforward loop , which generates an error signal by comparing the instantaneous array voltage and reference voltage . the reference voltage for the feedforward loop , corresponding to the mp point , is obtained by an off line trained neural network . experimental data is used for off line training of the neural network , which employs back propagation algorithm . the proposed fuzzy feedforward peak power tracking effectiveness is demonstrated through the simulation and experimental results , and compared with the conventional proportional plus integral ( pi ) controller based system . finally , a comparative study of interleaved boost and conventional boost converter for the pv applications is given and their suitability is discussed", "tokenized": "interleaved dual boost ( idb ) converter fed photovoltaic ( pv ) system using fuzzy controller . the tracking algorithm changes the duty ratio of the converter such that the solar cell array ( sca ) voltage equals the voltage corresponding to the mp point at that solar insolation . this is done by the feedforward loop , which generates an error signal by comparing the instantaneous array voltage and reference voltage . the reference voltage for the feedforward loop , corresponding to the mp point , is obtained by an off line trained neural network . experimental data is used for off line training of the neural network , which employs back propagation algorithm . the proposed fuzzy feedforward peak power tracking effectiveness is demonstrated through the simulation and experimental results , and compared with the conventional proportional plus integral ( pi ) controller based system . finally , a comparative study of interleaved boost and conventional boost converter for the pv applications is given and their suitability is discussed"}, "present_kps": {"text": ["feedforward maximum power point tracking", "pv systems", "fuzzy controller", "tracking algorithm", "duty ratio", "solar insolation", "feedforward loop", "error signal", "instantaneous array voltage", "reference voltage", "off line trained neural network", "back propagation algorithm", "fuzzy feedforward peak power tracking effectiveness"], "tokenized": ["feedforward maximum power point tracking", "pv systems", "fuzzy controller", "tracking algorithm", "duty ratio", "solar insolation", "feedforward loop", "error signal", "instantaneous array voltage", "reference voltage", "off line trained neural network", "back propagation algorithm", "fuzzy feedforward peak power tracking effectiveness"]}, "absent_kps": {"text": ["interleaved dual boost converter feed", "photovoltaic system", "solar cell array voltage"], "tokenized": ["interleaved dual boost converter feed", "photovoltaic system", "solar cell array voltage"]}}
{"id": 461, "title": {"text": "a pid standard what , why , how .", "tokenized": "a pid standard what , why , how ."}, "abstract": {"text": "the long existing and continuing problem of confusing information on p ids . the acronym p id is widely understood to mean the principal document used to define the details of how a process works and how it is controlled . the isa dictionary definition for p id tells what they do , show the interconnection of process equipment and the instrumentation used to control the process . in the process industry a standard set of symbols is used to prepare drawings of processes . the instrument symbols used in these drawings are generally based on isa s5 . [digit] . in the paper the isa standard is referred to as isa [digit] . [digit] . the article develops the concept of the standard and poses some of the questions that the standard can answer", "tokenized": "the long existing and continuing problem of confusing information on p ids . the acronym p id is widely understood to mean the principal document used to define the details of how a process works and how it is controlled . the isa dictionary definition for p id tells what they do , show the interconnection of process equipment and the instrumentation used to control the process . in the process industry a standard set of symbols is used to prepare drawings of processes . the instrument symbols used in these drawings are generally based on isa s5 . [digit] . in the paper the isa standard is referred to as isa [digit] . [digit] . the article develops the concept of the standard and poses some of the questions that the standard can answer"}, "present_kps": {"text": ["principal document", "isa standard", "isa [digit] . [digit]"], "tokenized": ["principal document", "isa standard", "isa [digit] . [digit]"]}, "absent_kps": {"text": ["process controlled", "p id standard"], "tokenized": ["process controlled", "p id standard"]}}
{"id": 462, "title": {"text": "quantitative speed control for srm drive using fuzzy adapted inverse model .", "tokenized": "quantitative speed control for srm drive using fuzzy adapted inverse model ."}, "abstract": {"text": "drive is considered to be rather difficult and challenging owing to its highly nonlinear dynamic behavior . a speed control scheme having two degree of freedom ( 2dof ) structure is developed here to improve the speed dynamic response of an srm drive . in the proposed control scheme , the feedback controller is quantitatively designed to meet the desired regulation control requirements first . then a reference model and a command feedforward controller based on an inverse plant model are employed to yield the desired tracking response at nominal case . as the variations of system parameters and operating conditions occur , the prescribed control specifications may not be satisfied any more . to improve this , the inverse model is adaptively tuned by a fuzzy control scheme so that the model following tracking error is significantly reduced . in addition , a simple disturbance cancellation robust controller is added to improve the tracking and regulation control performances further", "tokenized": "drive is considered to be rather difficult and challenging owing to its highly nonlinear dynamic behavior . a speed control scheme having two degree of freedom ( 2dof ) structure is developed here to improve the speed dynamic response of an srm drive . in the proposed control scheme , the feedback controller is quantitatively designed to meet the desired regulation control requirements first . then a reference model and a command feedforward controller based on an inverse plant model are employed to yield the desired tracking response at nominal case . as the variations of system parameters and operating conditions occur , the prescribed control specifications may not be satisfied any more . to improve this , the inverse model is adaptively tuned by a fuzzy control scheme so that the model following tracking error is significantly reduced . in addition , a simple disturbance cancellation robust controller is added to improve the tracking and regulation control performances further"}, "present_kps": {"text": ["quantitative speed control", "srm drive", "fuzzy adapted inverse model", "nonlinear dynamic behavior", "speed dynamic response", "regulation control requirements", "reference model", "command feedforward controller", "inverse plant model", "tracking response", "system parameters", "operating conditions", "control specifications", "fuzzy control scheme", "model following tracking error"], "tokenized": ["quantitative speed control", "srm drive", "fuzzy adapted inverse model", "nonlinear dynamic behavior", "speed dynamic response", "regulation control requirements", "reference model", "command feedforward controller", "inverse plant model", "tracking response", "system parameters", "operating conditions", "control specifications", "fuzzy control scheme", "model following tracking error"]}, "absent_kps": {"text": ["disturbance cancellation controller", "two degree of freedom structure", "switched reluctance motor"], "tokenized": ["disturbance cancellation controller", "two degree of freedom structure", "switched reluctance motor"]}}
{"id": 463, "title": {"text": "robust fuzzy controlled photovoltaic power inverter with taguchi method .", "tokenized": "robust fuzzy controlled photovoltaic power inverter with taguchi method ."}, "abstract": {"text": "photovoltaic ( pv ) power inverter with taguchi tuned scaling factors . to achieve fast transient response , small steady state error and system robustness , a robust fuzzy controller is adopted , in which its input and output scaling factors are determined efficiently by using the taguchi tuning algorithm . the proposed system can operate in different modes , grid connection mode and stand alone mode , and can accommodate wide load variations . simulation results and hardware measurements obtained from a prototype with a microcontroller ( intel 80196kc ) are presented to verify the theoretical discussions , and its adaptivity , robustness and feasibility", "tokenized": "photovoltaic ( pv ) power inverter with taguchi tuned scaling factors . to achieve fast transient response , small steady state error and system robustness , a robust fuzzy controller is adopted , in which its input and output scaling factors are determined efficiently by using the taguchi tuning algorithm . the proposed system can operate in different modes , grid connection mode and stand alone mode , and can accommodate wide load variations . simulation results and hardware measurements obtained from a prototype with a microcontroller ( intel 80196kc ) are presented to verify the theoretical discussions , and its adaptivity , robustness and feasibility"}, "present_kps": {"text": ["robust fuzzy controlled photovoltaic power inverter", "taguchi method", "tuned scaling factors", "transient response", "steady state error", "system robustness", "output scaling factors", "grid connection mode", "stand alone mode", "load variations", "microcontroller", "adaptivity", "feasibility"], "tokenized": ["robust fuzzy controlled photovoltaic power inverter", "taguchi method", "tuned scaling factors", "transient response", "steady state error", "system robustness", "output scaling factors", "grid connection mode", "stand alone mode", "load variations", "microcontroller", "adaptivity", "feasibility"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 464, "title": {"text": "robust wavelet neuro control for linear brushless motors .", "tokenized": "robust wavelet neuro control for linear brushless motors ."}, "abstract": {"text": "network learning controller for linear brushless dc motors ( lbdcm ) are considered . stability robustness with position tracking is the primary concern . the proposed controller deals mainly with external disturbances , e . g . nonlinear friction force and payload variation in motion control of linear motors . it consists of two parts , one is a state feedback component , and the other one is a learning feedback component . the state feedback controller is designed on the basis of a simple linear model , and the learning feedback component is a wavelet neural controller . the attenuation effect of wavelet neural networks on friction force is first verified by the numerical method . the learning effect of wavelet neural networks on friction force is also shown in the numerical results . then , a wavelet neural network is applied on a real lbdcm to on line suppress the friction force , which may be variable due to the different lubrication . the effectiveness of the proposed control schemes is demonstrated by simulated and experimental results", "tokenized": "network learning controller for linear brushless dc motors ( lbdcm ) are considered . stability robustness with position tracking is the primary concern . the proposed controller deals mainly with external disturbances , e . g . nonlinear friction force and payload variation in motion control of linear motors . it consists of two parts , one is a state feedback component , and the other one is a learning feedback component . the state feedback controller is designed on the basis of a simple linear model , and the learning feedback component is a wavelet neural controller . the attenuation effect of wavelet neural networks on friction force is first verified by the numerical method . the learning effect of wavelet neural networks on friction force is also shown in the numerical results . then , a wavelet neural network is applied on a real lbdcm to on line suppress the friction force , which may be variable due to the different lubrication . the effectiveness of the proposed control schemes is demonstrated by simulated and experimental results"}, "present_kps": {"text": ["robust wavelet neuro control", "linear brushless motors", "lbdcm", "stability robustness", "position tracking", "external disturbances", "nonlinear friction force", "friction force", "payload variation", "motion control", "state feedback component", "learning feedback component", "attenuation effect", "lubrication"], "tokenized": ["robust wavelet neuro control", "linear brushless motors", "lbdcm", "stability robustness", "position tracking", "external disturbances", "nonlinear friction force", "friction force", "payload variation", "motion control", "state feedback component", "learning feedback component", "attenuation effect", "lubrication"]}, "absent_kps": {"text": ["wavelet basis function network"], "tokenized": ["wavelet basis function network"]}}
{"id": 465, "title": {"text": "outlier resistant adaptive matched filtering .", "tokenized": "outlier resistant adaptive matched filtering ."}, "abstract": {"text": "censored from the covariance matrix estimate is considered in a maximum likelihood estimation ( mle ) setting . it is known that outlier data vectors whose steering vector is highly correlated with the desired steering vector , can significantly degrade the performance of amf algorithms such as sample matrix inversion ( smi ) or fast maximum likelihood ( fml ) . four new algorithms that censor outliers are presented which are derived via approximation to the mle solution . two algorithms each are related to using the smi or the fml to estimate the unknown underlying covariance matrix . results are presented using computer simulations which demonstrate the relative effectiveness of the four algorithms versus each other and also versus the smi and fml algorithms in the presence of outliers and no outliers . it is shown that one of the censoring algorithms , called the reiterative censored fast maximum likelihood ( cfml ) technique is significantly superior to the other three censoring methods in stressful outlier scenarios", "tokenized": "censored from the covariance matrix estimate is considered in a maximum likelihood estimation ( mle ) setting . it is known that outlier data vectors whose steering vector is highly correlated with the desired steering vector , can significantly degrade the performance of amf algorithms such as sample matrix inversion ( smi ) or fast maximum likelihood ( fml ) . four new algorithms that censor outliers are presented which are derived via approximation to the mle solution . two algorithms each are related to using the smi or the fml to estimate the unknown underlying covariance matrix . results are presented using computer simulations which demonstrate the relative effectiveness of the four algorithms versus each other and also versus the smi and fml algorithms in the presence of outliers and no outliers . it is shown that one of the censoring algorithms , called the reiterative censored fast maximum likelihood ( cfml ) technique is significantly superior to the other three censoring methods in stressful outlier scenarios"}, "present_kps": {"text": ["outlier resistant adaptive matched filtering", "covariance matrix estimate", "steering vector", "sample matrix inversion", "fast maximum likelihood", "censoring algorithms", "reiterative censored fast maximum likelihood"], "tokenized": ["outlier resistant adaptive matched filtering", "covariance matrix estimate", "steering vector", "sample matrix inversion", "fast maximum likelihood", "censoring algorithms", "reiterative censored fast maximum likelihood"]}, "absent_kps": {"text": ["maximum likelihood estimation setting"], "tokenized": ["maximum likelihood estimation setting"]}}
{"id": 466, "title": {"text": "brightness independent start up routine for star trackers .", "tokenized": "brightness independent start up routine for star trackers ."}, "abstract": {"text": "criteria for efficient organization of the on board database are discussed with reference to a brightness independent initial acquisition algorithm . star catalog generation preprocessing is described , with emphasis on the identification of minimum star brightness for detection by a sensor based on a charge coupled device ( ccd ) photodetector . this is a crucial step for proper evaluation of the attainable sky coverage when selecting the stars to be included in the on board catalog . test results are also reported , both for reliability and accuracy , even if the former is considered to be the primary target . probability of erroneous solution is [digit] . [digit] % in the case of single runs of the procedure , while attitude determination accuracy is in the order of [digit] . [digit] degrees in the average for the computation of the inertial pointing of the boresight axis", "tokenized": "criteria for efficient organization of the on board database are discussed with reference to a brightness independent initial acquisition algorithm . star catalog generation preprocessing is described , with emphasis on the identification of minimum star brightness for detection by a sensor based on a charge coupled device ( ccd ) photodetector . this is a crucial step for proper evaluation of the attainable sky coverage when selecting the stars to be included in the on board catalog . test results are also reported , both for reliability and accuracy , even if the former is considered to be the primary target . probability of erroneous solution is [digit] . [digit] % in the case of single runs of the procedure , while attitude determination accuracy is in the order of [digit] . [digit] degrees in the average for the computation of the inertial pointing of the boresight axis"}, "present_kps": {"text": ["brightness independent start up routine", "star trackers", "on board database", "star catalog generation preprocessing", "minimum star brightness", "reliability", "boresight axis"], "tokenized": ["brightness independent start up routine", "star trackers", "on board database", "star catalog generation preprocessing", "minimum star brightness", "reliability", "boresight axis"]}, "absent_kps": {"text": ["gyroless spacecraft", "charge coupled device photodetector", "initial attitude acquisition"], "tokenized": ["gyroless spacecraft", "charge coupled device photodetector", "initial attitude acquisition"]}}
{"id": 467, "title": {"text": "multiple model adaptive estimation with filter spawning .", "tokenized": "multiple model adaptive estimation with filter spawning ."}, "abstract": {"text": "detect and estimate partial actuator failures on the vista f [digit] . the truth model is a full six degree of freedom simulation provided by calspan and general dynamics . the design models are chosen as [digit] state linearized models , including first order actuator models . actuator failures are incorporated into the truth model and design model assuming a failure to free stream . filter spawning is used to include additional filters with partial actuator failure hypotheses into the mmae bank . the spawned filters are based on varying degrees of partial failures ( in terms of effectiveness ) associated with the complete actuaton failure hypothesis with the highest conditional probability of correctness at the current time . thus , a blended estimate of the failure effectiveness is found using the filters ' estimates based upon a no failure hypothesis , a complete actuator failure hypothesis , and the spawned filters ' partial failure hypotheses . this yields substantial precision in effectiveness estimation , compared with what is possible without spawning additional filters , making partial failure adaptation a viable methodology", "tokenized": "detect and estimate partial actuator failures on the vista f [digit] . the truth model is a full six degree of freedom simulation provided by calspan and general dynamics . the design models are chosen as [digit] state linearized models , including first order actuator models . actuator failures are incorporated into the truth model and design model assuming a failure to free stream . filter spawning is used to include additional filters with partial actuator failure hypotheses into the mmae bank . the spawned filters are based on varying degrees of partial failures ( in terms of effectiveness ) associated with the complete actuaton failure hypothesis with the highest conditional probability of correctness at the current time . thus , a blended estimate of the failure effectiveness is found using the filters ' estimates based upon a no failure hypothesis , a complete actuator failure hypothesis , and the spawned filters ' partial failure hypotheses . this yields substantial precision in effectiveness estimation , compared with what is possible without spawning additional filters , making partial failure adaptation a viable methodology"}, "present_kps": {"text": ["multiple model adaptive estimation", "filter spawning", "partial actuator failures", "vista f [digit]", "truth model", "six degree of freedom simulation", "calspan", "general dynamics", "linearized models", "mmae", "partial failures", "conditional probability", "no failure hypothesis"], "tokenized": ["multiple model adaptive estimation", "filter spawning", "partial actuator failures", "vista f [digit]", "truth model", "six degree of freedom simulation", "calspan", "general dynamics", "linearized models", "mmae", "partial failures", "conditional probability", "no failure hypothesis"]}, "absent_kps": {"text": ["test aircraft", "in flight simulator", "flight control systems"], "tokenized": ["test aircraft", "in flight simulator", "flight control systems"]}}
{"id": 468, "title": {"text": "matched filter template generation via spatial filtering application to fetal .", "tokenized": "matched filter template generation via spatial filtering application to fetal ."}, "abstract": {"text": "we have developed a two step procedure for signal processing of fetal biomagnetic recordings that removes cardiac interference and noise . first , a modified matched filter ( mf ) is applied to remove maternal cardiac interference then , a simple signal space projection ( ssp ) is applied to remove noise . the key difference between our mf and a conventional one is that the interference template and the template scaling are derived from a signal that has been spatially filtered to isolate the interference , rather than from the raw signal . unlike conventional mfs , ours is able to separate maternal and fetal cardiac complexes , even when they have similar morphology and overlap strongly . when followed by a ssp that preserves only the signal subspace , the noise is reduced to a low level", "tokenized": "we have developed a two step procedure for signal processing of fetal biomagnetic recordings that removes cardiac interference and noise . first , a modified matched filter ( mf ) is applied to remove maternal cardiac interference then , a simple signal space projection ( ssp ) is applied to remove noise . the key difference between our mf and a conventional one is that the interference template and the template scaling are derived from a signal that has been spatially filtered to isolate the interference , rather than from the raw signal . unlike conventional mfs , ours is able to separate maternal and fetal cardiac complexes , even when they have similar morphology and overlap strongly . when followed by a ssp that preserves only the signal subspace , the noise is reduced to a low level"}, "present_kps": {"text": ["spatial filtering", "modified matched filter", "maternal cardiac interference", "simple signal space projection", "interference template", "template scaling", "raw signal"], "tokenized": ["spatial filtering", "modified matched filter", "maternal cardiac interference", "simple signal space projection", "interference template", "template scaling", "raw signal"]}, "absent_kps": {"text": ["maternal cardiac interference removal", "signal subspace preservation", "fetal magnetocardiography", "noise removal"], "tokenized": ["maternal cardiac interference removal", "signal subspace preservation", "fetal magnetocardiography", "noise removal"]}}
{"id": 469, "title": {"text": "design and implementation of a brain computer interface with high transfer .", "tokenized": "design and implementation of a brain computer interface with high transfer ."}, "abstract": {"text": "this paper presents a brain computer interface ( bci ) that can help users to input phone numbers . the system is based on the steady state visual evoked potential ( ssvep ) . twelve buttons illuminated at different rates were displayed on a computer monitor . the buttons constituted a virtual telephone keypad , representing the ten digits [digit] [digit] , backspace , and enter . users could input phone number by gazing at these buttons . the frequency coded ssvep was used to judge which button the user desired . eight of the thirteen subjects succeeded in ringing the mobile phone using the system . the average transfer rate over all subjects was [digit] . [digit] bits min . the attractive features of the system are noninvasive signal recording , little training required for use , and high information transfer rate . approaches to improve the performance of the system are discussed", "tokenized": "this paper presents a brain computer interface ( bci ) that can help users to input phone numbers . the system is based on the steady state visual evoked potential ( ssvep ) . twelve buttons illuminated at different rates were displayed on a computer monitor . the buttons constituted a virtual telephone keypad , representing the ten digits [digit] [digit] , backspace , and enter . users could input phone number by gazing at these buttons . the frequency coded ssvep was used to judge which button the user desired . eight of the thirteen subjects succeeded in ringing the mobile phone using the system . the average transfer rate over all subjects was [digit] . [digit] bits min . the attractive features of the system are noninvasive signal recording , little training required for use , and high information transfer rate . approaches to improve the performance of the system are discussed"}, "present_kps": {"text": ["steady state visual evoked potential", "computer monitor", "virtual telephone keypad", "frequency coded ssvep"], "tokenized": ["steady state visual evoked potential", "computer monitor", "virtual telephone keypad", "frequency coded ssvep"]}, "absent_kps": {"text": ["brain computer interface with high transfer rates", "mobile phone ringing", "phone numbers input", "illuminated buttons", "system performance improvement"], "tokenized": ["brain computer interface with high transfer rates", "mobile phone ringing", "phone numbers input", "illuminated buttons", "system performance improvement"]}}
{"id": 470, "title": {"text": "noninvasive myocardial activation time imaging a novel inverse algorithm .", "tokenized": "noninvasive myocardial activation time imaging a novel inverse algorithm ."}, "abstract": {"text": "linear approaches like the minimum norm least square algorithm show insufficient performance when it comes to estimating the activation time map on the surface of the heart from electrocardiographic ( ecg ) mapping data . additional regularization has to be considered leading to a nonlinear problem formulation . the gauss newton approach is one of the standard mathematical tools capable of solving this kind of problem . to our experience , this algorithm has specific drawbacks which are caused by the applied regularization procedure . in particular , under clinical conditions the amount of regularization can not be determined clearly . for this reason , we have developed an iterative algorithm solving this nonlinear problem by a sequence of regularized linear problems . at each step of iteration , an individual l curve is computed . subsequent iteration steps are performed with the individual optimal regularization parameter . this novel approach is compared with the standard gauss newton approach . both methods are applied to simulated ecg mapping data as well as to single beat sinus rhythm data from two patients recorded in the catheter laboratory . the proposed approach shows excellent numerical and computational performance , even under clinical conditions at which the gauss newton approach begins to break down", "tokenized": "linear approaches like the minimum norm least square algorithm show insufficient performance when it comes to estimating the activation time map on the surface of the heart from electrocardiographic ( ecg ) mapping data . additional regularization has to be considered leading to a nonlinear problem formulation . the gauss newton approach is one of the standard mathematical tools capable of solving this kind of problem . to our experience , this algorithm has specific drawbacks which are caused by the applied regularization procedure . in particular , under clinical conditions the amount of regularization can not be determined clearly . for this reason , we have developed an iterative algorithm solving this nonlinear problem by a sequence of regularized linear problems . at each step of iteration , an individual l curve is computed . subsequent iteration steps are performed with the individual optimal regularization parameter . this novel approach is compared with the standard gauss newton approach . both methods are applied to simulated ecg mapping data as well as to single beat sinus rhythm data from two patients recorded in the catheter laboratory . the proposed approach shows excellent numerical and computational performance , even under clinical conditions at which the gauss newton approach begins to break down"}, "present_kps": {"text": ["noninvasive myocardial activation time imaging", "activation time imaging", "inverse algorithm", "gauss newton approach", "regularization procedure", "clinical conditions", "iteration steps", "individual optimal regularization parameter", "catheter laboratory"], "tokenized": ["noninvasive myocardial activation time imaging", "activation time imaging", "inverse algorithm", "gauss newton approach", "regularization procedure", "clinical conditions", "iteration steps", "individual optimal regularization parameter", "catheter laboratory"]}, "absent_kps": {"text": ["noninvasive electrocardiography", "heart surface", "clinical ecg mapping data", "l curve method", "electrodiagnostics", "tikhonov regularization"], "tokenized": ["noninvasive electrocardiography", "heart surface", "clinical ecg mapping data", "l curve method", "electrodiagnostics", "tikhonov regularization"]}}
{"id": 471, "title": {"text": "bayesian nonstationary autoregressive models for biomedical signal analysis .", "tokenized": "bayesian nonstationary autoregressive models for biomedical signal analysis ."}, "abstract": {"text": "multivariate autoregressive model with time varying coefficients that adapt according to a linear dynamical system . the algorithm allows for time and frequency domain characterization of nonstationary multivariate signals and is especially suited to the analysis of event related data . results are presented on synthetic data and real electroencephalogram data recorded in event related desynchronization and photic synchronization scenarios", "tokenized": "multivariate autoregressive model with time varying coefficients that adapt according to a linear dynamical system . the algorithm allows for time and frequency domain characterization of nonstationary multivariate signals and is especially suited to the analysis of event related data . results are presented on synthetic data and real electroencephalogram data recorded in event related desynchronization and photic synchronization scenarios"}, "present_kps": {"text": ["bayesian nonstationary autoregressive models", "biomedical signal analysis", "time varying coefficients", "linear dynamical system", "frequency domain characterization", "event related desynchronization", "photic synchronization scenarios"], "tokenized": ["bayesian nonstationary autoregressive models", "biomedical signal analysis", "time varying coefficients", "linear dynamical system", "frequency domain characterization", "event related desynchronization", "photic synchronization scenarios"]}, "absent_kps": {"text": ["kalman smoother", "time domain characterization", "variational bayesian algorithm", "eeg analysis"], "tokenized": ["kalman smoother", "time domain characterization", "variational bayesian algorithm", "eeg analysis"]}}
{"id": 472, "title": {"text": "supervisory control design based on hybrid systems and fuzzy events detection . .", "tokenized": "supervisory control design based on hybrid systems and fuzzy events detection . ."}, "abstract": {"text": "this paper presents a supervisory control scheme based on hybrid systems theory and fuzzy events detection . the fuzzy event detector is a linguistic model , which synthesizes complex relations between process variables and process events incorporating experts ' knowledge about the process operation . this kind of detection allows the anticipation of appropriate control actions , which depend upon the selected membership functions used to characterize the process under scrutiny . the proposed supervisory control scheme was successfully implemented for an oxichlorination reactor in a vinyl monomer plant", "tokenized": "this paper presents a supervisory control scheme based on hybrid systems theory and fuzzy events detection . the fuzzy event detector is a linguistic model , which synthesizes complex relations between process variables and process events incorporating experts ' knowledge about the process operation . this kind of detection allows the anticipation of appropriate control actions , which depend upon the selected membership functions used to characterize the process under scrutiny . the proposed supervisory control scheme was successfully implemented for an oxichlorination reactor in a vinyl monomer plant"}, "present_kps": {"text": ["supervisory control design", "hybrid systems", "linguistic model", "complex relations", "process variables", "process events", "process operation", "control actions", "membership functions", "oxichlorination reactor", "vinyl monomer plant"], "tokenized": ["supervisory control design", "hybrid systems", "linguistic model", "complex relations", "process variables", "process events", "process operation", "control actions", "membership functions", "oxichlorination reactor", "vinyl monomer plant"]}, "absent_kps": {"text": ["finite state machines", "discrete events systems", "events detection . fuzzy", "raw material consumption", "reactor stability", "expert knowledge", "reactive systems"], "tokenized": ["finite state machines", "discrete events systems", "events detection . fuzzy", "raw material consumption", "reactor stability", "expert knowledge", "reactive systems"]}}
{"id": 473, "title": {"text": "automated breath detection on long duration signals using feedforward .", "tokenized": "automated breath detection on long duration signals using feedforward ."}, "abstract": {"text": "a new breath detection algorithm is presented , intended to automate the analysis of respiratory data acquired during sleep . the algorithm is based on two independent artificial neural networks ( ann sub insp and ann sub expi ) that recognize , in the original signal , windows of interest where the onset of inspiration and expiration occurs . postprocessing consists in finding inside each of these windows of interest minimum and maximum corresponding to each inspiration and expiration . the ann sub insp and ann sub expi correctly determine respectively [digit] . [digit] % and [digit] . [digit] % of the desired windows , when compared with [digit] [digit] inspirations and [digit] [digit] expirations detected by a human expert , obtained from three entire night recordings . postprocessing allowed determination of inspiration and expiration onsets with a mean difference with respect to the same human expert of ( mean or sd ) [digit] or [digit] ms for inspiration and [digit] or [digit] ms for expiration . the method proved to be effective in detecting the onset of inspiration and expiration in full night continuous recordings . a comparison of five human experts performing the same classification task yielded that the automated algorithm was undifferentiable from these human experts , failing within the distribution of human expert results . besides being applicable to adult respiratory volume data , the presented algorithm was also successfully applied to infant sleep data , consisting of uncalibrated rib cage and abdominal movement recordings . a comparison with two previously published algorithms for breath detection in respiratory volume signal shows that the presented algorithm has a higher specificity , while presenting similar or higher positive predictive values", "tokenized": "a new breath detection algorithm is presented , intended to automate the analysis of respiratory data acquired during sleep . the algorithm is based on two independent artificial neural networks ( ann sub insp and ann sub expi ) that recognize , in the original signal , windows of interest where the onset of inspiration and expiration occurs . postprocessing consists in finding inside each of these windows of interest minimum and maximum corresponding to each inspiration and expiration . the ann sub insp and ann sub expi correctly determine respectively [digit] . [digit] % and [digit] . [digit] % of the desired windows , when compared with [digit] [digit] inspirations and [digit] [digit] expirations detected by a human expert , obtained from three entire night recordings . postprocessing allowed determination of inspiration and expiration onsets with a mean difference with respect to the same human expert of ( mean or sd ) [digit] or [digit] ms for inspiration and [digit] or [digit] ms for expiration . the method proved to be effective in detecting the onset of inspiration and expiration in full night continuous recordings . a comparison of five human experts performing the same classification task yielded that the automated algorithm was undifferentiable from these human experts , failing within the distribution of human expert results . besides being applicable to adult respiratory volume data , the presented algorithm was also successfully applied to infant sleep data , consisting of uncalibrated rib cage and abdominal movement recordings . a comparison with two previously published algorithms for breath detection in respiratory volume signal shows that the presented algorithm has a higher specificity , while presenting similar or higher positive predictive values"}, "present_kps": {"text": ["automated breath detection", "long duration signals", "inspiration", "expiration", "postprocessing", "human experts", "entire night recordings", "[digit] ms", "[digit] ms", "automated algorithm", "adult respiratory volume data", "infant sleep data", "uncalibrated rib cage", "abdominal movement recordings"], "tokenized": ["automated breath detection", "long duration signals", "inspiration", "expiration", "postprocessing", "human experts", "entire night recordings", "[digit] ms", "[digit] ms", "automated algorithm", "adult respiratory volume data", "infant sleep data", "uncalibrated rib cage", "abdominal movement recordings"]}, "absent_kps": {"text": ["feedforward backpropagation artificial neural networks", "respiratory movements"], "tokenized": ["feedforward backpropagation artificial neural networks", "respiratory movements"]}}
{"id": 474, "title": {"text": "model selection in electromagnetic source analysis with an application to vefs .", "tokenized": "model selection in electromagnetic source analysis with an application to vefs ."}, "abstract": {"text": "sources are required to describe the electroencephalogram or magnetoencephalogram adequately . model selection procedures ( msps ) or goodness of fit procedures give an estimate of the required number of sources . existing and new msps are evaluated in different source and noise settings two sources which are close or distant and noise which is uncorrelated or correlated . the commonly used msp residual variance is seen to be ineffective , that is it often selects too many sources . alternatives like the adjusted hotelling ' s test , bayes information criterion and the wald test on source amplitudes are seen to be effective . the adjusted hotelling ' s test is recommended if a conservative approach is taken and msps such as bayes information criterion or the wald test on source amplitudes are recommended if a more liberal approach is desirable . the msps are applied to empirical data ( visual evoked fields )", "tokenized": "sources are required to describe the electroencephalogram or magnetoencephalogram adequately . model selection procedures ( msps ) or goodness of fit procedures give an estimate of the required number of sources . existing and new msps are evaluated in different source and noise settings two sources which are close or distant and noise which is uncorrelated or correlated . the commonly used msp residual variance is seen to be ineffective , that is it often selects too many sources . alternatives like the adjusted hotelling ' s test , bayes information criterion and the wald test on source amplitudes are seen to be effective . the adjusted hotelling ' s test is recommended if a conservative approach is taken and msps such as bayes information criterion or the wald test on source amplitudes are recommended if a more liberal approach is desirable . the msps are applied to empirical data ( visual evoked fields )"}, "present_kps": {"text": ["model selection", "electromagnetic source analysis", "vefs", "goodness of fit", "noise settings", "residual variance", "adjusted hotelling ' s test", "wald test", "empirical data", "visual evoked fields"], "tokenized": ["model selection", "electromagnetic source analysis", "vefs", "goodness of fit", "noise settings", "residual variance", "adjusted hotelling ' s test", "wald test", "empirical data", "visual evoked fields"]}, "absent_kps": {"text": ["eeg source analysis", "source localization", "meg source analysis"], "tokenized": ["eeg source analysis", "source localization", "meg source analysis"]}}
{"id": 475, "title": {"text": "time varying properties of renal autoregulatory mechanisms .", "tokenized": "time varying properties of renal autoregulatory mechanisms ."}, "abstract": {"text": "autoregulation , time frequency and time scaling methods were applied to renal blood flow under broad band forced arterial blood pressure fluctuations and single nephron renal blood flow with spontaneous oscillations obtained from normotensive ( sprague dawley , wistar , and long evans ) rats , and spontaneously hypertensive rats . time frequency analyses of normotensive and hypertensive blood flow data obtained from either the whole kidney or the single nephron show that indeed both the myogenic and tubuloglomerular feedback ( tgf ) mechanisms have time varying characteristics . furthermore , we utilized the renyi entropy to measure the complexity of blood flow dynamics in the time frequency plane in an effort to discern differences between normotensive and hypertensive recordings . we found a clear difference in renyi entropy between normotensive and hypertensive blood flow recordings at the whole kidney level for both forced ( p < [digit] . [digit] ) and spontaneous arterial pressure fluctuations ( p < [digit] . [digit] ) , and at the single nephron level ( p < [digit] . [digit] ) . especially at the single nephron level , the mean renyi entropy is significantly larger for hypertensive than normotensive rats , suggesting more complex dynamics in the hypertensive condition . to further evaluate whether or not the separation of dynamics between normotensive and hypertensive rats is found in the prescribed frequency ranges of the myogenic and tgf mechanisms , we employed multiresolution wavelet transform . our analysis revealed that exclusively over scale ranges corresponding to the frequency intervals of the myogenic and tgf mechanisms , the widths of the blood flow wavelet coefficients fall into disjoint sets for normotensive and hypertensive rats . the separation of the scales at the myogenic and tgf frequency ranges is distinct and obtained with [digit] % accuracy . however , this observation remains valid only for the whole kidney blood pressure flow data . the results suggest that understanding of the time varying properties of the two mechanisms is required for a complete description of renal autoregulation", "tokenized": "autoregulation , time frequency and time scaling methods were applied to renal blood flow under broad band forced arterial blood pressure fluctuations and single nephron renal blood flow with spontaneous oscillations obtained from normotensive ( sprague dawley , wistar , and long evans ) rats , and spontaneously hypertensive rats . time frequency analyses of normotensive and hypertensive blood flow data obtained from either the whole kidney or the single nephron show that indeed both the myogenic and tubuloglomerular feedback ( tgf ) mechanisms have time varying characteristics . furthermore , we utilized the renyi entropy to measure the complexity of blood flow dynamics in the time frequency plane in an effort to discern differences between normotensive and hypertensive recordings . we found a clear difference in renyi entropy between normotensive and hypertensive blood flow recordings at the whole kidney level for both forced ( p < [digit] . [digit] ) and spontaneous arterial pressure fluctuations ( p < [digit] . [digit] ) , and at the single nephron level ( p < [digit] . [digit] ) . especially at the single nephron level , the mean renyi entropy is significantly larger for hypertensive than normotensive rats , suggesting more complex dynamics in the hypertensive condition . to further evaluate whether or not the separation of dynamics between normotensive and hypertensive rats is found in the prescribed frequency ranges of the myogenic and tgf mechanisms , we employed multiresolution wavelet transform . our analysis revealed that exclusively over scale ranges corresponding to the frequency intervals of the myogenic and tgf mechanisms , the widths of the blood flow wavelet coefficients fall into disjoint sets for normotensive and hypertensive rats . the separation of the scales at the myogenic and tgf frequency ranges is distinct and obtained with [digit] % accuracy . however , this observation remains valid only for the whole kidney blood pressure flow data . the results suggest that understanding of the time varying properties of the two mechanisms is required for a complete description of renal autoregulation"}, "present_kps": {"text": ["time varying properties", "renal autoregulatory mechanisms", "broad band forced arterial blood pressure fluctuations", "single nephron", "single nephron renal blood flow", "spontaneous oscillations", "hypertensive rats", "whole kidney", "renyi entropy", "spontaneous arterial pressure fluctuations", "normotensive rats"], "tokenized": ["time varying properties", "renal autoregulatory mechanisms", "broad band forced arterial blood pressure fluctuations", "single nephron", "single nephron renal blood flow", "spontaneous oscillations", "hypertensive rats", "whole kidney", "renyi entropy", "spontaneous arterial pressure fluctuations", "normotensive rats"]}, "absent_kps": {"text": ["wistar rats", "long evans rats", "sprague dawley rats"], "tokenized": ["wistar rats", "long evans rats", "sprague dawley rats"]}}
{"id": 476, "title": {"text": "the use of the spsa method in ecg analysis .", "tokenized": "the use of the spsa method in ecg analysis ."}, "abstract": {"text": "signals recorded of a single patient over a relatively long period of time is considered . the particular application we have in mind is high resolution ecg analysis , such as late potential analysis , morphology changes in qrs during arrythmias , t wave alternants , or the study of drug effects on ventricular activation . we propose to apply a modification of a classical method of cluster analysis or vector quantization . the novelty of our approach is that we use a new distortion measure to quantify the distance of two ecg cycles , and the class distortion measure is defined using a min max criterion . the new class distortion measure is much more sensitive to outliers than the usual distortion measures using average distance . the price of this practical advantage is that computational complexity is significantly increased . the resulting nonsmooth optimization problem is solved by an adapted version of the simultaneous perturbation stochastic approximation ( spsa ) method of j . spall ( ieee trans . automat . contr . , vol . [digit] , p . [digit] [digit] , mar . [digit] ) . the main idea is to generate a smooth approximation by a randomization procedure . the viability of the method is demonstrated on both simulated and real data . an experimental comparison with the widely used correlation method is given on real data", "tokenized": "signals recorded of a single patient over a relatively long period of time is considered . the particular application we have in mind is high resolution ecg analysis , such as late potential analysis , morphology changes in qrs during arrythmias , t wave alternants , or the study of drug effects on ventricular activation . we propose to apply a modification of a classical method of cluster analysis or vector quantization . the novelty of our approach is that we use a new distortion measure to quantify the distance of two ecg cycles , and the class distortion measure is defined using a min max criterion . the new class distortion measure is much more sensitive to outliers than the usual distortion measures using average distance . the price of this practical advantage is that computational complexity is significantly increased . the resulting nonsmooth optimization problem is solved by an adapted version of the simultaneous perturbation stochastic approximation ( spsa ) method of j . spall ( ieee trans . automat . contr . , vol . [digit] , p . [digit] [digit] , mar . [digit] ) . the main idea is to generate a smooth approximation by a randomization procedure . the viability of the method is demonstrated on both simulated and real data . an experimental comparison with the widely used correlation method is given on real data"}, "present_kps": {"text": ["cluster analysis", "distortion measure", "ecg cycles", "class distortion measure", "nonsmooth optimization problem", "randomization procedure", "correlation method"], "tokenized": ["cluster analysis", "distortion measure", "ecg cycles", "class distortion measure", "nonsmooth optimization problem", "randomization procedure", "correlation method"]}, "absent_kps": {"text": ["simultaneous perturbation stochastic approximation method", "ecg signals compression", "electrodiagnostics"], "tokenized": ["simultaneous perturbation stochastic approximation method", "ecg signals compression", "electrodiagnostics"]}}
{"id": 477, "title": {"text": "model intestinal microflora in computer simulation a simulation and modeling .", "tokenized": "model intestinal microflora in computer simulation a simulation and modeling ."}, "abstract": {"text": "the ecology of the human intestinal microflora and its interaction with the host are poorly understood . though more and more data are being acquired , in part using modern molecular methods , development of a quantitative theory has not kept pace with this increase in observing power . this is in part due to the complexity of the system and to the lack of simulation environments in which to test what the ecological effect of a hypothetical mechanism of interaction would be , before resorting to laboratory experiments . the mimics project attempts to address this through the development of a cellular automaton for simulation of the intestinal microflora . in this paper , the design and evaluation of this simulator is discussed", "tokenized": "the ecology of the human intestinal microflora and its interaction with the host are poorly understood . though more and more data are being acquired , in part using modern molecular methods , development of a quantitative theory has not kept pace with this increase in observing power . this is in part due to the complexity of the system and to the lack of simulation environments in which to test what the ecological effect of a hypothetical mechanism of interaction would be , before resorting to laboratory experiments . the mimics project attempts to address this through the development of a cellular automaton for simulation of the intestinal microflora . in this paper , the design and evaluation of this simulator is discussed"}, "present_kps": {"text": ["intestinal microflora", "human intestines", "molecular methods", "quantitative theory", "observing power", "mimics project"], "tokenized": ["intestinal microflora", "human intestines", "molecular methods", "quantitative theory", "observing power", "mimics project"]}, "absent_kps": {"text": ["microbial ecology", "system complexity", "host microflora interactions", "complex microbial ecosystem", "parallel computing"], "tokenized": ["microbial ecology", "system complexity", "host microflora interactions", "complex microbial ecosystem", "parallel computing"]}}
{"id": 478, "title": {"text": "conformal mapping design tools for coaxial couplers with complex cross section .", "tokenized": "conformal mapping design tools for coaxial couplers with complex cross section ."}, "abstract": {"text": "tool for the analysis and design of coaxial waveguides and couplers of complex cross section . an implementation based on the schwarz christoffel toolbox , a public domain matlab package , is applied to slotted coaxial cables and to symmetrical coaxial couplers , with circular or polygonal inner conductors and external shields . the effect of metallic diaphragms of arbitrary thickness , partially separating the inner conductors , is also easily taken into account . the proposed technique is validated against the results of the finite element method , showing excellent agreement at a fraction of the computational cost , and is also extended to the case of nonsymmetrical couplers , providing the designer with important additional degrees of freedom", "tokenized": "tool for the analysis and design of coaxial waveguides and couplers of complex cross section . an implementation based on the schwarz christoffel toolbox , a public domain matlab package , is applied to slotted coaxial cables and to symmetrical coaxial couplers , with circular or polygonal inner conductors and external shields . the effect of metallic diaphragms of arbitrary thickness , partially separating the inner conductors , is also easily taken into account . the proposed technique is validated against the results of the finite element method , showing excellent agreement at a fraction of the computational cost , and is also extended to the case of nonsymmetrical couplers , providing the designer with important additional degrees of freedom"}, "present_kps": {"text": ["conformal mapping design tools", "coaxial couplers", "complex cross section", "coaxial waveguides", "schwarz christoffel toolbox", "public domain matlab package", "slotted coaxial cables", "polygonal inner conductors", "external shields", "metallic diaphragms", "nonsymmetrical couplers"], "tokenized": ["conformal mapping design tools", "coaxial couplers", "complex cross section", "coaxial waveguides", "schwarz christoffel toolbox", "public domain matlab package", "slotted coaxial cables", "polygonal inner conductors", "external shields", "metallic diaphragms", "nonsymmetrical couplers"]}, "absent_kps": {"text": ["symmetrical couplers", "circular inner conductors", "numerical conformal transformations"], "tokenized": ["symmetrical couplers", "circular inner conductors", "numerical conformal transformations"]}}
{"id": 479, "title": {"text": "convolution based global simulation technique for millimeter wave photodetector .", "tokenized": "convolution based global simulation technique for millimeter wave photodetector ."}, "abstract": {"text": "a fast convolution based time domain approach to global photonic circuit simulation is presented that incorporates a physical device model in the complete detector or mixer circuit . the device used in the demonstration of this technique is a gaas metal semiconductor metal ( msm ) photodetector that offers a high response speed for the detection and generation of millimeter waves . global simulation greatly increases the accuracy in evaluating the complete circuit performance because it accounts for the effects of the millimeter wave embedding circuit . device and circuit performance are assessed by calculating optical responsivity and bandwidth . device only simulations using gaas msms are compared with global simulations that illustrate the strong interdependence between device and external circuit", "tokenized": "a fast convolution based time domain approach to global photonic circuit simulation is presented that incorporates a physical device model in the complete detector or mixer circuit . the device used in the demonstration of this technique is a gaas metal semiconductor metal ( msm ) photodetector that offers a high response speed for the detection and generation of millimeter waves . global simulation greatly increases the accuracy in evaluating the complete circuit performance because it accounts for the effects of the millimeter wave embedding circuit . device and circuit performance are assessed by calculating optical responsivity and bandwidth . device only simulations using gaas msms are compared with global simulations that illustrate the strong interdependence between device and external circuit"}, "present_kps": {"text": ["convolution based global simulation", "millimeter wave photodetector", "convolution based time domain approach", "global photonic circuit simulation", "physical device model", "gaas", "optical responsivity", "bandwidth"], "tokenized": ["convolution based global simulation", "millimeter wave photodetector", "convolution based time domain approach", "global photonic circuit simulation", "physical device model", "gaas", "optical responsivity", "bandwidth"]}, "absent_kps": {"text": ["mm wave embedding circuit", "photomixer", "gaas msm photodetector"], "tokenized": ["mm wave embedding circuit", "photomixer", "gaas msm photodetector"]}}
{"id": 480, "title": {"text": "accurate modeling of lossy nonuniform transmission lines by using differential .", "tokenized": "accurate modeling of lossy nonuniform transmission lines by using differential ."}, "abstract": {"text": "this paper discusses an efficient numerical approximation technique , called the differential quadrature method ( dqm ) , which has been adapted to model lossy uniform and nonuniform transmission lines . the dqm can quickly compute the derivative of a function at any point within its bounded domain by estimating a weighted linear sum of values of the function at a small set of points belonging to the domain . using the dqm , the frequency domain telegrapher ' s partial differential equations for transmission lines can be discretized into a set of easily solvable algebraic equations . dqm reduces interconnects into multiport models whose port voltages and currents are related by rational formulas in the frequency domain . although the rationalization process in dqm is comparable with the pade approximation of asymptotic waveform evaluation ( awe ) applied to transmission lines , the derivation mechanisms in these two disparate methods are significantly different . unlike awe , which employs a complex moment matching process to obtain rational approximation , the dqm requires no approximation of transcendental functions , thereby avoiding the process of moment generation and moment matching . due to global sampling of points in the dqm approximation , it requires far fewer grid points in order to build accurate discrete models than other numerical methods do . the dqm based time domain model can be readily integrated in a circuit simulator like spice", "tokenized": "this paper discusses an efficient numerical approximation technique , called the differential quadrature method ( dqm ) , which has been adapted to model lossy uniform and nonuniform transmission lines . the dqm can quickly compute the derivative of a function at any point within its bounded domain by estimating a weighted linear sum of values of the function at a small set of points belonging to the domain . using the dqm , the frequency domain telegrapher ' s partial differential equations for transmission lines can be discretized into a set of easily solvable algebraic equations . dqm reduces interconnects into multiport models whose port voltages and currents are related by rational formulas in the frequency domain . although the rationalization process in dqm is comparable with the pade approximation of asymptotic waveform evaluation ( awe ) applied to transmission lines , the derivation mechanisms in these two disparate methods are significantly different . unlike awe , which employs a complex moment matching process to obtain rational approximation , the dqm requires no approximation of transcendental functions , thereby avoiding the process of moment generation and moment matching . due to global sampling of points in the dqm approximation , it requires far fewer grid points in order to build accurate discrete models than other numerical methods do . the dqm based time domain model can be readily integrated in a circuit simulator like spice"}, "present_kps": {"text": ["lossy nonuniform transmission lines", "numerical approximation technique", "differential quadrature method", "partial differential equations", "algebraic equations", "interconnects", "multiport models", "rationalization process", "time domain model"], "tokenized": ["lossy nonuniform transmission lines", "numerical approximation technique", "differential quadrature method", "partial differential equations", "algebraic equations", "interconnects", "multiport models", "rationalization process", "time domain model"]}, "absent_kps": {"text": ["multiconductor transmission lines", "frequency domain telegrapher pde"], "tokenized": ["multiconductor transmission lines", "frequency domain telegrapher pde"]}}
{"id": 481, "title": {"text": "an unconditionally stable extended ( use ) finite element time domain solution of .", "tokenized": "an unconditionally stable extended ( use ) finite element time domain solution of ."}, "abstract": {"text": "this paper proposes an extension of the unconditionally stable finite element time domain ( fetd ) method for the global electromagnetic analysis of active microwave circuits . this formulation has two advantages . first , the time step size is no longer governed by the spatial discretization of the mesh , but rather by the nyquist sampling criterion . second , the implementation of the truncation by the perfectly matched layers ( pml ) is straightforward . an anisotropic pml absorbing material is presented for the truncation of fetd lattices . reflection less than [digit] db is obtained numerically over the entire propagation bandwidth in waveguide and microstrip line . a benchmark test on a microwave amplifier indicates that this extended fetd algorithm is not only superior to finite difference time domain based algorithm in mesh flexibility and simulation accuracy , but also reduces computation time dramatically", "tokenized": "this paper proposes an extension of the unconditionally stable finite element time domain ( fetd ) method for the global electromagnetic analysis of active microwave circuits . this formulation has two advantages . first , the time step size is no longer governed by the spatial discretization of the mesh , but rather by the nyquist sampling criterion . second , the implementation of the truncation by the perfectly matched layers ( pml ) is straightforward . an anisotropic pml absorbing material is presented for the truncation of fetd lattices . reflection less than [digit] db is obtained numerically over the entire propagation bandwidth in waveguide and microstrip line . a benchmark test on a microwave amplifier indicates that this extended fetd algorithm is not only superior to finite difference time domain based algorithm in mesh flexibility and simulation accuracy , but also reduces computation time dramatically"}, "present_kps": {"text": ["global electromagnetic analysis", "time step size", "nyquist sampling criterion", "perfectly matched layers", "anisotropic pml absorbing material", "waveguide", "microstrip line", "microwave amplifier", "mesh flexibility", "simulation accuracy"], "tokenized": ["global electromagnetic analysis", "time step size", "nyquist sampling criterion", "perfectly matched layers", "anisotropic pml absorbing material", "waveguide", "microstrip line", "microwave amplifier", "mesh flexibility", "simulation accuracy"]}, "absent_kps": {"text": ["finite element time domain method", "computation time reduction", "pml truncation", "global em analysis", "active nonlinear microwave circuits", "fetd lattices truncation", "unconditionally stable fetd method"], "tokenized": ["finite element time domain method", "computation time reduction", "pml truncation", "global em analysis", "active nonlinear microwave circuits", "fetd lattices truncation", "unconditionally stable fetd method"]}}
{"id": 482, "title": {"text": "low voltage dram sensing scheme with offset cancellation sense amplifier .", "tokenized": "low voltage dram sensing scheme with offset cancellation sense amplifier ."}, "abstract": {"text": "power dissipation and compatibility with low voltage cmos . one of the major obstacles in low voltage dram is the degradation of data retention time due to low signal level at the memory cell , which requires power consuming refresh operations more frequently . this paper proposes an offset cancellation sense amplifier scheme ( ocsa ) that improves data retention time significantly even at low supply voltage . it also improves die efficiency , because the proposed scheme reduces the number of sense amplifiers by supporting more cells in each sense amplifier . measurements show that the data retention time of the proposed scheme at [digit] . [digit] v supply voltage is [digit] . [digit] times of the conventional scheme at [digit] . [digit] v", "tokenized": "power dissipation and compatibility with low voltage cmos . one of the major obstacles in low voltage dram is the degradation of data retention time due to low signal level at the memory cell , which requires power consuming refresh operations more frequently . this paper proposes an offset cancellation sense amplifier scheme ( ocsa ) that improves data retention time significantly even at low supply voltage . it also improves die efficiency , because the proposed scheme reduces the number of sense amplifiers by supporting more cells in each sense amplifier . measurements show that the data retention time of the proposed scheme at [digit] . [digit] v supply voltage is [digit] . [digit] times of the conventional scheme at [digit] . [digit] v"}, "present_kps": {"text": ["data retention time", "memory cell", "power consuming refresh operations", "offset cancellation sense amplifier scheme", "[digit] . [digit] v"], "tokenized": ["data retention time", "memory cell", "power consuming refresh operations", "offset cancellation sense amplifier scheme", "[digit] . [digit] v"]}, "absent_kps": {"text": ["low voltage sensing scheme", "low power dissipation", "lv dram sensing scheme", "sensing margin", "differential amplifier configuration", "low voltage cmos compatibility", "bitline sensing scheme"], "tokenized": ["low voltage sensing scheme", "low power dissipation", "lv dram sensing scheme", "sensing margin", "differential amplifier configuration", "low voltage cmos compatibility", "bitline sensing scheme"]}}
{"id": 483, "title": {"text": "industry insiders loading up on cheap company stock .", "tokenized": "industry insiders loading up on cheap company stock ."}, "abstract": {"text": "stock in the last two months points toward a renewed optimism in the beleaguered sector , say some observers , who view the rash of insider buying as a vote of confidence from management . airgate pcs , charter communications , cox communications , crown castle international , nextel communications and nortel networks all have seen infusions of insider investment this summer , echoing trends in both the telecom industry and the national economy", "tokenized": "stock in the last two months points toward a renewed optimism in the beleaguered sector , say some observers , who view the rash of insider buying as a vote of confidence from management . airgate pcs , charter communications , cox communications , crown castle international , nextel communications and nortel networks all have seen infusions of insider investment this summer , echoing trends in both the telecom industry and the national economy"}, "present_kps": {"text": ["insider investment", "telecom industry"], "tokenized": ["insider investment", "telecom industry"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 484, "title": {"text": "new tuning method for pid controller .", "tokenized": "new tuning method for pid controller ."}, "abstract": {"text": "controller and the performance assessment formulas for this method are proposed . this tuning method is based on a genetic algorithm based pid controller design method . for deriving the tuning formula , the genetic algorithm based design method is applied to design pid controllers for a variety of processes . the relationship between the controller parameters and the parameters that characterize the process dynamics are determined and the tuning formula is then derived . using simulation studies , the rules for assessing the performance of a pid controller tuned by the proposed method are also given . this makes it possible to incorporate the capability to determine if the pid controller is well tuned or not into an autotuner . an autotuner based on this new tuning method and the corresponding performance assessment rules is also established . simulations and real time experimental results are given to demonstrate the effectiveness and usefulness of these formulas", "tokenized": "controller and the performance assessment formulas for this method are proposed . this tuning method is based on a genetic algorithm based pid controller design method . for deriving the tuning formula , the genetic algorithm based design method is applied to design pid controllers for a variety of processes . the relationship between the controller parameters and the parameters that characterize the process dynamics are determined and the tuning formula is then derived . using simulation studies , the rules for assessing the performance of a pid controller tuned by the proposed method are also given . this makes it possible to incorporate the capability to determine if the pid controller is well tuned or not into an autotuner . an autotuner based on this new tuning method and the corresponding performance assessment rules is also established . simulations and real time experimental results are given to demonstrate the effectiveness and usefulness of these formulas"}, "present_kps": {"text": ["tuning method", "pid controller", "genetic algorithm", "controller design method", "process dynamics", "autotuner"], "tokenized": ["tuning method", "pid controller", "genetic algorithm", "controller design method", "process dynamics", "autotuner"]}, "absent_kps": {"text": ["proportional integral derivative controller"], "tokenized": ["proportional integral derivative controller"]}}
{"id": 485, "title": {"text": "a [digit] mw [digit] d rendering engine with [digit] mb embedded dram and [digit] . [digit] gb s runtime .", "tokenized": "a [digit] mw [digit] d rendering engine with [digit] mb embedded dram and [digit] . [digit] gb s runtime ."}, "abstract": {"text": "a low power three dimensional ( [digit] d ) rendering engine is implemented as part of a mobile personal digital assistant ( pda ) chip . six megabit embedded dram macros attached to [digit] pixel parallel rendering logic are logically localized with a [digit] . [digit] gb s runtime reconfigurable bus , reducing the area by [digit] % compared with conventional local frame buffer architectures . the low power consumption is achieved by polygon dependent access to the embedded dram macros with line block mapping providing read modify write data transaction . the [digit] d rendering engine with [digit] . [digit] mpolygons s drawing speed was fabricated using [digit] . [digit] mu m cmos embedded memory logic technology . its area is [digit] mm sup [digit] and its power consumption is [digit] mw", "tokenized": "a low power three dimensional ( [digit] d ) rendering engine is implemented as part of a mobile personal digital assistant ( pda ) chip . six megabit embedded dram macros attached to [digit] pixel parallel rendering logic are logically localized with a [digit] . [digit] gb s runtime reconfigurable bus , reducing the area by [digit] % compared with conventional local frame buffer architectures . the low power consumption is achieved by polygon dependent access to the embedded dram macros with line block mapping providing read modify write data transaction . the [digit] d rendering engine with [digit] . [digit] mpolygons s drawing speed was fabricated using [digit] . [digit] mu m cmos embedded memory logic technology . its area is [digit] mm sup [digit] and its power consumption is [digit] mw"}, "present_kps": {"text": ["[digit] mw", "[digit] . [digit] gb s", "embedded dram macros", "[digit] pixel parallel rendering logic", "reconfigurable bus", "low power consumption", "polygon dependent access", "line block mapping", "read modify write data transaction", "cmos embedded memory logic technology"], "tokenized": ["[digit] mw", "[digit] . [digit] gb s", "embedded dram macros", "[digit] pixel parallel rendering logic", "reconfigurable bus", "low power consumption", "polygon dependent access", "line block mapping", "read modify write data transaction", "cmos embedded memory logic technology"]}, "absent_kps": {"text": ["3d graphics rendering", "three dimensional rendering engine", "low power 3d rendering engine", "mobile pda chip", "mobile personal digital assistant chip", "[digit] mbit", "[digit] . [digit] micron"], "tokenized": ["3d graphics rendering", "three dimensional rendering engine", "low power 3d rendering engine", "mobile pda chip", "mobile personal digital assistant chip", "[digit] mbit", "[digit] . [digit] micron"]}}
{"id": 486, "title": {"text": "a digital to analog converter based on differential quad switching .", "tokenized": "a digital to analog converter based on differential quad switching ."}, "abstract": {"text": "( dac ) for direct digital modulation is addressed in this paper . a new type of switching scheme , called differential quad switching , is presented . to verify the feasibility of this scheme , essential parts with some auxiliary circuitry for interfacing were fabricated in a [digit] . [digit] mu m cmos technology . measured results show that the switching scheme provides [digit] b resolution at [digit] msamples s and [digit] b at [digit] gsamples s . the degradation in signal to noise ratio is not observed for the variation of the supply voltage down to [digit] . [digit] v , which means the proposed scheme is suitable for low voltage applications", "tokenized": "( dac ) for direct digital modulation is addressed in this paper . a new type of switching scheme , called differential quad switching , is presented . to verify the feasibility of this scheme , essential parts with some auxiliary circuitry for interfacing were fabricated in a [digit] . [digit] mu m cmos technology . measured results show that the switching scheme provides [digit] b resolution at [digit] msamples s and [digit] b at [digit] gsamples s . the degradation in signal to noise ratio is not observed for the variation of the supply voltage down to [digit] . [digit] v , which means the proposed scheme is suitable for low voltage applications"}, "present_kps": {"text": ["digital to analog converter", "differential quad switching", "direct digital modulation", "cmos technology", "signal to noise ratio", "[digit] . [digit] v"], "tokenized": ["digital to analog converter", "differential quad switching", "direct digital modulation", "cmos technology", "signal to noise ratio", "[digit] . [digit] v"]}, "absent_kps": {"text": ["[digit] . [digit] micron", "snr", "oversampling dac", "high resolution dac", "high conversion rate dac"], "tokenized": ["[digit] . [digit] micron", "snr", "oversampling dac", "high resolution dac", "high conversion rate dac"]}}
{"id": 487, "title": {"text": "fast frequency acquisition phase frequency detectors for gsamples s .", "tokenized": "fast frequency acquisition phase frequency detectors for gsamples s ."}, "abstract": {"text": "this paper describes two techniques for designing phase frequency detectors ( pfds ) with higher operating frequencies periods of less than [digit] the delay of a fan out [digit] inverter ( fo [digit] ) and faster frequency acquisition . prototypes designed in [digit] . [digit] mu m cmos process exhibit operating frequencies of [digit] . [digit] ghz [digit] ( [digit] . fo [digit] ) and [digit] . [digit] ghz [digit] ( [digit] . [digit] . fo [digit] ) for two techniques , respectively , whereas a conventional pfd operates at < [digit] ghz [digit] ( [digit] . fo [digit] ) . the two proposed pfds achieve a capture range of [digit] . [digit] and [digit] . [digit] the conventional design , respectively", "tokenized": "this paper describes two techniques for designing phase frequency detectors ( pfds ) with higher operating frequencies periods of less than [digit] the delay of a fan out [digit] inverter ( fo [digit] ) and faster frequency acquisition . prototypes designed in [digit] . [digit] mu m cmos process exhibit operating frequencies of [digit] . [digit] ghz [digit] ( [digit] . fo [digit] ) and [digit] . [digit] ghz [digit] ( [digit] . [digit] . fo [digit] ) for two techniques , respectively , whereas a conventional pfd operates at < [digit] ghz [digit] ( [digit] . fo [digit] ) . the two proposed pfds achieve a capture range of [digit] . [digit] and [digit] . [digit] the conventional design , respectively"}, "present_kps": {"text": ["fast frequency acquisition", "phase frequency detectors", "cmos process", "[digit] . [digit] ghz", "[digit] . [digit] ghz"], "tokenized": ["fast frequency acquisition", "phase frequency detectors", "cmos process", "[digit] . [digit] ghz", "[digit] . [digit] ghz"]}, "absent_kps": {"text": ["gsamples s pll", "phase locked loop", "pass transistor dff pfd architecture", "[digit] . [digit] micron", "latch based pfd architecture", "clock generator"], "tokenized": ["gsamples s pll", "phase locked loop", "pass transistor dff pfd architecture", "[digit] . [digit] micron", "latch based pfd architecture", "clock generator"]}}
{"id": 488, "title": {"text": "high voltage transistor scaling circuit techniques for high density .", "tokenized": "high voltage transistor scaling circuit techniques for high density ."}, "abstract": {"text": "in order to scale high voltage transistors for high density negative gate channel erasing nor flash memories , two circuit techniques were developed . a proposed level shifter with low operating voltage is composed of three parts , a latch holding the negative erasing voltage , two coupling capacitors connected with the latched nodes in the latch , and high voltage drivers inverting the latch , resulting in reduction of the maximum internal voltage by [digit] . [digit] v . a proposed high voltage generator adds a path gate logic to a conventional high voltage generator to realize both low noise and low ripple voltage , resulting in a reduction of the maximum internal voltage by [digit] . [digit] v . as a result , these circuit techniques along with high coupling ratio cell technology can scale down the high voltage transistors by [digit] % and can realize higher density negative gate channel erase nor flash memories in comparison with the source erase nor flash memories", "tokenized": "in order to scale high voltage transistors for high density negative gate channel erasing nor flash memories , two circuit techniques were developed . a proposed level shifter with low operating voltage is composed of three parts , a latch holding the negative erasing voltage , two coupling capacitors connected with the latched nodes in the latch , and high voltage drivers inverting the latch , resulting in reduction of the maximum internal voltage by [digit] . [digit] v . a proposed high voltage generator adds a path gate logic to a conventional high voltage generator to realize both low noise and low ripple voltage , resulting in a reduction of the maximum internal voltage by [digit] . [digit] v . as a result , these circuit techniques along with high coupling ratio cell technology can scale down the high voltage transistors by [digit] % and can realize higher density negative gate channel erase nor flash memories in comparison with the source erase nor flash memories"}, "present_kps": {"text": ["level shifter", "high voltage drivers", "high voltage generator", "path gate logic", "low noise", "low ripple voltage", "high coupling ratio cell technology"], "tokenized": ["level shifter", "high voltage drivers", "high voltage generator", "path gate logic", "low noise", "low ripple voltage", "high coupling ratio cell technology"]}, "absent_kps": {"text": ["hv transistor scaling circuit techniques", "low operating voltage shifter", "negative gate channel erasing flash memories", "high density nor flash memories", "hv generator"], "tokenized": ["hv transistor scaling circuit techniques", "low operating voltage shifter", "negative gate channel erasing flash memories", "high density nor flash memories", "hv generator"]}}
{"id": 489, "title": {"text": "a [digit] . [digit] v [digit] kb four way set associative two level cmos cache memory using .", "tokenized": "a [digit] . [digit] v [digit] kb four way set associative two level cmos cache memory using ."}, "abstract": {"text": "this paper reports a [digit] . [digit] v [digit] kb four way set associative two level cmos cache memory using a novel two stage wordline bitline oriented tag compare ( wlotc blotc ) and sense wordline bitline ( swl sbl ) tag sense amplifiers with an eight transistor ( [digit] t ) tag cell in level [digit] ( l2 ) and a [digit] t shrunk logic swing ( sls ) memory cell . with the ground floating ( g f ) data sense amplifier in level [digit] ( l1 ) for high speed operation for low voltage low power vlsi system applications . owing to the reduced loading at the swl in the new [digit] t tag cell using the wlotc scheme , the [digit] t sls memory cell with g f sense amplifier in l1 , and the split comparison of the index signal in the [digit] t tag cells with swl sbl tag sense amplifiers in l2 , this [digit] . [digit] v cache memory implemented in a [digit] . [digit] v [digit] . [digit] mu m cmos technology has a measured l1 l2 hit time of [digit] . [digit] [digit] . [digit] ns at the average dissipation of [digit] . [digit] mw at [digit] mhz", "tokenized": "this paper reports a [digit] . [digit] v [digit] kb four way set associative two level cmos cache memory using a novel two stage wordline bitline oriented tag compare ( wlotc blotc ) and sense wordline bitline ( swl sbl ) tag sense amplifiers with an eight transistor ( [digit] t ) tag cell in level [digit] ( l2 ) and a [digit] t shrunk logic swing ( sls ) memory cell . with the ground floating ( g f ) data sense amplifier in level [digit] ( l1 ) for high speed operation for low voltage low power vlsi system applications . owing to the reduced loading at the swl in the new [digit] t tag cell using the wlotc scheme , the [digit] t sls memory cell with g f sense amplifier in l1 , and the split comparison of the index signal in the [digit] t tag cells with swl sbl tag sense amplifiers in l2 , this [digit] . [digit] v cache memory implemented in a [digit] . [digit] v [digit] . [digit] mu m cmos technology has a measured l1 l2 hit time of [digit] . [digit] [digit] . [digit] ns at the average dissipation of [digit] . [digit] mw at [digit] mhz"}, "present_kps": {"text": ["[digit] . [digit] v", "[digit] . [digit] v", "two level cmos cache memory", "wordline bitline oriented tag compare", "tag sense amplifiers", "high speed operation", "low power vlsi system applications", "[digit] . [digit] ns", "[digit] . [digit] ns", "[digit] . [digit] mw", "[digit] mhz"], "tokenized": ["[digit] . [digit] v", "[digit] . [digit] v", "two level cmos cache memory", "wordline bitline oriented tag compare", "tag sense amplifiers", "high speed operation", "low power vlsi system applications", "[digit] . [digit] ns", "[digit] . [digit] ns", "[digit] . [digit] mw", "[digit] mhz"]}, "absent_kps": {"text": ["low voltage vlsi system applications", "shrunk logic swing memory cell", "[digit] kbit", "eight transistor tag cell", "ground floating data sense amplifier", "sense wordline bitline amplifiers", "cache memory architecture", "four way set associative memory", "ten transistor memory cell", "[digit] . [digit] micron"], "tokenized": ["low voltage vlsi system applications", "shrunk logic swing memory cell", "[digit] kbit", "eight transistor tag cell", "ground floating data sense amplifier", "sense wordline bitline amplifiers", "cache memory architecture", "four way set associative memory", "ten transistor memory cell", "[digit] . [digit] micron"]}}
{"id": 490, "title": {"text": "learning spatial relations using an inductive logic programming system .", "tokenized": "learning spatial relations using an inductive logic programming system ."}, "abstract": {"text": "relevant tasks such as those associated with motion , orientation , navigation , etc . this paper reports on using an inductive logic programming ( ilp ) system for learning function free horn clause descriptions of spatial knowledge . its main contribution , however , is to show that an existing relation between two reference systems the speaker relative and the absolute can be automatically learned by an ilp system , given the proper background knowledge and positive examples", "tokenized": "relevant tasks such as those associated with motion , orientation , navigation , etc . this paper reports on using an inductive logic programming ( ilp ) system for learning function free horn clause descriptions of spatial knowledge . its main contribution , however , is to show that an existing relation between two reference systems the speaker relative and the absolute can be automatically learned by an ilp system , given the proper background knowledge and positive examples"}, "present_kps": {"text": ["spatial relations", "inductive logic programming system", "function free horn clause descriptions"], "tokenized": ["spatial relations", "inductive logic programming system", "function free horn clause descriptions"]}, "absent_kps": {"text": ["spatial relations learning"], "tokenized": ["spatial relations learning"]}}
{"id": 491, "title": {"text": "windows xp fast user switching .", "tokenized": "windows xp fast user switching ."}, "abstract": {"text": "multiple user accounts , but they ' ve taken the concept a step further with windows xp ' s fast user switching feature . fast user switching is a new feature of windows xp that allows multiple users to log on to the same machine and quickly switch between the logged on accounts . fast user switching is implemented using some of the built in capabilities of terminal services . terminal server has been around for a while but is much more feature rich and integrated in windows xp . a machine with the terminal services ( remote desktop ) client can log on to and run applications on a remote machine running the terminal server", "tokenized": "multiple user accounts , but they ' ve taken the concept a step further with windows xp ' s fast user switching feature . fast user switching is a new feature of windows xp that allows multiple users to log on to the same machine and quickly switch between the logged on accounts . fast user switching is implemented using some of the built in capabilities of terminal services . terminal server has been around for a while but is much more feature rich and integrated in windows xp . a machine with the terminal services ( remote desktop ) client can log on to and run applications on a remote machine running the terminal server"}, "present_kps": {"text": ["windows xp fast user switching", "multiple user accounts", "terminal services", "terminal server", "remote desktop"], "tokenized": ["windows xp fast user switching", "multiple user accounts", "terminal services", "terminal server", "remote desktop"]}, "absent_kps": {"text": ["multiple user logon access", "operating systems"], "tokenized": ["multiple user logon access", "operating systems"]}}
{"id": 492, "title": {"text": "generating code at run time with reflection . emit .", "tokenized": "generating code at run time with reflection . emit ."}, "abstract": {"text": "executable code the c and vb . net compilers get most of the attention , but there are others . the regex class ( in the system . text . regularexpressions namespace ) has the ability to compile favorite regular expressions into a . net assembly . in fact , the net common language runtime ( clr ) contains a whole namespace full of classes to help us build assemblies , define types , and emit their implementations , all at run time . these classes , which comprise the system . reflection . emit namespace , are known collectively as reflection . emit", "tokenized": "executable code the c and vb . net compilers get most of the attention , but there are others . the regex class ( in the system . text . regularexpressions namespace ) has the ability to compile favorite regular expressions into a . net assembly . in fact , the net common language runtime ( clr ) contains a whole namespace full of classes to help us build assemblies , define types , and emit their implementations , all at run time . these classes , which comprise the system . reflection . emit namespace , are known collectively as reflection . emit"}, "present_kps": {"text": ["reflection . emit", "regex class", "assemblies", "types", "system . reflection . emit namespace"], "tokenized": ["reflection . emit", "regex class", "assemblies", "types", "system . reflection . emit namespace"]}, "absent_kps": {"text": [". net framework sdk", "runtime code generation", ". net common language runtime"], "tokenized": [". net framework sdk", "runtime code generation", ". net common language runtime"]}}
{"id": 493, "title": {"text": ". net obfuscation and intellectual property .", "tokenized": ". net obfuscation and intellectual property ."}, "abstract": {"text": "programs won ' t need obfuscation because the loss caused by reverse engineering will be nonexistent . numerous obfuscators are already available for the . net platform , ranging from a basic renaming obfuscator to a fully functional obfuscator that handles mixed il native code assemblies created in any managed language , including microsoft ' s c with managed extensions . an obfuscator simply makes your application harder to reverse engineer . it does not prevent reverse engineering . however , the cost of obfuscation is insignificant when compared to the cost of a typical software development project . if you feel like an obfuscator provides you any benefit at all , it ' s probably worth the price", "tokenized": "programs won ' t need obfuscation because the loss caused by reverse engineering will be nonexistent . numerous obfuscators are already available for the . net platform , ranging from a basic renaming obfuscator to a fully functional obfuscator that handles mixed il native code assemblies created in any managed language , including microsoft ' s c with managed extensions . an obfuscator simply makes your application harder to reverse engineer . it does not prevent reverse engineering . however , the cost of obfuscation is insignificant when compared to the cost of a typical software development project . if you feel like an obfuscator provides you any benefit at all , it ' s probably worth the price"}, "present_kps": {"text": [". net obfuscation", "intellectual property", "reverse engineering"], "tokenized": [". net obfuscation", "intellectual property", "reverse engineering"]}, "absent_kps": {"text": [], "tokenized": []}}
{"id": 494, "title": {"text": "controller performance analysis with lqg benchmark obtained under closed loop .", "tokenized": "controller performance analysis with lqg benchmark obtained under closed loop ."}, "abstract": {"text": "this paper proposes a new method for obtaining a linear quadratic gaussian ( lqg ) benchmark in terms of the variances of process input and output from closed loop data , for assessing the controller performance . lqg benchmark has been proposed in the literature to assess controller performance since the lqg tradeoff curve represents the limit of performance in terms of input and output variances . however , an explicit parametric model is required to calculate the lqg benchmark . in this work , we propose a data driven subspace approach to calculate the lqg benchmark under closed loop conditions with certain external excitations . the optimal lqg benchmark variances are obtained directly from the subspace matrices corresponding to the deterministic inputs and the stochastic inputs , which are identified using closed loop data with setpoint excitation . these variances are used for assessing the controller performance . the method proposed in this paper is applicable to both univariate and multivariate systems . profit analysis for the implementation of feedforward control to the existing feedback only control system is also analyzed under the optimal lqg performance framework", "tokenized": "this paper proposes a new method for obtaining a linear quadratic gaussian ( lqg ) benchmark in terms of the variances of process input and output from closed loop data , for assessing the controller performance . lqg benchmark has been proposed in the literature to assess controller performance since the lqg tradeoff curve represents the limit of performance in terms of input and output variances . however , an explicit parametric model is required to calculate the lqg benchmark . in this work , we propose a data driven subspace approach to calculate the lqg benchmark under closed loop conditions with certain external excitations . the optimal lqg benchmark variances are obtained directly from the subspace matrices corresponding to the deterministic inputs and the stochastic inputs , which are identified using closed loop data with setpoint excitation . these variances are used for assessing the controller performance . the method proposed in this paper is applicable to both univariate and multivariate systems . profit analysis for the implementation of feedforward control to the existing feedback only control system is also analyzed under the optimal lqg performance framework"}, "present_kps": {"text": ["controller performance analysis", "lqg benchmark", "closed loop data", "subspace matrices", "deterministic inputs", "stochastic inputs", "multivariate systems", "profit analysis", "feedforward control"], "tokenized": ["controller performance analysis", "lqg benchmark", "closed loop data", "subspace matrices", "deterministic inputs", "stochastic inputs", "multivariate systems", "profit analysis", "feedforward control"]}, "absent_kps": {"text": ["univariate systems", "linear quadratic gaussian benchmark", "state space model"], "tokenized": ["univariate systems", "linear quadratic gaussian benchmark", "state space model"]}}
{"id": 495, "title": {"text": "lossy spice models produce realistic averaged simulations .", "tokenized": "lossy spice models produce realistic averaged simulations ."}, "abstract": {"text": "waveforms analysis were usually applied over perfect elements , non inclusive of the ohmic losses . however , if these elements play an active role in the dc transfer function , they affect the small signal ac analysis by introducing various damping effects . a model is introduced in a boost voltage mode application", "tokenized": "waveforms analysis were usually applied over perfect elements , non inclusive of the ohmic losses . however , if these elements play an active role in the dc transfer function , they affect the small signal ac analysis by introducing various damping effects . a model is introduced in a boost voltage mode application"}, "present_kps": {"text": ["lossy spice models", "realistic averaged simulations", "ohmic losses", "dc transfer function", "damping effects", "boost voltage mode application"], "tokenized": ["lossy spice models", "realistic averaged simulations", "ohmic losses", "dc transfer function", "damping effects", "boost voltage mode application"]}, "absent_kps": {"text": ["switch waveforms analysis", "state space averaging technique"], "tokenized": ["switch waveforms analysis", "state space averaging technique"]}}
{"id": 496, "title": {"text": "cad cae software aids converter design dc dc power conversion .", "tokenized": "cad cae software aids converter design dc dc power conversion ."}, "abstract": {"text": "this paper , the authors describe , using a flyback converter example , how cad cae tools can aid the power supply engineer in both areas , reducing prototyping costs and providing insights into system performance", "tokenized": "this paper , the authors describe , using a flyback converter example , how cad cae tools can aid the power supply engineer in both areas , reducing prototyping costs and providing insights into system performance"}, "present_kps": {"text": ["cad cae software", "prototyping costs"], "tokenized": ["cad cae software", "prototyping costs"]}, "absent_kps": {"text": ["power supply design", "dc dc power convertor design", "magnetic components", "electronic components", "flyback power convertor topology"], "tokenized": ["power supply design", "dc dc power convertor design", "magnetic components", "electronic components", "flyback power convertor topology"]}}
{"id": 497, "title": {"text": "using virtual reality to teach disability awareness .", "tokenized": "using virtual reality to teach disability awareness ."}, "abstract": {"text": "children about the accessibility and attitudinal barriers encountered by their peers with mobility impairments . within this software , children sitting in a virtual wheelchair experience obstacles such as stairs , narrow doors , objects too high to reach , and attitudinal barriers such as inappropriate comments . using a collaborative research methodology , [digit] youth with mobility impairments assisted in developing and beta testing the software . the effectiveness of the program was then evaluated with [digit] children in grades [digit] [digit] using a controlled pretest posttest design . the results indicated that the program was effective for increasing children ' s knowledge of accessibility barriers . attitudes , grade level , familiarity with individuals with a disability , and gender were also investigated", "tokenized": "children about the accessibility and attitudinal barriers encountered by their peers with mobility impairments . within this software , children sitting in a virtual wheelchair experience obstacles such as stairs , narrow doors , objects too high to reach , and attitudinal barriers such as inappropriate comments . using a collaborative research methodology , [digit] youth with mobility impairments assisted in developing and beta testing the software . the effectiveness of the program was then evaluated with [digit] children in grades [digit] [digit] using a controlled pretest posttest design . the results indicated that the program was effective for increasing children ' s knowledge of accessibility barriers . attitudes , grade level , familiarity with individuals with a disability , and gender were also investigated"}, "present_kps": {"text": ["virtual reality", "children", "accessibility", "mobility impairments", "virtual wheelchair", "collaborative research methodology", "gender"], "tokenized": ["virtual reality", "children", "accessibility", "mobility impairments", "virtual wheelchair", "collaborative research methodology", "gender"]}, "absent_kps": {"text": ["disability awareness teaching", "software beta testing", "software effectiveness", "computer aided instruction", "collaborative software development"], "tokenized": ["disability awareness teaching", "software beta testing", "software effectiveness", "computer aided instruction", "collaborative software development"]}}
{"id": 498, "title": {"text": "effects of white space in learning via the web .", "tokenized": "effects of white space in learning via the web ."}, "abstract": {"text": "from instructional web materials . the study also measured learners ' beliefs regarding web based instruction . prior research indicated that small changes in the handling of presentation elements can affect learning . achievement results from this study indicated that in on line materials , when content and overall structure are sound , minor differences regarding table borders and vertical spacing in text do not hinder learning . beliefs regarding web based instruction and instructors who use it did not differ significantly between treatment groups . implications of the study and cautions regarding generalizing from the results are discussed", "tokenized": "from instructional web materials . the study also measured learners ' beliefs regarding web based instruction . prior research indicated that small changes in the handling of presentation elements can affect learning . achievement results from this study indicated that in on line materials , when content and overall structure are sound , minor differences regarding table borders and vertical spacing in text do not hinder learning . beliefs regarding web based instruction and instructors who use it did not differ significantly between treatment groups . implications of the study and cautions regarding generalizing from the results are discussed"}, "present_kps": {"text": ["web based instruction", "presentation", "table borders"], "tokenized": ["web based instruction", "presentation", "table borders"]}, "absent_kps": {"text": ["text vertical spacing", "white space features", "online educational materials", "internet"], "tokenized": ["text vertical spacing", "white space features", "online educational materials", "internet"]}}
{"id": 499, "title": {"text": "the efficacy of electronic telecommunications in fostering interpersonal .", "tokenized": "the efficacy of electronic telecommunications in fostering interpersonal ."}, "abstract": {"text": "the effectiveness of electronic telecommunications as a supplementary aid to instruction and as a communication link between students , and between students and instructors in fostering interpersonal relationships was explored in this study . more specifically , the impacts of e mail , one of the most accessible , convenient , and easy to use computer mediated communications , on student attitudes toward the instructor , group mates , and other classmates were investigated . a posttest only experimental design was adopted . in total , [digit] prospective teachers enrolling in a computers in education course participated in the study for a whole semester . results from the study provided substantial evidence supporting e mail ' s beneficial effects on student attitudes toward the instructor and other classmates", "tokenized": "the effectiveness of electronic telecommunications as a supplementary aid to instruction and as a communication link between students , and between students and instructors in fostering interpersonal relationships was explored in this study . more specifically , the impacts of e mail , one of the most accessible , convenient , and easy to use computer mediated communications , on student attitudes toward the instructor , group mates , and other classmates were investigated . a posttest only experimental design was adopted . in total , [digit] prospective teachers enrolling in a computers in education course participated in the study for a whole semester . results from the study provided substantial evidence supporting e mail ' s beneficial effects on student attitudes toward the instructor and other classmates"}, "present_kps": {"text": ["telecommunications", "interpersonal relationships", "e mail", "computer mediated communications", "student attitudes", "computers in education course"], "tokenized": ["telecommunications", "interpersonal relationships", "e mail", "computer mediated communications", "student attitudes", "computers in education course"]}, "absent_kps": {"text": ["student communication link", "educational technology"], "tokenized": ["student communication link", "educational technology"]}}