{"id": 0, "title": {"text": "scalable grid service discovery based on uddi .", "tokenized": "scalable grid service discovery based on uddi ."}, "abstract": {"text": "efficient discovery of grid services is essential for the success of grid computing . the standardization of grids based on web services has resulted in the need for scalable web service discovery mechanisms to be deployed in grids even though uddi has been the de facto industry standard for web services discovery , imposed requirements of tight replication among registries and lack of autonomous control has severely hindered its widespread deployment and usage . with the advent of grid computing the scalability issue of uddi will become a roadblock that will prevent its deployment in grids . in this paper we present our distributed web service discovery architecture , called dude ( distributed uddi deployment engine ) . dude leverages dht ( distributed hash tables ) as a rendezvous mechanism between multiple uddi registries . dude enables consumers to query multiple registries , still at the same time allowing organizations to have autonomous control over their registries . . based on preliminary prototype on planetlab , we believe that dude architecture can support effective distribution of uddi registries thereby making uddi more robust and also addressing its scaling issues . furthermore , the dude architecture for scalable distribution can be applied beyond uddi to any grid service discovery mechanism . categories and subject descriptors c2 . [digit] distributed systems general terms design , experimentation , standardization .", "tokenized": "efficient discovery of grid services is essential for the success of grid computing . the standardization of grids based on web services has resulted in the need for scalable web service discovery mechanisms to be deployed in grids even though uddi has been the de facto industry standard for web services discovery , imposed requirements of tight replication among registries and lack of autonomous control has severely hindered its widespread deployment and usage . with the advent of grid computing the scalability issue of uddi will become a roadblock that will prevent its deployment in grids . in this paper we present our distributed web service discovery architecture , called dude ( distributed uddi deployment engine ) . dude leverages dht ( distributed hash tables ) as a rendezvous mechanism between multiple uddi registries . dude enables consumers to query multiple registries , still at the same time allowing organizations to have autonomous control over their registries . . based on preliminary prototype on planetlab , we believe that dude architecture can support effective distribution of uddi registries thereby making uddi more robust and also addressing its scaling issues . furthermore , the dude architecture for scalable distribution can be applied beyond uddi to any grid service discovery mechanism . categories and subject descriptors c2 . [digit] distributed systems general terms design , experimentation , standardization ."}, "present_kps": {"text": ["grid servic discoveri", "discoveri", "uddi", "grid comput", "web servic", "autonom control", "scalabl issu", "distribut web servic discoveri architectur", "dht", "uddi registri", "queri"], "tokenized": ["grid servic discoveri", "discoveri", "uddi", "grid comput", "web servic", "autonom control", "scalabl issu", "distribut web servic discoveri architectur", "dht", "uddi registri", "queri"]}, "absent_kps": {"text": ["longest avail prefix", "md", "case insensit search", "bamboo dht code", "soft state", "deploy issu", "dht base uddi registri hierarchi", "qo base servic discoveri"], "tokenized": ["longest avail prefix", "md", "case insensit search", "bamboo dht code", "soft state", "deploy issu", "dht base uddi registri hierarchi", "qo base servic discoveri"]}}
{"id": 1, "title": {"text": "self adaptive applications on the grid .", "tokenized": "self adaptive applications on the grid ."}, "abstract": {"text": "grids are inherently heterogeneous and dynamic . one important problem in grid computing is resource selection , that is , finding an appropriate resource set for the application . another problem is adaptation to the changing characteristics of the grid environment . existing solutions to these two problems require that a performance model for an application is known . however , constructing such models is a complex task . in this paper , we investigate an approach that does not require performance models . we start an application on any set of resources . during the application run , we periodically collect the statistics about the application run and deduce application requirements from these statistics . then , we adjust the resource set to better fit the application needs . this approach allows us to avoid performance bottlenecks , such as overloaded wan links or very slow processors , and therefore can yield significant performance improvements . we evaluate our approach in a number of scenarios typical for the grid . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems distributed applications c . [digit] performance of systems measurement techniques , modelling techniques general terms algorithms , measurement , performance , experimentation", "tokenized": "grids are inherently heterogeneous and dynamic . one important problem in grid computing is resource selection , that is , finding an appropriate resource set for the application . another problem is adaptation to the changing characteristics of the grid environment . existing solutions to these two problems require that a performance model for an application is known . however , constructing such models is a complex task . in this paper , we investigate an approach that does not require performance models . we start an application on any set of resources . during the application run , we periodically collect the statistics about the application run and deduce application requirements from these statistics . then , we adjust the resource set to better fit the application needs . this approach allows us to avoid performance bottlenecks , such as overloaded wan links or very slow processors , and therefore can yield significant performance improvements . we evaluate our approach in a number of scenarios typical for the grid . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems distributed applications c . [digit] performance of systems measurement techniques , modelling techniques general terms algorithms , measurement , performance , experimentation"}, "present_kps": {"text": ["self adapt", "grid comput", "resourc select", "grid environ"], "tokenized": ["self adapt", "grid comput", "resourc select", "grid environ"]}, "absent_kps": {"text": ["parallel comput", "homogen parallel environ", "heterogen of resourc resourc heterogen", "high bandwidth local area network", "lower bandwidth wide area network", "network link", "commun time", "idl time of the processor the processor idl time", "degre of parallel parallel degre", "overload resourc", "divid and conquer"], "tokenized": ["parallel comput", "homogen parallel environ", "heterogen of resourc resourc heterogen", "high bandwidth local area network", "lower bandwidth wide area network", "network link", "commun time", "idl time of the processor the processor idl time", "degre of parallel parallel degre", "overload resourc", "divid and conquer"]}}
{"id": 2, "title": {"text": "intra flow loss recovery and control for volp .", "tokenized": "intra flow loss recovery and control for volp ."}, "abstract": {"text": "best effort packet switched networks , like the internet , do not offer a reliable transmission of packets to applications with real time constraints such as voice . thus , the loss of packets impairs the application level utility . for voice this utility impairment is twofold on one hand , even short bursts of lost packets may decrease significantly the ability of the receiver to conceal the packet loss and the speech signal playout is interrupted . on the other hand , some packets may be particular sensitive to loss as they carry more important information in terms of user perception than other packets . we first develop an end to end model based on loss runlengths with which we can describe the loss distribution within a flow . these packet level metrics are then linked to user level objective speech quality metrics . using this framework , we find that for low compressing sample based codecs ( pcm ) with loss concealment isolated packet losses can be concealed well , whereas burst losses have a higher perceptual impact . for high compressing frame based codecs ( g . [digit] ) on one hand the impact of loss is amplified through error propagation caused by the decoder filter memories , though on the other hand such coding schemes help to perform loss concealment by extrapolation of decoder state . contrary to sample based codecs we show that the concealment performance may break at transitions within the speech signal however . we then propose mechanisms which differentiate between packets within a voice data flow to minimize the impact of packet loss . we designate these methods as intra flow loss recovery and control . at the end to end level , identification of packets sensitive to loss ( sender ) as well as loss concealment ( receiver ) takes place . hop by hop support schemes then allow to ( statistically ) trade the loss of one packet , which is considered more important , against another one of the same flow which is of lower importance . as both packets require the same cost in terms of network transmission , a gain in user perception is obtainable . we show that significant speech quality improvements can be achieved and additional data and delay overhead can be avoided while still maintaining a network service which is virtually identical to best effort in the long term . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems distributed applications ( [digit] . [digit] . [digit] computer communication networks internetworking routers c . [digit] computer systems organization performance of systems <unk> techniques c . [digit] computer systems organization performance of systems modeling techniques general terms design , measurement , performance , reliability", "tokenized": "best effort packet switched networks , like the internet , do not offer a reliable transmission of packets to applications with real time constraints such as voice . thus , the loss of packets impairs the application level utility . for voice this utility impairment is twofold on one hand , even short bursts of lost packets may decrease significantly the ability of the receiver to conceal the packet loss and the speech signal playout is interrupted . on the other hand , some packets may be particular sensitive to loss as they carry more important information in terms of user perception than other packets . we first develop an end to end model based on loss runlengths with which we can describe the loss distribution within a flow . these packet level metrics are then linked to user level objective speech quality metrics . using this framework , we find that for low compressing sample based codecs ( pcm ) with loss concealment isolated packet losses can be concealed well , whereas burst losses have a higher perceptual impact . for high compressing frame based codecs ( g . [digit] ) on one hand the impact of loss is amplified through error propagation caused by the decoder filter memories , though on the other hand such coding schemes help to perform loss concealment by extrapolation of decoder state . contrary to sample based codecs we show that the concealment performance may break at transitions within the speech signal however . we then propose mechanisms which differentiate between packets within a voice data flow to minimize the impact of packet loss . we designate these methods as intra flow loss recovery and control . at the end to end level , identification of packets sensitive to loss ( sender ) as well as loss concealment ( receiver ) takes place . hop by hop support schemes then allow to ( statistically ) trade the loss of one packet , which is considered more important , against another one of the same flow which is of lower importance . as both packets require the same cost in terms of network transmission , a gain in user perception is obtainable . we show that significant speech quality improvements can be achieved and additional data and delay overhead can be avoided while still maintaining a network service which is virtually identical to best effort in the long term . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems distributed applications ( [digit] . [digit] . [digit] computer communication networks internetworking routers c . [digit] computer systems organization performance of systems <unk> techniques c . [digit] computer systems organization performance of systems modeling techniques general terms design , measurement , performance , reliability"}, "present_kps": {"text": ["loss recoveri and control", "end to end model", "packet level metric", "sampl base codec", "loss conceal", "frame base codec"], "tokenized": ["loss recoveri and control", "end to end model", "packet level metric", "sampl base codec", "loss conceal", "frame base codec"]}, "absent_kps": {"text": ["loss sensit", "object speech qualiti measur", "loss metric", "voic over ip", "queue manag algorithm", "sensit of voip traffic voip traffic sensit", "queue manag", "intra flow loss control", "voip traffic", "end to end loss recoveri", "qualiti of servic servic qualiti", "network support for real time multimedia", "gener markov model", "differenti servic"], "tokenized": ["loss sensit", "object speech qualiti measur", "loss metric", "voic over ip", "queue manag algorithm", "sensit of voip traffic voip traffic sensit", "queue manag", "intra flow loss control", "voip traffic", "end to end loss recoveri", "qualiti of servic servic qualiti", "network support for real time multimedia", "gener markov model", "differenti servic"]}}
{"id": 3, "title": {"text": "design and implementation of a distributed content management system .", "tokenized": "design and implementation of a distributed content management system ."}, "abstract": {"text": "the convergence of advances in storage , encoding , and networking technologies has brought us to an environment where huge amounts of continuous media content is routinely stored and exchanged between network enabled devices . keeping track of ( or managing ) such content remains challenging due to the sheer volume of data . storing live continuous media ( such as tv or radio content ) adds to the complexity in that this content has no well defined start or end and is therefore cumbersome to deal with . networked storage allows content that is logically viewed as part of the same collection to in fact be distributed across a network , making the task of content management all but impossible to deal with without a content management system . in this paper we present the design and implementation of the spectrum content management system , which deals with rich media content effectively in this environment . spectrum has a modular architecture that allows its application to both stand alone and various networked scenarios . a unique aspect of spectrum is that it requires one ( or more ) retention policies to apply to every piece of content that is stored in the system . this means that there are no eviction policies . content that no longer has a retention policy applied to it is simply removed from the system . different retention policies can easily be applied to the same content thus naturally facilitating sharing without duplication . this approach also allows spectrum to easily apply time based policies which are basic building blocks required to deal with the storage of live continuous media , to content . we not only describe the details of the spectrum architecture but also give typical use cases . categories and subject descriptors c . [digit] . [digit] computer systems organization computer communication networks distributed systems h . [digit] . [digit] information systems information storage and retrieval systems and software general terms design , management", "tokenized": "the convergence of advances in storage , encoding , and networking technologies has brought us to an environment where huge amounts of continuous media content is routinely stored and exchanged between network enabled devices . keeping track of ( or managing ) such content remains challenging due to the sheer volume of data . storing live continuous media ( such as tv or radio content ) adds to the complexity in that this content has no well defined start or end and is therefore cumbersome to deal with . networked storage allows content that is logically viewed as part of the same collection to in fact be distributed across a network , making the task of content management all but impossible to deal with without a content management system . in this paper we present the design and implementation of the spectrum content management system , which deals with rich media content effectively in this environment . spectrum has a modular architecture that allows its application to both stand alone and various networked scenarios . a unique aspect of spectrum is that it requires one ( or more ) retention policies to apply to every piece of content that is stored in the system . this means that there are no eviction policies . content that no longer has a retention policy applied to it is simply removed from the system . different retention policies can easily be applied to the same content thus naturally facilitating sharing without duplication . this approach also allows spectrum to easily apply time based policies which are basic building blocks required to deal with the storage of live continuous media , to content . we not only describe the details of the spectrum architecture but also give typical use cases . categories and subject descriptors c . [digit] . [digit] computer systems organization computer communication networks distributed systems h . [digit] . [digit] information systems information storage and retrieval systems and software general terms design , management"}, "present_kps": {"text": ["distribut content manag", "spectrum content manag system"], "tokenized": ["distribut content manag", "spectrum content manag system"]}, "absent_kps": {"text": ["continu media storag", "home network scenario", "applic program interfac", "content distribut network", "uniform resourc locat", "polici manag", "network enabl dvr", "high perform databas system", "carrier grade spectrum manag"], "tokenized": ["continu media storag", "home network scenario", "applic program interfac", "content distribut network", "uniform resourc locat", "polici manag", "network enabl dvr", "high perform databas system", "carrier grade spectrum manag"]}}
{"id": 4, "title": {"text": "operation context and context based operational transformation .", "tokenized": "operation context and context based operational transformation ."}, "abstract": {"text": "operational transformation ( ot ) is a technique for consistency maintenance and group undo , and is being applied to an increasing number of collaborative applications . the theoretical foundation for ot is crucial in determining its capability to solve existing and new problems , as well as the quality of those solutions . the theory of causality has been the foundation of all prior ot systems , but it is inadequate to capture essential correctness requirements . past research had invented various patches to work around this problem , resulting in increasingly intricate and complicated ot algorithms . after having designed , implemented , and experimented with a series of ot algorithms , we reflected on what had been learned and set out to develop a new theoretical framework for better understanding and resolving ot problems , reducing its complexity , and supporting its continual evolution . in this paper , we report the main results of this effort the theory of operation context and the cot ( context based ot ) algorithm . the cot algorithm is capable of supporting both do and undo of any operations at anytime , without requiring transformation functions to preserve reversibility property , convergence property [digit] , inverse properties [digit] and [digit] . the cot algorithm is not only simpler and more efficient than prior ot control algorithms , but also simplifies the design of transformation functions . we have implemented the cot algorithm in a generic collaboration engine and used it for supporting a range of novel collaborative applications . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems distributed applications h . [digit] . [digit] information interfaces and presentation group and organization interfaces collaborative computing synchronous interaction general terms algorithms , design , theory", "tokenized": "operational transformation ( ot ) is a technique for consistency maintenance and group undo , and is being applied to an increasing number of collaborative applications . the theoretical foundation for ot is crucial in determining its capability to solve existing and new problems , as well as the quality of those solutions . the theory of causality has been the foundation of all prior ot systems , but it is inadequate to capture essential correctness requirements . past research had invented various patches to work around this problem , resulting in increasingly intricate and complicated ot algorithms . after having designed , implemented , and experimented with a series of ot algorithms , we reflected on what had been learned and set out to develop a new theoretical framework for better understanding and resolving ot problems , reducing its complexity , and supporting its continual evolution . in this paper , we report the main results of this effort the theory of operation context and the cot ( context based ot ) algorithm . the cot algorithm is capable of supporting both do and undo of any operations at anytime , without requiring transformation functions to preserve reversibility property , convergence property [digit] , inverse properties [digit] and [digit] . the cot algorithm is not only simpler and more efficient than prior ot control algorithms , but also simplifies the design of transformation functions . we have implemented the cot algorithm in a generic collaboration engine and used it for supporting a range of novel collaborative applications . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems distributed applications h . [digit] . [digit] information interfaces and presentation group and organization interfaces collaborative computing synchronous interaction general terms algorithms , design , theory"}, "present_kps": {"text": ["oper context", "oper transform", "ot", "consist mainten", "undo", "cot", "context base ot", "context base ot", "distribut applic"], "tokenized": ["oper context", "oper transform", "ot", "consist mainten", "undo", "cot", "context base ot", "context base ot", "distribut applic"]}, "absent_kps": {"text": ["transform oper", "group editor", "vector represent of oper context oper context vector represent", "histori buffer", "exclus transform", "document state", "invers oper", "concurr relat", "concurr condit", "causal depend", "origin oper", "invers cluster"], "tokenized": ["transform oper", "group editor", "vector represent of oper context oper context vector represent", "histori buffer", "exclus transform", "document state", "invers oper", "concurr relat", "concurr condit", "causal depend", "origin oper", "invers cluster"]}}
{"id": 5, "title": {"text": "edas providing an environment for decentralized adaptive services .", "tokenized": "edas providing an environment for decentralized adaptive services ."}, "abstract": {"text": "as the idea of virtualisation of compute power , storage and bandwidth becomes more and more important , grid computing evolves and is applied to a rising number of applications . the environment for decentralized adaptive services ( edas ) provides a grid like infrastructure for user accessed , longterm services ( e . g . webserver , source code repository etc . ) . it aims at supporting the autonomous execution and evolution of services in terms of scalability and resource aware distribution . edas offers flexible service models based on distributed mobile objects ranging from a traditional clientserver scenario to a fully peer to peer based approach . automatic , dynamic resource management allows optimized use of available resources while minimizing the administrative complexity . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems distributed applications d . [digit] . 12b software software engineering interoperability distributed objects general terms design , management", "tokenized": "as the idea of virtualisation of compute power , storage and bandwidth becomes more and more important , grid computing evolves and is applied to a rising number of applications . the environment for decentralized adaptive services ( edas ) provides a grid like infrastructure for user accessed , longterm services ( e . g . webserver , source code repository etc . ) . it aims at supporting the autonomous execution and evolution of services in terms of scalability and resource aware distribution . edas offers flexible service models based on distributed mobile objects ranging from a traditional clientserver scenario to a fully peer to peer based approach . automatic , dynamic resource management allows optimized use of available resources while minimizing the administrative complexity . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems distributed applications d . [digit] . 12b software software engineering interoperability distributed objects general terms design , management"}, "present_kps": {"text": ["eda", "decentr adapt servic", "adapt", "grid comput", "infrastructur", "resourc", "resourc manag"], "tokenized": ["eda", "decentr adapt servic", "adapt", "grid comput", "infrastructur", "resourc", "resourc manag"]}, "absent_kps": {"text": ["home environ", "client", "long term servic", "local limit", "global limit", "node", "fragment object"], "tokenized": ["home environ", "client", "long term servic", "local limit", "global limit", "node", "fragment object"]}}
{"id": 6, "title": {"text": "sensor deployment strategy for target detection .", "tokenized": "sensor deployment strategy for target detection ."}, "abstract": {"text": "in order to monitor a region for traffic traversal , sensors can be deployed to perform collaborative target detection . such a sensor network achieves a certain level of detection performance with an associated cost of deployment . this paper addresses this problem by proposing path exposure as a measure of the goodness of a deployment and presents an approach for sequential deployment in steps . it illustrates that the cost of deployment can be minimized to achieve the desired detection performance by appropriately choosing the number of sensors deployed in each step . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems distributed applications c . [digit] special purpose and application based systems signal processing systems general terms algorithms , design , performance", "tokenized": "in order to monitor a region for traffic traversal , sensors can be deployed to perform collaborative target detection . such a sensor network achieves a certain level of detection performance with an associated cost of deployment . this paper addresses this problem by proposing path exposure as a measure of the goodness of a deployment and presents an approach for sequential deployment in steps . it illustrates that the cost of deployment can be minimized to achieve the desired detection performance by appropriately choosing the number of sensors deployed in each step . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems distributed applications c . [digit] special purpose and application based systems signal processing systems general terms algorithms , design , performance"}, "present_kps": {"text": ["deploy", "target detect", "collabor target detect", "sensor network", "path exposur", "exposur", "sequenti deploy"], "tokenized": ["deploy", "target detect", "collabor target detect", "sensor network", "path exposur", "exposur", "sequenti deploy"]}, "absent_kps": {"text": ["number of sensor sensor number", "minimum exposur", "random sensor placement", "sensor field", "target decai", "valu fusion"], "tokenized": ["number of sensor sensor number", "minimum exposur", "random sensor placement", "sensor field", "target decai", "valu fusion"]}}
{"id": 7, "title": {"text": "deployment issues of a voip conferencing system in a virtual conferencing environment .", "tokenized": "deployment issues of a voip conferencing system in a virtual conferencing environment ."}, "abstract": {"text": "real time services have been supported by and large on circuitswitched networks . recent trends favour services ported on packet switched networks . for audio conferencing , we need to consider many issues scalability , quality of the conference application , floor control and load on the clients servers to name a few . in this paper , we describe an audio service framework designed to provide a virtual conferencing environment ( vce ) . the system is designed to accommodate a large number of end users speaking at the same time and spread across the internet . the framework is based on conference servers [digit] , which facilitate the audio handling , while we exploit the sip capabilities for signaling purposes . client selection is based on a recent quantifier called loudness number that helps mimic a physical face to face conference . we deal with deployment issues of the proposed solution both in terms of scalability and interactivity , while explaining the techniques we use to reduce the traffic . we have implemented a conference server ( cs ) application on a campus wide network at our institute . categories and subjects descriptors c . [digit] . [digit] computer communication networks distributed systems client server , distributed applications . general terms algorithms , performance , design , theory .", "tokenized": "real time services have been supported by and large on circuitswitched networks . recent trends favour services ported on packet switched networks . for audio conferencing , we need to consider many issues scalability , quality of the conference application , floor control and load on the clients servers to name a few . in this paper , we describe an audio service framework designed to provide a virtual conferencing environment ( vce ) . the system is designed to accommodate a large number of end users speaking at the same time and spread across the internet . the framework is based on conference servers [digit] , which facilitate the audio handling , while we exploit the sip capabilities for signaling purposes . client selection is based on a recent quantifier called loudness number that helps mimic a physical face to face conference . we deal with deployment issues of the proposed solution both in terms of scalability and interactivity , while explaining the techniques we use to reduce the traffic . we have implemented a conference server ( cs ) application on a campus wide network at our institute . categories and subjects descriptors c . [digit] . [digit] computer communication networks distributed systems client server , distributed applications . general terms algorithms , performance , design , theory ."}, "present_kps": {"text": ["voip conferenc system", "voip", "virtual conferenc environ", "packet switch network", "audio servic framework", "vce", "confer server", "sip", "loud number"], "tokenized": ["voip conferenc system", "voip", "virtual conferenc environ", "packet switch network", "audio servic framework", "vce", "confer server", "sip", "loud number"]}, "absent_kps": {"text": ["partial mix", "voic activ detect", "suffici of three simultan speaker three simultan speaker suffici", "vad techniqu", "real time audio", "simultan speaker"], "tokenized": ["partial mix", "voic activ detect", "suffici of three simultan speaker three simultan speaker suffici", "vad techniqu", "real time audio", "simultan speaker"]}}
{"id": 8, "title": {"text": "an initial analysis and presentation of malware exhibiting swarm like behavior .", "tokenized": "an initial analysis and presentation of malware exhibiting swarm like behavior ."}, "abstract": {"text": "the slammer , which is currently the fastest computer worm in recorded history , was observed to infect [digit] percent of all vulnerable internets hosts within [digit] minutes . although the main action that the slammer worm takes is a relatively unsophisticated replication of itself , it still spreads so quickly that human response was ineffective . most proposed countermeasures strategies are based primarily on rate detection and limiting algorithms . however , such strategies are being designed and developed to effectively contain worms whose behaviors are similar to that of slammer . in our work , we put forth the hypothesis that next generation worms will be radically different , and potentially such techniques will prove ineffective . specifically , we propose to study a new generation of worms called swarm worms , whose behavior is predicated on the concept of emergent intelligence . emergent intelligence is the behavior of systems , very much like biological systems such as ants or bees , where simple local interactions of autonomous members , with simple primitive actions , gives rise to complex and intelligent global behavior . in this manuscript we will introduce the basic principles behind the idea of swarm worms , as well as the basic structure required in order to be considered a swarm worm . in addition , we will present preliminary results on the propagation speeds of one such swarm worm , called the zachik worm . we will show that zachik is capable of propagating at a rate [digit] orders of magnitude faster than similar worms without swarm capabilities . categories and subject descriptors c . [digit] . [digit] distributed systems intrusion detection d . [digit] . [digit] security and protection invasive software general terms experimentation , security", "tokenized": "the slammer , which is currently the fastest computer worm in recorded history , was observed to infect [digit] percent of all vulnerable internets hosts within [digit] minutes . although the main action that the slammer worm takes is a relatively unsophisticated replication of itself , it still spreads so quickly that human response was ineffective . most proposed countermeasures strategies are based primarily on rate detection and limiting algorithms . however , such strategies are being designed and developed to effectively contain worms whose behaviors are similar to that of slammer . in our work , we put forth the hypothesis that next generation worms will be radically different , and potentially such techniques will prove ineffective . specifically , we propose to study a new generation of worms called swarm worms , whose behavior is predicated on the concept of emergent intelligence . emergent intelligence is the behavior of systems , very much like biological systems such as ants or bees , where simple local interactions of autonomous members , with simple primitive actions , gives rise to complex and intelligent global behavior . in this manuscript we will introduce the basic principles behind the idea of swarm worms , as well as the basic structure required in order to be considered a swarm worm . in addition , we will present preliminary results on the propagation speeds of one such swarm worm , called the zachik worm . we will show that zachik is capable of propagating at a rate [digit] orders of magnitude faster than similar worms without swarm capabilities . categories and subject descriptors c . [digit] . [digit] distributed systems intrusion detection d . [digit] . [digit] security and protection invasive software general terms experimentation , security"}, "present_kps": {"text": ["malwar", "slammer worm", "swarm worm", "emerg intellig", "zachik"], "tokenized": ["malwar", "slammer worm", "swarm worm", "emerg intellig", "zachik"]}, "absent_kps": {"text": ["local commun mechan", "prng method", "pre gener target list", "distribut intellig", "intrus detect", "countermeasur system", "emerg behavior", "internet worm", "swarm intellig"], "tokenized": ["local commun mechan", "prng method", "pre gener target list", "distribut intellig", "intrus detect", "countermeasur system", "emerg behavior", "internet worm", "swarm intellig"]}}
{"id": 9, "title": {"text": "service interface a new abstraction for implementing and composing protocols .", "tokenized": "service interface a new abstraction for implementing and composing protocols ."}, "abstract": {"text": "in this paper we compare two approaches to the design of protocol frameworks tools for implementing modular network protocols . the most common approach uses events as the main abstraction for a local interaction between protocol modules . we argue that an alternative approach , that is based on service abstraction , is more suitable for expressing modular protocols . it also facilitates advanced features in the design of protocols , such as dynamic update of distributed protocols . we then describe an experimental implementation of a service based protocol framework in java . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed applications", "tokenized": "in this paper we compare two approaches to the design of protocol frameworks tools for implementing modular network protocols . the most common approach uses events as the main abstraction for a local interaction between protocol modules . we argue that an alternative approach , that is based on service abstraction , is more suitable for expressing modular protocols . it also facilitates advanced features in the design of protocols , such as dynamic update of distributed protocols . we then describe an experimental implementation of a service based protocol framework in java . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed applications"}, "present_kps": {"text": ["servic interfac", "protocol framework", "modular", "network", "modul", "commun"], "tokenized": ["servic interfac", "protocol framework", "modular", "network", "modul", "commun"]}, "absent_kps": {"text": ["distribut algorithm", "distribut system", "event base framework", "stack", "request", "repli", "dynam protocol replac"], "tokenized": ["distribut algorithm", "distribut system", "event base framework", "stack", "request", "repli", "dynam protocol replac"]}}
{"id": 10, "title": {"text": "live data center migration across wans a robust cooperative context aware approach .", "tokenized": "live data center migration across wans a robust cooperative context aware approach ."}, "abstract": {"text": "a significant concern for internet based service providers is the continued operation and availability of services in the face of outages , whether planned or unplanned . in this paper we advocate a cooperative , context aware approach to data center migration across wans to deal with outages in a non disruptive manner . we specifically seek to achieve high availability of data center services in the face of both planned and unanticipated outages of data center facilities . we make use of server virtualization technologies to enable the replication and migration of server functions . we propose new network functions to enable server migration and replication across wide area networks ( e . g . , the internet ) , and finally show the utility of intelligent and dynamic storage replication technology to ensure applications have access to data in the face of outages with very tight recovery point objectives . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems general terms design , reliability", "tokenized": "a significant concern for internet based service providers is the continued operation and availability of services in the face of outages , whether planned or unplanned . in this paper we advocate a cooperative , context aware approach to data center migration across wans to deal with outages in a non disruptive manner . we specifically seek to achieve high availability of data center services in the face of both planned and unanticipated outages of data center facilities . we make use of server virtualization technologies to enable the replication and migration of server functions . we propose new network functions to enable server migration and replication across wide area networks ( e . g . , the internet ) , and finally show the utility of intelligent and dynamic storage replication technology to ensure applications have access to data in the face of outages with very tight recovery point objectives . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems general terms design , reliability"}, "present_kps": {"text": ["data center migrat", "wan", "internet base servic", "storag replic", "storag"], "tokenized": ["data center migrat", "wan", "internet base servic", "storag replic", "storag"]}, "absent_kps": {"text": ["lan", "virtual server", "synchron replic", "asynchron replic", "network support", "voic over ip", "voip", "databas"], "tokenized": ["lan", "virtual server", "synchron replic", "asynchron replic", "network support", "voic over ip", "voip", "databas"]}}
{"id": 11, "title": {"text": "runtime metrics collection for middleware supported adaptation of mobile applications .", "tokenized": "runtime metrics collection for middleware supported adaptation of mobile applications ."}, "abstract": {"text": "this paper proposes , implements , and evaluates in terms of worst case performance , an online metrics collection strategy to facilitate application adaptation via object mobility using a mobile object framework and supporting middleware . the solution is based upon an abstract representation of the mobile object system , which holds containers aggregating metrics for each specific component including host managers , runtimes and mobile objects . a key feature of the solution is the specification of multiple configurable criteria to control the measurement and propagation of metrics through the system . the mobjex platform was used as the basis for implementation and testing with a number of laboratory tests conducted to measure scalability , efficiency and the application of simple measurement and propagation criteria to reduce collection overhead . categories and subject descriptors c . [digit] . [digit] distributed systems d . [digit] . [digit] metrics general terms measurement , performance .", "tokenized": "this paper proposes , implements , and evaluates in terms of worst case performance , an online metrics collection strategy to facilitate application adaptation via object mobility using a mobile object framework and supporting middleware . the solution is based upon an abstract representation of the mobile object system , which holds containers aggregating metrics for each specific component including host managers , runtimes and mobile objects . a key feature of the solution is the specification of multiple configurable criteria to control the measurement and propagation of metrics through the system . the mobjex platform was used as the basis for implementation and testing with a number of laboratory tests conducted to measure scalability , efficiency and the application of simple measurement and propagation criteria to reduce collection overhead . categories and subject descriptors c . [digit] . [digit] distributed systems d . [digit] . [digit] metrics general terms measurement , performance ."}, "present_kps": {"text": ["metric collect", "adapt", "mobil object framework", "mobil object", "framework", "measur", "mobjex"], "tokenized": ["metric collect", "adapt", "mobil object framework", "mobil object", "framework", "measur", "mobjex"]}, "absent_kps": {"text": ["data", "object orient applic", "java", "metricscontain", "proxi", "perform and scalabl", "propag and deliveri"], "tokenized": ["data", "object orient applic", "java", "metricscontain", "proxi", "perform and scalabl", "propag and deliveri"]}}
{"id": 12, "title": {"text": "implementation of a dynamic adjustment mechanism with efficient replica selection in data grid environments .", "tokenized": "implementation of a dynamic adjustment mechanism with efficient replica selection in data grid environments ."}, "abstract": {"text": "the co allocation architecture was developed in order to enable parallel downloading of datasets from multiple servers . several co allocation strategies have been coupled and used to exploit rate differences among various client server links and to address dynamic rate fluctuations by dividing files into multiple blocks of equal sizes . however , a major obstacle , the idle time of faster servers having to wait for the slowest server to deliver the final block , makes it important to reduce differences in finishing time among replica servers . in this paper , we propose a dynamic coallocation scheme , namely recursive adjustment co allocation scheme , to improve the performance of data transfer in data grids . our approach reduces the idle time spent waiting for the slowest server and decreases data transfer completion time . we also provide an effective scheme for reducing the cost of reassembling data blocks . categories and subject descriptors c . [digit] . [digit] distributed systems distributed applications . h . [digit] . [digit] online information services data sharing , web based services . general terms management , performance , design , experimentation .", "tokenized": "the co allocation architecture was developed in order to enable parallel downloading of datasets from multiple servers . several co allocation strategies have been coupled and used to exploit rate differences among various client server links and to address dynamic rate fluctuations by dividing files into multiple blocks of equal sizes . however , a major obstacle , the idle time of faster servers having to wait for the slowest server to deliver the final block , makes it important to reduce differences in finishing time among replica servers . in this paper , we propose a dynamic coallocation scheme , namely recursive adjustment co allocation scheme , to improve the performance of data transfer in data grids . our approach reduces the idle time spent waiting for the slowest server and decreases data transfer completion time . we also provide an effective scheme for reducing the cost of reassembling data blocks . categories and subject descriptors c . [digit] . [digit] distributed systems distributed applications . h . [digit] . [digit] online information services data sharing , web based services . general terms management , performance , design , experimentation ."}, "present_kps": {"text": ["replica", "replica select", "data grid", "co alloc", "server", "co alloc strategi", "perform", "data transfer"], "tokenized": ["replica", "replica select", "data grid", "co alloc", "server", "co alloc strategi", "perform", "data transfer"]}, "absent_kps": {"text": ["distribut resourc", "data grid applic", "replic", "larg dataset", "resourc manag protocol", "grid comput", "globu", "gridftp"], "tokenized": ["distribut resourc", "data grid applic", "replic", "larg dataset", "resourc manag protocol", "grid comput", "globu", "gridftp"]}}
{"id": 13, "title": {"text": "a high accuracy , low cost localization system for wireless sensor networks .", "tokenized": "a high accuracy , low cost localization system for wireless sensor networks ."}, "abstract": {"text": "the problem of localization of wireless sensor nodes has long been regarded as very difficult to solve , when considering the realities of real world environments . in this paper , we formally describe , design , implement and evaluate a novel localization system , called spotlight . our system uses the spatio temporal properties of well controlled events in the network ( e . g . , light ) , to obtain the locations of sensor nodes . we demonstrate that a high accuracy in localization can be achieved without the aid of expensive hardware on the sensor nodes , as required by other localization systems . we evaluate the performance of our system in deployments of mica2 and xsm motes . through performance evaluations of a real system deployed outdoors , we obtain a [digit] cm localization error . a sensor network , with any number of nodes , deployed in a 2500m2 area , can be localized in under [digit] minutes , using a device that costs less than [digit] . to the best of our knowledge , this is the first report of a sub meter localization error , obtained in an outdoor environment , without equipping the wireless sensor nodes with specialized ranging hardware . categories and subject descriptors c . [digit] . [digit] computer communications networks distributed systems c . [digit] special purpose and application based systems real time and embedded systems . general terms algorithms , measurement , performance , design , experimentation", "tokenized": "the problem of localization of wireless sensor nodes has long been regarded as very difficult to solve , when considering the realities of real world environments . in this paper , we formally describe , design , implement and evaluate a novel localization system , called spotlight . our system uses the spatio temporal properties of well controlled events in the network ( e . g . , light ) , to obtain the locations of sensor nodes . we demonstrate that a high accuracy in localization can be achieved without the aid of expensive hardware on the sensor nodes , as required by other localization systems . we evaluate the performance of our system in deployments of mica2 and xsm motes . through performance evaluations of a real system deployed outdoors , we obtain a [digit] cm localization error . a sensor network , with any number of nodes , deployed in a 2500m2 area , can be localized in under [digit] minutes , using a device that costs less than [digit] . to the best of our knowledge , this is the first report of a sub meter localization error , obtained in an outdoor environment , without equipping the wireless sensor nodes with specialized ranging hardware . categories and subject descriptors c . [digit] . [digit] computer communications networks distributed systems c . [digit] special purpose and application based systems real time and embedded systems . general terms algorithms , measurement , performance , design , experimentation"}, "present_kps": {"text": ["accuraci", "local", "wireless sensor network", "sensor network", "perform", "local error", "distribut"], "tokenized": ["accuraci", "local", "wireless sensor network", "sensor network", "perform", "local error", "distribut"]}, "absent_kps": {"text": ["rang base local", "rang free scheme", "transmiss", "spotlight system", "local techniqu", "event distribut", "laser"], "tokenized": ["rang base local", "rang free scheme", "transmiss", "spotlight system", "local techniqu", "event distribut", "laser"]}}
{"id": 14, "title": {"text": "packageblast an adaptive multi policy grid service for biological sequence comparison .", "tokenized": "packageblast an adaptive multi policy grid service for biological sequence comparison ."}, "abstract": {"text": "in this paper , we propose an adaptive task allocation framework to perform blast searches in a grid environment against sequence database segments . the framework , called packageblast , provides an infrastructure to choose or incorporate task allocation strategies . furthermore , we propose a mechanism to compute grid nodes execution weight , adapting the chosen allocation policy to the current computational power of the nodes . our results present very good speedups and also show that no single allocation strategy is able to achieve the lowest execution times for all scenarios . categories and subject descriptors c . [digit] . [digit] distributed systems distributed applications j . [digit] life and medical sciences biology and genetics", "tokenized": "in this paper , we propose an adaptive task allocation framework to perform blast searches in a grid environment against sequence database segments . the framework , called packageblast , provides an infrastructure to choose or incorporate task allocation strategies . furthermore , we propose a mechanism to compute grid nodes execution weight , adapting the chosen allocation policy to the current computational power of the nodes . our results present very good speedups and also show that no single allocation strategy is able to achieve the lowest execution times for all scenarios . categories and subject descriptors c . [digit] . [digit] distributed systems distributed applications j . [digit] life and medical sciences biology and genetics"}, "present_kps": {"text": ["packageblast", "adapt multi polici grid servic", "biolog sequenc comparison", "task alloc", "blast search", "grid environ"], "tokenized": ["packageblast", "adapt multi polici grid servic", "biolog sequenc comparison", "task alloc", "blast search", "grid environ"]}, "absent_kps": {"text": ["bioinformat", "grid comput", "comput biologi", "genom project", "segment genet databas", "heterogen non dedic platform", "pss", "packag weight adapt self schedul"], "tokenized": ["bioinformat", "grid comput", "comput biologi", "genom project", "segment genet databas", "heterogen non dedic platform", "pss", "packag weight adapt self schedul"]}}
{"id": 15, "title": {"text": "implementation and performance evaluation of conflex g grid enabled molecular conformational space search program with omnirpc .", "tokenized": "implementation and performance evaluation of conflex g grid enabled molecular conformational space search program with omnirpc ."}, "abstract": {"text": "conflex g is the grid enabled version of a molecular conformational space search program called conflex . we have implemented conflex g using a grid rpc system called omnirpc . in this paper , we report the performance of conflex g in a grid testbed of several geographically distributed pc clusters . in order to explore many conformation of large bio molecules , conflex g generates trial structures of the molecules and allocates jobs to optimize a trial structure with a reliable molecular mechanics method in the grid . omnirpc provides a restricted persistence model to support the parametric search applications . in this model , when the initialization procedure is defined in the rpc module , the module is automatically initialized at the time of invocation by calling the initialization procedure . this can eliminate unnecessary communication and initialization at each call in conflex g . <unk> can achieve performance comparable to conflex mpi and can exploit more computing resources by allowing the use of a cluster of multiple clusters in the grid . the experimental result shows that conflex g achieved a speedup of [digit] . [digit] times in the case of the <unk> molecule , where the molecule consists of a large number of atoms , and each trial structure optimization requires significant time . the load imbalance of the optimization time of the trial structure may also cause performance degradation . categories and subject descriptors c . [digit] . [digit] computer systems organization <unk> network distributed systems j . [digit] . [digit] computer applications physical sciences and engineering general terms design , performance", "tokenized": "conflex g is the grid enabled version of a molecular conformational space search program called conflex . we have implemented conflex g using a grid rpc system called omnirpc . in this paper , we report the performance of conflex g in a grid testbed of several geographically distributed pc clusters . in order to explore many conformation of large bio molecules , conflex g generates trial structures of the molecules and allocates jobs to optimize a trial structure with a reliable molecular mechanics method in the grid . omnirpc provides a restricted persistence model to support the parametric search applications . in this model , when the initialization procedure is defined in the rpc module , the module is automatically initialized at the time of invocation by calling the initialization procedure . this can eliminate unnecessary communication and initialization at each call in conflex g . <unk> can achieve performance comparable to conflex mpi and can exploit more computing resources by allowing the use of a cluster of multiple clusters in the grid . the experimental result shows that conflex g achieved a speedup of [digit] . [digit] times in the case of the <unk> molecule , where the molecule consists of a large number of atoms , and each trial structure optimization requires significant time . the load imbalance of the optimization time of the trial structure may also cause performance degradation . categories and subject descriptors c . [digit] . [digit] computer systems organization <unk> network distributed systems j . [digit] . [digit] computer applications physical sciences and engineering general terms design , performance"}, "present_kps": {"text": ["conflex g", "conform space search", "omnirpc", "grid rpc system", "pc cluster", "bio molecul", "molecular mechan", "initi procedur", "rpc modul"], "tokenized": ["conflex g", "conform space search", "omnirpc", "grid rpc system", "pc cluster", "bio molecul", "molecular mechan", "initi procedur", "rpc modul"]}, "absent_kps": {"text": ["mpu", "grid comput", "automat initializ modul", "comput chemistri"], "tokenized": ["mpu", "grid comput", "automat initializ modul", "comput chemistri"]}}
{"id": 16, "title": {"text": "bullet high bandwidth data dissemination using an overlay mesh .", "tokenized": "bullet high bandwidth data dissemination using an overlay mesh ."}, "abstract": {"text": "in recent years , overlay networks have become an effective alternative to ip multicast for efficient point to multipoint communication across the internet . typically , nodes self organize with the goal of forming an efficient overlay tree , one that meets performance targets without placing undue burden on the underlying network . in this paper , we target high bandwidth data distribution from a single source to a large number of receivers . applications include large file transfers and real time multimedia streaming . for these applications , we argue that an overlay mesh , rather than a tree , can deliver fundamentally higher bandwidth and reliability relative to typical tree structures . this paper presents bullet , a scalable and distributed algorithm that enables nodes spread across the internet to self organize into a high bandwidth overlay mesh . we construct bullet around the insight that data should be distributed in a disjoint manner to strategic points in the network . individual bullet receivers are then responsible for locating and retrieving the data from multiple points in parallel . key contributions of this work include i ) an algorithm that sends data to different points in the overlay such that any data object is equally likely to appear at any node , ii ) a scalable and decentralized algorithm that allows nodes to locate and recover missing data items , and iii ) a complete implementation and evaluation of bullet running across the internet and in a large scale emulation environment reveals up to a factor two bandwidth improvements under a variety of circumstances . in addition , we find that , relative to tree based solutions , bullet reduces the need to perform expensive bandwidth probing . in a tree , it is critical that a node s parent delivers a high rate of application data to each child . in bullet however , nodes simultaneously receive data from multiple sources in parallel , making it less important to locate any single source capable of sustaining a high transmission rate . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems h . [digit] . [digit] information systems applications communications applications general terms experimentation , management , performance", "tokenized": "in recent years , overlay networks have become an effective alternative to ip multicast for efficient point to multipoint communication across the internet . typically , nodes self organize with the goal of forming an efficient overlay tree , one that meets performance targets without placing undue burden on the underlying network . in this paper , we target high bandwidth data distribution from a single source to a large number of receivers . applications include large file transfers and real time multimedia streaming . for these applications , we argue that an overlay mesh , rather than a tree , can deliver fundamentally higher bandwidth and reliability relative to typical tree structures . this paper presents bullet , a scalable and distributed algorithm that enables nodes spread across the internet to self organize into a high bandwidth overlay mesh . we construct bullet around the insight that data should be distributed in a disjoint manner to strategic points in the network . individual bullet receivers are then responsible for locating and retrieving the data from multiple points in parallel . key contributions of this work include i ) an algorithm that sends data to different points in the overlay such that any data object is equally likely to appear at any node , ii ) a scalable and decentralized algorithm that allows nodes to locate and recover missing data items , and iii ) a complete implementation and evaluation of bullet running across the internet and in a large scale emulation environment reveals up to a factor two bandwidth improvements under a variety of circumstances . in addition , we find that , relative to tree based solutions , bullet reduces the need to perform expensive bandwidth probing . in a tree , it is critical that a node s parent delivers a high rate of application data to each child . in bullet however , nodes simultaneously receive data from multiple sources in parallel , making it less important to locate any single source capable of sustaining a high transmission rate . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems h . [digit] . [digit] information systems applications communications applications general terms experimentation , management , performance"}, "present_kps": {"text": ["bullet", "bandwidth", "data dissemin", "ip multicast", "multipoint commun", "high bandwidth data distribut", "larg file transfer", "real time multimedia stream", "bandwidth probe"], "tokenized": ["bullet", "bandwidth", "data dissemin", "ip multicast", "multipoint commun", "high bandwidth data distribut", "larg file transfer", "real time multimedia stream", "bandwidth probe"]}, "absent_kps": {"text": ["overlai mesh", "overlai network", "peer to peer", "ransub", "content deliveri", "tfrc", "overlai"], "tokenized": ["overlai mesh", "overlai network", "peer to peer", "ransub", "content deliveri", "tfrc", "overlai"]}}
{"id": 17, "title": {"text": "<unk> a distributed peer to peer file sharing system for intranets .", "tokenized": "<unk> a distributed peer to peer file sharing system for intranets ."}, "abstract": {"text": "many organizations are required to author documents for various purposes , and such documents may need to be accessible by all member of the organization . this access may be needed for editing or simply viewing a document . in some cases these documents are shared between authors , via email , to be edited . this can easily cause incorrect version to be sent or conflicts created between multiple users trying to make amendments to a document . there may even be multiple different documents in the process of being edited . the user may be required to search for a particular document , which some search tools such as google desktop may be a solution for local documents but will not find a document on another user s machine . another problem arises when a document is made available on a user s machine and that user is offline , in which case the document is no longer accessible . in this paper we present <unk> , a revolutionary distributed p2p file sharing system for intranets . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems distributed applications . general terms design , experimentation , performance .", "tokenized": "many organizations are required to author documents for various purposes , and such documents may need to be accessible by all member of the organization . this access may be needed for editing or simply viewing a document . in some cases these documents are shared between authors , via email , to be edited . this can easily cause incorrect version to be sent or conflicts created between multiple users trying to make amendments to a document . there may even be multiple different documents in the process of being edited . the user may be required to search for a particular document , which some search tools such as google desktop may be a solution for local documents but will not find a document on another user s machine . another problem arises when a document is made available on a user s machine and that user is offline , in which case the document is no longer accessible . in this paper we present <unk> , a revolutionary distributed p2p file sharing system for intranets . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems distributed applications . general terms design , experimentation , performance ."}, "present_kps": {"text": ["peer to peer", "file share system", "file share", "intranet", "author", "document", "p2p"], "tokenized": ["peer to peer", "file share system", "file share", "intranet", "author", "document", "p2p"]}, "absent_kps": {"text": ["apocrita", "jxta", "distribut index", "peer to peer distribut model", "idl queri", "index file", "incom file", "p2p search"], "tokenized": ["apocrita", "jxta", "distribut index", "peer to peer distribut model", "idl queri", "index file", "incom file", "p2p search"]}}
{"id": 18, "title": {"text": "buddycache high performance object storage for collaborative strong consistency applications in a wan .", "tokenized": "buddycache high performance object storage for collaborative strong consistency applications in a wan ."}, "abstract": {"text": "collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task . they require strong consistency for shared persistent data and efficient access to fine grained objects . these properties are difficult to provide in wide area networks because of high network latency . buddycache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong consistency applications in high latency network environments . the challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers . we have implemented a buddycache prototype and evaluated its performance . analytical results , confirmed by measurements of the buddycache prototype using the multiuser [digit] benchmark indicate that for typical internet latencies , e . g . ranging from [digit] to [digit] milliseconds round trip time to the storage server , peers using buddycache can reduce by up to [digit] % the latency of access to shared objects compared to accessing the remote servers directly . categories and subject descriptors c . [digit] . [digit] computer systems organization distributed systems general terms design , performance", "tokenized": "collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task . they require strong consistency for shared persistent data and efficient access to fine grained objects . these properties are difficult to provide in wide area networks because of high network latency . buddycache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong consistency applications in high latency network environments . the challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers . we have implemented a buddycache prototype and evaluated its performance . analytical results , confirmed by measurements of the buddycache prototype using the multiuser [digit] benchmark indicate that for typical internet latencies , e . g . ranging from [digit] to [digit] milliseconds round trip time to the storage server , peers using buddycache can reduce by up to [digit] % the latency of access to shared objects compared to accessing the remote servers directly . categories and subject descriptors c . [digit] . [digit] computer systems organization distributed systems general terms design , performance"}, "present_kps": {"text": ["buddycach", "collabor strong consist applic", "wide area network", "transact"], "tokenized": ["buddycach", "collabor strong consist applic", "wide area network", "transact"]}, "absent_kps": {"text": ["object storag system", "cooper web cach", "fine grain share", "fault toler properti", "domin perform cost", "optimist system", "peer fetch", "multi user oo7 benchmark", "cooper cach", "fine grain share", "fault toler"], "tokenized": ["object storag system", "cooper web cach", "fine grain share", "fault toler properti", "domin perform cost", "optimist system", "peer fetch", "multi user oo7 benchmark", "cooper cach", "fine grain share", "fault toler"]}}
{"id": 19, "title": {"text": "rewards based negotiation for providing context information .", "tokenized": "rewards based negotiation for providing context information ."}, "abstract": {"text": "how to provide appropriate context information is a challenging problem in context aware computing . most existing approaches use a centralized selection mechanism to decide which context information is appropriate . in this paper , we propose a novel approach based on negotiation with rewards to solving such problem . distributed context providers negotiate with each other to decide who can provide context and how they allocate proceeds . in order to support our approach , we have designed a concrete negotiation model with rewards . we also evaluate our approach and show that it indeed can choose an appropriate context provider and allocate the proceeds fairly . categories and subject descriptors c . [digit] . [digit] distributed systems distributed <unk> context information general terms context", "tokenized": "how to provide appropriate context information is a challenging problem in context aware computing . most existing approaches use a centralized selection mechanism to decide which context information is appropriate . in this paper , we propose a novel approach based on negotiation with rewards to solving such problem . distributed context providers negotiate with each other to decide who can provide context and how they allocate proceeds . in order to support our approach , we have designed a concrete negotiation model with rewards . we also evaluate our approach and show that it indeed can choose an appropriate context provider and allocate the proceeds fairly . categories and subject descriptors c . [digit] . [digit] distributed systems distributed <unk> context information general terms context"}, "present_kps": {"text": ["negoti", "context awar", "context awar comput", "context provid", "concret negoti model"], "tokenized": ["negoti", "context awar", "context awar comput", "context provid", "concret negoti model"]}, "absent_kps": {"text": ["distribut applic", "pervas comput", "reput", "qualiti of context context qualiti", "persuas argument"], "tokenized": ["distribut applic", "pervas comput", "reput", "qualiti of context context qualiti", "persuas argument"]}}
{"id": 20, "title": {"text": "researches on scheme of pairwise key establishment for <unk> networks .", "tokenized": "researches on scheme of pairwise key establishment for <unk> networks ."}, "abstract": {"text": "security schemes of pairwise key establishment , which enable sensors to communicate with each other securely , play a fundamental role in research on security issue in wireless sensor networks . a new kind of cluster deployed sensor networks distribution model is presented , and based on which , an innovative hierarchical hypercube model h ( k , u , m , v , n ) and the mapping relationship between cluster deployed sensor networks and the h ( k , u , m , v , n ) are proposed . by utilizing nice properties of h ( k , u , m , v , n ) model , a new general framework for pairwise key predistribution and a new pairwise key establishment algorithm are designed , which combines the idea of kdc ( key distribution center ) and polynomial pool schemes . furthermore , the working performance of the newly proposed pairwise key establishment algorithm is seriously inspected . theoretic analysis and experimental figures show that the new algorithm has better performance and provides higher possibilities for sensor to establish pairwise key , compared with previous related works . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems distributed applications . general terms security .", "tokenized": "security schemes of pairwise key establishment , which enable sensors to communicate with each other securely , play a fundamental role in research on security issue in wireless sensor networks . a new kind of cluster deployed sensor networks distribution model is presented , and based on which , an innovative hierarchical hypercube model h ( k , u , m , v , n ) and the mapping relationship between cluster deployed sensor networks and the h ( k , u , m , v , n ) are proposed . by utilizing nice properties of h ( k , u , m , v , n ) model , a new general framework for pairwise key predistribution and a new pairwise key establishment algorithm are designed , which combines the idea of kdc ( key distribution center ) and polynomial pool schemes . furthermore , the working performance of the newly proposed pairwise key establishment algorithm is seriously inspected . theoretic analysis and experimental figures show that the new algorithm has better performance and provides higher possibilities for sensor to establish pairwise key , compared with previous related works . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems distributed applications . general terms security ."}, "present_kps": {"text": ["secur", "sensor network", "hierarch hypercub model"], "tokenized": ["secur", "sensor network", "hierarch hypercub model"]}, "absent_kps": {"text": ["kei pool", "kei predistribut", "pairwis kei establish algorithm", "cluster base distribut model", "polynomi kei", "encrypt", "node code", "high fault toler", "pairwis kei"], "tokenized": ["kei pool", "kei predistribut", "pairwis kei establish algorithm", "cluster base distribut model", "polynomi kei", "encrypt", "node code", "high fault toler", "pairwis kei"]}}
{"id": 21, "title": {"text": "encryption enforced access control in dynamic multi domain publish subscribe networks .", "tokenized": "encryption enforced access control in dynamic multi domain publish subscribe networks ."}, "abstract": {"text": "publish subscribe systems provide an efficient , event based , wide area distributed communications infrastructure . large scale publish subscribe systems are likely to employ components of the event transport network owned by cooperating , but independent organisations . as the number of participants in the network increases , security becomes an increasing concern . this paper extends previous work to present and evaluate a secure multi domain publish subscribe infrastructure that supports and enforces fine grained access control over the individual attributes of event types . key refresh allows us to ensure forward and backward security when event brokers join and leave the network . we demonstrate that the time and space overheads can be minimised by careful consideration of encryption techniques , and by the use of caching to decrease unnecessary decryptions . we show that our approach has a smaller overall communication overhead than existing approaches for achieving the same degree of control over security in publish subscribe networks . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems distributed applications general terms security , performance", "tokenized": "publish subscribe systems provide an efficient , event based , wide area distributed communications infrastructure . large scale publish subscribe systems are likely to employ components of the event transport network owned by cooperating , but independent organisations . as the number of participants in the network increases , security becomes an increasing concern . this paper extends previous work to present and evaluate a secure multi domain publish subscribe infrastructure that supports and enforces fine grained access control over the individual attributes of event types . key refresh allows us to ensure forward and backward security when event brokers join and leave the network . we demonstrate that the time and space overheads can be minimised by careful consideration of encryption techniques , and by the use of caching to decrease unnecessary decryptions . we show that our approach has a smaller overall communication overhead than existing approaches for achieving the same degree of control over security in publish subscribe networks . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems distributed applications general terms security , performance"}, "present_kps": {"text": ["encrypt", "multi domain", "distribut system distribut applic", "perform"], "tokenized": ["encrypt", "multi domain", "distribut system distribut applic", "perform"]}, "absent_kps": {"text": ["secur publish subscrib system", "distribut access control", "multipl administr domain", "attribut encrypt", "overal commun overhead", "congest charg servic", "distribut access control", "administr domain"], "tokenized": ["secur publish subscrib system", "distribut access control", "multipl administr domain", "attribut encrypt", "overal commun overhead", "congest charg servic", "distribut access control", "administr domain"]}}
{"id": 22, "title": {"text": "a framework for architecting peer to peer receiver driven overlays .", "tokenized": "a framework for architecting peer to peer receiver driven overlays ."}, "abstract": {"text": "this paper presents a simple and scalable framework for architecting peer to peer overlays called peer to peer <unk> overlay ( or pro ) . pro is designed for non interactive streaming applications and its primary design goal is to maximize delivered bandwidth ( and thus delivered quality ) to peers with heterogeneous and asymmetric bandwidth . to achieve this goal , pro adopts a receiver driven approach where each receiver ( or participating peer ) ( i ) independently discovers other peers in the overlay through gossiping , and ( ii ) selfishly determines the best subset of parent peers through which to connect to the overlay to maximize its own delivered bandwidth . participating peers form an unstructured overlay which is inherently robust to high churn rate . furthermore , each receiver leverages congestion controlled bandwidth from its parents as implicit signal to detect and react to long term changes in network or overlay condition without any explicit coordination with other participating peers . independent parent selection by individual peers dynamically converge to an efficient overlay structure . categories and subject descriptors c . [digit] . [digit] <unk> networks distributed systems general terms design , measurement", "tokenized": "this paper presents a simple and scalable framework for architecting peer to peer overlays called peer to peer <unk> overlay ( or pro ) . pro is designed for non interactive streaming applications and its primary design goal is to maximize delivered bandwidth ( and thus delivered quality ) to peers with heterogeneous and asymmetric bandwidth . to achieve this goal , pro adopts a receiver driven approach where each receiver ( or participating peer ) ( i ) independently discovers other peers in the overlay through gossiping , and ( ii ) selfishly determines the best subset of parent peers through which to connect to the overlay to maximize its own delivered bandwidth . participating peers form an unstructured overlay which is inherently robust to high churn rate . furthermore , each receiver leverages congestion controlled bandwidth from its parents as implicit signal to detect and react to long term changes in network or overlay condition without any explicit coordination with other participating peers . independent parent selection by individual peers dynamically converge to an efficient overlay structure . categories and subject descriptors c . [digit] . [digit] <unk> networks distributed systems general terms design , measurement"}, "present_kps": {"text": ["pro", "design", "receiv driven approach", "congest control", "distribut system", "measur"], "tokenized": ["pro", "design", "receiv driven approach", "congest control", "distribut system", "measur"]}, "absent_kps": {"text": ["peer to peer stream", "receiv driven overlai", "effici overlai structur", "proper subset of parent peer", "gossip base peer discoveri", "receiv driven parent select", "peer to peer stream"], "tokenized": ["peer to peer stream", "receiv driven overlai", "effici overlai structur", "proper subset of parent peer", "gossip base peer discoveri", "receiv driven parent select", "peer to peer stream"]}}
{"id": 23, "title": {"text": "edge indexing in a grid for highly dynamic virtual environments .", "tokenized": "edge indexing in a grid for highly dynamic virtual environments ."}, "abstract": {"text": "newly emerging game based application systems such as second <unk> provide 3d virtual environments where multiple users interact with each other in real time . they are filled with autonomous , mutable virtual content which is continuously augmented by the users . to make the systems highly scalable and dynamically extensible , they are usually built on a client server based grid subspace division where the virtual worlds are partitioned into manageable sub worlds . in each sub world , the user continuously receives relevant geometry updates of moving objects from remotely connected servers and renders them according to her viewpoint , rather than retrieving them from a local storage medium . in such systems , the determination of the set of objects that are visible from a user s viewpoint is one of the primary factors that affect server throughput and scalability . specifically , performing real time visibility tests in extremely dynamic virtual environments is a very challenging task as millions of objects and sub millions of active users are moving and interacting . we recognize that the described challenges are closely related to a spatial database problem , and hence we map the moving geometry objects in the virtual space to a set of multi dimensional objects in a spatial database while modeling each avatar both as a spatial object and a moving query . unfortunately , existing spatial indexing methods are unsuitable for this kind of new environments . the main goal of this paper is to present an efficient spatial index structure that minimizes unexpected object popping and supports highly scalable real time visibility determination . we then uncover many useful properties of this structure and compare the index structure with various spatial indexing methods in terms of query quality , system throughput , and resource utilization . we expect our approach to lay the groundwork for next generation virtual frameworks that may merge into existing web based services in the near future . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems client server , distributed applications , distributed databases i . [digit] . [digit] computer graphics three dimensional graphics and realism virtual reality general terms algorithms , design , performance", "tokenized": "newly emerging game based application systems such as second <unk> provide 3d virtual environments where multiple users interact with each other in real time . they are filled with autonomous , mutable virtual content which is continuously augmented by the users . to make the systems highly scalable and dynamically extensible , they are usually built on a client server based grid subspace division where the virtual worlds are partitioned into manageable sub worlds . in each sub world , the user continuously receives relevant geometry updates of moving objects from remotely connected servers and renders them according to her viewpoint , rather than retrieving them from a local storage medium . in such systems , the determination of the set of objects that are visible from a user s viewpoint is one of the primary factors that affect server throughput and scalability . specifically , performing real time visibility tests in extremely dynamic virtual environments is a very challenging task as millions of objects and sub millions of active users are moving and interacting . we recognize that the described challenges are closely related to a spatial database problem , and hence we map the moving geometry objects in the virtual space to a set of multi dimensional objects in a spatial database while modeling each avatar both as a spatial object and a moving query . unfortunately , existing spatial indexing methods are unsuitable for this kind of new environments . the main goal of this paper is to present an efficient spatial index structure that minimizes unexpected object popping and supports highly scalable real time visibility determination . we then uncover many useful properties of this structure and compare the index structure with various spatial indexing methods in terms of query quality , system throughput , and resource utilization . we expect our approach to lay the groundwork for next generation virtual frameworks that may merge into existing web based services in the near future . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems client server , distributed applications , distributed databases i . [digit] . [digit] computer graphics three dimensional graphics and realism virtual reality general terms algorithms , design , performance"}, "present_kps": {"text": ["edg index", "dynam virtual environ", "game base applic", "mutabl virtual content", "real time visibl test", "spatial index method", "spatial index", "object pop"], "tokenized": ["edg index", "dynam virtual environ", "game base applic", "mutabl virtual content", "real time visibl test", "spatial index method", "spatial index", "object pop"]}, "absent_kps": {"text": ["spatial databas", "object initi view model", "3d spatial extens", "3d object stream", "object pop problem", "visibl model"], "tokenized": ["spatial databas", "object initi view model", "3d spatial extens", "3d object stream", "object pop problem", "visibl model"]}}
{"id": 24, "title": {"text": "addressing strategic behavior in a deployed microeconomic resource allocator .", "tokenized": "addressing strategic behavior in a deployed microeconomic resource allocator ."}, "abstract": {"text": "while market based systems have long been proposed as solutions for distributed resource allocation , few have been deployed for production use in real computer systems . towards this end , we present our initial experience using mirage , a microeconomic resource allocation system based on a repeated combinatorial auction . mirage allocates time on a heavily used [digit] node wireless sensor network testbed . in particular , we focus on observed strategic user behavior over a four month period in which [digit] , [digit] node hours were allocated across [digit] research projects . based on these results , we present a set of key challenges for market based resource allocation systems based on repeated combinatorial auctions . finally , we propose refinements to the system s current auction scheme to mitigate the strategies observed to date and also comment on some initial steps toward building an approximately strategyproof repeated combinatorial auction . categories and subject descriptors c . [digit] . [digit] distributed systems distributed applications general terms measurement , design , economics , experimentation", "tokenized": "while market based systems have long been proposed as solutions for distributed resource allocation , few have been deployed for production use in real computer systems . towards this end , we present our initial experience using mirage , a microeconomic resource allocation system based on a repeated combinatorial auction . mirage allocates time on a heavily used [digit] node wireless sensor network testbed . in particular , we focus on observed strategic user behavior over a four month period in which [digit] , [digit] node hours were allocated across [digit] research projects . based on these results , we present a set of key challenges for market based resource allocation systems based on repeated combinatorial auctions . finally , we propose refinements to the system s current auction scheme to mitigate the strategies observed to date and also comment on some initial steps toward building an approximately strategyproof repeated combinatorial auction . categories and subject descriptors c . [digit] . [digit] distributed systems distributed applications general terms measurement , design , economics , experimentation"}, "present_kps": {"text": ["strateg behavior", "resourc alloc", "market base system", "market base system", "resourc alloc system", "combinatori auction", "distribut system", "distribut applic"], "tokenized": ["strateg behavior", "resourc alloc", "market base system", "market base system", "resourc alloc system", "combinatori auction", "distribut system", "distribut applic"]}, "absent_kps": {"text": ["ration", "auction base scheme", "mirag system", "sensornet testb", "node hour price", "usabl overhead", "batch schedul"], "tokenized": ["ration", "auction base scheme", "mirag system", "sensornet testb", "node hour price", "usabl overhead", "batch schedul"]}}
{"id": 25, "title": {"text": "personalized query expansion for the web .", "tokenized": "personalized query expansion for the web ."}, "abstract": {"text": "the inherent ambiguity of short keyword queries demands for enhanced methods for web retrieval . in this paper we propose to improve such web queries by expanding them with terms collected from each user s personal information repository , thus implicitly personalizing the search output . we introduce five broad techniques for generating the additional query keywords by analyzing user data at increasing granularity levels , ranging from term and compound level analysis up to global co occurrence statistics , as well as to using external thesauri . our extensive empirical analysis under four different scenarios shows some of these approaches to perform very well , especially on ambiguous queries , producing a very strong increase in the quality of the output rankings . subsequently , we move this personalized search framework one step further and propose to make the expansion process adaptive to various features of each query . a separate set of experiments indicates the adaptive algorithms to bring an additional statistically significant improvement over the best static expansion approach . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval h . [digit] . [digit] information storage and retrieval online information services web based services general terms algorithms , experimentation , measurement", "tokenized": "the inherent ambiguity of short keyword queries demands for enhanced methods for web retrieval . in this paper we propose to improve such web queries by expanding them with terms collected from each user s personal information repository , thus implicitly personalizing the search output . we introduce five broad techniques for generating the additional query keywords by analyzing user data at increasing granularity levels , ranging from term and compound level analysis up to global co occurrence statistics , as well as to using external thesauri . our extensive empirical analysis under four different scenarios shows some of these approaches to perform very well , especially on ambiguous queries , producing a very strong increase in the quality of the output rankings . subsequently , we move this personalized search framework one step further and propose to make the expansion process adaptive to various features of each query . a separate set of experiments indicates the adaptive algorithms to bring an additional statistically significant improvement over the best static expansion approach . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval h . [digit] . [digit] information storage and retrieval online information services web based services general terms algorithms , experimentation , measurement"}, "present_kps": {"text": ["short keyword queri", "web retriev", "web queri", "person inform repositori", "search output", "addit queri keyword", "granular level", "term and compound level analysi", "global co occurr statist", "ambigu queri", "qualiti", "output rank", "person search framework", "variou featur of each queri", "adapt algorithm"], "tokenized": ["short keyword queri", "web retriev", "web queri", "person inform repositori", "search output", "addit queri keyword", "granular level", "term and compound level analysi", "global co occurr statist", "ambigu queri", "qualiti", "output rank", "person search framework", "variou featur of each queri", "adapt algorithm"]}, "absent_kps": {"text": ["extern thesauru", "keyword extract", "expans process", "signific improv", "static expans approach", "person web search", "queri expans", "desktop profil", "extens empir analysi", "keyword co occurr"], "tokenized": ["extern thesauru", "keyword extract", "expans process", "signific improv", "static expans approach", "person web search", "queri expans", "desktop profil", "extens empir analysi", "keyword co occurr"]}}
{"id": 26, "title": {"text": "using query contexts in information retrieval .", "tokenized": "using query contexts in information retrieval ."}, "abstract": {"text": "user query is an element that specifies an information need , but it is not the only one . studies in literature have found many contextual factors that strongly influence the interpretation of a query . recent studies have tried to consider the user s interests by creating a user profile . however , a single profile for a user may not be sufficient for a variety of queries of the user . in this study , we propose to use query specific contexts instead of user centric ones , including context around query and context within query . the former specifies the environment of a query such as the domain of interest , while the latter refers to context words within the query , which is particularly useful for the selection of relevant term relations . in this paper , both types of context are integrated in an ir model based on language modeling . our experiments on several trec collections show that each of the context factors brings significant improvements in retrieval effectiveness . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval retrieval models general terms algorithms , performance , experimentation , theory .", "tokenized": "user query is an element that specifies an information need , but it is not the only one . studies in literature have found many contextual factors that strongly influence the interpretation of a query . recent studies have tried to consider the user s interests by creating a user profile . however , a single profile for a user may not be sufficient for a variety of queries of the user . in this study , we propose to use query specific contexts instead of user centric ones , including context around query and context within query . the former specifies the environment of a query such as the domain of interest , while the latter refers to context words within the query , which is particularly useful for the selection of relevant term relations . in this paper , both types of context are integrated in an ir model based on language modeling . our experiments on several trec collections show that each of the context factors brings significant improvements in retrieval effectiveness . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval retrieval models general terms algorithms , performance , experimentation , theory ."}, "present_kps": {"text": ["queri context", "inform need", "user profil", "queri specif context", "term relat", "languag model", "context factor"], "tokenized": ["queri context", "inform need", "user profil", "queri specif context", "term relat", "languag model", "context factor"]}, "absent_kps": {"text": ["search context", "domain knowledg", "domain of interest interest domain", "problem of knowledg ambigu knowledg ambigu problem", "context independ", "context inform", "domain model", "radic solut", "googl person search", "user centric on", "word sens disambigu", "util of gener knowledg gener knowledg util"], "tokenized": ["search context", "domain knowledg", "domain of interest interest domain", "problem of knowledg ambigu knowledg ambigu problem", "context independ", "context inform", "domain model", "radic solut", "googl person search", "user centric on", "word sens disambigu", "util of gener knowledg gener knowledg util"]}}
{"id": 27, "title": {"text": "towards task based personal information management evaluations .", "tokenized": "towards task based personal information management evaluations ."}, "abstract": {"text": "personal information management ( pim ) is a rapidly growing area of research concerned with how people store , manage and re find information . a feature of pim research is that many systems have been designed to assist users manage and re find information , but very few have been evaluated . this has been noted by several scholars and explained by the difficulties involved in performing pim evaluations . the difficulties include that people re find information from within unique personal collections researchers know little about the tasks that cause people to re find information and numerous privacy issues concerning personal information . in this paper we aim to facilitate pim evaluations by addressing each of these difficulties . in the first part , we present a diary study of information re finding tasks . the study examines the kind of tasks that require users to re find information and produces a taxonomy of re finding tasks for email messages and web pages . in the second part , we propose a task based evaluation methodology based on our findings and examine the feasibility of the approach using two different methods of task creation . categories and subject descriptors h3 . [digit] information search and retrieval general terms measurement , management , experimentation , human factors", "tokenized": "personal information management ( pim ) is a rapidly growing area of research concerned with how people store , manage and re find information . a feature of pim research is that many systems have been designed to assist users manage and re find information , but very few have been evaluated . this has been noted by several scholars and explained by the difficulties involved in performing pim evaluations . the difficulties include that people re find information from within unique personal collections researchers know little about the tasks that cause people to re find information and numerous privacy issues concerning personal information . in this paper we aim to facilitate pim evaluations by addressing each of these difficulties . in the first part , we present a diary study of information re finding tasks . the study examines the kind of tasks that require users to re find information and produces a taxonomy of re finding tasks for email messages and web pages . in the second part , we propose a task based evaluation methodology based on our findings and examine the feasibility of the approach using two different methods of task creation . categories and subject descriptors h3 . [digit] information search and retrieval general terms measurement , management , experimentation , human factors"}, "present_kps": {"text": ["person inform manag", "re find inform", "privaci issu", "taxonomi", "email messag", "measur", "human factor"], "tokenized": ["person inform manag", "re find inform", "privaci issu", "taxonomi", "email messag", "measur", "human factor"]}, "absent_kps": {"text": ["experiment", "individu collect", "naturalist approach", "laboratori base studi", "user evalu"], "tokenized": ["experiment", "individu collect", "naturalist approach", "laboratori base studi", "user evalu"]}}
{"id": 28, "title": {"text": "utility based information distillation over temporally sequenced documents .", "tokenized": "utility based information distillation over temporally sequenced documents ."}, "abstract": {"text": "this paper examines a new approach to information distillation over temporally ordered documents , and proposes a novel evaluation scheme for such a framework . it combines the strengths of and extends beyond conventional adaptive filtering , novelty detection and non redundant passage ranking with respect to long lasting information needs ( tasks with multiple queries ) . our approach supports fine grained user feedback via highlighting of arbitrary spans of text , and leverages such information for utility optimization in adaptive settings . for our experiments , we defined hypothetical tasks based on news events in the tdt4 corpus , with multiple queries per task . answer keys ( nuggets ) were generated for each query and a semiautomatic procedure was used for acquiring rules that allow automatically matching nuggets against system responses . we also propose an extension of the ndcg metric for assessing the utility of ranked passages as a combination of relevance and novelty . our results show encouraging utility enhancements using the new approach , compared to the baseline systems without incremental learning or the novelty detection components . categories and subject descriptors h . [digit] . [digit] information search and retrieval information filtering , relevance feedback , retrieval models , selection process i . [digit] . [digit] general terms design , measurement , performance , experimentation .", "tokenized": "this paper examines a new approach to information distillation over temporally ordered documents , and proposes a novel evaluation scheme for such a framework . it combines the strengths of and extends beyond conventional adaptive filtering , novelty detection and non redundant passage ranking with respect to long lasting information needs ( tasks with multiple queries ) . our approach supports fine grained user feedback via highlighting of arbitrary spans of text , and leverages such information for utility optimization in adaptive settings . for our experiments , we defined hypothetical tasks based on news events in the tdt4 corpus , with multiple queries per task . answer keys ( nuggets ) were generated for each query and a semiautomatic procedure was used for acquiring rules that allow automatically matching nuggets against system responses . we also propose an extension of the ndcg metric for assessing the utility of ranked passages as a combination of relevance and novelty . our results show encouraging utility enhancements using the new approach , compared to the baseline systems without incremental learning or the novelty detection components . categories and subject descriptors h . [digit] . [digit] information search and retrieval information filtering , relevance feedback , retrieval models , selection process i . [digit] . [digit] general terms design , measurement , performance , experimentation ."}, "present_kps": {"text": ["util base inform distil", "tempor order document", "adapt filter", "adapt filter", "novelti detect", "passag rank", "passag rank", "ndcg metric"], "tokenized": ["util base inform distil", "tempor order document", "adapt filter", "adapt filter", "novelti detect", "passag rank", "passag rank", "ndcg metric"]}, "absent_kps": {"text": ["unifi framework", "util base distil", "nugget match rule", "exibl user feedback", "answer kei", "new evalu methodolog", "ad hoc retriev", "unifi framework", "evalu methodolog"], "tokenized": ["unifi framework", "util base distil", "nugget match rule", "exibl user feedback", "answer kei", "new evalu methodolog", "ad hoc retriev", "unifi framework", "evalu methodolog"]}}
{"id": 29, "title": {"text": "efficient bayesian hierarchical user modeling for recommendation systems .", "tokenized": "efficient bayesian hierarchical user modeling for recommendation systems ."}, "abstract": {"text": "a content based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual user s interest . a system serving millions of users can learn a better user profile for a new user , or a user with little feedback , by borrowing information from other users through the use of a bayesian hierarchical model . learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive . the commonly used em algorithm converges very slowly due to the sparseness of the data in ir applications . this paper proposes a new fast learning technique to learn a large number of individual user profiles . the efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from netflix and movielens . categories and subject descriptors b . [digit] . [digit] information search and retrieval information filtering general terms algorithms", "tokenized": "a content based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual user s interest . a system serving millions of users can learn a better user profile for a new user , or a user with little feedback , by borrowing information from other users through the use of a bayesian hierarchical model . learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive . the commonly used em algorithm converges very slowly due to the sparseness of the data in ir applications . this paper proposes a new fast learning technique to learn a large number of individual user profiles . the efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from netflix and movielens . categories and subject descriptors b . [digit] . [digit] information search and retrieval information filtering general terms algorithms"}, "present_kps": {"text": ["model", "recommend system", "recommend system", "content base", "person", "bayesian hierarch model", "paramet", "em algorithm", "ir", "learn techniqu", "inform filter"], "tokenized": ["model", "recommend system", "recommend system", "content base", "person", "bayesian hierarch model", "paramet", "em algorithm", "ir", "learn techniqu", "inform filter"]}, "absent_kps": {"text": ["linear regress", "collabor filter", "classif", "rate"], "tokenized": ["linear regress", "collabor filter", "classif", "rate"]}}
{"id": 30, "title": {"text": "robust test collections for retrieval evaluation .", "tokenized": "robust test collections for retrieval evaluation ."}, "abstract": {"text": "low cost methods for acquiring relevance judgments can be a boon to researchers who need to evaluate new retrieval tasks or topics but do not have the resources to make thousands of judgments . while these judgments are very useful for a one time evaluation , it is not clear that they can be trusted when re used to evaluate new systems . in this work , we formally define what it means for judgments to be reusable the confidence in an evaluation of new systems can be accurately assessed from an existing set of relevance judgments . we then present a method for augmenting a set of relevance judgments with relevance estimates that require no additional assessor effort . using this method practically guarantees reusability with as few as five judgments per topic taken from only two systems , we can reliably evaluate a larger set of ten systems . even the smallest sets of judgments can be useful for evaluation of new systems . categories and subject descriptors h . [digit] information storage and retrieval h . [digit] . [digit] systems and software performance evaluation general terms experimentation , measurement , reliability", "tokenized": "low cost methods for acquiring relevance judgments can be a boon to researchers who need to evaluate new retrieval tasks or topics but do not have the resources to make thousands of judgments . while these judgments are very useful for a one time evaluation , it is not clear that they can be trusted when re used to evaluate new systems . in this work , we formally define what it means for judgments to be reusable the confidence in an evaluation of new systems can be accurately assessed from an existing set of relevance judgments . we then present a method for augmenting a set of relevance judgments with relevance estimates that require no additional assessor effort . using this method practically guarantees reusability with as few as five judgments per topic taken from only two systems , we can reliably evaluate a larger set of ten systems . even the smallest sets of judgments can be useful for evaluation of new systems . categories and subject descriptors h . [digit] information storage and retrieval h . [digit] . [digit] systems and software performance evaluation general terms experimentation , measurement , reliability"}, "present_kps": {"text": ["test collect", "evalu", "reusabl"], "tokenized": ["test collect", "evalu", "reusabl"]}, "absent_kps": {"text": ["inform retriev", "relev judgement", "lowerest confid comparison", "mtc", "rtc", "expect", "varianc", "distribut of relev relev distribut"], "tokenized": ["inform retriev", "relev judgement", "lowerest confid comparison", "mtc", "rtc", "expect", "varianc", "distribut of relev relev distribut"]}}
{"id": 31, "title": {"text": "learn from web search logs to organize search results .", "tokenized": "learn from web search logs to organize search results ."}, "abstract": {"text": "effective organization of search results is critical for improving the utility of any search engine . clustering search results is an effective way to organize search results , which allows a user to navigate into relevant documents quickly . however , two deficiencies of this approach make it not always work well ( [digit] ) the clusters discovered do not necessarily correspond to the interesting aspects of a topic from the user s perspective and ( [digit] ) the cluster labels generated are not informative enough to allow a user to identify the right cluster . in this paper , we propose to address these two deficiencies by ( [digit] ) learning interesting aspects of a topic from web search logs and organizing search results accordingly and ( [digit] ) generating more meaningful cluster labels using past query words entered by users . we evaluate our proposed method on a commercial search engine log data . compared with the traditional methods of clustering search results , our method can give better result organization and more meaningful labels . categories and subject descriptors h . [digit] . [digit] information search and retrieval clustering , search process general terms algorithm , experimentation", "tokenized": "effective organization of search results is critical for improving the utility of any search engine . clustering search results is an effective way to organize search results , which allows a user to navigate into relevant documents quickly . however , two deficiencies of this approach make it not always work well ( [digit] ) the clusters discovered do not necessarily correspond to the interesting aspects of a topic from the user s perspective and ( [digit] ) the cluster labels generated are not informative enough to allow a user to identify the right cluster . in this paper , we propose to address these two deficiencies by ( [digit] ) learning interesting aspects of a topic from web search logs and organizing search results accordingly and ( [digit] ) generating more meaningful cluster labels using past query words entered by users . we evaluate our proposed method on a commercial search engine log data . compared with the traditional methods of clustering search results , our method can give better result organization and more meaningful labels . categories and subject descriptors h . [digit] . [digit] information search and retrieval clustering , search process general terms algorithm , experimentation"}, "present_kps": {"text": ["interest aspect", "past queri", "search engin log"], "tokenized": ["interest aspect", "past queri", "search engin log"]}, "absent_kps": {"text": ["search result organ", "mean averag precis", "log base method", "reciproc rank", "centroid prototyp", "cosin similar", "centroid base method", "similar threshold paramet", "pairwis similar graph", "retriev model", "search result snippet", "suffix tree cluster algorithm", "star cluster algorithm", "clickthrough", "histori collect", "meaning cluster label", "cluster view", "ambigu", "rank function", "pseudo document", "monothet cluster algorithm"], "tokenized": ["search result organ", "mean averag precis", "log base method", "reciproc rank", "centroid prototyp", "cosin similar", "centroid base method", "similar threshold paramet", "pairwis similar graph", "retriev model", "search result snippet", "suffix tree cluster algorithm", "star cluster algorithm", "clickthrough", "histori collect", "meaning cluster label", "cluster view", "ambigu", "rank function", "pseudo document", "monothet cluster algorithm"]}}
{"id": 32, "title": {"text": "regularized clustering for documents .", "tokenized": "regularized clustering for documents ."}, "abstract": {"text": "in recent years , document clustering has been receiving more and more attentions as an important and fundamental technique for unsupervised document organization , automatic topic extraction , and fast information retrieval or filtering . in this paper , we propose a novel method for clustering documents using regularization . unlike traditional globally regularized clustering methods , our method first construct a local regularized linear label predictor for each document vector , and then combine all those local regularizers with a global smoothness regularizer . so we call our algorithm clustering with local and global regularization ( clgr ) . we will show that the cluster memberships of the documents can be achieved by eigenvalue decomposition of a sparse symmetric matrix , which can be efficiently solved by iterative methods . finally our experimental evaluations on several datasets are presented to show the superiorities of clgr over traditional document clustering methods . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval clustering i . [digit] . [digit] artificial intelligence learning concept learning general terms algorithms", "tokenized": "in recent years , document clustering has been receiving more and more attentions as an important and fundamental technique for unsupervised document organization , automatic topic extraction , and fast information retrieval or filtering . in this paper , we propose a novel method for clustering documents using regularization . unlike traditional globally regularized clustering methods , our method first construct a local regularized linear label predictor for each document vector , and then combine all those local regularizers with a global smoothness regularizer . so we call our algorithm clustering with local and global regularization ( clgr ) . we will show that the cluster memberships of the documents can be achieved by eigenvalue decomposition of a sparse symmetric matrix , which can be efficiently solved by iterative methods . finally our experimental evaluations on several datasets are presented to show the superiorities of clgr over traditional document clustering methods . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval clustering i . [digit] . [digit] artificial intelligence learning concept learning general terms algorithms"}, "present_kps": {"text": ["regular", "document cluster", "document cluster", "global regular"], "tokenized": ["regular", "document cluster", "document cluster", "global regular"]}, "absent_kps": {"text": ["cluster hierarchi", "spectrum", "specifi search", "hierarch method", "partit method", "label predict", "function estim", "manifold"], "tokenized": ["cluster hierarchi", "spectrum", "specifi search", "hierarch method", "partit method", "label predict", "function estim", "manifold"]}}
{"id": 33, "title": {"text": "laplacian optimal design for image retrieval .", "tokenized": "laplacian optimal design for image retrieval ."}, "abstract": {"text": "relevance feedback is a powerful technique to enhance contentbased image retrieval ( cbir ) performance . it solicits the user s relevance judgments on the retrieved images returned by the cbir systems . the user s labeling is then used to learn a classifier to distinguish between relevant and irrelevant images . however , the top returned images may not be the most informative ones . the challenge is thus to determine which unlabeled images would be the most informative ( i . e . , improve the classifier the most ) if they were labeled and used as training samples . in this paper , we propose a novel active learning algorithm , called laplacian optimal design ( lod ) , for relevance feedback image retrieval . our algorithm is based on a regression model which minimizes the least square error on the measured ( or , labeled ) images and simultaneously preserves the local geometrical structure of the image space . specifically , we assume that if two images are sufficiently close to each other , then their measurements ( or , labels ) are close as well . by constructing a nearest neighbor graph , the geometrical structure of the image space can be described by the graph laplacian . we discuss how results from the field of optimal experimental design may be used to guide our selection of a subset of images , which gives us the most amount of information . experimental results on corel database suggest that the proposed approach achieves higher precision in relevance feedback image retrieval . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval relevance feedback g . [digit] mathematics of computing probability and statistics experimental design general terms algorithms , performance , theory", "tokenized": "relevance feedback is a powerful technique to enhance contentbased image retrieval ( cbir ) performance . it solicits the user s relevance judgments on the retrieved images returned by the cbir systems . the user s labeling is then used to learn a classifier to distinguish between relevant and irrelevant images . however , the top returned images may not be the most informative ones . the challenge is thus to determine which unlabeled images would be the most informative ( i . e . , improve the classifier the most ) if they were labeled and used as training samples . in this paper , we propose a novel active learning algorithm , called laplacian optimal design ( lod ) , for relevance feedback image retrieval . our algorithm is based on a regression model which minimizes the least square error on the measured ( or , labeled ) images and simultaneously preserves the local geometrical structure of the image space . specifically , we assume that if two images are sufficiently close to each other , then their measurements ( or , labels ) are close as well . by constructing a nearest neighbor graph , the geometrical structure of the image space can be described by the graph laplacian . we discuss how results from the field of optimal experimental design may be used to guide our selection of a subset of images , which gives us the most amount of information . experimental results on corel database suggest that the proposed approach achieves higher precision in relevance feedback image retrieval . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval relevance feedback g . [digit] mathematics of computing probability and statistics experimental design general terms algorithms , performance , theory"}, "present_kps": {"text": ["imag retriev", "relev feedback", "label", "top return imag", "activ learn", "activ learn"], "tokenized": ["imag retriev", "relev feedback", "label", "top return imag", "activ learn", "activ learn"]}, "absent_kps": {"text": ["imag represent", "contentbas imag retriev", "least squar regress model", "optim experiment design", "precis rate", "intrins geometr structur", "patten recognit"], "tokenized": ["imag represent", "contentbas imag retriev", "least squar regress model", "optim experiment design", "precis rate", "intrins geometr structur", "patten recognit"]}}
{"id": 34, "title": {"text": "fast generation of result snippets in web search .", "tokenized": "fast generation of result snippets in web search ."}, "abstract": {"text": "the presentation of query biased document snippets as part of results pages presented by search engines has become an expectation of search engine users . in this paper we explore the algorithms and data structures required as part of a search engine to allow efficient generation of query biased snippets . we begin by proposing and analysing a document compression method that reduces snippet generation time by [digit] % over a baseline using the zlib compression library . these experiments reveal that finding documents on secondary storage dominates the total cost of generating snippets , and so caching documents in ram is essential for a fast snippet generation process . using simulation , we examine snippet generation performance for different size ram caches . finally we propose and analyse document reordering and compaction , revealing a scheme that increases the number of document cache hits with only a marginal affect on snippet quality . this scheme effectively doubles the number of documents that can fit in a fixed size cache . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval h . [digit] . [digit] information storage and retrieval systems and software performance evaluation ( efficiency and effectiveness ) general terms algorithms , experimentation , measurement , performance", "tokenized": "the presentation of query biased document snippets as part of results pages presented by search engines has become an expectation of search engine users . in this paper we explore the algorithms and data structures required as part of a search engine to allow efficient generation of query biased snippets . we begin by proposing and analysing a document compression method that reduces snippet generation time by [digit] % over a baseline using the zlib compression library . these experiments reveal that finding documents on secondary storage dominates the total cost of generating snippets , and so caching documents in ram is essential for a fast snippet generation process . using simulation , we examine snippet generation performance for different size ram caches . finally we propose and analyse document reordering and compaction , revealing a scheme that increases the number of document cache hits with only a marginal affect on snippet quality . this scheme effectively doubles the number of documents that can fit in a fixed size cache . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval h . [digit] . [digit] information storage and retrieval systems and software performance evaluation ( efficiency and effectiveness ) general terms algorithms , experimentation , measurement , performance"}, "present_kps": {"text": ["search engin", "snippet gener", "ram", "perform", "document cach", "document cach"], "tokenized": ["search engin", "snippet gener", "ram", "perform", "document cach", "document cach"]}, "absent_kps": {"text": ["link graph measur", "web summari", "special purpos filesystem", "document compact", "text fragment", "precomput final result page", "vbyte code scheme", "semi static compress"], "tokenized": ["link graph measur", "web summari", "special purpos filesystem", "document compact", "text fragment", "precomput final result page", "vbyte code scheme", "semi static compress"]}}
{"id": 35, "title": {"text": "the influence of caption features on clickthrough patterns in web search .", "tokenized": "the influence of caption features on clickthrough patterns in web search ."}, "abstract": {"text": "web search engines present lists of captions , comprising title , snippet , and url , to help users decide which search results to visit . understanding the influence of features of these captions on web search behavior may help validate algorithms and guidelines for their improved generation . in this paper we develop a methodology to use clickthrough logs from a commercial search engine to study user behavior when interacting with search result captions . the findings of our study suggest that relatively simple caption features such as the presence of all terms query terms , the readability of the snippet , and the length of the url shown in the caption , can significantly influence users web search behavior . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval search process general terms experimentation , human factors", "tokenized": "web search engines present lists of captions , comprising title , snippet , and url , to help users decide which search results to visit . understanding the influence of features of these captions on web search behavior may help validate algorithms and guidelines for their improved generation . in this paper we develop a methodology to use clickthrough logs from a commercial search engine to study user behavior when interacting with search result captions . the findings of our study suggest that relatively simple caption features such as the presence of all terms query terms , the readability of the snippet , and the length of the url shown in the caption , can significantly influence users web search behavior . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval search process general terms experimentation , human factors"}, "present_kps": {"text": ["caption featur", "clickthrough pattern", "web search", "snippet", "web search behavior", "human factor"], "tokenized": ["caption featur", "clickthrough pattern", "web search", "snippet", "web search behavior", "human factor"]}, "absent_kps": {"text": ["extract summar", "queri log", "queri re formul", "signific word", "clickthrough invers", "queri term match", "summar"], "tokenized": ["extract summar", "queri log", "queri re formul", "signific word", "clickthrough invers", "queri term match", "summar"]}}
{"id": 36, "title": {"text": "studying the use of popular destinations to enhance web search interaction .", "tokenized": "studying the use of popular destinations to enhance web search interaction ."}, "abstract": {"text": "we present a novel web search interaction feature which , for a given query , provides links to websites frequently visited by other users with similar information needs . these popular destinations complement traditional search results , allowing direct navigation to authoritative resources for the query topic . destinations are identified using the history of search and browsing behavior of many users over an extended time period , whose collective behavior provides a basis for computing source authority . we describe a user study which compared the suggestion of destinations with the previously proposed suggestion of related queries , as well as with traditional , unaided web search . results show that search enhanced by destination suggestions outperforms other systems for exploratory tasks , with best performance obtained from mining past user behavior at query level granularity . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval search process . general terms human factors , experimentation .", "tokenized": "we present a novel web search interaction feature which , for a given query , provides links to websites frequently visited by other users with similar information needs . these popular destinations complement traditional search results , allowing direct navigation to authoritative resources for the query topic . destinations are identified using the history of search and browsing behavior of many users over an extended time period , whose collective behavior provides a basis for computing source authority . we describe a user study which compared the suggestion of destinations with the previously proposed suggestion of related queries , as well as with traditional , unaided web search . results show that search enhanced by destination suggestions outperforms other systems for exploratory tasks , with best performance obtained from mining past user behavior at query level granularity . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval search process . general terms human factors , experimentation ."}, "present_kps": {"text": ["popular destin", "enhanc web search", "web search interact", "user studi", "relat queri"], "tokenized": ["popular destin", "enhanc web search", "web search interact", "user studi", "relat queri"]}, "absent_kps": {"text": ["improv queri", "retriev perform", "inform seek experi", "queri trail", "session trail", "lookup base approach", "log base evalu", "search destin"], "tokenized": ["improv queri", "retriev perform", "inform seek experi", "queri trail", "session trail", "lookup base approach", "log base evalu", "search destin"]}}
{"id": 37, "title": {"text": "the impact of caching on search engines .", "tokenized": "the impact of caching on search engines ."}, "abstract": {"text": "in this paper we study the trade offs in designing efficient caching systems for web search engines . we explore the impact of different approaches , such as static vs . dynamic caching , and caching query results vs . caching posting lists . using a query log spanning a whole year we explore the limitations of caching and we demonstrate that caching posting lists can achieve higher hit rates than caching query answers . we propose a new algorithm for static caching of posting lists , which outperforms previous methods . we also study the problem of finding the optimal way to split the static cache between answers and posting lists . finally , we measure how the changes in the query log affect the effectiveness of static caching , given our observation that the distribution of the queries changes slowly over time . our results and observations are applicable to different levels of the data access hierarchy , for instance , for a memory disk layer or a broker remote server layer . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval search process h . [digit] . [digit] information storage and retrieval systems and software distributed systems , performance evaluation ( efficiency and effectiveness ) general terms algorithms , experimentation", "tokenized": "in this paper we study the trade offs in designing efficient caching systems for web search engines . we explore the impact of different approaches , such as static vs . dynamic caching , and caching query results vs . caching posting lists . using a query log spanning a whole year we explore the limitations of caching and we demonstrate that caching posting lists can achieve higher hit rates than caching query answers . we propose a new algorithm for static caching of posting lists , which outperforms previous methods . we also study the problem of finding the optimal way to split the static cache between answers and posting lists . finally , we measure how the changes in the query log affect the effectiveness of static caching , given our observation that the distribution of the queries changes slowly over time . our results and observations are applicable to different levels of the data access hierarchy , for instance , for a memory disk layer or a broker remote server layer . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval search process h . [digit] . [digit] information storage and retrieval systems and software distributed systems , performance evaluation ( efficiency and effectiveness ) general terms algorithms , experimentation"}, "present_kps": {"text": ["cach", "effici cach system", "web search engin", "web search", "dynam cach", "cach queri result", "cach post list", "queri log", "static cach", "static cach", "answer and post list", "data access hierarchi", "disk layer", "remot server layer"], "tokenized": ["cach", "effici cach system", "web search engin", "web search", "dynam cach", "cach queri result", "cach post list", "queri log", "static cach", "static cach", "answer and post list", "data access hierarchi", "disk layer", "remot server layer"]}, "absent_kps": {"text": ["effect of static cach static cach effect", "distribut of the queri the queri distribut", "inform retriev system"], "tokenized": ["effect of static cach static cach effect", "distribut of the queri the queri distribut", "inform retriev system"]}}
{"id": 38, "title": {"text": "pruning policies for two tiered inverted index with correctness guarantee .", "tokenized": "pruning policies for two tiered inverted index with correctness guarantee ."}, "abstract": {"text": "the web search engines maintain large scale inverted indexes which are queried thousands of times per second by users eager for information . in order to cope with the vast amounts of query loads , search engines prune their index to keep documents that are likely to be returned as top results , and use this pruned index to compute the first batches of results . while this approach can improve performance by reducing the size of the index , if we compute the top results only from the pruned index we may notice a significant degradation in the result quality if a document should be in the top results but was not included in the pruned index , it will be placed behind the results computed from the pruned index . given the fierce competition in the online search market , this phenomenon is clearly undesirable . in this paper , we study how we can avoid any degradation of result quality due to the pruning based performance optimization , while still realizing most of its benefit . our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top matching pages are always placed at the top search results , even though we are computing the first batch from the pruned index most of the time . we also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of [digit] million web pages . categories and subject descriptors h . [digit] . [digit] information storage and retrieval content analysis and indexing h . [digit] . [digit] information storage and retrieval information search and retrieval general terms algorithms , measuring , performance , design , experimentation", "tokenized": "the web search engines maintain large scale inverted indexes which are queried thousands of times per second by users eager for information . in order to cope with the vast amounts of query loads , search engines prune their index to keep documents that are likely to be returned as top results , and use this pruned index to compute the first batches of results . while this approach can improve performance by reducing the size of the index , if we compute the top results only from the pruned index we may notice a significant degradation in the result quality if a document should be in the top results but was not included in the pruned index , it will be placed behind the results computed from the pruned index . given the fierce competition in the online search market , this phenomenon is clearly undesirable . in this paper , we study how we can avoid any degradation of result quality due to the pruning based performance optimization , while still realizing most of its benefit . our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top matching pages are always placed at the top search results , even though we are computing the first batch from the pruned index most of the time . we also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of [digit] million web pages . categories and subject descriptors h . [digit] . [digit] information storage and retrieval content analysis and indexing h . [digit] . [digit] information storage and retrieval information search and retrieval general terms algorithms , measuring , performance , design , experimentation"}, "present_kps": {"text": ["prune", "invert index", "web search engin", "larg scale invert index", "queri load", "prune index", "onlin search market", "prune base perform optim", "prune techniqu", "result comput algorithm", "top match page", "top search result", "optim size"], "tokenized": ["prune", "invert index", "web search engin", "larg scale invert index", "queri load", "prune index", "onlin search market", "prune base perform optim", "prune techniqu", "result comput algorithm", "top match page", "top search result", "optim size"]}, "absent_kps": {"text": ["degrad of result qualiti result qualiti degrad", "correct guarante"], "tokenized": ["degrad of result qualiti result qualiti degrad", "correct guarante"]}}
{"id": 39, "title": {"text": "topic segmentation with shared topic detection and alignment of multiple documents .", "tokenized": "topic segmentation with shared topic detection and alignment of multiple documents ."}, "abstract": {"text": "topic detection and tracking [digit] and topic segmentation [digit] play an important role in capturing the local and sequential information of documents . previous work in this area usually focuses on single documents , although similar multiple documents are available in many domains . in this paper , we introduce a novel unsupervised method for shared topic detection and topic segmentation of multiple similar documents based on mutual information ( mi ) and weighted mutual information ( wmi ) that is a combination of mi and term weights . the basic idea is that the optimal segmentation maximizes mi ( or wmi ) . our approach can detect shared topics among documents . it can find the optimal boundaries in a document , and align segments among documents at the same time . it also can handle single document segmentation as a special case of the multi document segmentation and alignment . our methods can identify and strengthen cue terms that can be used for segmentation and partially remove stop words by using term weights based on entropy learned from multiple documents . our experimental results show that our algorithm works well for the tasks of single document segmentation , shared topic detection , and multi document segmentation . utilizing information from multiple documents can tremendously improve the performance of topic segmentation , and using wmi is even better than using mi for the multi document segmentation . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval clustering h . [digit] . [digit] information storage and retrieval content analysis and <unk> processing i . [digit] . [digit] artificial intelligence natural language processing text analysis i . [digit] . [digit] pattern recognition clustering algorithms similarity measures general terms algorithms , design , experimentation", "tokenized": "topic detection and tracking [digit] and topic segmentation [digit] play an important role in capturing the local and sequential information of documents . previous work in this area usually focuses on single documents , although similar multiple documents are available in many domains . in this paper , we introduce a novel unsupervised method for shared topic detection and topic segmentation of multiple similar documents based on mutual information ( mi ) and weighted mutual information ( wmi ) that is a combination of mi and term weights . the basic idea is that the optimal segmentation maximizes mi ( or wmi ) . our approach can detect shared topics among documents . it can find the optimal boundaries in a document , and align segments among documents at the same time . it also can handle single document segmentation as a special case of the multi document segmentation and alignment . our methods can identify and strengthen cue terms that can be used for segmentation and partially remove stop words by using term weights based on entropy learned from multiple documents . our experimental results show that our algorithm works well for the tasks of single document segmentation , shared topic detection , and multi document segmentation . utilizing information from multiple documents can tremendously improve the performance of topic segmentation , and using wmi is even better than using mi for the multi document segmentation . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval clustering h . [digit] . [digit] information storage and retrieval content analysis and <unk> processing i . [digit] . [digit] artificial intelligence natural language processing text analysis i . [digit] . [digit] pattern recognition clustering algorithms similarity measures general terms algorithms , design , experimentation"}, "present_kps": {"text": ["topic segment", "share topic detect", "share topic", "topic detect", "multipl document", "track", "local and sequenti inform of document", "singl document", "mutual inform", "term weight", "optim boundari", "singl document segment", "multi document segment", "cue term", "stop word"], "tokenized": ["topic segment", "share topic detect", "share topic", "topic detect", "multipl document", "track", "local and sequenti inform of document", "singl document", "mutual inform", "term weight", "optim boundari", "singl document segment", "multi document segment", "cue term", "stop word"]}, "absent_kps": {"text": ["perform of topic segment topic segment perform", "wmu", "topic align"], "tokenized": ["perform of topic segment topic segment perform", "wmu", "topic align"]}}
{"id": 40, "title": {"text": "analyzing feature trajectories for event detection .", "tokenized": "analyzing feature trajectories for event detection ."}, "abstract": {"text": "we consider the problem of analyzing word trajectories in both time and frequency domains , with the specific goal of identifying important and less reported , periodic and aperiodic words . a set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner . the document frequency of each word across time is treated like a time series , where each element is the document frequency inverse document frequency ( dfidf ) score at one time point . in this paper , we [digit] ) first applied spectral analysis to categorize features for different event characteristics important and less reported , periodic and aperiodic [digit] ) modeled aperiodic features with gaussian density and periodic features with gaussian mixture densities , and subsequently detected each feature s burst by the truncated gaussian approach [digit] ) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events . all of the above methods can be applied to time series data in general . we extensively evaluated our methods on the [digit] year reuters news corpus [digit] and showed that they were able to uncover meaningful aperiodic and periodic events . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval general terms algorithms , experimentation .", "tokenized": "we consider the problem of analyzing word trajectories in both time and frequency domains , with the specific goal of identifying important and less reported , periodic and aperiodic words . a set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner . the document frequency of each word across time is treated like a time series , where each element is the document frequency inverse document frequency ( dfidf ) score at one time point . in this paper , we [digit] ) first applied spectral analysis to categorize features for different event characteristics important and less reported , periodic and aperiodic [digit] ) modeled aperiodic features with gaussian density and periodic features with gaussian mixture densities , and subsequently detected each feature s burst by the truncated gaussian approach [digit] ) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events . all of the above methods can be applied to time series data in general . we extensively evaluated our methods on the [digit] year reuters news corpus [digit] and showed that they were able to uncover meaningful aperiodic and periodic events . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval general terms algorithms , experimentation ."}, "present_kps": {"text": ["event detect", "word trajectori", "time seri", "spectral analysi", "gaussian", "period event"], "tokenized": ["event detect", "word trajectori", "time seri", "spectral analysi", "gaussian", "period event"]}, "absent_kps": {"text": ["aperiod event", "word signal", "topic detect", "topic track", "text stream", "new stream", "featur categor", "dft"], "tokenized": ["aperiod event", "word signal", "topic detect", "topic track", "text stream", "new stream", "featur categor", "dft"]}}
{"id": 41, "title": {"text": "new event detection based on indexing tree and named entity .", "tokenized": "new event detection based on indexing tree and named entity ."}, "abstract": {"text": "new event detection ( ned ) aims at detecting from one or multiple streams of news stories that which one is reported on a new event ( i . e . not reported previously ) . with the overwhelming volume of news available today , there is an increasing need for a ned system which is able to detect new events more efficiently and accurately . in this paper we propose a new ned model to speed up the ned task by using news indexing tree dynamically . moreover , based on the observation that terms of different types have different effects for ned task , two term reweighting approaches are proposed to improve ned accuracy . in the first approach , we propose to adjust term weights dynamically based on previous story clusters and in the second approach , we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories . experimental results on two linguistic data consortium ( ldc ) datasets tdt2 and tdt3 show that the proposed model can improve both efficiency and accuracy of ned task significantly , compared to the baseline system and other existing systems . categories and subject descriptors h . [digit] . [digit] information systems information search and retrieval h . [digit] . [digit] information systems applications types of <unk> support . general terms algorithms , performance , experimentation", "tokenized": "new event detection ( ned ) aims at detecting from one or multiple streams of news stories that which one is reported on a new event ( i . e . not reported previously ) . with the overwhelming volume of news available today , there is an increasing need for a ned system which is able to detect new events more efficiently and accurately . in this paper we propose a new ned model to speed up the ned task by using news indexing tree dynamically . moreover , based on the observation that terms of different types have different effects for ned task , two term reweighting approaches are proposed to improve ned accuracy . in the first approach , we propose to adjust term weights dynamically based on previous story clusters and in the second approach , we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories . experimental results on two linguistic data consortium ( ldc ) datasets tdt2 and tdt3 show that the proposed model can improve both efficiency and accuracy of ned task significantly , compared to the baseline system and other existing systems . categories and subject descriptors h . [digit] . [digit] information systems information search and retrieval h . [digit] . [digit] information systems applications types of <unk> support . general terms algorithms , performance , experimentation"}, "present_kps": {"text": ["new event detect", "name entiti", "term reweight approach", "ned accuraci", "term weight", "statist", "train data", "linguist data consortium", "baselin system", "exist system"], "tokenized": ["new event detect", "name entiti", "term reweight approach", "ned accuraci", "term weight", "statist", "train data", "linguist data consortium", "baselin system", "exist system"]}, "absent_kps": {"text": ["volum of new new volum", "stream of new stori new stori stream", "name entiti reweight mode", "class of stori stori class", "topic detect and track", "new index tree", "real time index"], "tokenized": ["volum of new new volum", "stream of new stori new stori stream", "name entiti reweight mode", "class of stori stori class", "topic detect and track", "new index tree", "real time index"]}}
{"id": 42, "title": {"text": "robust classification of rare queries using web knowledge .", "tokenized": "robust classification of rare queries using web knowledge ."}, "abstract": {"text": "we propose a methodology for building a practical robust query classification system that can identify thousands of query classes with reasonable accuracy , while dealing in realtime with the query volume of a commercial web search engine . we use a blind feedback technique given a query , we determine its topic by classifying the web search results retrieved by the query . motivated by the needs of search advertising , we primarily focus on rare queries , which are the hardest from the point of view of machine learning , yet in aggregation account for a considerable fraction of search engine traffic . empirical evaluation confirms that our methodology yields a considerably higher classification accuracy than previously reported . we believe that the proposed methodology will lead to better matching of online ads to rare queries and overall to a better user experience . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval relevance feedback , search process general terms algorithms , measurement , performance , experimentation", "tokenized": "we propose a methodology for building a practical robust query classification system that can identify thousands of query classes with reasonable accuracy , while dealing in realtime with the query volume of a commercial web search engine . we use a blind feedback technique given a query , we determine its topic by classifying the web search results retrieved by the query . motivated by the needs of search advertising , we primarily focus on rare queries , which are the hardest from the point of view of machine learning , yet in aggregation account for a considerable fraction of search engine traffic . empirical evaluation confirms that our methodology yields a considerably higher classification accuracy than previously reported . we believe that the proposed methodology will lead to better matching of online ads to rare queries and overall to a better user experience . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval relevance feedback , search process general terms algorithms , measurement , performance , experimentation"}, "present_kps": {"text": ["queri classif", "web search", "search engin", "machin learn", "relev feedback"], "tokenized": ["queri classif", "web search", "search engin", "machin learn", "relev feedback"]}, "absent_kps": {"text": ["search advertis", "vote scheme", "crawl", "topic taxonomi", "affin score", "condit probabl", "adapt", "inform retriev", "blind relev feedback"], "tokenized": ["search advertis", "vote scheme", "crawl", "topic taxonomi", "affin score", "condit probabl", "adapt", "inform retriev", "blind relev feedback"]}}
{"id": 43, "title": {"text": "investigating the querying and browsing behavior of advanced search engine users .", "tokenized": "investigating the querying and browsing behavior of advanced search engine users ."}, "abstract": {"text": "one way to help all users of commercial web search engines be more successful in their searches is to better understand what those users with greater search expertise are doing , and use this knowledge to benefit everyone . in this paper we study the interaction logs of advanced search engine users ( and those not so advanced ) to better understand how these user groups search . the results show that there are marked differences in the queries , result clicks , post query browsing , and search success of users we classify as advanced ( based on their use of query operators ) , relative to those classified as non advanced . our findings have implications for how advanced users should be supported during their searches , and how their interactions could be used to help searchers of all experience levels find more relevant information and learn improved searching strategies . categories and subject descriptors h . [digit] . [digit] information search and retrieval query formulation , search process , relevance feedback . general terms experimentation , human factors .", "tokenized": "one way to help all users of commercial web search engines be more successful in their searches is to better understand what those users with greater search expertise are doing , and use this knowledge to benefit everyone . in this paper we study the interaction logs of advanced search engine users ( and those not so advanced ) to better understand how these user groups search . the results show that there are marked differences in the queries , result clicks , post query browsing , and search success of users we classify as advanced ( based on their use of query operators ) , relative to those classified as non advanced . our findings have implications for how advanced users should be supported during their searches , and how their interactions could be used to help searchers of all experience levels find more relevant information and learn improved searching strategies . categories and subject descriptors h . [digit] . [digit] information search and retrieval query formulation , search process , relevance feedback . general terms experimentation , human factors ."}, "present_kps": {"text": ["queri", "search engin", "search success", "relev inform", "relev", "search strategi", "relev feedback"], "tokenized": ["queri", "search engin", "search success", "relev inform", "relev", "search strategi", "relev feedback"]}, "absent_kps": {"text": ["toler latenc", "advanc syntax", "navig behavior", "search behavior", "queri syntax", "advanc search featur", "expert search"], "tokenized": ["toler latenc", "advanc syntax", "navig behavior", "search behavior", "queri syntax", "advanc search featur", "expert search"]}}
{"id": 44, "title": {"text": "term feedback for information retrieval with language models .", "tokenized": "term feedback for information retrieval with language models ."}, "abstract": {"text": "in this paper we study term based feedback for information retrieval in the language modeling approach . with term feedback a user directly judges the relevance of individual terms without interaction with feedback documents , taking full control of the query expansion process . we propose a cluster based method for selecting terms to present to the user for judgment , as well as effective algorithms for constructing refined query language models from user term feedback . our algorithms are shown to bring significant improvement in retrieval accuracy over a non feedback baseline , and achieve comparable performance to relevance feedback . they are helpful even when there are no relevant documents in the top . categories and subject descriptors h . [digit] . [digit] information search and retrieval retrieval models general terms algorithms", "tokenized": "in this paper we study term based feedback for information retrieval in the language modeling approach . with term feedback a user directly judges the relevance of individual terms without interaction with feedback documents , taking full control of the query expansion process . we propose a cluster based method for selecting terms to present to the user for judgment , as well as effective algorithms for constructing refined query language models from user term feedback . our algorithms are shown to bring significant improvement in retrieval accuracy over a non feedback baseline , and achieve comparable performance to relevance feedback . they are helpful even when there are no relevant documents in the top . categories and subject descriptors h . [digit] . [digit] information search and retrieval retrieval models general terms algorithms"}, "present_kps": {"text": ["inform retriev", "languag model", "term base feedback"], "tokenized": ["inform retriev", "languag model", "term base feedback"]}, "absent_kps": {"text": ["queri expans process", "queri model", "interact adhoc search", "retriev perform", "probabl", "kl diverg", "present term", "queri expans", "interact retriev"], "tokenized": ["queri expans process", "queri model", "interact adhoc search", "retriev perform", "probabl", "kl diverg", "present term", "queri expans", "interact retriev"]}}
{"id": 45, "title": {"text": "a support vector method for optimizing average precision .", "tokenized": "a support vector method for optimizing average precision ."}, "abstract": {"text": "machine learning is commonly used to improve ranked retrieval systems . due to computational difficulties , few learning techniques have been developed to directly optimize for mean average precision ( map ) , despite its widespread use in evaluating such systems . existing approaches optimizing map either do not find a globally optimal solution , or are computationally expensive . in contrast , we present a general svm learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of map . we evaluate our approach using the trec [digit] and trec [digit] web track corpora ( wt10g ) , comparing against svms optimized for accuracy and rocarea . in most cases we show our method to produce statistically significant improvements in map scores . categories and subject descriptors h . [digit] . [digit] information search and retrieval retrieval models general terms algorithm , theory , experimentation", "tokenized": "machine learning is commonly used to improve ranked retrieval systems . due to computational difficulties , few learning techniques have been developed to directly optimize for mean average precision ( map ) , despite its widespread use in evaluating such systems . existing approaches optimizing map either do not find a globally optimal solution , or are computationally expensive . in contrast , we present a general svm learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of map . we evaluate our approach using the trec [digit] and trec [digit] web track corpora ( wt10g ) , comparing against svms optimized for accuracy and rocarea . in most cases we show our method to produce statistically significant improvements in map scores . categories and subject descriptors h . [digit] . [digit] information search and retrieval retrieval models general terms algorithm , theory , experimentation"}, "present_kps": {"text": ["machin learn", "rank retriev system", "rank", "learn techniqu", "optim solut"], "tokenized": ["machin learn", "rank retriev system", "rank", "learn techniqu", "optim solut"]}, "absent_kps": {"text": ["mean averag precis", "relax of map map relax", "inform retriev system", "probabl", "surrog measur", "loss function", "supervis learn", "machin learn for inform retriev", "support vector machin"], "tokenized": ["mean averag precis", "relax of map map relax", "inform retriev system", "probabl", "surrog measur", "loss function", "supervis learn", "machin learn for inform retriev", "support vector machin"]}}
{"id": 46, "title": {"text": "estimation and use of uncertainty in pseudo relevance feedback .", "tokenized": "estimation and use of uncertainty in pseudo relevance feedback ."}, "abstract": {"text": "existing pseudo relevance feedback methods typically perform averaging over the top retrieved documents , but ignore an important statistical dimension the risk or variance associated with either the individual document models , or their combination . treating the baseline feedback method as a black box , and the output feedback model as a random variable , we estimate a posterior distribution for the feedback model by resampling a given query s top retrieved documents , using the posterior mean or mode as the enhanced feedback model . we then perform model combination over several enhanced models , each based on a slightly modified query sampled from the original query . we find that resampling documents helps increase individual feedback model precision by removing noise terms , while sampling from the query improves robustness ( worst case performance ) by emphasizing terms related to multiple query aspects . the result is a meta feedback algorithm that is both more robust and more precise than the original strong baseline method . categories and subject descriptors h . [digit] . [digit] information retrieval retrieval models general terms algorithms , experimentation", "tokenized": "existing pseudo relevance feedback methods typically perform averaging over the top retrieved documents , but ignore an important statistical dimension the risk or variance associated with either the individual document models , or their combination . treating the baseline feedback method as a black box , and the output feedback model as a random variable , we estimate a posterior distribution for the feedback model by resampling a given query s top retrieved documents , using the posterior mean or mode as the enhanced feedback model . we then perform model combination over several enhanced models , each based on a slightly modified query sampled from the original query . we find that resampling documents helps increase individual feedback model precision by removing noise terms , while sampling from the query improves robustness ( worst case performance ) by emphasizing terms related to multiple query aspects . the result is a meta feedback algorithm that is both more robust and more precise than the original strong baseline method . categories and subject descriptors h . [digit] . [digit] information retrieval retrieval models general terms algorithms , experimentation"}, "present_kps": {"text": ["pseudo relev feedback", "feedback method", "risk", "feedback model", "posterior distribut", "enhanc feedback model", "inform retriev"], "tokenized": ["pseudo relev feedback", "feedback method", "risk", "feedback model", "posterior distribut", "enhanc feedback model", "inform retriev"]}, "absent_kps": {"text": ["queri expans", "probabl distribut", "vector space base algorithm", "estim uncertainti", "languag model", "feedback distribut"], "tokenized": ["queri expans", "probabl distribut", "vector space base algorithm", "estim uncertainti", "languag model", "feedback distribut"]}}
{"id": 47, "title": {"text": "latent concept expansion using markov random fields .", "tokenized": "latent concept expansion using markov random fields ."}, "abstract": {"text": "query expansion , in the form of pseudo relevance feedback or relevance feedback , is a common technique used to improve retrieval effectiveness . most previous approaches have ignored important issues , such as the role of features and the importance of modeling term dependencies . in this paper , we propose a robust query expansion technique based on the markov random field model for information retrieval . the technique , called latent concept expansion , provides a mechanism for modeling term dependencies during expansion . furthermore , the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques . we evaluate our technique against relevance models , a state of the art language modeling query expansion technique . our model demonstrates consistent and significant improvements in retrieval effectiveness across several trec data sets . we also describe how our technique can be used to generate meaningful multi term concepts for tasks such as query suggestion reformulation . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval general terms algorithms , experimentation , theory", "tokenized": "query expansion , in the form of pseudo relevance feedback or relevance feedback , is a common technique used to improve retrieval effectiveness . most previous approaches have ignored important issues , such as the role of features and the importance of modeling term dependencies . in this paper , we propose a robust query expansion technique based on the markov random field model for information retrieval . the technique , called latent concept expansion , provides a mechanism for modeling term dependencies during expansion . furthermore , the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques . we evaluate our technique against relevance models , a state of the art language modeling query expansion technique . our model demonstrates consistent and significant improvements in retrieval effectiveness across several trec data sets . we also describe how our technique can be used to generate meaningful multi term concepts for tasks such as query suggestion reformulation . categories and subject descriptors h . [digit] . [digit] information storage and retrieval information search and retrieval general terms algorithms , experimentation , theory"}, "present_kps": {"text": ["markov random field", "pseudo relev feedback", "relev feedback", "inform retriev"], "tokenized": ["markov random field", "pseudo relev feedback", "relev feedback", "inform retriev"]}, "absent_kps": {"text": ["mrf model", "ad hoc retriev", "document rout", "rm3", "languag model framework", "robust queri expans techniqu", "relev distribut", "queri expans", "web search", "languag model approach", "languag model queri expans techniqu", "rocchio algorithm", "mrf"], "tokenized": ["mrf model", "ad hoc retriev", "document rout", "rm3", "languag model framework", "robust queri expans techniqu", "relev distribut", "queri expans", "web search", "languag model approach", "languag model queri expans techniqu", "rocchio algorithm", "mrf"]}}
{"id": 48, "title": {"text": "a study of poisson query generation model for information retrieval .", "tokenized": "a study of poisson query generation model for information retrieval ."}, "abstract": {"text": "many variants of language models have been proposed for information retrieval . most existing models are based on multinomial distribution and would score documents based on query likelihood computed based on a query generation probabilistic model . in this paper , we propose and study a new family of query generation models based on poisson distribution . we show that while in their simplest forms , the new family of models and the existing multinomial models are equivalent , they behave differently for many smoothing methods . we show that the poisson model has several advantages over the multinomial model , including naturally accommodating per term smoothing and allowing for more accurate background modeling . we present several variants of the new model corresponding to different smoothing methods , and evaluate them on four representative trec test collections . the results show that while their basic models perform comparably , the poisson model can outperform multinomial model with per term smoothing . the performance can be further improved with two stage smoothing . categories and subject descriptors h . [digit] . [digit] information search and retrieval retrieval models general terms algorithms", "tokenized": "many variants of language models have been proposed for information retrieval . most existing models are based on multinomial distribution and would score documents based on query likelihood computed based on a query generation probabilistic model . in this paper , we propose and study a new family of query generation models based on poisson distribution . we show that while in their simplest forms , the new family of models and the existing multinomial models are equivalent , they behave differently for many smoothing methods . we show that the poisson model has several advantages over the multinomial model , including naturally accommodating per term smoothing and allowing for more accurate background modeling . we present several variants of the new model corresponding to different smoothing methods , and evaluate them on four representative trec test collections . the results show that while their basic models perform comparably , the poisson model can outperform multinomial model with per term smoothing . the performance can be further improved with two stage smoothing . categories and subject descriptors h . [digit] . [digit] information search and retrieval retrieval models general terms algorithms"}, "present_kps": {"text": ["queri gener", "languag model", "multinomi distribut", "queri gener probabilist model", "poisson distribut", "two stage smooth"], "tokenized": ["queri gener", "languag model", "multinomi distribut", "queri gener probabilist model", "poisson distribut", "two stage smooth"]}, "absent_kps": {"text": ["poisson process", "singl pseudo term", "homogen poisson process", "new term depend smooth algorithm", "formal model", "perterm smooth", "term frequenc", "speech recognit", "multivari bernoullu distribut", "vocabulari set", "term depend smooth"], "tokenized": ["poisson process", "singl pseudo term", "homogen poisson process", "new term depend smooth algorithm", "formal model", "perterm smooth", "term frequenc", "speech recognit", "multivari bernoullu distribut", "vocabulari set", "term depend smooth"]}}
{"id": 49, "title": {"text": "interesting nuggets and their impact on definitional question answering .", "tokenized": "interesting nuggets and their impact on definitional question answering ."}, "abstract": {"text": "current approaches to identifying definitional sentences in the context of question answering mainly involve the use of linguistic or syntactic patterns to identify informative nuggets . this is insufficient as they do not address the novelty factor that a definitional nugget must also possess . this paper proposes to address the deficiency by building a human interest model from external knowledge . it is hoped that such a model will allow the computation of human interest in the sentence with respect to the topic . we compare and contrast our model with current definitional question answering models to show that interestingness plays an important factor in definitional question answering . categories and subject descriptors h . [digit] . [digit] information search and retrieval retrieval models h . [digit] . [digit] user machine systems human factors general terms algorithms , human factors , experimentation", "tokenized": "current approaches to identifying definitional sentences in the context of question answering mainly involve the use of linguistic or syntactic patterns to identify informative nuggets . this is insufficient as they do not address the novelty factor that a definitional nugget must also possess . this paper proposes to address the deficiency by building a human interest model from external knowledge . it is hoped that such a model will allow the computation of human interest in the sentence with respect to the topic . we compare and contrast our model with current definitional question answering models to show that interestingness plays an important factor in definitional question answering . categories and subject descriptors h . [digit] . [digit] information search and retrieval retrieval models h . [digit] . [digit] user machine systems human factors general terms algorithms , human factors , experimentation"}, "present_kps": {"text": ["interest", "interest nugget", "definit question answer", "inform nugget", "human interest", "extern knowledg"], "tokenized": ["interest", "interest nugget", "definit question answer", "inform nugget", "human interest", "extern knowledg"]}, "absent_kps": {"text": ["new corpu", "sentenc fragment", "human reader", "comput of human interest human interest comput", "uniqu qualiti", "surpris factor", "lexic pattern", "manual labor", "baselin system", "question topic", "us of linguist linguist us"], "tokenized": ["new corpu", "sentenc fragment", "human reader", "comput of human interest human interest comput", "uniqu qualiti", "surpris factor", "lexic pattern", "manual labor", "baselin system", "question topic", "us of linguist linguist us"]}}
{"id": 50, "title": {"text": "aborting tasks in bdi agents .", "tokenized": "aborting tasks in bdi agents ."}, "abstract": {"text": "intelligent agents that are intended to work in dynamic environments must be able to gracefully handle unsuccessful tasks and plans . in addition , such agents should be able to make rational decisions about an appropriate course of action , which may include aborting a task or plan , either as a result of the agent s own deliberations , or potentially at the request of another agent . in this paper we investigate the incorporation of aborts into a bdi style architecture . we discuss some conditions under which aborting a task or plan is appropriate , and how to determine the consequences of such a decision . we augment each plan with an optional abort method , analogous to the failure method found in some agent programming languages . we provide an operational semantics for the execution cycle in the presence of aborts in the abstract agent language can , which enables us to specify a bdi based execution model without limiting our attention to a particular agent system ( such as jack , jadex , jason , or spark ) . a key technical challenge we address is the presence of parallel execution threads and of sub tasks , which require the agent to ensure that the abort methods for each plan are carried out in an appropriate sequence . categories and subject descriptors i . [digit] . [digit] artificial intelligence distributed artificial intelligence intelligent agents general terms design , reliability , theory", "tokenized": "intelligent agents that are intended to work in dynamic environments must be able to gracefully handle unsuccessful tasks and plans . in addition , such agents should be able to make rational decisions about an appropriate course of action , which may include aborting a task or plan , either as a result of the agent s own deliberations , or potentially at the request of another agent . in this paper we investigate the incorporation of aborts into a bdi style architecture . we discuss some conditions under which aborting a task or plan is appropriate , and how to determine the consequences of such a decision . we augment each plan with an optional abort method , analogous to the failure method found in some agent programming languages . we provide an operational semantics for the execution cycle in the presence of aborts in the abstract agent language can , which enables us to specify a bdi based execution model without limiting our attention to a particular agent system ( such as jack , jadex , jason , or spark ) . a key technical challenge we address is the presence of parallel execution threads and of sub tasks , which require the agent to ensure that the abort methods for each plan are carried out in an appropriate sequence . categories and subject descriptors i . [digit] . [digit] artificial intelligence distributed artificial intelligence intelligent agents general terms design , reliability , theory"}, "present_kps": {"text": ["task", "agent", "intellig agent", "abort method", "failur", "oper semant"], "tokenized": ["task", "agent", "intellig agent", "abort method", "failur", "oper semant"]}, "absent_kps": {"text": ["deal", "cleanup method", "goal", "goal construct", "reactiv and delib architectur", "formal model of agenc agenc formal model"], "tokenized": ["deal", "cleanup method", "goal", "goal construct", "reactiv and delib architectur", "formal model of agenc agenc formal model"]}}
{"id": 51, "title": {"text": "meta level coordination for solving negotiation chains in semi cooperative multi agent systems .", "tokenized": "meta level coordination for solving negotiation chains in semi cooperative multi agent systems ."}, "abstract": {"text": "a negotiation chain is formed when multiple related negotiations are spread over multiple agents . in order to appropriately order and structure the negotiations occurring in the chain so as to optimize the expected utility , we present an extension to a <unk> concurrent negotiation framework . this work is aimed at semi cooperative multi agent systems , where each agent has its own goals and works to maximize its local utility however , the performance of each individual agent is tightly related to other agent s cooperation and the system s overall performance . we introduce a pre negotiation phase that allows agents to transfer meta level information . using this information , the agent can build a more accurate model of the negotiation in terms of modeling the relationship of flexibility and success probability . this more accurate model helps the agent in choosing a better negotiation solution in the global negotiation chain context . the agent can also use this information to allocate appropriate time for each negotiation , hence to find a good ordering of all related negotiations . the experimental data shows that these mechanisms improve the agents and the system s overall performance significantly . categories and subject descriptors i . [digit] . [digit] distributed artificial intelligence multiagent systems general terms algorithms , performance , experimentation", "tokenized": "a negotiation chain is formed when multiple related negotiations are spread over multiple agents . in order to appropriately order and structure the negotiations occurring in the chain so as to optimize the expected utility , we present an extension to a <unk> concurrent negotiation framework . this work is aimed at semi cooperative multi agent systems , where each agent has its own goals and works to maximize its local utility however , the performance of each individual agent is tightly related to other agent s cooperation and the system s overall performance . we introduce a pre negotiation phase that allows agents to transfer meta level information . using this information , the agent can build a more accurate model of the negotiation in terms of modeling the relationship of flexibility and success probability . this more accurate model helps the agent in choosing a better negotiation solution in the global negotiation chain context . the agent can also use this information to allocate appropriate time for each negotiation , hence to find a good ordering of all related negotiations . the experimental data shows that these mechanisms improve the agents and the system s overall performance significantly . categories and subject descriptors i . [digit] . [digit] distributed artificial intelligence multiagent systems general terms algorithms , performance , experimentation"}, "present_kps": {"text": ["negoti chain", "semi cooper multi agent system", "agent", "multipl agent", "negoti framework", "pre negoti", "flexibl"], "tokenized": ["negoti chain", "semi cooper multi agent system", "agent", "multipl agent", "negoti framework", "pre negoti", "flexibl"]}, "absent_kps": {"text": ["multi link negoti", "distribut set", "multipl concurr task", "virtual organ", "sub task reloc", "reput mechan", "complex suppli chain scenario", "multi link negoti"], "tokenized": ["multi link negoti", "distribut set", "multipl concurr task", "virtual organ", "sub task reloc", "reput mechan", "complex suppli chain scenario", "multi link negoti"]}}
{"id": 52, "title": {"text": "towards self organising agent based resource allocation in a multi server environment .", "tokenized": "towards self organising agent based resource allocation in a multi server environment ."}, "abstract": {"text": "distributed applications require distributed techniques for efficient resource allocation . these techniques need to take into account the heterogeneity and potential unreliability of resources and resource consumers in a distributed environments . in this paper we propose a distributed algorithm that solves the resource allocation problem in distributed multiagent systems . our solution is based on the self organisation of agents , which does not require any facilitator or management layer . the resource allocation in the system is a purely emergent effect . we present results of the proposed resource allocation mechanism in the simulated static and dynamic multi server environment . categories and subject descriptors i . [digit] . [digit] distributed artificial intelligence coherence and coordination general terms algorithms", "tokenized": "distributed applications require distributed techniques for efficient resource allocation . these techniques need to take into account the heterogeneity and potential unreliability of resources and resource consumers in a distributed environments . in this paper we propose a distributed algorithm that solves the resource allocation problem in distributed multiagent systems . our solution is based on the self organisation of agents , which does not require any facilitator or management layer . the resource allocation in the system is a purely emergent effect . we present results of the proposed resource allocation mechanism in the simulated static and dynamic multi server environment . categories and subject descriptors i . [digit] . [digit] distributed artificial intelligence coherence and coordination general terms algorithms"}, "present_kps": {"text": ["agent", "resourc alloc", "distribut algorithm"], "tokenized": ["agent", "resourc alloc", "distribut algorithm"]}, "absent_kps": {"text": ["multi agent system", "dynam alloc task", "network of server server network", "server utilis", "adapt process", "competit", "predictor", "distribut control", "self organis"], "tokenized": ["multi agent system", "dynam alloc task", "network of server server network", "server utilis", "adapt process", "competit", "predictor", "distribut control", "self organis"]}}
{"id": 53, "title": {"text": "dynamic semantics for agent communication languages .", "tokenized": "dynamic semantics for agent communication languages ."}, "abstract": {"text": "this paper proposes dynamic semantics for agent communication languages ( acls ) as a method for tackling some of the fundamental problems associated with agent communication in open multiagent systems . based on the idea of providing alternative semantic variants for speech acts and transition rules between them that are contingent on previous agent behaviour , our framework provides an improved notion of grounding semantics in ongoing interaction , a simple mechanism for distinguishing between compliant and expected behaviour , and a way to specify sanction and reward mechanisms as part of the acl itself . we extend a common framework for commitment based acl semantics to obtain these properties , discuss desiderata for the design of concrete dynamic semantics together with examples , and analyse their properties . categories and subject descriptors i . [digit] . [digit] artificial intelligence distributed artificial intelligence multiagent systems", "tokenized": "this paper proposes dynamic semantics for agent communication languages ( acls ) as a method for tackling some of the fundamental problems associated with agent communication in open multiagent systems . based on the idea of providing alternative semantic variants for speech acts and transition rules between them that are contingent on previous agent behaviour , our framework provides an improved notion of grounding semantics in ongoing interaction , a simple mechanism for distinguishing between compliant and expected behaviour , and a way to specify sanction and reward mechanisms as part of the acl itself . we extend a common framework for commitment based acl semantics to obtain these properties , discuss desiderata for the design of concrete dynamic semantics together with examples , and analyse their properties . categories and subject descriptors i . [digit] . [digit] artificial intelligence distributed artificial intelligence multiagent systems"}, "present_kps": {"text": ["dynam semant", "agent commun languag"], "tokenized": ["dynam semant", "agent commun languag"]}, "absent_kps": {"text": ["social reason", "commit base semant", "state transit system", "reput base adapt", "mutual of expect expect mutual", "recoveri mechan", "non redund", "social reason"], "tokenized": ["social reason", "commit base semant", "state transit system", "reput base adapt", "mutual of expect expect mutual", "recoveri mechan", "non redund", "social reason"]}}
{"id": 54, "title": {"text": "commitment and extortion .", "tokenized": "commitment and extortion ."}, "abstract": {"text": "making commitments , e . g . , through promises and threats , enables a player to exploit the strengths of his own strategic position as well as the weaknesses of that of his opponents . which commitments a player can make with credibility depends on the circumstances . in some , a player can only commit to the performance of an action , in others , he can commit himself conditionally on the actions of the other players . some situations even allow for commitments on commitments or for commitments to randomized actions . we explore the formal properties of these types of ( conditional ) commitment and their interrelationships . so as to preclude inconsistencies among conditional commitments , we assume an order in which the players make their commitments . central to our analyses is the notion of an extortion , which we define , for a given order of the players , as a profile that contains , for each player , an optimal commitment given the commitments of the players that committed earlier . on this basis , we investigate for different commitment types whether it is advantageous to commit earlier rather than later , and how the outcomes obtained through extortions relate to backward induction and pareto efficiency . general terms economics , theory categories and subject descriptors i . [digit] . [digit] distributed artificial intelligence multiagent systems j . [digit] computer applications social and behavioral <unk>", "tokenized": "making commitments , e . g . , through promises and threats , enables a player to exploit the strengths of his own strategic position as well as the weaknesses of that of his opponents . which commitments a player can make with credibility depends on the circumstances . in some , a player can only commit to the performance of an action , in others , he can commit himself conditionally on the actions of the other players . some situations even allow for commitments on commitments or for commitments to randomized actions . we explore the formal properties of these types of ( conditional ) commitment and their interrelationships . so as to preclude inconsistencies among conditional commitments , we assume an order in which the players make their commitments . central to our analyses is the notion of an extortion , which we define , for a given order of the players , as a profile that contains , for each player , an optimal commitment given the commitments of the players that committed earlier . on this basis , we investigate for different commitment types whether it is advantageous to commit earlier rather than later , and how the outcomes obtained through extortions relate to backward induction and pareto efficiency . general terms economics , theory categories and subject descriptors i . [digit] . [digit] distributed artificial intelligence multiagent systems j . [digit] computer applications social and behavioral <unk>"}, "present_kps": {"text": ["commit", "extort", "strateg posit", "credibl", "pareto effici", "multiag system"], "tokenized": ["commit", "extort", "strateg posit", "credibl", "pareto effici", "multiag system"]}, "absent_kps": {"text": ["game theori", "decis make", "freedom of action action freedom", "distribut comput", "electron market", "stackleberg set", "optim condit commit", "sequenti commit type", "induct hypothesi", "pareto effici condit extort"], "tokenized": ["game theori", "decis make", "freedom of action action freedom", "distribut comput", "electron market", "stackleberg set", "optim condit commit", "sequenti commit type", "induct hypothesi", "pareto effici condit extort"]}}
{"id": 55, "title": {"text": "temporal linear logic as a basis for flexible agent interactions .", "tokenized": "temporal linear logic as a basis for flexible agent interactions ."}, "abstract": {"text": "interactions between agents in an open system such as the internet require a significant degree of flexibility . a crucial aspect of the development of such methods is the notion of commitments , which provides a mechanism for coordinating interactive behaviors among agents . in this paper , we investigate an approach to model commitments with tight integration with protocol actions . this means that there is no need to have an explicit mapping from protocols actions to operations on commitments and an external mechanism to process and enforce commitments . we show how agents can reason about commitments and protocol actions to achieve the end results of protocols using a reasoning system based on temporal linear logic , which incorporates both temporal and resource sensitive reasoning . we also discuss the application of this framework to scenarios such as online commerce . categories and subject descriptors i . [digit] . [digit] distributed artificial intelligence intelligent agents d . [digit] . [digit] programming languages language classifications general terms theory , design", "tokenized": "interactions between agents in an open system such as the internet require a significant degree of flexibility . a crucial aspect of the development of such methods is the notion of commitments , which provides a mechanism for coordinating interactive behaviors among agents . in this paper , we investigate an approach to model commitments with tight integration with protocol actions . this means that there is no need to have an explicit mapping from protocols actions to operations on commitments and an external mechanism to process and enforce commitments . we show how agents can reason about commitments and protocol actions to achieve the end results of protocols using a reasoning system based on temporal linear logic , which incorporates both temporal and resource sensitive reasoning . we also discuss the application of this framework to scenarios such as online commerce . categories and subject descriptors i . [digit] . [digit] distributed artificial intelligence intelligent agents d . [digit] . [digit] programming languages language classifications general terms theory , design"}, "present_kps": {"text": ["linear logic", "interact behavior"], "tokenized": ["linear logic", "interact behavior"]}, "absent_kps": {"text": ["multi agent environ", "tempor constraint", "interact protocol", "multipl conjunct", "classic conjunct", "level of predict predict level", "pre commit", "linear implic", "emerg protocol", "condit commit", "request messag", "causal relationship", "agent commun languag and protocol", "logic and formal model of agenc and multi agent system"], "tokenized": ["multi agent environ", "tempor constraint", "interact protocol", "multipl conjunct", "classic conjunct", "level of predict predict level", "pre commit", "linear implic", "emerg protocol", "condit commit", "request messag", "causal relationship", "agent commun languag and protocol", "logic and formal model of agenc and multi agent system"]}}
{"id": 56, "title": {"text": "smile sound multi agent incremental learning .", "tokenized": "smile sound multi agent incremental learning ."}, "abstract": {"text": "this article deals with the problem of collaborative learning in a multi agent system . here each agent can update incrementally its beliefs b ( the concept representation ) so that it is in a way kept consistent with the whole set of information k ( the examples ) that he has received from the environment or other agents . we extend this notion of consistency ( or soundness ) to the whole mas and discuss how to obtain that , at any moment , a same consistent concept representation is present in each agent . the corresponding protocol is applied to supervised concept learning . the resulting method smile ( standing for sound multiagent incremental learning ) is described and experimented here . surprisingly some difficult boolean formulas are better learned , given the same learning set , by a multi agent system than by a single agent . categories and subject descriptors i . [digit] . [digit] artificial intelligence learning concept learning i . [digit] . [digit] artificial intelligence distributed artificial intelligence multiagent system general terms experimentation , algorithms , measurement , performance", "tokenized": "this article deals with the problem of collaborative learning in a multi agent system . here each agent can update incrementally its beliefs b ( the concept representation ) so that it is in a way kept consistent with the whole set of information k ( the examples ) that he has received from the environment or other agents . we extend this notion of consistency ( or soundness ) to the whole mas and discuss how to obtain that , at any moment , a same consistent concept representation is present in each agent . the corresponding protocol is applied to supervised concept learning . the resulting method smile ( standing for sound multiagent incremental learning ) is described and experimented here . surprisingly some difficult boolean formulas are better learned , given the same learning set , by a multi agent system than by a single agent . categories and subject descriptors i . [digit] . [digit] artificial intelligence learning concept learning i . [digit] . [digit] artificial intelligence distributed artificial intelligence multiagent system general terms experimentation , algorithms , measurement , performance"}, "present_kps": {"text": ["agent", "increment learn"], "tokenized": ["agent", "increment learn"]}, "absent_kps": {"text": ["multi agent learn", "collabor concept learn", "learn process", "knowledg", "ma consist", "updat mechan", "synchron", "multi agent learn"], "tokenized": ["multi agent learn", "collabor concept learn", "learn process", "knowledg", "ma consist", "updat mechan", "synchron", "multi agent learn"]}}
{"id": 57, "title": {"text": "real time agent characterization and prediction .", "tokenized": "real time agent characterization and prediction ."}, "abstract": {"text": "reasoning about agents that we observe in the world is challenging . our available information is often limited to observations of the agent s external behavior in the past and present . to understand these actions , we need to deduce the agent s internal state , which includes not only rational elements ( such as intentions and plans ) , but also emotive ones ( such as fear ) . in addition , we often want to predict the agent s future actions , which are constrained not only by these inward characteristics , but also by the dynamics of the agent s interaction with its environment . bee ( behavior evolution and extrapolation ) uses a faster than real time agentbased model of the environment to characterize agents internal state by evolution against observed behavior , and then predict their future behavior , taking into account the dynamics of their interaction with the environment . categories and subject descriptors i . [digit] . [digit] artificial intelligence learning parameter learning . i . [digit] . [digit] artificial intelligence distributed artificial intelligence multiagent systems . general terms algorithms , measurement , experimentation .", "tokenized": "reasoning about agents that we observe in the world is challenging . our available information is often limited to observations of the agent s external behavior in the past and present . to understand these actions , we need to deduce the agent s internal state , which includes not only rational elements ( such as intentions and plans ) , but also emotive ones ( such as fear ) . in addition , we often want to predict the agent s future actions , which are constrained not only by these inward characteristics , but also by the dynamics of the agent s interaction with its environment . bee ( behavior evolution and extrapolation ) uses a faster than real time agentbased model of the environment to characterize agents internal state by evolution against observed behavior , and then predict their future behavior , taking into account the dynamics of their interaction with the environment . categories and subject descriptors i . [digit] . [digit] artificial intelligence learning parameter learning . i . [digit] . [digit] artificial intelligence distributed artificial intelligence multiagent systems . general terms algorithms , measurement , experimentation ."}, "present_kps": {"text": ["predict", "extern behavior", "intern state", "emot", "dynam", "behavior evolut and extrapol", "evolut", "futur behavior"], "tokenized": ["predict", "extern behavior", "intern state", "emot", "dynam", "behavior evolut and extrapol", "evolut", "futur behavior"]}, "absent_kps": {"text": ["swarm intellig", "bdi", "plan infer", "agent reason", "digit pheromon", "pheromon flavor", "agent ' s goal", "nonlinear dynam system", "agent behavior predict", "plan recognit", "disposit"], "tokenized": ["swarm intellig", "bdi", "plan infer", "agent reason", "digit pheromon", "pheromon flavor", "agent ' s goal", "nonlinear dynam system", "agent behavior predict", "plan recognit", "disposit"]}}
{"id": 58, "title": {"text": "sharing experiences to learn user characteristics in dynamic environments with sparse data .", "tokenized": "sharing experiences to learn user characteristics in dynamic environments with sparse data ."}, "abstract": {"text": "this paper investigates the problem of estimating the value of probabilistic parameters needed for decision making in environments in which an agent , operating within a multi agent system , has no a priori information about the structure of the distribution of parameter values . the agent must be able to produce estimations even when it may have made only a small number of direct observations , and thus it must be able to operate with sparse data . the paper describes a mechanism that enables the agent to significantly improve its estimation by augmenting its direct observations with those obtained by other agents with which it is coordinating . to avoid undesirable bias in relatively heterogeneous environments while effectively using relevant data to improve its estimations , the mechanism weighs the contributions of other agents observations based on a real time estimation of the level of similarity between each of these agents and itself . the coordination autonomy module of a coordination manager system provided an empirical setting for evaluation . simulation based evaluations demonstrated that the proposed mechanism outperforms estimations based exclusively on an agent s own observations as well as estimations based on an unweighted aggregate of all other agents observations . categories and subject descriptors i . [digit] . [digit] artificial intelligence learning parameter learning i . [digit] . [digit] artificial intelligence distributed artificial intelligence intelligent agents , multiagent systems g . [digit] mathematics of computing probability and statistics distribution functions general terms algorithms , experimentation", "tokenized": "this paper investigates the problem of estimating the value of probabilistic parameters needed for decision making in environments in which an agent , operating within a multi agent system , has no a priori information about the structure of the distribution of parameter values . the agent must be able to produce estimations even when it may have made only a small number of direct observations , and thus it must be able to operate with sparse data . the paper describes a mechanism that enables the agent to significantly improve its estimation by augmenting its direct observations with those obtained by other agents with which it is coordinating . to avoid undesirable bias in relatively heterogeneous environments while effectively using relevant data to improve its estimations , the mechanism weighs the contributions of other agents observations based on a real time estimation of the level of similarity between each of these agents and itself . the coordination autonomy module of a coordination manager system provided an empirical setting for evaluation . simulation based evaluations demonstrated that the proposed mechanism outperforms estimations based exclusively on an agent s own observations as well as estimations based on an unweighted aggregate of all other agents observations . categories and subject descriptors i . [digit] . [digit] artificial intelligence learning parameter learning i . [digit] . [digit] artificial intelligence distributed artificial intelligence intelligent agents , multiagent systems g . [digit] mathematics of computing probability and statistics distribution functions general terms algorithms , experimentation"}, "present_kps": {"text": ["probabilist paramet", "agent"], "tokenized": ["probabilist paramet", "agent"]}, "absent_kps": {"text": ["inform share", "decis make", "fast pace environ", "multi agent distribut system", "learn mechan", "select share", "paramet estim", "adjust autonomi", "interrupt manag"], "tokenized": ["inform share", "decis make", "fast pace environ", "multi agent distribut system", "learn mechan", "select share", "paramet estim", "adjust autonomi", "interrupt manag"]}}
{"id": 59, "title": {"text": "a reinforcement learning based distributed search algorithm for hierarchical peer to peer information retrieval systems .", "tokenized": "a reinforcement learning based distributed search algorithm for hierarchical peer to peer information retrieval systems ."}, "abstract": {"text": "the dominant existing routing strategies employed in peerto peer ( p2p ) based information retrieval ( ir ) systems are similarity based approaches . in these approaches , agents depend on the content similarity between incoming queries and their direct neighboring agents to direct the distributed search sessions . however , such a heuristic is myopic in that the neighboring agents may not be connected to more relevant agents . in this paper , an online reinforcement learning based approach is developed to take advantage of the dynamic run time characteristics of p2p ir systems as represented by information about past search sessions . specifically , agents maintain estimates on the downstream agents abilities to provide relevant documents for incoming queries . these estimates are updated gradually by learning from the feedback information returned from previous search sessions . based on this information , the agents derive corresponding routing policies . thereafter , these agents route the queries based on the learned policies and update the estimates based on the new routing policies . experimental results demonstrate that the learning algorithm improves considerably the routing performance on two test collection sets that have been used in a variety of distributed ir studies . categories and subject descriptors i . [digit] . [digit] distributed artificial intelligence multiagent systems general terms algorithms , performance , experimentation", "tokenized": "the dominant existing routing strategies employed in peerto peer ( p2p ) based information retrieval ( ir ) systems are similarity based approaches . in these approaches , agents depend on the content similarity between incoming queries and their direct neighboring agents to direct the distributed search sessions . however , such a heuristic is myopic in that the neighboring agents may not be connected to more relevant agents . in this paper , an online reinforcement learning based approach is developed to take advantage of the dynamic run time characteristics of p2p ir systems as represented by information about past search sessions . specifically , agents maintain estimates on the downstream agents abilities to provide relevant documents for incoming queries . these estimates are updated gradually by learning from the feedback information returned from previous search sessions . based on this information , the agents derive corresponding routing policies . thereafter , these agents route the queries based on the learned policies and update the estimates based on the new routing policies . experimental results demonstrate that the learning algorithm improves considerably the routing performance on two test collection sets that have been used in a variety of distributed ir studies . categories and subject descriptors i . [digit] . [digit] distributed artificial intelligence multiagent systems general terms algorithms , performance , experimentation"}, "present_kps": {"text": ["reinforc learn", "distribut search algorithm", "peer to peer inform retriev system", "peer to peer inform retriev", "queri", "rout polici", "learn algorithm"], "tokenized": ["reinforc learn", "distribut search algorithm", "peer to peer inform retriev system", "peer to peer inform retriev", "queri", "rout polici", "learn algorithm"]}, "absent_kps": {"text": ["rout decis", "util", "network", "multi agent learn", "distribut search control"], "tokenized": ["rout decis", "util", "network", "multi agent learn", "distribut search control"]}}
{"id": 60, "title": {"text": "information searching and sharing in large scale dynamic networks .", "tokenized": "information searching and sharing in large scale dynamic networks ."}, "abstract": {"text": "finding the right agents in a large and dynamic network to provide the needed resources in a timely fashion , is a long standing problem . this paper presents a method for information searching and sharing that combines routing indices with <unk> methods . the proposed method enables agents to search effectively by acquiring their neighbors interests , advertising their information provision abilities and maintaining indices for routing queries , in an integrated way . specifically , the paper demonstrates through performance experiments how static and dynamic networks of agents can be tuned to answer queries effectively as they gather evidence for the interests and information provision abilities of others , without altering the topology or imposing an overlay structure to the network of acquaintances . categories and subject descriptors i . [digit] . [digit] artificial intelligence distributed artificial intelligence", "tokenized": "finding the right agents in a large and dynamic network to provide the needed resources in a timely fashion , is a long standing problem . this paper presents a method for information searching and sharing that combines routing indices with <unk> methods . the proposed method enables agents to search effectively by acquiring their neighbors interests , advertising their information provision abilities and maintaining indices for routing queries , in an integrated way . specifically , the paper demonstrates through performance experiments how static and dynamic networks of agents can be tuned to answer queries effectively as they gather evidence for the interests and information provision abilities of others , without altering the topology or imposing an overlay structure to the network of acquaintances . categories and subject descriptors i . [digit] . [digit] artificial intelligence distributed artificial intelligence"}, "present_kps": {"text": ["inform search and share", "perform"], "tokenized": ["inform search and share", "perform"]}, "absent_kps": {"text": ["social network", "cooper agent", "peer to peer search network", "peer to peer system", "dynam and larg scale network", "decentr partial observ markov decis process", "decentr control", "myopic algorithm", "knn approach", "gradient search scheme", "artifici social system", "scalabl", "robust", "depend"], "tokenized": ["social network", "cooper agent", "peer to peer search network", "peer to peer system", "dynam and larg scale network", "decentr partial observ markov decis process", "decentr control", "myopic algorithm", "knn approach", "gradient search scheme", "artifici social system", "scalabl", "robust", "depend"]}}
{"id": 61, "title": {"text": "an advanced bidding agent for advertisement selection on public displays .", "tokenized": "an advanced bidding agent for advertisement selection on public displays ."}, "abstract": {"text": "in this paper we present an advanced bidding agent that participates in first price sealed bid auctions to allocate advertising space on bluscreen an experimental public advertisement system that detects users through the presence of their bluetooth enabled devices . our bidding agent is able to build probabilistic models of both the behaviour of users who view the adverts , and the auctions that it participates within . it then uses these models to maximise the exposure that its adverts receive . we evaluate the effectiveness of this bidding agent through simulation against a range of alternative selection mechanisms including a simple bidding strategy , random allocation , and a centralised optimal allocation with perfect foresight . our bidding agent significantly outperforms both the simple bidding strategy and the random allocation , and in a mixed population of agents it is able to expose its adverts to [digit] % more users than the simple bidding strategy . moreover , its performance is within [digit] . [digit] % of that of the centralised optimal allocation despite the highly uncertain environment in which it must operate . categories and subject descriptors i . [digit] . [digit] distributed artificial intelligence intelligent agents general terms algorithms , design , theory", "tokenized": "in this paper we present an advanced bidding agent that participates in first price sealed bid auctions to allocate advertising space on bluscreen an experimental public advertisement system that detects users through the presence of their bluetooth enabled devices . our bidding agent is able to build probabilistic models of both the behaviour of users who view the adverts , and the auctions that it participates within . it then uses these models to maximise the exposure that its adverts receive . we evaluate the effectiveness of this bidding agent through simulation against a range of alternative selection mechanisms including a simple bidding strategy , random allocation , and a centralised optimal allocation with perfect foresight . our bidding agent significantly outperforms both the simple bidding strategy and the random allocation , and in a mixed population of agents it is able to expose its adverts to [digit] % more users than the simple bidding strategy . moreover , its performance is within [digit] . [digit] % of that of the centralised optimal allocation despite the highly uncertain environment in which it must operate . categories and subject descriptors i . [digit] . [digit] distributed artificial intelligence intelligent agents general terms algorithms , design , theory"}, "present_kps": {"text": ["advanc bid agent", "bid agent", "auction", "bluscreen", "bluetooth", "probabilist model", "distribut artifici intellig"], "tokenized": ["advanc bid agent", "bid agent", "auction", "bluscreen", "bluetooth", "probabilist model", "distribut artifici intellig"]}, "absent_kps": {"text": ["experiment public advertis system", "centralis optim alloc", "decentralis multi agent auction mechan", "independ poisson process", "decis theoret approach", "stochast optimis algorithm", "public displai"], "tokenized": ["experiment public advertis system", "centralis optim alloc", "decentralis multi agent auction mechan", "independ poisson process", "decis theoret approach", "stochast optimis algorithm", "public displai"]}}
{"id": 62, "title": {"text": "collaboration among a satellite swarm .", "tokenized": "collaboration among a satellite swarm ."}, "abstract": {"text": "the paper deals with on board planning for a satellite swarm via communication and negotiation . we aim at defining individual behaviours that result in a global behaviour that meets the mission requirements . we will present the formalization of the problem , a communication protocol , a solving method based on reactive decision rules , and first results . categories and subject descriptors h . [digit] information systems applications miscellaneous i . [digit] . [digit] artificial intelligence problem solving , control methods , and search plan execution , formation , and generation i . [digit] . [digit] artificial intelligence distributed artificial intelligence coherence and coordination general terms algorithms", "tokenized": "the paper deals with on board planning for a satellite swarm via communication and negotiation . we aim at defining individual behaviours that result in a global behaviour that meets the mission requirements . we will present the formalization of the problem , a communication protocol , a solving method based on reactive decision rules , and first results . categories and subject descriptors h . [digit] information systems applications miscellaneous i . [digit] . [digit] artificial intelligence problem solving , control methods , and search plan execution , formation , and generation i . [digit] . [digit] artificial intelligence distributed artificial intelligence coherence and coordination general terms algorithms"}, "present_kps": {"text": ["satellit swarm", "on board plan", "commun and negoti", "inform system applic", "coordin"], "tokenized": ["satellit swarm", "on board plan", "commun and negoti", "inform system applic", "coordin"]}, "absent_kps": {"text": ["reactiv decis rule", "multiag system", "task and resourc alloc", "objectag architectur", "teamag", "dip", "prospect ant", "cooper distribut problem solv", "cooper and teamwork"], "tokenized": ["reactiv decis rule", "multiag system", "task and resourc alloc", "objectag architectur", "teamag", "dip", "prospect ant", "cooper distribut problem solv", "cooper and teamwork"]}}
{"id": 63, "title": {"text": "bidding optimally in concurrent second price auctions of perfectly substitutable goods .", "tokenized": "bidding optimally in concurrent second price auctions of perfectly substitutable goods ."}, "abstract": {"text": "we derive optimal bidding strategies for a global bidding agent that participates in multiple , simultaneous second price auctions with perfect substitutes . we first consider a model where all other bidders are local and participate in a single auction . for this case , we prove that , assuming free disposal , the global bidder should always place non zero bids in all available auctions , irrespective of the local bidders valuation distribution . furthermore , for non decreasing valuation distributions , we prove that the problem of finding the optimal bids reduces to two dimensions . these results hold both in the case where the number of local bidders is known and when this number is determined by a poisson distribution . this analysis extends to online markets where , typically , auctions occur both concurrently and sequentially . in addition , by combining analytical and simulation results , we demonstrate that similar results hold in the case of several global bidders , provided that the market consists of both global and local bidders . finally , we address the efficiency of the overall market , and show that information about the number of local bidders is an important determinant for the way in which a global bidder affects efficiency . categories and subject descriptors i . [digit] . [digit] distributed artificial intelligence multiagent systems j . [digit] social and behavioral sciences economics general terms economics", "tokenized": "we derive optimal bidding strategies for a global bidding agent that participates in multiple , simultaneous second price auctions with perfect substitutes . we first consider a model where all other bidders are local and participate in a single auction . for this case , we prove that , assuming free disposal , the global bidder should always place non zero bids in all available auctions , irrespective of the local bidders valuation distribution . furthermore , for non decreasing valuation distributions , we prove that the problem of finding the optimal bids reduces to two dimensions . these results hold both in the case where the number of local bidders is known and when this number is determined by a poisson distribution . this analysis extends to online markets where , typically , auctions occur both concurrently and sequentially . in addition , by combining analytical and simulation results , we demonstrate that similar results hold in the case of several global bidders , provided that the market consists of both global and local bidders . finally , we address the efficiency of the overall market , and show that information about the number of local bidders is an important determinant for the way in which a global bidder affects efficiency . categories and subject descriptors i . [digit] . [digit] distributed artificial intelligence multiagent systems j . [digit] social and behavioral sciences economics general terms economics"}, "present_kps": {"text": ["optim bid strategi", "global bid agent", "simultan second price auction", "perfect substitut", "onlin market", "multiag system", "social and behavior scienc"], "tokenized": ["optim bid strategi", "global bid agent", "simultan second price auction", "perfect substitut", "onlin market", "multiag system", "social and behavior scienc"]}, "absent_kps": {"text": ["non decreas valuat distribut", "market effici", "vickrei auction", "utilitymaximis strategi", "simultan auction"], "tokenized": ["non decreas valuat distribut", "market effici", "vickrei auction", "utilitymaximis strategi", "simultan auction"]}}
{"id": 64, "title": {"text": "computing the banzhaf power index in network flow games .", "tokenized": "computing the banzhaf power index in network flow games ."}, "abstract": {"text": "preference aggregation is used in a variety of multiagent applications , and as a result , voting theory has become an important topic in multiagent system research . however , power indices ( which reflect how much real power a voter has in a weighted voting system ) have received relatively little attention , although they have long been studied in political science and economics . the banzhaf power index is one of the most popular it is also well defined for any simple coalitional game . in this paper , we examine the computational complexity of calculating the banzhaf power index within a particular multiagent domain , a network flow game . agents control the edges of a graph a coalition wins if it can send a flow of a given size from a source vertex to a target vertex . the relative power of each edge agent reflects its significance in enabling such a flow , and in real world networks could be used , for example , to allocate resources for maintaining parts of the network . we show that calculating the banzhaf power index of each agent in this network flow domain is p complete . we also show that for some restricted network flow domains there exists a polynomial algorithm to calculate agents banzhaf power indices . categories and subject descriptors f . [digit] theory of computation analysis of algorithms and problem complexity i . [digit] . [digit] artificial intelligence distributed artificial <unk> systems j . [digit] computer applications social and behavioral <unk> general terms algorithms , theory , economics", "tokenized": "preference aggregation is used in a variety of multiagent applications , and as a result , voting theory has become an important topic in multiagent system research . however , power indices ( which reflect how much real power a voter has in a weighted voting system ) have received relatively little attention , although they have long been studied in political science and economics . the banzhaf power index is one of the most popular it is also well defined for any simple coalitional game . in this paper , we examine the computational complexity of calculating the banzhaf power index within a particular multiagent domain , a network flow game . agents control the edges of a graph a coalition wins if it can send a flow of a given size from a source vertex to a target vertex . the relative power of each edge agent reflects its significance in enabling such a flow , and in real world networks could be used , for example , to allocate resources for maintaining parts of the network . we show that calculating the banzhaf power index of each agent in this network flow domain is p complete . we also show that for some restricted network flow domains there exists a polynomial algorithm to calculate agents banzhaf power indices . categories and subject descriptors f . [digit] theory of computation analysis of algorithms and problem complexity i . [digit] . [digit] artificial intelligence distributed artificial <unk> systems j . [digit] computer applications social and behavioral <unk> general terms algorithms , theory , economics"}, "present_kps": {"text": ["banzhaf power index", "power index", "network flow game", "prefer aggreg", "multiag applic", "vote theori", "vote", "comput complex"], "tokenized": ["banzhaf power index", "power index", "network flow game", "prefer aggreg", "multiag applic", "vote theori", "vote", "comput complex"]}, "absent_kps": {"text": ["analysi of algorithm and problem complex algorithm and problem complex analysi", "social choic theori", "autom agent vote", "probabilist model", "connect game"], "tokenized": ["analysi of algorithm and problem complex algorithm and problem complex analysi", "social choic theori", "autom agent vote", "probabilist model", "connect game"]}}
{"id": 65, "title": {"text": "interactions between market barriers and communication networks in marketing systems .", "tokenized": "interactions between market barriers and communication networks in marketing systems ."}, "abstract": {"text": "we investigate a framework where agents search for satisfying products by using referrals from other agents . our model of a mechanism for transmitting word of mouth and the resulting behavioural effects is based on integrating a module governing the local behaviour of agents with a module governing the structure and function of the underlying network of agents . local behaviour incorporates a satisficing model of choice , a set of rules governing the interactions between agents , including learning about the trustworthiness of other agents over time , and external constraints on behaviour that may be imposed by market barriers or switching costs . local behaviour takes place on a network substrate across which agents exchange positive and negative information about products . we use various degree distributions dictating the extent of connectivity , and incorporate both small world effects and the notion of preferential attachment in our network models . we compare the effectiveness of referral systems over various network structures for easy and hard choice tasks , and evaluate how this effectiveness changes with the imposition of market barriers . categories and subject descriptors i . [digit] . [digit] artificial intelligence distributed artificial intelligence general terms performance , experimentation", "tokenized": "we investigate a framework where agents search for satisfying products by using referrals from other agents . our model of a mechanism for transmitting word of mouth and the resulting behavioural effects is based on integrating a module governing the local behaviour of agents with a module governing the structure and function of the underlying network of agents . local behaviour incorporates a satisficing model of choice , a set of rules governing the interactions between agents , including learning about the trustworthiness of other agents over time , and external constraints on behaviour that may be imposed by market barriers or switching costs . local behaviour takes place on a network substrate across which agents exchange positive and negative information about products . we use various degree distributions dictating the extent of connectivity , and incorporate both small world effects and the notion of preferential attachment in our network models . we compare the effectiveness of referral systems over various network structures for easy and hard choice tasks , and evaluate how this effectiveness changes with the imposition of market barriers . categories and subject descriptors i . [digit] . [digit] artificial intelligence distributed artificial intelligence general terms performance , experimentation"}, "present_kps": {"text": ["market barrier", "market system", "switch cost", "referr system"], "tokenized": ["market barrier", "market system", "switch cost", "referr system"]}, "absent_kps": {"text": ["purchas behaviour", "word of mouth commun", "defect behaviour", "psycholog affin", "switch behaviour", "agent base model", "social psycholog", "consum choic", "social network", "cognit model", "artifici social system"], "tokenized": ["purchas behaviour", "word of mouth commun", "defect behaviour", "psycholog affin", "switch behaviour", "agent base model", "social psycholog", "consum choic", "social network", "cognit model", "artifici social system"]}}
{"id": 66, "title": {"text": "realistic cognitive load modeling for enhancing shared mental models in human agent collaboration .", "tokenized": "realistic cognitive load modeling for enhancing shared mental models in human agent collaboration ."}, "abstract": {"text": "human team members often develop shared expectations to predict each other s needs and coordinate their behaviors . in this paper the concept shared belief map is proposed as a basis for developing realistic shared expectations among a team of human agent pairs ( haps ) . the establishment of shared belief maps relies on inter agent information sharing , the effectiveness of which highly depends on agents processing loads and the instantaneous cognitive loads of their human partners . we investigate hmm based cognitive load models to facilitate team members to share the right information with the right party at the right time . the shared belief map concept and the cognitive processing load models have been implemented in a cognitive agent <unk> . a series of experiments were conducted to evaluate the concept , the models , and their impacts on the evolving of shared mental models of hap teams . categories and subject descriptors i . [digit] . [digit] artificial intelligence distributed artificial intelligence intelligent agents , multiagent systems general terms design , experimentation , human factors", "tokenized": "human team members often develop shared expectations to predict each other s needs and coordinate their behaviors . in this paper the concept shared belief map is proposed as a basis for developing realistic shared expectations among a team of human agent pairs ( haps ) . the establishment of shared belief maps relies on inter agent information sharing , the effectiveness of which highly depends on agents processing loads and the instantaneous cognitive loads of their human partners . we investigate hmm based cognitive load models to facilitate team members to share the right information with the right party at the right time . the shared belief map concept and the cognitive processing load models have been implemented in a cognitive agent <unk> . a series of experiments were conducted to evaluate the concept , the models , and their impacts on the evolving of shared mental models of hap teams . categories and subject descriptors i . [digit] . [digit] artificial intelligence distributed artificial intelligence intelligent agents , multiagent systems general terms design , experimentation , human factors"}, "present_kps": {"text": ["collabor", "expect", "share belief map", "share belief map"], "tokenized": ["collabor", "expect", "share belief map", "share belief map"]}, "absent_kps": {"text": ["problem solv", "heurist", "teamwork", "multiag teamwork", "teamwork schema", "human center teamwork", "cognit load theori", "human perform", "resourc alloc", "task perform", "info share", "multi parti commun", "cognit model", "reason", "human agent team perform"], "tokenized": ["problem solv", "heurist", "teamwork", "multiag teamwork", "teamwork schema", "human center teamwork", "cognit load theori", "human perform", "resourc alloc", "task perform", "info share", "multi parti commun", "cognit model", "reason", "human agent team perform"]}}
{"id": 67, "title": {"text": "sequential decision making in parallel two sided economic search .", "tokenized": "sequential decision making in parallel two sided economic search ."}, "abstract": {"text": "this paper presents a two sided economic search model in which agents are searching for beneficial pairwise partnerships . in each search stage , each of the agents is randomly matched with several other agents in parallel , and makes a decision whether to accept a potential partnership with one of them . the distinguishing feature of the proposed model is that the agents are not restricted to maintaining a synchronized ( instantaneous ) decision protocol and can sequentially accept and reject partnerships within the same search stage . we analyze the dynamics which drive the agents strategies towards a stable equilibrium in the new model and show that the proposed search strategy weakly dominates the one currently in use for the two sided parallel economic search model . by identifying several unique characteristics of the equilibrium we manage to efficiently bound the strategy space that needs to be explored by the agents and propose an efficient means for extracting the distributed equilibrium strategies in common environments . categories and subject descriptors i . [digit] . [digit] artificial intelligence distributed artificial <unk> agents general terms algorithms , economics", "tokenized": "this paper presents a two sided economic search model in which agents are searching for beneficial pairwise partnerships . in each search stage , each of the agents is randomly matched with several other agents in parallel , and makes a decision whether to accept a potential partnership with one of them . the distinguishing feature of the proposed model is that the agents are not restricted to maintaining a synchronized ( instantaneous ) decision protocol and can sequentially accept and reject partnerships within the same search stage . we analyze the dynamics which drive the agents strategies towards a stable equilibrium in the new model and show that the proposed search strategy weakly dominates the one currently in use for the two sided parallel economic search model . by identifying several unique characteristics of the equilibrium we manage to efficiently bound the strategy space that needs to be explored by the agents and propose an efficient means for extracting the distributed equilibrium strategies in common environments . categories and subject descriptors i . [digit] . [digit] artificial intelligence distributed artificial <unk> agents general terms algorithms , economics"}, "present_kps": {"text": ["partnership", "match", "equilibrium strategi"], "tokenized": ["partnership", "match", "equilibrium strategi"]}, "absent_kps": {"text": ["sequenti decis make", "instantan decis make", "search perform", "costli environ", "partnership format", "coalit format", "pairwis partnership", "parallel interact", "multi equilibrium scenario", "search cost", "util", "inform process", "peer to peer applic", "decis", "two side search", "bound methodolog"], "tokenized": ["sequenti decis make", "instantan decis make", "search perform", "costli environ", "partnership format", "coalit format", "pairwis partnership", "parallel interact", "multi equilibrium scenario", "search cost", "util", "inform process", "peer to peer applic", "decis", "two side search", "bound methodolog"]}}
{"id": 68, "title": {"text": "distributed management of flexible times schedules .", "tokenized": "distributed management of flexible times schedules ."}, "abstract": {"text": "we consider the problem of managing schedules in an uncertain , distributed environment . we assume a team of collaborative agents , each responsible for executing a portion of a globally pre established schedule , but none possessing a global view of either the problem or solution . the goal is to maximize the joint quality obtained from the activities executed by all agents , given that , during execution , unexpected events will force changes to some prescribed activities and reduce the utility of executing others . we describe an agent architecture for solving this problem that couples two basic mechanisms ( [digit] ) a flexible times representation of the agent s schedule ( using a simple temporal network ) and ( [digit] ) an incremental rescheduling procedure . the former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions , and the latter acts to revise the agent s schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set . basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter dependent activities . then , as time permits , the core local problem solving infra structure is used to drive an inter agent option generation and query process , aimed at identifying opportunities for solution improvement through joint change . using a simulator to model the environment , we compare the performance of our multi agent system with that of an expected optimal ( but non scalable ) centralized mdp solver . categories and subject descriptors i . [digit] . [digit] computing methodologies artificial <unk> artificial intelligence general terms algorithms , design", "tokenized": "we consider the problem of managing schedules in an uncertain , distributed environment . we assume a team of collaborative agents , each responsible for executing a portion of a globally pre established schedule , but none possessing a global view of either the problem or solution . the goal is to maximize the joint quality obtained from the activities executed by all agents , given that , during execution , unexpected events will force changes to some prescribed activities and reduce the utility of executing others . we describe an agent architecture for solving this problem that couples two basic mechanisms ( [digit] ) a flexible times representation of the agent s schedule ( using a simple temporal network ) and ( [digit] ) an incremental rescheduling procedure . the former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions , and the latter acts to revise the agent s schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set . basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter dependent activities . then , as time permits , the core local problem solving infra structure is used to drive an inter agent option generation and query process , aimed at identifying opportunities for solution improvement through joint change . using a simulator to model the environment , we compare the performance of our multi agent system with that of an expected optimal ( but non scalable ) centralized mdp solver . categories and subject descriptors i . [digit] . [digit] computing methodologies artificial <unk> artificial intelligence general terms algorithms , design"}, "present_kps": {"text": ["manag", "flexibl time", "schedul", "manag schedul", "distribut environ", "agent architectur", "inter depend activ", "perform"], "tokenized": ["manag", "flexibl time", "schedul", "manag schedul", "distribut environ", "agent architectur", "inter depend activ", "perform"]}, "absent_kps": {"text": ["geograph separ", "central plan", "schedul execut", "slack", "shortest path algorithm", "activ alloc", "conflict driven approach", "optimist synchron", "inter agent coordin", "multi agent schedul"], "tokenized": ["geograph separ", "central plan", "schedul execut", "slack", "shortest path algorithm", "activ alloc", "conflict driven approach", "optimist synchron", "inter agent coordin", "multi agent schedul"]}}
{"id": 69, "title": {"text": "distributed task allocation in social networks .", "tokenized": "distributed task allocation in social networks ."}, "abstract": {"text": "this paper proposes a new variant of the task allocation problem , where the agents are connected in a social network and tasks arrive at the agents distributed over the network . we show that the complexity of this problem remains nphard . moreover , it is not approximable within some factor . we develop an algorithm based on the contract net protocol . our algorithm is completely distributed , and it assumes that agents have only local knowledge about tasks and resources . we conduct a set of experiments to evaluate the performance and scalability of the proposed algorithm in terms of solution quality and computation time . three different types of networks , namely small world , random and scale free networks , are used to represent various social relationships among agents in realistic applications . the results demonstrate that our algorithm works well and that it scales well to large scale applications . categories and subject descriptors i . [digit] . [digit] distributed artificial intelligence multiagent systems general terms algorithms , experimentation", "tokenized": "this paper proposes a new variant of the task allocation problem , where the agents are connected in a social network and tasks arrive at the agents distributed over the network . we show that the complexity of this problem remains nphard . moreover , it is not approximable within some factor . we develop an algorithm based on the contract net protocol . our algorithm is completely distributed , and it assumes that agents have only local knowledge about tasks and resources . we conduct a set of experiments to evaluate the performance and scalability of the proposed algorithm in terms of solution quality and computation time . three different types of networks , namely small world , random and scale free networks , are used to represent various social relationships among agents in realistic applications . the results demonstrate that our algorithm works well and that it scales well to large scale applications . categories and subject descriptors i . [digit] . [digit] distributed artificial intelligence multiagent systems general terms algorithms , experimentation"}, "present_kps": {"text": ["task alloc", "alloc", "social network", "agent", "algorithm", "resourc", "social relationship", "multiag system"], "tokenized": ["task alloc", "alloc", "social network", "agent", "algorithm", "resourc", "social relationship", "multiag system"]}, "absent_kps": {"text": ["util", "commun messag", "behavior", "strateg agent", "interact", "comput complex"], "tokenized": ["util", "commun messag", "behavior", "strateg agent", "interact", "comput complex"]}}
{"id": 70, "title": {"text": "reasoning about judgment and preference aggregation .", "tokenized": "reasoning about judgment and preference aggregation ."}, "abstract": {"text": "agents that must reach agreements with other agents need to reason about how their preferences , judgments , and beliefs might be aggregated with those of others by the social choice mechanisms that govern their interactions . the recently emerging field of judgment aggregation studies aggregation from a logical perspective , and considers how multiple sets of logical formulae can be aggregated to a single consistent set . as a special case , judgment aggregation can be seen to subsume classical preference aggregation . we present a modal logic that is intended to support reasoning about judgment aggregation scenarios ( and hence , as a special case , about preference aggregation ) the logical language is interpreted directly in judgment aggregation rules . we present a sound and complete axiomatisation of such rules . we show that the logic can express aggregation rules such as majority voting rule properties such as independence and results such as the discursive paradox , arrow s theorem and condorcet s paradox which are derivable as formal theorems of the logic . the logic is parameterised in such a way that it can be used as a general framework for comparing the logical properties of different types of aggregation including classical preference aggregation . categories and subject descriptors i . [digit] . [digit] artificial intelligence distributed artificial <unk> systems i . [digit] . [digit] artificial intelligence knowledge representation formalisms and methods modal logic general terms theory", "tokenized": "agents that must reach agreements with other agents need to reason about how their preferences , judgments , and beliefs might be aggregated with those of others by the social choice mechanisms that govern their interactions . the recently emerging field of judgment aggregation studies aggregation from a logical perspective , and considers how multiple sets of logical formulae can be aggregated to a single consistent set . as a special case , judgment aggregation can be seen to subsume classical preference aggregation . we present a modal logic that is intended to support reasoning about judgment aggregation scenarios ( and hence , as a special case , about preference aggregation ) the logical language is interpreted directly in judgment aggregation rules . we present a sound and complete axiomatisation of such rules . we show that the logic can express aggregation rules such as majority voting rule properties such as independence and results such as the discursive paradox , arrow s theorem and condorcet s paradox which are derivable as formal theorems of the logic . the logic is parameterised in such a way that it can be used as a general framework for comparing the logical properties of different types of aggregation including classical preference aggregation . categories and subject descriptors i . [digit] . [digit] artificial intelligence distributed artificial <unk> systems i . [digit] . [digit] artificial intelligence knowledge representation formalisms and methods modal logic general terms theory"}, "present_kps": {"text": ["prefer aggreg", "judgment aggreg", "modal logic", "judgment aggreg rule", "express"], "tokenized": ["prefer aggreg", "judgment aggreg", "modal logic", "judgment aggreg rule", "express"]}, "absent_kps": {"text": ["knowledg represent formal", "social welfar function", "complet axiomatis", "syntax and semant of jal jal syntax and semant", "discurs paradox", "arrow ' s theorem", "non dictatorship", "unanim", "arrow logic", "jal"], "tokenized": ["knowledg represent formal", "social welfar function", "complet axiomatis", "syntax and semant of jal jal syntax and semant", "discurs paradox", "arrow ' s theorem", "non dictatorship", "unanim", "arrow logic", "jal"]}}
{"id": 71, "title": {"text": "an adversarial environment model for bounded rational agents in zero sum interactions .", "tokenized": "an adversarial environment model for bounded rational agents in zero sum interactions ."}, "abstract": {"text": "multiagent environments are often not cooperative nor collaborative in many cases , agents have conflicting interests , leading to adversarial interactions . this paper presents a formal adversarial environment model for bounded rational agents operating in a zero sum environment . in such environments , attempts to use classical utility based search methods can raise a variety of difficulties ( e . g . , implicitly modeling the opponent as an omniscient utility maximizer , rather than leveraging a more nuanced , explicit opponent model ) . we define an adversarial environment by describing the mental states of an agent in such an environment . we then present behavioral axioms that are intended to serve as design principles for building such adversarial agents . we explore the application of our approach by analyzing log files of completed connect four games , and present an empirical analysis of the axioms appropriateness . categories and subject descriptors i . [digit] . [digit] artificial intelligence distributed artificial intelligence intelligent agents , multiagent systems i . [digit] . [digit] artificial intelligence knowledge representation formalisms and methods modal logic general terms design , theory", "tokenized": "multiagent environments are often not cooperative nor collaborative in many cases , agents have conflicting interests , leading to adversarial interactions . this paper presents a formal adversarial environment model for bounded rational agents operating in a zero sum environment . in such environments , attempts to use classical utility based search methods can raise a variety of difficulties ( e . g . , implicitly modeling the opponent as an omniscient utility maximizer , rather than leveraging a more nuanced , explicit opponent model ) . we define an adversarial environment by describing the mental states of an agent in such an environment . we then present behavioral axioms that are intended to serve as design principles for building such adversarial agents . we explore the application of our approach by analyzing log files of completed connect four games , and present an empirical analysis of the axioms appropriateness . categories and subject descriptors i . [digit] . [digit] artificial intelligence distributed artificial intelligence intelligent agents , multiagent systems i . [digit] . [digit] artificial intelligence knowledge representation formalisms and methods modal logic general terms design , theory"}, "present_kps": {"text": ["adversari environ", "agent", "interact", "multiag environ", "adversari interact", "behavior axiom", "connect four game", "multiag system", "modal logic"], "tokenized": ["adversari environ", "agent", "interact", "multiag environ", "adversari interact", "behavior axiom", "connect four game", "multiag system", "modal logic"]}, "absent_kps": {"text": ["axiomat model", "zero sum encount", "treatment group", "eval valu", "evalu function", "bilater and multilater instanti", "benefici action", "empir studi"], "tokenized": ["axiomat model", "zero sum encount", "treatment group", "eval valu", "evalu function", "bilater and multilater instanti", "benefici action", "empir studi"]}}
{"id": 72, "title": {"text": "a formal road from institutional norms to organizational structures .", "tokenized": "a formal road from institutional norms to organizational structures ."}, "abstract": {"text": "up to now , the way institutions and organizations have been used in the development of open systems has not often gone further than a useful heuristics . in order to develop systems actually implementing institutions and organizations , formal methods should take the place of heuristic ones . the paper presents a formal semantics for the notion of institution and its components ( abstract and concrete norms , empowerment of agents , roles ) and defines a formal relation between institutions and organizational structures . as a result , it is shown how institutional norms can be refined to <unk> structures which are closer to an implemented system . it is also shown how such a refinement process can be fully formalized and it is therefore amenable to rigorous verification . categories and subject descriptors f . [digit] . [digit] mathematical logic and formal languages modal logic i . [digit] . [digit] distributed artificial intelligence multiagent systems f . [digit] . [digit] distributed artificial intelligence coherence and coordination general terms theory .", "tokenized": "up to now , the way institutions and organizations have been used in the development of open systems has not often gone further than a useful heuristics . in order to develop systems actually implementing institutions and organizations , formal methods should take the place of heuristic ones . the paper presents a formal semantics for the notion of institution and its components ( abstract and concrete norms , empowerment of agents , roles ) and defines a formal relation between institutions and organizational structures . as a result , it is shown how institutional norms can be refined to <unk> structures which are closer to an implemented system . it is also shown how such a refinement process can be fully formalized and it is therefore amenable to rigorous verification . categories and subject descriptors f . [digit] . [digit] mathematical logic and formal languages modal logic i . [digit] . [digit] distributed artificial intelligence multiagent systems f . [digit] . [digit] distributed artificial intelligence coherence and coordination general terms theory ."}, "present_kps": {"text": ["institut norm", "institut", "norm", "organiz structur", "formal method", "role", "logic"], "tokenized": ["institut norm", "institut", "norm", "organiz structur", "formal method", "role", "logic"]}, "absent_kps": {"text": ["abstract constraint", "formal for repres organiz structur", "entiti", "properti", "descript logic", "dynam logic", "terminolog axiom", "infrastructur"], "tokenized": ["abstract constraint", "formal for repres organiz structur", "entiti", "properti", "descript logic", "dynam logic", "terminolog axiom", "infrastructur"]}}
{"id": 73, "title": {"text": "resolving conflict and inconsistency in norm regulated virtual organizations .", "tokenized": "resolving conflict and inconsistency in norm regulated virtual organizations ."}, "abstract": {"text": "norm governed virtual organizations define , govern and facilitate coordinated resource sharing and problem solving in societies of agents . with an explicit account of norms , openness in virtual organizations can be achieved new components , designed by various parties , can be seamlessly accommodated . we focus on virtual organizations realised as multi agent systems , in which human and software agents interact to achieve individual and global goals . however , any realistic account of norms should address their dynamic nature norms will change as agents interact with each other and their environment . due to the changing nature of norms or due to norms stemming from different virtual organizations , there will be situations when an action is simultaneously permitted and prohibited , that is , a conflict arises . likewise , there will be situations when an action is both obliged and prohibited , that is , an inconsistency arises . we introduce an approach , based on first order unification , to detect and resolve such conflicts and inconsistencies . in our proposed solution , we annotate a norm with the set of values their variables should not have in order to avoid a conflict or an inconsistency with another norm . our approach neatly accommodates the domain dependent interrelations among actions and the indirect conflicts inconsistencies these may cause . more generally , we can capture a useful notion of inter agent ( and inter role ) delegation of actions and norms associated to them , and use it to address conflicts inconsistencies caused by action delegation . we illustrate our approach with an e science example in which agents support grid services . categories and subject descriptors i . [digit] . [digit] artificial intelligence applications and expert <unk> i . [digit] . [digit] artificial intelligence distributed artificial intelligence multi agent systems general terms algorithms , theory", "tokenized": "norm governed virtual organizations define , govern and facilitate coordinated resource sharing and problem solving in societies of agents . with an explicit account of norms , openness in virtual organizations can be achieved new components , designed by various parties , can be seamlessly accommodated . we focus on virtual organizations realised as multi agent systems , in which human and software agents interact to achieve individual and global goals . however , any realistic account of norms should address their dynamic nature norms will change as agents interact with each other and their environment . due to the changing nature of norms or due to norms stemming from different virtual organizations , there will be situations when an action is simultaneously permitted and prohibited , that is , a conflict arises . likewise , there will be situations when an action is both obliged and prohibited , that is , an inconsistency arises . we introduce an approach , based on first order unification , to detect and resolve such conflicts and inconsistencies . in our proposed solution , we annotate a norm with the set of values their variables should not have in order to avoid a conflict or an inconsistency with another norm . our approach neatly accommodates the domain dependent interrelations among actions and the indirect conflicts inconsistencies these may cause . more generally , we can capture a useful notion of inter agent ( and inter role ) delegation of actions and norms associated to them , and use it to address conflicts inconsistencies caused by action delegation . we illustrate our approach with an e science example in which agents support grid services . categories and subject descriptors i . [digit] . [digit] artificial intelligence applications and expert <unk> i . [digit] . [digit] artificial intelligence distributed artificial intelligence multi agent systems general terms algorithms , theory"}, "present_kps": {"text": ["virtual organ", "agent", "multi agent system"], "tokenized": ["virtual organ", "agent", "multi agent system"]}, "absent_kps": {"text": ["norm regul vo", "norm conflict", "conflict prohibit", "norm inconsist", "extern agent", "governor agent", "artifici social system"], "tokenized": ["norm regul vo", "norm conflict", "conflict prohibit", "norm inconsist", "extern agent", "governor agent", "artifici social system"]}}
{"id": 74, "title": {"text": "distributed norm management in regulated multi agent systems .", "tokenized": "distributed norm management in regulated multi agent systems ."}, "abstract": {"text": "norms are widely recognised as a means of coordinating multi agent systems . the distributed management of norms is a challenging issue and we observe a lack of truly distributed computational realisations of normative models . in order to regulate the behaviour of autonomous agents that take part in multiple , related activities , we propose a normative model , the normative structure ( ns ) , an artifact that is based on the propagation of normative positions ( obligations , prohibitions , permissions ) , as consequences of agents actions . within a ns , conflicts may arise due to the dynamic nature of the mas and the concurrency of agents actions . however , ensuring conflict freedom of a ns at design time is computationally intractable . we show this by formalising the notion of conflict , providing a mapping of nss into coloured petri nets and borrowing well known theoretical results from that field . since online conflict resolution is required , we present a tractable algorithm to be employed distributedly . we then demonstrate that this algorithm is paramount for the distributed enactment of a ns . categories and subject descriptors i . [digit] . [digit] distributed artificial intelligence languages and structures general terms algorithms , design , theory", "tokenized": "norms are widely recognised as a means of coordinating multi agent systems . the distributed management of norms is a challenging issue and we observe a lack of truly distributed computational realisations of normative models . in order to regulate the behaviour of autonomous agents that take part in multiple , related activities , we propose a normative model , the normative structure ( ns ) , an artifact that is based on the propagation of normative positions ( obligations , prohibitions , permissions ) , as consequences of agents actions . within a ns , conflicts may arise due to the dynamic nature of the mas and the concurrency of agents actions . however , ensuring conflict freedom of a ns at design time is computationally intractable . we show this by formalising the notion of conflict , providing a mapping of nss into coloured petri nets and borrowing well known theoretical results from that field . since online conflict resolution is required , we present a tractable algorithm to be employed distributedly . we then demonstrate that this algorithm is paramount for the distributed enactment of a ns . categories and subject descriptors i . [digit] . [digit] distributed artificial intelligence languages and structures general terms algorithms , design , theory"}, "present_kps": {"text": ["regul multi agent system", "coordin", "activ", "norm structur", "norm posit", "prohibit", "conflict", "algorithm"], "tokenized": ["regul multi agent system", "coordin", "activ", "norm structur", "norm posit", "prohibit", "conflict", "algorithm"]}, "absent_kps": {"text": ["organis", "norm scene", "permiss overlap", "token", "protocol", "scenario", "norm conflict", "electron institut", "norm transit rule", "bi partit graph"], "tokenized": ["organis", "norm scene", "permiss overlap", "token", "protocol", "scenario", "norm conflict", "electron institut", "norm transit rule", "bi partit graph"]}}
{"id": 75, "title": {"text": "generalized trade reduction mechanisms .", "tokenized": "generalized trade reduction mechanisms ."}, "abstract": {"text": "when designing a mechanism there are several desirable properties to maintain such as incentive compatibility ( ic ) , individual rationality ( ir ) , and budget balance ( bb ) . it is well known [digit] that it is impossible for a mechanism to maximize social welfare whilst also being ir , ic , and bb . there have been several attempts to circumvent [digit] by trading welfare for bb , e . g . , in domains such as double sided auctions [digit] , distributed markets [digit] and supply chain problems [digit] , [digit] . in this paper we provide a procedure called a generalized trade reduction ( gtr ) for single value players , which given an ir and ic mechanism , outputs a mechanism which is ir , ic and bb with a loss of welfare . we bound the welfare achieved by our procedure for a wide range of domains . in particular , our results improve on existing solutions for problems such as double sided markets with homogenous goods , distributed markets and several kinds of supply chains . furthermore , our solution provides budget balanced mechanisms for several open problems such as combinatorial double sided auctions and distributed markets with strategic transportation edges . categories and subject descriptors j . [digit] social and behavioral sciences economics k . [digit] . [digit] electronic commerce payment scheme general terms algorithms , design , economics , theory", "tokenized": "when designing a mechanism there are several desirable properties to maintain such as incentive compatibility ( ic ) , individual rationality ( ir ) , and budget balance ( bb ) . it is well known [digit] that it is impossible for a mechanism to maximize social welfare whilst also being ir , ic , and bb . there have been several attempts to circumvent [digit] by trading welfare for bb , e . g . , in domains such as double sided auctions [digit] , distributed markets [digit] and supply chain problems [digit] , [digit] . in this paper we provide a procedure called a generalized trade reduction ( gtr ) for single value players , which given an ir and ic mechanism , outputs a mechanism which is ir , ic and bb with a loss of welfare . we bound the welfare achieved by our procedure for a wide range of domains . in particular , our results improve on existing solutions for problems such as double sided markets with homogenous goods , distributed markets and several kinds of supply chains . furthermore , our solution provides budget balanced mechanisms for several open problems such as combinatorial double sided auctions and distributed markets with strategic transportation edges . categories and subject descriptors j . [digit] social and behavioral sciences economics k . [digit] . [digit] electronic commerce payment scheme general terms algorithms , design , economics , theory"}, "present_kps": {"text": ["gener trade reduct", "trade reduct", "budget balanc", "gtr", "homogen good", "budget balanc mechan"], "tokenized": ["gener trade reduct", "trade reduct", "budget balanc", "gtr", "homogen good", "budget balanc mechan"]}, "absent_kps": {"text": ["intern competit", "extern competit", "effici", "power of player player power", "optim", "inequ in welfar", "multi mind player", "spatial distribut market"], "tokenized": ["intern competit", "extern competit", "effici", "power of player player power", "optim", "inequ in welfar", "multi mind player", "spatial distribut market"]}}
{"id": 76, "title": {"text": "worst case optimal redistribution of vcg payments .", "tokenized": "worst case optimal redistribution of vcg payments ."}, "abstract": {"text": "for allocation problems with one or more items , the wellknown vickrey clarke groves ( vcg ) mechanism is efficient , strategy proof , individually rational , and does not incur a deficit . however , the vcg mechanism is not ( strongly ) budget balanced generally , the agents payments will sum to more than [digit] . if there is an auctioneer who is selling the items , this may be desirable , because the surplus payment corresponds to revenue for the auctioneer . however , if the items do not have an owner and the agents are merely interested in allocating the items efficiently among themselves , any surplus payment is undesirable , because it will have to flow out of the system of agents . in [digit] , cavallo [digit] proposed a mechanism that redistributes some of the vcg payment back to the agents , while maintaining efficiency , strategy proofness , individual rationality , and the non deficit property . in this paper , we extend this result in a restricted setting . we study allocation settings where there are multiple indistinguishable units of a single good , and agents have unit demand . ( for this specific setting , cavallo s mechanism coincides with a mechanism proposed by bailey in [digit] [digit] . ) here we propose a family of mechanisms that redistribute some of the vcg payment back to the agents . all mechanisms in the family are efficient , strategyproof , individually rational , and never incur a deficit . the family includes the bailey cavallo mechanism as a special case . we then provide an optimization model for finding the optimal mechanism that is , the mechanism that maximizes redistribution in the worst case inside the family , and show how to cast this model as a linear program . we give both numerical and analytical solutions of this linear program , and the ( unique ) resulting mechanism shows significant improvement over the bailey cavallo mechanism ( in the worst case ) . finally , we prove that the obtained mechanism is optimal among all anonymous deterministic mechanisms that satisfy the above properties . categories and subject descriptors j . [digit] computer applications social and behavioral sciences economics i . [digit] . [digit] distributed artificial intelligence multiagent systems general terms algorithms , economics , theory", "tokenized": "for allocation problems with one or more items , the wellknown vickrey clarke groves ( vcg ) mechanism is efficient , strategy proof , individually rational , and does not incur a deficit . however , the vcg mechanism is not ( strongly ) budget balanced generally , the agents payments will sum to more than [digit] . if there is an auctioneer who is selling the items , this may be desirable , because the surplus payment corresponds to revenue for the auctioneer . however , if the items do not have an owner and the agents are merely interested in allocating the items efficiently among themselves , any surplus payment is undesirable , because it will have to flow out of the system of agents . in [digit] , cavallo [digit] proposed a mechanism that redistributes some of the vcg payment back to the agents , while maintaining efficiency , strategy proofness , individual rationality , and the non deficit property . in this paper , we extend this result in a restricted setting . we study allocation settings where there are multiple indistinguishable units of a single good , and agents have unit demand . ( for this specific setting , cavallo s mechanism coincides with a mechanism proposed by bailey in [digit] [digit] . ) here we propose a family of mechanisms that redistribute some of the vcg payment back to the agents . all mechanisms in the family are efficient , strategyproof , individually rational , and never incur a deficit . the family includes the bailey cavallo mechanism as a special case . we then provide an optimization model for finding the optimal mechanism that is , the mechanism that maximizes redistribution in the worst case inside the family , and show how to cast this model as a linear program . we give both numerical and analytical solutions of this linear program , and the ( unique ) resulting mechanism shows significant improvement over the bailey cavallo mechanism ( in the worst case ) . finally , we prove that the obtained mechanism is optimal among all anonymous deterministic mechanisms that satisfy the above properties . categories and subject descriptors j . [digit] computer applications social and behavioral sciences economics i . [digit] . [digit] distributed artificial intelligence multiagent systems general terms algorithms , economics , theory"}, "present_kps": {"text": ["mechan", "strategi proof"], "tokenized": ["mechan", "strategi proof"]}, "absent_kps": {"text": ["mechan design", "vickrei clark grove", "redistribut payment", "effici mechan", "individu ration mechan", "linear vcg redistribut mechan", "transform to linear program", "analyt character", "worst case optim mechan", "vickrei clark grove mechan", "payment redistribut"], "tokenized": ["mechan design", "vickrei clark grove", "redistribut payment", "effici mechan", "individu ration mechan", "linear vcg redistribut mechan", "transform to linear program", "analyt character", "worst case optim mechan", "vickrei clark grove mechan", "payment redistribut"]}}
{"id": 77, "title": {"text": "budget optimization in search based advertising auctions .", "tokenized": "budget optimization in search based advertising auctions ."}, "abstract": {"text": "internet search companies sell advertisement slots based on users search queries via an auction . while there has been previous work on the auction process and its game theoretic aspects , most of it focuses on the internet company . in this work , we focus on the advertisers , who must solve a complex optimization problem to decide how to place bids on keywords to maximize their return ( the number of user clicks on their ads ) for a given budget . we model the entire process and study this budget optimization problem . while most variants are np hard , we show , perhaps surprisingly , that simply randomizing between two uniform strategies that bid equally on all the keywords works well . more precisely , this strategy gets at least a [digit] [digit] e fraction of the maximum clicks possible . as our preliminary experiments show , such uniform strategies are likely to be practical . we also present inapproximability results , and optimal algorithms for variants of the budget optimization problem . categories and subject descriptors f . [digit] theory of computation analysis of algorithms and problem complexity j . [digit] computer applications social and behavioral sciences economics general terms algorithms , economics , theory .", "tokenized": "internet search companies sell advertisement slots based on users search queries via an auction . while there has been previous work on the auction process and its game theoretic aspects , most of it focuses on the internet company . in this work , we focus on the advertisers , who must solve a complex optimization problem to decide how to place bids on keywords to maximize their return ( the number of user clicks on their ads ) for a given budget . we model the entire process and study this budget optimization problem . while most variants are np hard , we show , perhaps surprisingly , that simply randomizing between two uniform strategies that bid equally on all the keywords works well . more precisely , this strategy gets at least a [digit] [digit] e fraction of the maximum clicks possible . as our preliminary experiments show , such uniform strategies are likely to be practical . we also present inapproximability results , and optimal algorithms for variants of the budget optimization problem . categories and subject descriptors f . [digit] theory of computation analysis of algorithms and problem complexity j . [digit] computer applications social and behavioral sciences economics general terms algorithms , economics , theory ."}, "present_kps": {"text": ["budget optim", "optim", "auction", "internet", "bid", "keyword"], "tokenized": ["budget optim", "optim", "auction", "internet", "bid", "keyword"]}, "absent_kps": {"text": ["search base advertis auction", "advertis", "game theori", "intrigu heurist", "uniform bid strategi", "vickrei clark grove", "lp", "gener second price", "sponsor search"], "tokenized": ["search base advertis auction", "advertis", "game theori", "intrigu heurist", "uniform bid strategi", "vickrei clark grove", "lp", "gener second price", "sponsor search"]}}
{"id": 78, "title": {"text": "revenue analysis of a family of ranking rules for keyword auctions .", "tokenized": "revenue analysis of a family of ranking rules for keyword auctions ."}, "abstract": {"text": "keyword auctions lie at the core of the business models of today s leading search engines . advertisers bid for placement alongside search results , and are charged for clicks on their ads . advertisers are typically ranked according to a score that takes into account their bids and potential clickthrough rates . we consider a family of ranking rules that contains those typically used to model yahoo and google s auction designs as special cases . we find that in general neither of these is necessarily revenue optimal in equilibrium , and that the choice of ranking rule can be guided by considering the correlation between bidders values and click through rates . we propose a simple approach to determine a revenue optimal ranking rule within our family , taking into account effects on advertiser satisfaction and user experience . we illustrate the approach using monte carlo simulations based on distributions fitted to yahoo bid and click through rate data for a high volume keyword . categories and subject descriptors j . [digit] computer applications social and behavioral sciences economics general terms economics , theory", "tokenized": "keyword auctions lie at the core of the business models of today s leading search engines . advertisers bid for placement alongside search results , and are charged for clicks on their ads . advertisers are typically ranked according to a score that takes into account their bids and potential clickthrough rates . we consider a family of ranking rules that contains those typically used to model yahoo and google s auction designs as special cases . we find that in general neither of these is necessarily revenue optimal in equilibrium , and that the choice of ranking rule can be guided by considering the correlation between bidders values and click through rates . we propose a simple approach to determine a revenue optimal ranking rule within our family , taking into account effects on advertiser satisfaction and user experience . we illustrate the approach using monte carlo simulations based on distributions fitted to yahoo bid and click through rate data for a high volume keyword . categories and subject descriptors j . [digit] computer applications social and behavioral sciences economics general terms economics , theory"}, "present_kps": {"text": ["revenu", "rank rule", "keyword auction", "search engin", "revenu optim rank"], "tokenized": ["revenu", "rank rule", "keyword auction", "search engin", "revenu optim rank"]}, "absent_kps": {"text": ["advertis", "sponsor search", "rank by bid", "rank by revenu", "profit", "advertis revenu", "price search keyword", "optim auction design problem", "sponsor search"], "tokenized": ["advertis", "sponsor search", "rank by bid", "rank by revenu", "profit", "advertis revenu", "price search keyword", "optim auction design problem", "sponsor search"]}}
{"id": 79, "title": {"text": "the role of compatibility in the diffusion of technologies through social networks .", "tokenized": "the role of compatibility in the diffusion of technologies through social networks ."}, "abstract": {"text": "in many settings , competing technologies for example , operating systems , instant messenger systems , or document <unk> be seen adopting a limited amount of compatibility with one another in other words , the difficulty in using multiple technologies is balanced somewhere between the two extremes of impossibility and effortless interoperability . there are a range of reasons why this phenomenon occurs , many of which based on legal , social , or business considerations seem to defy concise mathematical models . despite this , we show that the advantages of limited compatibility can arise in a very simple model of diffusion in social networks , thus offering a basic explanation for this phenomenon in purely strategic terms . our approach builds on work on the diffusion of innovations in the economics literature , which seeks to model how a new technology a might spread through a social network of individuals who are currently users of technology b . we consider several ways of capturing the compatibility of a and b , focusing primarily on a model in which users can choose to adopt a , adopt b , or at an extra cost adopt both a and b . we characterize how the ability of a to spread depends on both its quality relative to b , and also this additional cost of adopting both , and find some surprising non monotonicity properties in the dependence on these", "tokenized": "in many settings , competing technologies for example , operating systems , instant messenger systems , or document <unk> be seen adopting a limited amount of compatibility with one another in other words , the difficulty in using multiple technologies is balanced somewhere between the two extremes of impossibility and effortless interoperability . there are a range of reasons why this phenomenon occurs , many of which based on legal , social , or business considerations seem to defy concise mathematical models . despite this , we show that the advantages of limited compatibility can arise in a very simple model of diffusion in social networks , thus offering a basic explanation for this phenomenon in purely strategic terms . our approach builds on work on the diffusion of innovations in the economics literature , which seeks to model how a new technology a might spread through a social network of individuals who are currently users of technology b . we consider several ways of capturing the compatibility of a and b , focusing primarily on a model in which users can choose to adopt a , adopt b , or at an extra cost adopt both a and b . we characterize how the ability of a to spread depends on both its quality relative to b , and also this additional cost of adopting both , and find some surprising non monotonicity properties in the dependence on these"}, "present_kps": {"text": ["limit compat"], "tokenized": ["limit compat"]}, "absent_kps": {"text": ["diffus process", "game theoret diffus model", "strateg incompat", "bilingu", "interoper", "non convex properti", "character", "morri ' s theorem", "contagion threshold", "contagion game", "potenti function", "algorithm game theori", "contagion on network", "diffus of innov innov diffus"], "tokenized": ["diffus process", "game theoret diffus model", "strateg incompat", "bilingu", "interoper", "non convex properti", "character", "morri ' s theorem", "contagion threshold", "contagion game", "potenti function", "algorithm game theori", "contagion on network", "diffus of innov innov diffus"]}}
{"id": 80, "title": {"text": "strong equilibrium in cost sharing connection games .", "tokenized": "strong equilibrium in cost sharing connection games ."}, "abstract": {"text": "in this work we study cost sharing connection games , where each player has a source and sink he would like to connect , and the cost of the edges is either shared equally ( fair connection games ) or in an arbitrary way ( general connection games ) . we study the graph topologies that guarantee the existence of a strong equilibrium ( where no coalition can improve the cost of each of its members ) regardless of the specific costs on the edges . our main existence results are the following ( [digit] ) for a single source and sink we show that there is always a strong equilibrium ( both for fair and general connection games ) . ( [digit] ) for a single source multiple sinks we show that for a series parallel graph a strong equilibrium always exists ( both for fair and general connection games ) . ( [digit] ) for multi source and sink we show that an extension parallel graph always admits a strong equilibrium in fair connection games . as for the quality of the strong equilibrium we show that in any fair connection games the cost of a strong equilibrium is ( log n ) from the optimal solution , where n is the number of players . ( this should be contrasted with the ( n ) price of anarchy for the same setting . ) for single source general connection games and single source single sink fair connection games , we show that a strong equilibrium is always an optimal solution . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems f . [digit] . [digit] analysis of algorithms and problem complexity general j . [digit] social and behavioral sciences economics k . [digit] . [digit] electronic commerce payment schemes general terms theory , economics , algorithms", "tokenized": "in this work we study cost sharing connection games , where each player has a source and sink he would like to connect , and the cost of the edges is either shared equally ( fair connection games ) or in an arbitrary way ( general connection games ) . we study the graph topologies that guarantee the existence of a strong equilibrium ( where no coalition can improve the cost of each of its members ) regardless of the specific costs on the edges . our main existence results are the following ( [digit] ) for a single source and sink we show that there is always a strong equilibrium ( both for fair and general connection games ) . ( [digit] ) for a single source multiple sinks we show that for a series parallel graph a strong equilibrium always exists ( both for fair and general connection games ) . ( [digit] ) for multi source and sink we show that an extension parallel graph always admits a strong equilibrium in fair connection games . as for the quality of the strong equilibrium we show that in any fair connection games the cost of a strong equilibrium is ( log n ) from the optimal solution , where n is the number of players . ( this should be contrasted with the ( n ) price of anarchy for the same setting . ) for single source general connection games and single source single sink fair connection games , we show that a strong equilibrium is always an optimal solution . categories and subject descriptors c . [digit] . [digit] computer communication networks distributed systems f . [digit] . [digit] analysis of algorithms and problem complexity general j . [digit] social and behavioral sciences economics k . [digit] . [digit] electronic commerce payment schemes general terms theory , economics , algorithms"}, "present_kps": {"text": ["strong equilibrium", "cost share connect game", "fair connect game", "gener connect game", "graph topolog", "coalit", "specif cost", "singl sourc and sink", "singl sourc multipl sink", "multi sourc and sink", "optim solut"], "tokenized": ["strong equilibrium", "cost share connect game", "fair connect game", "gener connect game", "graph topolog", "coalit", "specif cost", "singl sourc and sink", "singl sourc multipl sink", "multi sourc and sink", "optim solut"]}, "absent_kps": {"text": ["network design", "number of player player number", "extens parallel graph", "game theori", "nash equilibrium", "price of anarchi anarchi price", "strong price of anarchi", "cost of the edg edg cost", "cost share game"], "tokenized": ["network design", "number of player player number", "extens parallel graph", "game theori", "nash equilibrium", "price of anarchi anarchi price", "strong price of anarchi", "cost of the edg edg cost", "cost share game"]}}
{"id": 81, "title": {"text": "computation in a distributed information market .", "tokenized": "computation in a distributed information market ."}, "abstract": {"text": "according to economic theory supported by empirical and laboratory evidence the equilibrium price of a financial security reflects all of the information regarding the security s value . we investigate the computational process on the path toward equilibrium , where information distributed among traders is revealed step by step over time and incorporated into the market price . we develop a simplified model of an information market , along with trading strategies , in order to formalize the computational properties of the process . we show that securities whose payoffs can not be expressed as weighted threshold functions of distributed input bits are not guaranteed to converge to the proper equilibrium predicted by economic theory . on the other hand , securities whose payoffs are threshold functions are guaranteed to converge , for all prior probability distributions . moreover , these threshold securities converge in at most n rounds , where n is the number of bits of distributed information . we also prove a lower bound , showing a type of threshold security that requires at least n [digit] rounds to converge in the worst case . categories and subject descriptors f . m theory of computation miscellaneous j . [digit] computer applications social and behavioral <unk> c . [digit] . [digit] computer systems organization computer communication networks distributed systems general terms economics , theory", "tokenized": "according to economic theory supported by empirical and laboratory evidence the equilibrium price of a financial security reflects all of the information regarding the security s value . we investigate the computational process on the path toward equilibrium , where information distributed among traders is revealed step by step over time and incorporated into the market price . we develop a simplified model of an information market , along with trading strategies , in order to formalize the computational properties of the process . we show that securities whose payoffs can not be expressed as weighted threshold functions of distributed input bits are not guaranteed to converge to the proper equilibrium predicted by economic theory . on the other hand , securities whose payoffs are threshold functions are guaranteed to converge , for all prior probability distributions . moreover , these threshold securities converge in at most n rounds , where n is the number of bits of distributed information . we also prove a lower bound , showing a type of threshold security that requires at least n [digit] rounds to converge in the worst case . categories and subject descriptors f . m theory of computation miscellaneous j . [digit] computer applications social and behavioral <unk> c . [digit] . [digit] computer systems organization computer communication networks distributed systems general terms economics , theory"}, "present_kps": {"text": ["distribut inform market", "distribut inform", "inform market", "econom theori", "empir and laboratori evid", "equilibrium price", "secur", "comput process", "path toward equilibrium", "trader", "market price", "simplifi model", "trade strategi", "comput properti of the process", "payoff", "threshold function", "probabl distribut", "round", "lower bound", "worst case"], "tokenized": ["distribut inform market", "distribut inform", "inform market", "econom theori", "empir and laboratori evid", "equilibrium price", "secur", "comput process", "path toward equilibrium", "trader", "market price", "simplifi model", "trade strategi", "comput properti of the process", "payoff", "threshold function", "probabl distribut", "round", "lower bound", "worst case"]}, "absent_kps": {"text": ["number of bit bit number", "ration expect", "secur ' s valu", "financi secur", "market comput", "inform aggreg", "converg to equilibrium", "effici market hypothesi"], "tokenized": ["number of bit bit number", "ration expect", "secur ' s valu", "financi secur", "market comput", "inform aggreg", "converg to equilibrium", "effici market hypothesi"]}}
{"id": 82, "title": {"text": "understanding user behavior in online feedback reporting .", "tokenized": "understanding user behavior in online feedback reporting ."}, "abstract": {"text": "online reviews have become increasingly popular as a way to judge the quality of various products and services . previous work has demonstrated that contradictory reporting and underlying user biases make judging the true worth of a service difficult . in this paper , we investigate underlying factors that influence user behavior when reporting feedback . we look at two sources of information besides numerical ratings linguistic evidence from the textual comment accompanying a review , and patterns in the time sequence of reports . we first show that groups of users who amply discuss a certain feature are more likely to agree on a common rating for that feature . second , we show that a user s rating partly reflects the difference between true quality and prior expectation of quality as inferred from previous reviews . both give us a less noisy way to produce rating estimates and reveal the reasons behind user bias . our hypotheses were validated by statistical evidence from hotel reviews on the tripadvisor website . categories and subject descriptors j . [digit] social and behavioral sciences economics general terms economics , experimentation , reliability", "tokenized": "online reviews have become increasingly popular as a way to judge the quality of various products and services . previous work has demonstrated that contradictory reporting and underlying user biases make judging the true worth of a service difficult . in this paper , we investigate underlying factors that influence user behavior when reporting feedback . we look at two sources of information besides numerical ratings linguistic evidence from the textual comment accompanying a review , and patterns in the time sequence of reports . we first show that groups of users who amply discuss a certain feature are more likely to agree on a common rating for that feature . second , we show that a user s rating partly reflects the difference between true quality and prior expectation of quality as inferred from previous reviews . both give us a less noisy way to produce rating estimates and reveal the reasons behind user bias . our hypotheses were validated by statistical evidence from hotel reviews on the tripadvisor website . categories and subject descriptors j . [digit] social and behavioral sciences economics general terms economics , experimentation , reliability"}, "present_kps": {"text": ["onlin review", "rate"], "tokenized": ["onlin review", "rate"]}, "absent_kps": {"text": ["reput mechan", "featur by featur estim of qualiti", "absenc of clear incent clear incent absenc", "util of the product product util", "brag and moan model", "great probabl bi modal", "u shape distribut", "semant orient of product evalu", "correl", "larg span of time"], "tokenized": ["reput mechan", "featur by featur estim of qualiti", "absenc of clear incent clear incent absenc", "util of the product product util", "brag and moan model", "great probabl bi modal", "u shape distribut", "semant orient of product evalu", "correl", "larg span of time"]}}
{"id": 83, "title": {"text": "trading networks with price setting agents .", "tokenized": "trading networks with price setting agents ."}, "abstract": {"text": "in a wide range of markets , individual buyers and sellers often trade through intermediaries , who determine prices via strategic considerations . typically , not all buyers and sellers have access to the same intermediaries , and they trade at correspondingly different prices that reflect their relative amounts of power in the market . we model this phenomenon using a game in which buyers , sellers , and traders engage in trade on a graph that represents the access each buyer and seller has to the traders . in this model , traders set prices strategically , and then buyers and sellers react to the prices they are offered . we show that the resulting game always has a subgame perfect nash equilibrium , and that all equilibria lead to an efficient ( i . e . socially optimal ) allocation of goods . we extend these results to a more general type of matching market , such as one finds in the matching of job applicants and employers . finally , we consider how the profits obtained by the traders depend on the underlying graph roughly , a trader can command a positive profit if and only if it has an essential connection in the network structure , thus providing a graph theoretic basis for quantifying the amount of competition among traders . our work differs from recent studies of how price is affected by network structure through our modeling of price setting as a strategic activity carried out by a subset of agents in the system , rather than studying prices set via competitive equilibrium or by a truthful mechanism . categories and subject descriptors j . [digit] social and behavioral sciences economics general terms economics , theory", "tokenized": "in a wide range of markets , individual buyers and sellers often trade through intermediaries , who determine prices via strategic considerations . typically , not all buyers and sellers have access to the same intermediaries , and they trade at correspondingly different prices that reflect their relative amounts of power in the market . we model this phenomenon using a game in which buyers , sellers , and traders engage in trade on a graph that represents the access each buyer and seller has to the traders . in this model , traders set prices strategically , and then buyers and sellers react to the prices they are offered . we show that the resulting game always has a subgame perfect nash equilibrium , and that all equilibria lead to an efficient ( i . e . socially optimal ) allocation of goods . we extend these results to a more general type of matching market , such as one finds in the matching of job applicants and employers . finally , we consider how the profits obtained by the traders depend on the underlying graph roughly , a trader can command a positive profit if and only if it has an essential connection in the network structure , thus providing a graph theoretic basis for quantifying the amount of competition among traders . our work differs from recent studies of how price is affected by network structure through our modeling of price setting as a strategic activity carried out by a subset of agents in the system , rather than studying prices set via competitive equilibrium or by a truthful mechanism . categories and subject descriptors j . [digit] social and behavioral sciences economics general terms economics , theory"}, "present_kps": {"text": ["trade network", "trade network", "market"], "tokenized": ["trade network", "trade network", "market"]}, "absent_kps": {"text": ["algorithm game theori", "interact of buyer and seller buyer and seller interact", "initi endow of monei", "bid price", "perfect competit", "benefit", "maximum and minimum amount", "econom and financ", "strateg behavior of trader", "complementari slack", "monopoli"], "tokenized": ["algorithm game theori", "interact of buyer and seller buyer and seller interact", "initi endow of monei", "bid price", "perfect competit", "benefit", "maximum and minimum amount", "econom and financ", "strateg behavior of trader", "complementari slack", "monopoli"]}}
{"id": 84, "title": {"text": "on the complexity of combinatorial auctions structured item graphs and hypertree decompositions .", "tokenized": "on the complexity of combinatorial auctions structured item graphs and hypertree decompositions ."}, "abstract": {"text": "the winner determination problem in combinatorial auctions is the problem of determining the allocation of the items among the bidders that maximizes the sum of the accepted bid prices . while this problem is in general nphard , it is known to be feasible in polynomial time on those instances whose associated item graphs have bounded treewidth ( called structured item graphs ) . formally , an item graph is a graph whose nodes are in one to one correspondence with items , and edges are such that for any bid , the items occurring in it induce a connected subgraph . note that many item graphs might be associated with a given combinatorial auction , depending on the edges selected for guaranteeing the connectedness . in fact , the tractability of determining whether a structured item graph of a fixed treewidth exists ( and if so , computing one ) was left as a crucial open problem . in this paper , we solve this problem by proving that the existence of a structured item graph is computationally intractable , even for treewidth [digit] . motivated by this bad news , we investigate different kinds of structural requirements that can be used to isolate tractable classes of combinatorial auctions . we show that the notion of hypertree decomposition , a recently introduced measure of hypergraph cyclicity , turns out to be most useful here . indeed , we show that the winner determination problem is solvable in polynomial time on instances whose bidder interactions can be represented with ( dual ) hypergraphs having bounded hypertree width . even more surprisingly , we show that the class of tractable instances identified by means of our approach properly contains the class of instances having a structured item graph . categories and subject descriptors j . [digit] computer applications social and behavioral sciences economics f . [digit] theory of computation analysis of algorithms and problem complexity", "tokenized": "the winner determination problem in combinatorial auctions is the problem of determining the allocation of the items among the bidders that maximizes the sum of the accepted bid prices . while this problem is in general nphard , it is known to be feasible in polynomial time on those instances whose associated item graphs have bounded treewidth ( called structured item graphs ) . formally , an item graph is a graph whose nodes are in one to one correspondence with items , and edges are such that for any bid , the items occurring in it induce a connected subgraph . note that many item graphs might be associated with a given combinatorial auction , depending on the edges selected for guaranteeing the connectedness . in fact , the tractability of determining whether a structured item graph of a fixed treewidth exists ( and if so , computing one ) was left as a crucial open problem . in this paper , we solve this problem by proving that the existence of a structured item graph is computationally intractable , even for treewidth [digit] . motivated by this bad news , we investigate different kinds of structural requirements that can be used to isolate tractable classes of combinatorial auctions . we show that the notion of hypertree decomposition , a recently introduced measure of hypergraph cyclicity , turns out to be most useful here . indeed , we show that the winner determination problem is solvable in polynomial time on instances whose bidder interactions can be represented with ( dual ) hypergraphs having bounded hypertree width . even more surprisingly , we show that the class of tractable instances identified by means of our approach properly contains the class of instances having a structured item graph . categories and subject descriptors j . [digit] computer applications social and behavioral sciences economics f . [digit] theory of computation analysis of algorithms and problem complexity"}, "present_kps": {"text": ["combinatori auction", "structur item graph", "accept bid price", "polynomi time", "fix treewidth", "hypergraph"], "tokenized": ["combinatori auction", "structur item graph", "accept bid price", "polynomi time", "fix treewidth", "hypergraph"]}, "absent_kps": {"text": ["hypertre decomposit", "well known mechan for resourc and task alloc", "hypertre base decomposit method", "hypergraph hg", "complex of structur item graph structur item graph complex", "simplif of the primal graph primal graph simplif"], "tokenized": ["hypertre decomposit", "well known mechan for resourc and task alloc", "hypertre base decomposit method", "hypergraph hg", "complex of structur item graph structur item graph complex", "simplif of the primal graph primal graph simplif"]}}
{"id": 85, "title": {"text": "computing good nash equilibria in graphical games .", "tokenized": "computing good nash equilibria in graphical games ."}, "abstract": {"text": "this paper addresses the problem of fair equilibrium selection in graphical games . our approach is based on the data structure called the best response policy , which was proposed by kearns et al . [digit] as a way to represent all nash equilibria of a graphical game . in [digit] , it was shown that the best response policy has polynomial size as long as the underlying graph is a path . in this paper , we show that if the underlying graph is a bounded degree tree and the best response policy has polynomial size then there is an efficient algorithm which constructs a nash equilibrium that guarantees certain payoffs to all participants . another attractive solution concept is a nash equilibrium that maximizes the social welfare . we show that , while exactly computing the latter is infeasible ( we prove that solving this problem may involve algebraic numbers of an arbitrarily high degree ) , there exists an fptas for finding such an equilibrium as long as the best response policy has polynomial size . these two algorithms can be combined to produce nash equilibria that satisfy various fairness criteria . categories and subject descriptors f . [digit] theory of computation analysis of algorithms and problem complexity j . [digit] computer applications social and behavioral sciences economics general terms algorithms , economics , theory", "tokenized": "this paper addresses the problem of fair equilibrium selection in graphical games . our approach is based on the data structure called the best response policy , which was proposed by kearns et al . [digit] as a way to represent all nash equilibria of a graphical game . in [digit] , it was shown that the best response policy has polynomial size as long as the underlying graph is a path . in this paper , we show that if the underlying graph is a bounded degree tree and the best response policy has polynomial size then there is an efficient algorithm which constructs a nash equilibrium that guarantees certain payoffs to all participants . another attractive solution concept is a nash equilibrium that maximizes the social welfare . we show that , while exactly computing the latter is infeasible ( we prove that solving this problem may involve algebraic numbers of an arbitrarily high degree ) , there exists an fptas for finding such an equilibrium as long as the best response policy has polynomial size . these two algorithms can be combined to produce nash equilibria that satisfy various fairness criteria . categories and subject descriptors f . [digit] theory of computation analysis of algorithms and problem complexity j . [digit] computer applications social and behavioral sciences economics general terms algorithms , economics , theory"}, "present_kps": {"text": ["graphic game", "nash equilibrium", "social welfar"], "tokenized": ["graphic game", "nash equilibrium", "social welfar"]}, "absent_kps": {"text": ["approxim scheme", "exponenti time algorithm", "approxim", "variou sociallydesir properti", "overal payoff", "distribut profit", "integ payoff graphic game g", "sever drawback", "strategi profil", "degre bound graph"], "tokenized": ["approxim scheme", "exponenti time algorithm", "approxim", "variou sociallydesir properti", "overal payoff", "distribut profit", "integ payoff graphic game g", "sever drawback", "strategi profil", "degre bound graph"]}}
{"id": 86, "title": {"text": "generalized value decomposition and structured multiattribute auctions .", "tokenized": "generalized value decomposition and structured multiattribute auctions ."}, "abstract": {"text": "multiattribute auction mechanisms generally either remain agnostic about traders preferences , or presume highly restrictive forms , such as full additivity . real preferences often exhibit dependencies among attributes , yet may possess some structure that can be usefully exploited to streamline communication and simplify operation of a multiattribute auction . we develop such a structure using the theory of measurable value functions , a cardinal utility representation based on an underlying order over preference differences . a set of local conditional independence relations over such differences supports a generalized additive preference representation , which decomposes utility across overlapping clusters of related attributes . we introduce an iterative auction mechanism that maintains prices on local clusters of attributes rather than the full space of joint configurations . when traders preferences are consistent with the auction s generalized additive structure , the mechanism produces approximately optimal allocations , at approximate vcg prices . categories and subject descriptors j . [digit] computer applications social and behavioral sciences economics general terms algorithms , economics", "tokenized": "multiattribute auction mechanisms generally either remain agnostic about traders preferences , or presume highly restrictive forms , such as full additivity . real preferences often exhibit dependencies among attributes , yet may possess some structure that can be usefully exploited to streamline communication and simplify operation of a multiattribute auction . we develop such a structure using the theory of measurable value functions , a cardinal utility representation based on an underlying order over preference differences . a set of local conditional independence relations over such differences supports a generalized additive preference representation , which decomposes utility across overlapping clusters of related attributes . we introduce an iterative auction mechanism that maintains prices on local clusters of attributes rather than the full space of joint configurations . when traders preferences are consistent with the auction s generalized additive structure , the mechanism produces approximately optimal allocations , at approximate vcg prices . categories and subject descriptors j . [digit] computer applications social and behavioral sciences economics general terms algorithms , economics"}, "present_kps": {"text": ["multiattribut auction", "auction", "iter auction mechan"], "tokenized": ["multiattribut auction", "auction", "iter auction mechan"]}, "absent_kps": {"text": ["prefer handl", "theori of measur valu function measur valu function theori", "mvf", "gau", "gai base auction"], "tokenized": ["prefer handl", "theori of measur valu function measur valu function theori", "mvf", "gau", "gai base auction"]}}
{"id": 87, "title": {"text": "truthful mechanism design for multi dimensional scheduling via cycle monotonicity .", "tokenized": "truthful mechanism design for multi dimensional scheduling via cycle monotonicity ."}, "abstract": {"text": "we consider the problem of makespan minimization on m unrelated machines in the context of algorithmic mechanism design , where the machines are the strategic players . this is a multidimensional scheduling domain , and the only known positive results for makespan minimization in such a domain are o ( m ) approximation truthful mechanisms [digit] , [digit] . we study a well motivated special case of this problem , where the processing time of a job on each machine may either be low or high , and the low and high values are public and job dependent . this preserves the multidimensionality of the domain , and generalizes the restricted machines ( i . e . , pj , ) setting in scheduling . we give a general technique to convert any c approximation algorithm to a <unk> truthful in expectation mechanism . this is one of the few known results that shows how to export approximation algorithms for a multidimensional problem into truthful mechanisms in a black box fashion . when the low and high values are the same for all jobs , we devise a deterministic [digit] approximation truthful mechanism . these are the first truthful mechanisms with non trivial performance guarantees for a multidimensional scheduling domain . our constructions are novel in two respects . first , we do not utilize or rely on explicit price definitions to prove truthfulness instead we design algorithms that satisfy cycle monotonicity . cycle monotonicity [digit] is a necessary and sufficient condition for truthfulness , is a generalization of value monotonicity for multidimensional domains . however , whereas value monotonicity has been used extensively and successfully to design truthful mechanisms in <unk> domains , ours is the first work that leverages cycle monotonicity in the multidimensional setting . second , our randomized mechanisms are obtained by first constructing a fractional truthful mechanism for a fractional relaxation of the problem , and then converting it into a <unk> expectation mechanism . this builds upon a technique of [digit] , and shows the usefulness of fractional mechanisms in truthful mechanism design . categories and subject descriptors f . [digit] analysis of algorithms and problem complexity j . [digit] social and behavioral sciences economics general terms algorithms , economics , theory", "tokenized": "we consider the problem of makespan minimization on m unrelated machines in the context of algorithmic mechanism design , where the machines are the strategic players . this is a multidimensional scheduling domain , and the only known positive results for makespan minimization in such a domain are o ( m ) approximation truthful mechanisms [digit] , [digit] . we study a well motivated special case of this problem , where the processing time of a job on each machine may either be low or high , and the low and high values are public and job dependent . this preserves the multidimensionality of the domain , and generalizes the restricted machines ( i . e . , pj , ) setting in scheduling . we give a general technique to convert any c approximation algorithm to a <unk> truthful in expectation mechanism . this is one of the few known results that shows how to export approximation algorithms for a multidimensional problem into truthful mechanisms in a black box fashion . when the low and high values are the same for all jobs , we devise a deterministic [digit] approximation truthful mechanism . these are the first truthful mechanisms with non trivial performance guarantees for a multidimensional scheduling domain . our constructions are novel in two respects . first , we do not utilize or rely on explicit price definitions to prove truthfulness instead we design algorithms that satisfy cycle monotonicity . cycle monotonicity [digit] is a necessary and sufficient condition for truthfulness , is a generalization of value monotonicity for multidimensional domains . however , whereas value monotonicity has been used extensively and successfully to design truthful mechanisms in <unk> domains , ours is the first work that leverages cycle monotonicity in the multidimensional setting . second , our randomized mechanisms are obtained by first constructing a fractional truthful mechanism for a fractional relaxation of the problem , and then converting it into a <unk> expectation mechanism . this builds upon a technique of [digit] , and shows the usefulness of fractional mechanisms in truthful mechanism design . categories and subject descriptors f . [digit] analysis of algorithms and problem complexity j . [digit] social and behavioral sciences economics general terms algorithms , economics , theory"}, "present_kps": {"text": ["truth mechan design", "mechan design", "schedul", "schedul", "cycl monoton", "makespan minim", "algorithm", "approxim algorithm", "random mechan"], "tokenized": ["truth mechan design", "mechan design", "schedul", "schedul", "cycl monoton", "makespan minim", "algorithm", "approxim algorithm", "random mechan"]}, "absent_kps": {"text": ["multi dimension schedul", "us of fraction mechan fraction mechan us", "fraction domain"], "tokenized": ["multi dimension schedul", "us of fraction mechan fraction mechan us", "fraction domain"]}}
{"id": 88, "title": {"text": "mediators in position auctions .", "tokenized": "mediators in position auctions ."}, "abstract": {"text": "a mediator is a reliable entity , which can play on behalf of agents in a given game . a mediator however can not enforce the use of its services , and each agent is free to participate in the game directly . in this paper we introduce a study of mediators for games with incomplete information , and apply it to the context of position auctions , a central topic in electronic commerce . vcg position auctions , which are currently not used in practice , possess some nice theoretical properties , such as the optimization of social surplus and having dominant strategies . these properties may not be satisfied by current position auctions and their variants . we therefore concentrate on the search for mediators that will allow to transform current position auctions into vcg position auctions . we require that accepting the mediator services , and reporting honestly to the mediator , will form an ex post equilibrium , which satisfies the following rationality condition an agent s payoff can not be negative regardless of the actions taken by the agents who did not choose the mediator s services , or by the agents who report false types to the mediator . we prove the existence of such desired mediators for the next price ( google like ) position auctions , as well as for a richer class of position auctions , including all k price position auctions , k > [digit] . for k [digit] , the self price position auction , we show that the existence of such mediator depends on the tie breaking rule used in the auction . categories and subject descriptors j . [digit] social and behavioral sciences economics i . [digit] artificial intelligence distributed artificial <unk> systems general terms economics , theory", "tokenized": "a mediator is a reliable entity , which can play on behalf of agents in a given game . a mediator however can not enforce the use of its services , and each agent is free to participate in the game directly . in this paper we introduce a study of mediators for games with incomplete information , and apply it to the context of position auctions , a central topic in electronic commerce . vcg position auctions , which are currently not used in practice , possess some nice theoretical properties , such as the optimization of social surplus and having dominant strategies . these properties may not be satisfied by current position auctions and their variants . we therefore concentrate on the search for mediators that will allow to transform current position auctions into vcg position auctions . we require that accepting the mediator services , and reporting honestly to the mediator , will form an ex post equilibrium , which satisfies the following rationality condition an agent s payoff can not be negative regardless of the actions taken by the agents who did not choose the mediator s services , or by the agents who report false types to the mediator . we prove the existence of such desired mediators for the next price ( google like ) position auctions , as well as for a richer class of position auctions , including all k price position auctions , k > [digit] . for k [digit] , the self price position auction , we show that the existence of such mediator depends on the tie breaking rule used in the auction . categories and subject descriptors j . [digit] social and behavioral sciences economics i . [digit] artificial intelligence distributed artificial <unk> systems general terms economics , theory"}, "present_kps": {"text": ["mediat", "posit auction", "auction", "agent", "electron commerc", "ex post equilibrium", "equilibrium", "richer class of posit auction", "self price posit auction"], "tokenized": ["mediat", "posit auction", "auction", "agent", "electron commerc", "ex post equilibrium", "equilibrium", "richer class of posit auction", "self price posit auction"]}, "absent_kps": {"text": ["next price posit auction", "multi agent system", "t strategi", "vcg outcom function"], "tokenized": ["next price posit auction", "multi agent system", "t strategi", "vcg outcom function"]}}
{"id": 89, "title": {"text": "clearing algorithms for barter exchange markets enabling nationwide kidney exchanges .", "tokenized": "clearing algorithms for barter exchange markets enabling nationwide kidney exchanges ."}, "abstract": {"text": "in barter exchange markets , agents seek to swap their items with one another , in order to improve their own utilities . these swaps consist of cycles of agents , with each agent receiving the item of the next agent in the cycle . we focus mainly on the upcoming national kidney exchange market , where patients with kidney disease can obtain compatible donors by swapping their own willing but incompatible donors . with over [digit] , [digit] patients already waiting for a cadaver kidney in the us , this market is seen as the only ethical way to significantly reduce the [digit] , [digit] deaths per year attributed to kidney disease . the clearing problem involves finding a social welfare maximizing exchange when the maximum length of a cycle is fixed . long cycles are forbidden , since , for incentive reasons , all transplants in a cycle must be performed simultaneously . also , in barter exchanges generally , more agents are affected if one drops out of a longer cycle . we prove that the clearing problem with this cycle length constraint is np hard . solving it exactly is one of the main challenges in establishing a national kidney exchange . we present the first algorithm capable of clearing these markets on a nationwide scale . the key is incremental problem formulation . we adapt two paradigms for the task constraint generation and column generation . for each , we develop techniques that dramatically improve both runtime and memory usage . we conclude that column generation scales drastically better than constraint generation . our algorithm also supports several generalizations , as demanded by real world kidney exchanges . our algorithm replaced cplex as the clearing algorithm of the alliance for paired donation , one of the leading kidney exchanges . the match runs are conducted every two weeks and transplants based on our optimizations have already been conducted . categories and subject descriptors j . [digit] computer applications social and behavioral sciences economics f . [digit] analysis of algorithms and problem complexity general general terms algorithms , economics", "tokenized": "in barter exchange markets , agents seek to swap their items with one another , in order to improve their own utilities . these swaps consist of cycles of agents , with each agent receiving the item of the next agent in the cycle . we focus mainly on the upcoming national kidney exchange market , where patients with kidney disease can obtain compatible donors by swapping their own willing but incompatible donors . with over [digit] , [digit] patients already waiting for a cadaver kidney in the us , this market is seen as the only ethical way to significantly reduce the [digit] , [digit] deaths per year attributed to kidney disease . the clearing problem involves finding a social welfare maximizing exchange when the maximum length of a cycle is fixed . long cycles are forbidden , since , for incentive reasons , all transplants in a cycle must be performed simultaneously . also , in barter exchanges generally , more agents are affected if one drops out of a longer cycle . we prove that the clearing problem with this cycle length constraint is np hard . solving it exactly is one of the main challenges in establishing a national kidney exchange . we present the first algorithm capable of clearing these markets on a nationwide scale . the key is incremental problem formulation . we adapt two paradigms for the task constraint generation and column generation . for each , we develop techniques that dramatically improve both runtime and memory usage . we conclude that column generation scales drastically better than constraint generation . our algorithm also supports several generalizations , as demanded by real world kidney exchanges . our algorithm replaced cplex as the clearing algorithm of the alliance for paired donation , one of the leading kidney exchanges . the match runs are conducted every two weeks and transplants based on our optimizations have already been conducted . categories and subject descriptors j . [digit] computer applications social and behavioral sciences economics f . [digit] analysis of algorithms and problem complexity general general terms algorithms , economics"}, "present_kps": {"text": ["barter exchang market", "barter", "exchang", "transplant", "column gener", "match", "match"], "tokenized": ["barter exchang market", "barter", "exchang", "transplant", "column gener", "match", "match"]}, "absent_kps": {"text": ["kidnei", "market characterist", "instanc gener", "solut approach", "edg formul", "cycl formul", "branch and price"], "tokenized": ["kidnei", "market characterist", "instanc gener", "solut approach", "edg formul", "cycl formul", "branch and price"]}}
{"id": 90, "title": {"text": "a strategic model for information markets .", "tokenized": "a strategic model for information markets ."}, "abstract": {"text": "information markets , which are designed specifically to aggregate traders information , are becoming increasingly popular as a means for predicting future events . recent research in information markets has resulted in two new designs , market scoring rules and dynamic parimutuel markets . we develop an analytic method to guide the design and strategic analysis of information markets . our central contribution is a new abstract betting game , the projection game , that serves as a useful model for information markets . we demonstrate that this game can serve as a strategic model of dynamic parimutuel markets , and also captures the essence of the strategies in market scoring rules . the projection game is tractable to analyze , and has an attractive geometric visualization that makes the strategic moves and interactions more transparent . we use it to prove several strategic properties about the dynamic parimutuel market . we also prove that a special form of the projection game is strategically equivalent to the spherical scoring rule , and it is strategically similar to other scoring rules . finally , we illustrate two applications of the model to analysis of complex strategic scenarios we analyze the precision of a market in which traders have inertia , and a market in which a trader can profit by manipulating another trader s beliefs . categories and subject descriptors j . [digit] computer applications social and behavioral sciences economics general terms economics , theory", "tokenized": "information markets , which are designed specifically to aggregate traders information , are becoming increasingly popular as a means for predicting future events . recent research in information markets has resulted in two new designs , market scoring rules and dynamic parimutuel markets . we develop an analytic method to guide the design and strategic analysis of information markets . our central contribution is a new abstract betting game , the projection game , that serves as a useful model for information markets . we demonstrate that this game can serve as a strategic model of dynamic parimutuel markets , and also captures the essence of the strategies in market scoring rules . the projection game is tractable to analyze , and has an attractive geometric visualization that makes the strategic moves and interactions more transparent . we use it to prove several strategic properties about the dynamic parimutuel market . we also prove that a special form of the projection game is strategically equivalent to the spherical scoring rule , and it is strategically similar to other scoring rules . finally , we illustrate two applications of the model to analysis of complex strategic scenarios we analyze the precision of a market in which traders have inertia , and a market in which a trader can profit by manipulating another trader s beliefs . categories and subject descriptors j . [digit] computer applications social and behavioral sciences economics general terms economics , theory"}, "present_kps": {"text": ["inform market", "market score rule", "dynam parimutuel market", "strateg analysi", "project game", "spheric score rule", "social and behavior scienc econom"], "tokenized": ["inform market", "market score rule", "dynam parimutuel market", "strateg analysi", "project game", "spheric score rule", "social and behavior scienc econom"]}, "absent_kps": {"text": ["project game model", "predict market", "long rang manipul strategi", "liquid time", "dpm", "msr"], "tokenized": ["project game model", "predict market", "long rang manipul strategi", "liquid time", "dpm", "msr"]}}
{"id": 91, "title": {"text": "betting on permutations .", "tokenized": "betting on permutations ."}, "abstract": {"text": "we consider a permutation betting scenario , where people wager on the final ordering of n candidates for example , the outcome of a horse race . we examine the auctioneer problem of risklessly matching up wagers or , equivalently , finding arbitrage opportunities among the proposed wagers . requiring bidders to explicitly list the orderings that they d like to bet on is both unnatural and intractable , because the number of orderings is n and the number of subsets of orderings is 2n . we propose two expressive betting languages that seem natural for bidders , and examine the computational complexity of the auctioneer problem in each case . subset betting allows traders to bet either that a candidate will end up ranked among some subset of positions in the final ordering , for example , horse a will finish in positions [digit] , [digit] , or [digit] [digit] , or that a position will be taken by some subset of candidates , for example horse a , b , or d will finish in position [digit] . for subset betting , we show that the auctioneer problem can be solved in polynomial time if orders are divisible . pair betting allows traders to bet on whether one candidate will end up ranked higher than another candidate , for example horse a will beat horse b . we prove that the auctioneer problem becomes np hard for pair betting . we identify a sufficient condition for the existence of a pair betting match that can be verified in polynomial time . we also show that a natural greedy algorithm gives a poor approximation for indivisible orders . categories and subject descriptors j . [digit] computer applications social and behavioral sciences economics general terms economics , theory", "tokenized": "we consider a permutation betting scenario , where people wager on the final ordering of n candidates for example , the outcome of a horse race . we examine the auctioneer problem of risklessly matching up wagers or , equivalently , finding arbitrage opportunities among the proposed wagers . requiring bidders to explicitly list the orderings that they d like to bet on is both unnatural and intractable , because the number of orderings is n and the number of subsets of orderings is 2n . we propose two expressive betting languages that seem natural for bidders , and examine the computational complexity of the auctioneer problem in each case . subset betting allows traders to bet either that a candidate will end up ranked among some subset of positions in the final ordering , for example , horse a will finish in positions [digit] , [digit] , or [digit] [digit] , or that a position will be taken by some subset of candidates , for example horse a , b , or d will finish in position [digit] . for subset betting , we show that the auctioneer problem can be solved in polynomial time if orders are divisible . pair betting allows traders to bet on whether one candidate will end up ranked higher than another candidate , for example horse a will beat horse b . we prove that the auctioneer problem becomes np hard for pair betting . we identify a sufficient condition for the existence of a pair betting match that can be verified in polynomial time . we also show that a natural greedy algorithm gives a poor approximation for indivisible orders . categories and subject descriptors j . [digit] computer applications social and behavioral sciences economics general terms economics , theory"}, "present_kps": {"text": ["permut bet", "express bet", "comput complex", "subset bet", "greedi algorithm"], "tokenized": ["permut bet", "express bet", "comput complex", "subset bet", "greedi algorithm"]}, "absent_kps": {"text": ["bilater trade partner", "polynomi time algorithm", "inform aggreg", "permut combinator", "pair bet market", "bipartit graph", "minimum feedback", "complex polynomi transform", "predict market", "order match"], "tokenized": ["bilater trade partner", "polynomi time algorithm", "inform aggreg", "permut combinator", "pair bet market", "bipartit graph", "minimum feedback", "complex polynomi transform", "predict market", "order match"]}}
{"id": 92, "title": {"text": "frugality ratios and improved truthful mechanisms for vertex cover .", "tokenized": "frugality ratios and improved truthful mechanisms for vertex cover ."}, "abstract": {"text": "in set system auctions , there are several overlapping teams of agents , and a task that can be completed by any of these teams . the auctioneer s goal is to hire a team and pay as little as possible . examples of this setting include shortest path auctions and vertex cover auctions . recently , karlin , kempe and tamir introduced a new definition of frugality ratio for this problem . informally , the frugality ratio is the ratio of the total payment of a mechanism to a desired payment bound . the ratio captures the extent to which the mechanism overpays , relative to perceived fair cost in a truthful auction . in this paper , we propose a new truthful polynomial time auction for the vertex cover problem and bound its frugality ratio . we show that the solution quality is with a constant factor of optimal and the frugality ratio is within a constant factor of the best possible worst case bound this is the first auction for this problem to have these properties . moreover , we show how to transform any truthful auction into a frugal one while preserving the approximation ratio . also , we consider two natural modifications of the definition of karlin et al . , and we analyse the properties of the resulting payment bounds , such as monotonicity , computational hardness , and robustness with respect to the draw resolution rule . we study the relationships between the different payment bounds , both for general set systems and for specific set system auctions , such as path auctions and vertex cover auctions . we use these new definitions in the proof of our main result for vertex cover auctions via a bootstrapping technique , which may be of independent interest . categories and subject descriptors f . [digit] theory of computation analysis of algorithms and problem complexity j . [digit] computer applications social and behavioral sciences economics general terms algorithms , economics , theory", "tokenized": "in set system auctions , there are several overlapping teams of agents , and a task that can be completed by any of these teams . the auctioneer s goal is to hire a team and pay as little as possible . examples of this setting include shortest path auctions and vertex cover auctions . recently , karlin , kempe and tamir introduced a new definition of frugality ratio for this problem . informally , the frugality ratio is the ratio of the total payment of a mechanism to a desired payment bound . the ratio captures the extent to which the mechanism overpays , relative to perceived fair cost in a truthful auction . in this paper , we propose a new truthful polynomial time auction for the vertex cover problem and bound its frugality ratio . we show that the solution quality is with a constant factor of optimal and the frugality ratio is within a constant factor of the best possible worst case bound this is the first auction for this problem to have these properties . moreover , we show how to transform any truthful auction into a frugal one while preserving the approximation ratio . also , we consider two natural modifications of the definition of karlin et al . , and we analyse the properties of the resulting payment bounds , such as monotonicity , computational hardness , and robustness with respect to the draw resolution rule . we study the relationships between the different payment bounds , both for general set systems and for specific set system auctions , such as path auctions and vertex cover auctions . we use these new definitions in the proof of our main result for vertex cover auctions via a bootstrapping technique , which may be of independent interest . categories and subject descriptors f . [digit] theory of computation analysis of algorithms and problem complexity j . [digit] computer applications social and behavioral sciences economics general terms algorithms , economics , theory"}, "present_kps": {"text": ["frugal ratio", "frugal", "vertex cover", "auction", "vertex cover auction", "polynomi time", "bootstrap techniqu"], "tokenized": ["frugal ratio", "frugal", "vertex cover", "auction", "vertex cover auction", "polynomi time", "bootstrap techniqu"]}, "absent_kps": {"text": ["transfer util", "consecut payment bound", "monoton alloc rule", "co oper", "nonmonoton"], "tokenized": ["transfer util", "consecut payment bound", "monoton alloc rule", "co oper", "nonmonoton"]}}
{"id": 93, "title": {"text": "betting boolean style a framework for trading in securities based on logical formulas .", "tokenized": "betting boolean style a framework for trading in securities based on logical formulas ."}, "abstract": {"text": "we develop a framework for trading in compound securities financial instruments that pay off contingent on the outcomes of arbitrary statements in propositional logic . buying or selling securities which can be thought of as betting on or against a particular future outcome allows agents both to hedge risk and to profit ( in expectation ) on subjective predictions . a compound securities market allows agents to place bets on arbitrary boolean combinations of events , enabling them to more closely achieve their optimal risk exposure , and enabling the market as a whole to more closely achieve the social optimum . the tradeoff for allowing such expressivity is in the complexity of the agents and auctioneer s optimization problems . we develop and motivate the concept of a compound securities market , presenting the framework through a series of formal definitions and examples . we then analyze in detail the auctioneer s matching problem . we show that , with n events , the matching problem is co np complete in the divisible case and p [digit] complete in the indivisible case . we show that the latter hardness result holds even under severe language restrictions on bids . with log n events , the problem is polynomial in the divisible case and np complete in the indivisible case . we briefly discuss matching algorithms and tractable special cases . categories and subject descriptors f . [digit] . [digit] theory of computation analysis of algorithms and problem complexity nonnumerical algorithms and problems j . [digit] computer applications social and behavioral sciences economics general terms algorithms , economics , theory .", "tokenized": "we develop a framework for trading in compound securities financial instruments that pay off contingent on the outcomes of arbitrary statements in propositional logic . buying or selling securities which can be thought of as betting on or against a particular future outcome allows agents both to hedge risk and to profit ( in expectation ) on subjective predictions . a compound securities market allows agents to place bets on arbitrary boolean combinations of events , enabling them to more closely achieve their optimal risk exposure , and enabling the market as a whole to more closely achieve the social optimum . the tradeoff for allowing such expressivity is in the complexity of the agents and auctioneer s optimization problems . we develop and motivate the concept of a compound securities market , presenting the framework through a series of formal definitions and examples . we then analyze in detail the auctioneer s matching problem . we show that , with n events , the matching problem is co np complete in the divisible case and p [digit] complete in the indivisible case . we show that the latter hardness result holds even under severe language restrictions on bids . with log n events , the problem is polynomial in the divisible case and np complete in the indivisible case . we briefly discuss matching algorithms and tractable special cases . categories and subject descriptors f . [digit] . [digit] theory of computation analysis of algorithms and problem complexity nonnumerical algorithms and problems j . [digit] computer applications social and behavioral sciences economics general terms algorithms , economics , theory ."}, "present_kps": {"text": ["bet", "compound secur", "hedg", "compound secur market"], "tokenized": ["bet", "compound secur", "hedg", "compound secur market"]}, "absent_kps": {"text": ["combinatori bet", "specul", "inform aggreg", "risk alloc", "trade in financi instrument base on logic formula", "combinatori bet", "comput complex of match", "base secur", "payoff vector", "approxim algorithm", "combin valu trade", "bayesian network", "arbitrari logic combin", "effect probabl assess", "tractabl case", "gambl"], "tokenized": ["combinatori bet", "specul", "inform aggreg", "risk alloc", "trade in financi instrument base on logic formula", "combinatori bet", "comput complex of match", "base secur", "payoff vector", "approxim algorithm", "combin valu trade", "bayesian network", "arbitrari logic combin", "effect probabl assess", "tractabl case", "gambl"]}}
{"id": 94, "title": {"text": "combinatorial agency .", "tokenized": "combinatorial agency ."}, "abstract": {"text": "much recent research concerns systems , such as the internet , whose components are owned and operated by different parties , each with his own selfish goal . the field of algorithmic mechanism design handles the issue of private information held by the different parties in such computational settings . this paper deals with a complementary problem in such settings handling the hidden actions that are performed by the different parties . our model is a combinatorial variant of the classical principalagent problem from economic theory . in our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf , but their actions are hidden from him . our focus is on cases where complex combinations of the efforts of the agents influence the outcome . the principal motivates the agents by offering to them a set of contracts , which together put the agents in an equilibrium point of the induced game . we present formal models for this setting , suggest and embark on an analysis of some basic issues , but leave many questions open . categories and subject descriptors j . [digit] social and behavioral sciences economics k . [digit] . [digit] electronic commerce payment schemes c . [digit] . [digit] <unk> networks distributed systems general terms design , economics , theory", "tokenized": "much recent research concerns systems , such as the internet , whose components are owned and operated by different parties , each with his own selfish goal . the field of algorithmic mechanism design handles the issue of private information held by the different parties in such computational settings . this paper deals with a complementary problem in such settings handling the hidden actions that are performed by the different parties . our model is a combinatorial variant of the classical principalagent problem from economic theory . in our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf , but their actions are hidden from him . our focus is on cases where complex combinations of the efforts of the agents influence the outcome . the principal motivates the agents by offering to them a set of contracts , which together put the agents in an equilibrium point of the induced game . we present formal models for this setting , suggest and embark on an analysis of some basic issues , but leave many questions open . categories and subject descriptors j . [digit] social and behavioral sciences economics k . [digit] . [digit] electronic commerce payment schemes c . [digit] . [digit] <unk> networks distributed systems general terms design , economics , theory"}, "present_kps": {"text": ["combinatori agenc"], "tokenized": ["combinatori agenc"]}, "absent_kps": {"text": ["optim set of contract", "classic princip agent", "qualiti of servic servic qualiti", "nash equilibrium", "contract action", "k orbit", "anonym technolog", "seri parallel network", "price of unaccount unaccount price", "agenc theori", "princip agent model", "incent", "con"], "tokenized": ["optim set of contract", "classic princip agent", "qualiti of servic servic qualiti", "nash equilibrium", "contract action", "k orbit", "anonym technolog", "seri parallel network", "price of unaccount unaccount price", "agenc theori", "princip agent model", "incent", "con"]}}
{"id": 95, "title": {"text": "learning from revealed preference .", "tokenized": "learning from revealed preference ."}, "abstract": {"text": "a sequence of prices and demands are rationalizable if there exists a concave , continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price . afriat [digit] presented necessary and sufficient conditions for a finite sequence to be rationalizable . varian [digit] and later blundell et al . [digit] , [digit] continued this line of work studying nonparametric methods to forecasts demand . their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast . the present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts . our results show that the class of all demand functions has unbounded complexity and therefore is not learnable , but that there exist interesting and potentially useful classes that are learnable from finite samples . we also present a learning algorithm that is an adaptation of a new proof of afriat s theorem due to teo and vohra [digit] . categories and subject descriptors f . [digit] theory of computation analysis of algorithms and problem complexity j . [digit] computer applications social and behavioral sciences economics i . [digit] . [digit] learning parameter learning general terms economics , algorithms , theory", "tokenized": "a sequence of prices and demands are rationalizable if there exists a concave , continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price . afriat [digit] presented necessary and sufficient conditions for a finite sequence to be rationalizable . varian [digit] and later blundell et al . [digit] , [digit] continued this line of work studying nonparametric methods to forecasts demand . their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast . the present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts . our results show that the class of all demand functions has unbounded complexity and therefore is not learnable , but that there exist interesting and potentially useful classes that are learnable from finite samples . we also present a learning algorithm that is an adaptation of a new proof of afriat s theorem due to teo and vohra [digit] . categories and subject descriptors f . [digit] theory of computation analysis of algorithms and problem complexity j . [digit] computer applications social and behavioral sciences economics i . [digit] . [digit] learning parameter learning general terms economics , algorithms , theory"}, "present_kps": {"text": ["learn from reveal prefer", "reveal prefer", "rationaliz", "forecast", "demand function"], "tokenized": ["learn from reveal prefer", "reveal prefer", "rationaliz", "forecast", "demand function"]}, "absent_kps": {"text": ["complex problem", "probabl approxim correct", "monoton concav util function", "finit set of observ observ finit set", "incom lipschitz", "fat shatter dimens", "machin learn", "fat shatter"], "tokenized": ["complex problem", "probabl approxim correct", "monoton concav util function", "finit set of observ observ finit set", "incom lipschitz", "fat shatter dimens", "machin learn", "fat shatter"]}}
{"id": 96, "title": {"text": "approximately strategyproof and tractable multi unit auctions .", "tokenized": "approximately strategyproof and tractable multi unit auctions ."}, "abstract": {"text": "we present an approximately efficient and <unk> auction mechanism for a single good multi unit allocation problem . the bidding language in our auctions allows marginal decreasing piecewise constant curves . first , we develop a fully polynomial time approximation scheme for the multi unit allocation problem , which computes a ( [digit] ) approximation in worst case time t o ( n3 ) , given n bids each with a constant number of pieces . second , we embed this approximation scheme within a vickrey clarke groves ( vcg ) mechanism and compute payments to n agents for an asymptotic cost of o ( t log n ) . the maximal possible gain from manipulation to a bidder in the combined scheme is bounded by ( [digit] ) v , where v is the total surplus in the efficient outcome . categories and subject descriptors f . [digit] theory of computation analysis of algorithms and problem complexity j . [digit] computer applications social and behavioral sciences economics . general terms algorithms , economics .", "tokenized": "we present an approximately efficient and <unk> auction mechanism for a single good multi unit allocation problem . the bidding language in our auctions allows marginal decreasing piecewise constant curves . first , we develop a fully polynomial time approximation scheme for the multi unit allocation problem , which computes a ( [digit] ) approximation in worst case time t o ( n3 ) , given n bids each with a constant number of pieces . second , we embed this approximation scheme within a vickrey clarke groves ( vcg ) mechanism and compute payments to n agents for an asymptotic cost of o ( t log n ) . the maximal possible gain from manipulation to a bidder in the combined scheme is bounded by ( [digit] ) v , where v is the total surplus in the efficient outcome . categories and subject descriptors f . [digit] theory of computation analysis of algorithms and problem complexity j . [digit] computer applications social and behavioral sciences economics . general terms algorithms , economics ."}, "present_kps": {"text": ["strategyproof", "multi unit auction", "singl good multi unit alloc problem", "bid languag", "fulli polynomi time approxim scheme"], "tokenized": ["strategyproof", "multi unit auction", "singl good multi unit alloc problem", "bid languag", "fulli polynomi time approxim scheme"]}, "absent_kps": {"text": ["approxim effici and approximatelystrategyproof auction mechan", "vickrei clark grove", "forward auction", "revers auction", "equilibrium", "margin decreas piecewis constant curv", "dynam program", "approxim algorithm"], "tokenized": ["approxim effici and approximatelystrategyproof auction mechan", "vickrei clark grove", "forward auction", "revers auction", "equilibrium", "margin decreas piecewis constant curv", "dynam program", "approxim algorithm"]}}
{"id": 97, "title": {"text": "implementation with a bounded action space .", "tokenized": "implementation with a bounded action space ."}, "abstract": {"text": "while traditional mechanism design typically assumes isomorphism between the agents type and action spaces , in many situations the agents face strict restrictions on their action space due to , e . g . , technical , behavioral or regulatory reasons . we devise a general framework for the study of mechanism design in single parameter environments with restricted action spaces . our contribution is threefold . first , we characterize sufficient conditions under which the information theoretically optimal social choice rule can be implemented in dominant strategies , and prove that any multilinear social choice rule is dominant strategy implementable with no additional cost . second , we identify necessary conditions for the optimality of action bounded mechanisms , and fully characterize the optimal mechanisms and strategies in games with two players and two alternatives . finally , we prove that for any multilinear social choice rule , the optimal mechanism with k actions incurs an expected loss of o ( [digit] k2 ) compared to the optimal mechanisms with unrestricted action spaces . our results apply to various economic and computational settings , and we demonstrate their applicability to signaling games , public good models and routing in networks . categories and subject descriptors j . [digit] social and behavioral sciences economics k . [digit] . [digit] electronic commerce payment schemes general terms economics , design , theory", "tokenized": "while traditional mechanism design typically assumes isomorphism between the agents type and action spaces , in many situations the agents face strict restrictions on their action space due to , e . g . , technical , behavioral or regulatory reasons . we devise a general framework for the study of mechanism design in single parameter environments with restricted action spaces . our contribution is threefold . first , we characterize sufficient conditions under which the information theoretically optimal social choice rule can be implemented in dominant strategies , and prove that any multilinear social choice rule is dominant strategy implementable with no additional cost . second , we identify necessary conditions for the optimality of action bounded mechanisms , and fully characterize the optimal mechanisms and strategies in games with two players and two alternatives . finally , we prove that for any multilinear social choice rule , the optimal mechanism with k actions incurs an expected loss of o ( [digit] k2 ) compared to the optimal mechanisms with unrestricted action spaces . our results apply to various economic and computational settings , and we demonstrate their applicability to signaling games , public good models and routing in networks . categories and subject descriptors j . [digit] social and behavioral sciences economics k . [digit] . [digit] electronic commerce payment schemes general terms economics , design , theory"}, "present_kps": {"text": ["implement", "bound action space", "domin strategi", "action bound mechan", "optim mechan"], "tokenized": ["implement", "bound action space", "domin strategi", "action bound mechan", "optim mechan"]}, "absent_kps": {"text": ["social choic function", "decis function", "singl cross condit", "multilinear function", "probabl of success success probabl", "mechansm design", "singl cross condit", "commun complex"], "tokenized": ["social choic function", "decis function", "singl cross condit", "multilinear function", "probabl of success success probabl", "mechansm design", "singl cross condit", "commun complex"]}}
{"id": 98, "title": {"text": "computing the optimal strategy to commit to .", "tokenized": "computing the optimal strategy to commit to ."}, "abstract": {"text": "in multiagent systems , strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously . however , this model is not always realistic . in many settings , one player is able to commit to a strategy before the other player makes a decision . such models are synonymously referred to as leadership , commitment , or stackelberg models , and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously . the recent surge in interest in computing game theoretic solutions has so far ignored leadership models ( with the exception of the interest in mechanism design , where the designer is implicitly in a leadership position ) . in this paper , we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies , in both normal form and bayesian games . we give both positive results ( efficient algorithms ) and negative results ( np hardness results ) . categories and subject descriptors j . [digit] computer applications social and behavioral sciences economics i . [digit] . [digit] distributed artificial intelligence multiagent systems f . [digit] theory of computation analysis of algorithms and problem complexity general terms algorithms , economics , theory", "tokenized": "in multiagent systems , strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously . however , this model is not always realistic . in many settings , one player is able to commit to a strategy before the other player makes a decision . such models are synonymously referred to as leadership , commitment , or stackelberg models , and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously . the recent surge in interest in computing game theoretic solutions has so far ignored leadership models ( with the exception of the interest in mechanism design , where the designer is implicitly in a leadership position ) . in this paper , we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies , in both normal form and bayesian games . we give both positive results ( efficient algorithms ) and negative results ( np hardness results ) . categories and subject descriptors j . [digit] computer applications social and behavioral sciences economics i . [digit] . [digit] distributed artificial intelligence multiagent systems f . [digit] theory of computation analysis of algorithms and problem complexity general terms algorithms , economics , theory"}, "present_kps": {"text": ["optim strategi", "commit", "multiag system", "leadership", "stackelberg model", "stackelberg", "leadership model", "pure strategi", "mix strategi", "bayesian game", "np hard"], "tokenized": ["optim strategi", "commit", "multiag system", "leadership", "stackelberg model", "stackelberg", "leadership model", "pure strategi", "mix strategi", "bayesian game", "np hard"]}, "absent_kps": {"text": ["simultan manner", "normal form game", "nash equilibrium", "game theori"], "tokenized": ["simultan manner", "normal form game", "nash equilibrium", "game theori"]}}
{"id": 99, "title": {"text": "nash equilibria in graphical games on trees revisited .", "tokenized": "nash equilibria in graphical games on trees revisited ."}, "abstract": {"text": "graphical games have been proposed as a game theoretic model of large scale distributed networks of non cooperative agents . when the number of players is large , and the underlying graph has low degree , they provide a concise way to represent the players payoffs . it has recently been shown that the problem of finding nash equilibria in a general degree [digit] graphical game with two actions per player is complete for the complexity class ppad , indicating that it is unlikely that there is any polynomial time algorithm for this problem . in this paper , we study the complexity of graphical games with two actions per player on bounded degree trees . this setting was first considered by kearns , littman and singh , who proposed a dynamic programming based algorithm that computes all nash equilibria of such games . the running time of their algorithm is exponential , though approximate equilibria can be computed efficiently . later , littman , kearns and singh proposed a modification to this algorithm that can find a single nash equilibrium in polynomial time . we show that this modified algorithm is incorrect the output is not always a nash equilibrium . we then propose a new algorithm that is based on the ideas of kearns et al . and computes all nash equilibria in quadratic time if the input graph is a path , and in polynomial time if it is an arbitrary graph of maximum degree [digit] . moreover , our algorithm can be used to compute nash equilibria of graphical games on arbitrary trees , but the running time can be exponential , even when the tree has bounded degree . we show that this is inevitable any algorithm of this type will take exponential time , even on bounded degree trees with pathwidth [digit] . it is an open question whether our algorithm runs in polynomial time on graphs with pathwidth [digit] , but we show that finding a nash equilibrium for a [digit] action graphical game in which the underlying graph has maximum degree [digit] and constant pathwidth is ppad complete ( so is unlikely to be tractable ) . categories and subject descriptors f . [digit] theory of computation analysis of algorithms and problem complexity j . [digit] computer applications social and behavioral sciences economics general terms algorithms , economics , theory", "tokenized": "graphical games have been proposed as a game theoretic model of large scale distributed networks of non cooperative agents . when the number of players is large , and the underlying graph has low degree , they provide a concise way to represent the players payoffs . it has recently been shown that the problem of finding nash equilibria in a general degree [digit] graphical game with two actions per player is complete for the complexity class ppad , indicating that it is unlikely that there is any polynomial time algorithm for this problem . in this paper , we study the complexity of graphical games with two actions per player on bounded degree trees . this setting was first considered by kearns , littman and singh , who proposed a dynamic programming based algorithm that computes all nash equilibria of such games . the running time of their algorithm is exponential , though approximate equilibria can be computed efficiently . later , littman , kearns and singh proposed a modification to this algorithm that can find a single nash equilibrium in polynomial time . we show that this modified algorithm is incorrect the output is not always a nash equilibrium . we then propose a new algorithm that is based on the ideas of kearns et al . and computes all nash equilibria in quadratic time if the input graph is a path , and in polynomial time if it is an arbitrary graph of maximum degree [digit] . moreover , our algorithm can be used to compute nash equilibria of graphical games on arbitrary trees , but the running time can be exponential , even when the tree has bounded degree . we show that this is inevitable any algorithm of this type will take exponential time , even on bounded degree trees with pathwidth [digit] . it is an open question whether our algorithm runs in polynomial time on graphs with pathwidth [digit] , but we show that finding a nash equilibrium for a [digit] action graphical game in which the underlying graph has maximum degree [digit] and constant pathwidth is ppad complete ( so is unlikely to be tractable ) . categories and subject descriptors f . [digit] theory of computation analysis of algorithms and problem complexity j . [digit] computer applications social and behavioral sciences economics general terms algorithms , economics , theory"}, "present_kps": {"text": ["graphic game", "larg scale distribut network", "dynam program base algorithm", "nash equilibrium", "ppad complet"], "tokenized": ["graphic game", "larg scale distribut network", "dynam program base algorithm", "nash equilibrium", "ppad complet"]}, "absent_kps": {"text": ["degre", "bound degre tree", "gener algorithm", "respons polici", "downstream pass", "breakpoint polici"], "tokenized": ["degre", "bound degre tree", "gener algorithm", "respons polici", "downstream pass", "breakpoint polici"]}}